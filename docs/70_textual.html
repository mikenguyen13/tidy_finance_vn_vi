<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>44&nbsp; Textual Analysis ‚Äì T√†i Ch√≠nh ·ª®ng D·ª•ng v·ªõi Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./71_image.html" rel="next">
<link href="./63_structural_models_finance.html" rel="prev">
<link href="./favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ed993afc62d41eaa40b4794cd0abf8eb.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-72097b8a1e3a3da1d7b8bbfaaf81c3d8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-ed993afc62d41eaa40b4794cd0abf8eb.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="44&nbsp; Textual Analysis ‚Äì T√†i Ch√≠nh ·ª®ng D·ª•ng v·ªõi Python">
<meta property="og:description" content="">
<meta property="og:site_name" content="T√†i Ch√≠nh ·ª®ng D·ª•ng v·ªõi Python">
<meta name="twitter:title" content="44&nbsp; Textual Analysis ‚Äì T√†i Ch√≠nh ·ª®ng D·ª•ng v·ªõi Python">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">T√†i Ch√≠nh ·ª®ng D·ª•ng v·ªõi Python</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mikenguyen13.github.io/tidy_finance_vn/"> 
<span class="menu-text">üìò English Book</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mikenguyen13.github.io/tidy_finance_vn_vi/"> 
<span class="menu-text">üìó S√°ch Ti·∫øng Vi·ªát</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/mikenguyen13/tidy_finance_vn_vi" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./70_textual.html">D·ªØ li·ªáu thay th·∫ø v√† Tr√≠ tu·ªá nh√¢n t·∫°o trong t√†i ch√≠nh</a></li><li class="breadcrumb-item"><a href="./70_textual.html"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Textual Analysis</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L·ªùi n√≥i ƒë·∫ßu</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Th·ªã tr∆∞·ªùng t√†i ch√≠nh, th·ªÉ ch·∫ø v√† d·ªØ li·ªáu Vi·ªát Nam</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_institutional_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">N·ªÅn t·∫£ng th·ªÉ ch·∫ø v√† c·∫•u tr√∫c th·ªã tr∆∞·ªùng c·ªßa th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_accessing_and_managing_financial_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Truy c·∫≠p v√† qu·∫£n l√Ω d·ªØ li·ªáu t√†i ch√≠nh VN</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_datacore_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Datacore Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_market_microstructure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Market Microstructure in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_risk_free_rate_construction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Risk-Free Rate Construction in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_working_with_stock_returns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Constructing and Analyzing Equity Return Series</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_compound_return.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Compound Returns</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">X√¢y d·ª±ng danh m·ª•c ƒë·∫ßu t∆∞, r·ªßi ro v√† c∆° h·ªçc th·ª±c nghi·ªám</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_modern_portfolio_theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modern Portfolio Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_univariate_portfolio_sort.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Univariate Portfolio Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_size_sorts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Size Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_value_bivariate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Value and Bivariate Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_portfolio_weighting_and_rebalancing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Portfolio Weighting and Rebalancing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_missing_data_and_survivorship.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Missing Data and Survivorship Bias</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_liquidity_and_turnover_measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Liquidity and Turnover Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_beta_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Beta Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">M√¥ h√¨nh ƒë·ªãnh gi√° t√†i s·∫£n</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_capm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">The Capital Asset Pricing Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_fama_french.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Fama-French Factors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_momentum.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Momentum Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_factor_construction_principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Factor Construction Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24_fama_macbeth.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Fama-MacBeth Regressions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25_factor_zoo_and_multiple_testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Factor Zoo and Multiple Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26_time_series_vs_cross_section.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Time-Series vs.&nbsp;Cross-Sectional Factor Tests</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">C√°c y·∫øu t·ªë c∆° b·∫£n c·ªßa c√¥ng ty, ƒë·ªãnh gi√° v√† t√≠n hi·ªáu doanh nghi·ªáp</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_financial_statement_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Financial Statement Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31_discounted_cash_flow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Discounted Cash Flow Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32_info_earnings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Information Content of Earnings Announcements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33_accruals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Accruals, Earnings Persistence, and Market Efficiency</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./34_earning_management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Earnings Management: Detection and Measurement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./35_pe_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">P/E Ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./36_valuation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Firm Valuation, Financial Distress, and Company Maturity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./37_disclosure_quality_and_timing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Disclosure Quality and Timing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./38_sue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Standardized Earnings Surprises (SUE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./39_divop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Measuring Divergence of Investor Opinion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Quy·ªÅn s·ªü h·ªØu, ma s√°t th·ªã tr∆∞·ªùng v√† r·ªßi ro qu·ªëc t·∫ø</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./50_institutional_ownership.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Institutional Ownership Analytics in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./52_institutional_trade_flow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Institutional Trades, Flows, and Turnover Ratios</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./53_governance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Corporate Governance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./54_return_gaps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Return Gap: Measuring Unobserved Actions of Fund Managers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./55_price_limits_and_volatility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Price Limits and Volatility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./56_market_integration_and_segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Market Integration and Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./57_exchange_rate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Exchange Rate Dynamics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">M√¥ h√¨nh t√†i ch√≠nh n√¢ng cao</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./60_event_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Event Studies in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./61_tail_risk_extreme_events.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Tail Risk and Extreme Events</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./62_corporate_finance_estimators.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Corporate Finance Estimators and Identification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./63_structural_models_finance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Structural Models in Finance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">D·ªØ li·ªáu thay th·∫ø v√† Tr√≠ tu·ªá nh√¢n t·∫°o trong t√†i ch√≠nh</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./70_textual.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Textual Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./71_image.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Image and Visual Data in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./73_networks_graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Networks and Graphs in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./74_multimodel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Multimodal Models in Finance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-textual-why-vietnam" id="toc-sec-textual-why-vietnam" class="nav-link active" data-scroll-target="#sec-textual-why-vietnam"><span class="header-section-number">44.1</span> Why Textual Analysis for Vietnamese Finance?</a></li>
  <li><a href="#sec-textual-literature" id="toc-sec-textual-literature" class="nav-link" data-scroll-target="#sec-textual-literature"><span class="header-section-number">45</span> Literature Review</a>
  <ul class="collapse">
  <li><a href="#sec-textual-lit-finance" id="toc-sec-textual-lit-finance" class="nav-link" data-scroll-target="#sec-textual-lit-finance"><span class="header-section-number">45.1</span> Textual Analysis in Finance</a></li>
  <li><a href="#sec-textual-lit-vnlp" id="toc-sec-textual-lit-vnlp" class="nav-link" data-scroll-target="#sec-textual-lit-vnlp"><span class="header-section-number">45.2</span> NLP for Vietnamese Language</a></li>
  </ul></li>
  <li><a href="#sec-textual-data" id="toc-sec-textual-data" class="nav-link" data-scroll-target="#sec-textual-data"><span class="header-section-number">46</span> Data: Vietnamese Listed Firms from DataCore.vn</a>
  <ul class="collapse">
  <li><a href="#sec-textual-universe" id="toc-sec-textual-universe" class="nav-link" data-scroll-target="#sec-textual-universe"><span class="header-section-number">46.1</span> Constructing the Universe</a></li>
  <li><a href="#sec-textual-bus-desc" id="toc-sec-textual-bus-desc" class="nav-link" data-scroll-target="#sec-textual-bus-desc"><span class="header-section-number">46.2</span> Retrieving Business Descriptions</a></li>
  <li><a href="#sec-textual-annual-text" id="toc-sec-textual-annual-text" class="nav-link" data-scroll-target="#sec-textual-annual-text"><span class="header-section-number">46.3</span> Retrieving Annual Report Text</a></li>
  </ul></li>
  <li><a href="#sec-textual-preprocessing" id="toc-sec-textual-preprocessing" class="nav-link" data-scroll-target="#sec-textual-preprocessing"><span class="header-section-number">47</span> Text Preprocessing for Vietnamese</a>
  <ul class="collapse">
  <li><a href="#sec-textual-segmentation" id="toc-sec-textual-segmentation" class="nav-link" data-scroll-target="#sec-textual-segmentation"><span class="header-section-number">47.1</span> Vietnamese Word Segmentation</a></li>
  <li><a href="#sec-textual-cleaning" id="toc-sec-textual-cleaning" class="nav-link" data-scroll-target="#sec-textual-cleaning"><span class="header-section-number">47.2</span> Full Text Cleaning Pipeline</a></li>
  <li><a href="#sec-textual-english-cleaning" id="toc-sec-textual-english-cleaning" class="nav-link" data-scroll-target="#sec-textual-english-cleaning"><span class="header-section-number">47.3</span> English Text Cleaning</a></li>
  </ul></li>
  <li><a href="#sec-textual-bow-tfidf" id="toc-sec-textual-bow-tfidf" class="nav-link" data-scroll-target="#sec-textual-bow-tfidf"><span class="header-section-number">48</span> Document Representation: Bag-of-Words and TF-IDF</a>
  <ul class="collapse">
  <li><a href="#sec-textual-bow" id="toc-sec-textual-bow" class="nav-link" data-scroll-target="#sec-textual-bow"><span class="header-section-number">48.1</span> Bag-of-Words Representation</a></li>
  <li><a href="#sec-textual-tfidf" id="toc-sec-textual-tfidf" class="nav-link" data-scroll-target="#sec-textual-tfidf"><span class="header-section-number">48.2</span> TF-IDF Weighting</a></li>
  </ul></li>
  <li><a href="#sec-textual-topic-modeling" id="toc-sec-textual-topic-modeling" class="nav-link" data-scroll-target="#sec-textual-topic-modeling"><span class="header-section-number">49</span> Topic Modeling</a>
  <ul class="collapse">
  <li><a href="#sec-textual-lda" id="toc-sec-textual-lda" class="nav-link" data-scroll-target="#sec-textual-lda"><span class="header-section-number">49.1</span> Latent Dirichlet Allocation (LDA)</a></li>
  <li><a href="#sec-textual-bertopic" id="toc-sec-textual-bertopic" class="nav-link" data-scroll-target="#sec-textual-bertopic"><span class="header-section-number">49.2</span> BERTopic: Neural Topic Modeling</a></li>
  </ul></li>
  <li><a href="#sec-textual-sentiment" id="toc-sec-textual-sentiment" class="nav-link" data-scroll-target="#sec-textual-sentiment"><span class="header-section-number">50</span> Financial Sentiment Analysis</a>
  <ul class="collapse">
  <li><a href="#sec-textual-dict-sentiment" id="toc-sec-textual-dict-sentiment" class="nav-link" data-scroll-target="#sec-textual-dict-sentiment"><span class="header-section-number">50.1</span> Dictionary-Based Approach</a></li>
  <li><a href="#sec-textual-bert-sentiment" id="toc-sec-textual-bert-sentiment" class="nav-link" data-scroll-target="#sec-textual-bert-sentiment"><span class="header-section-number">50.2</span> Transformer-Based Sentiment Classification</a></li>
  </ul></li>
  <li><a href="#sec-textual-similarity" id="toc-sec-textual-similarity" class="nav-link" data-scroll-target="#sec-textual-similarity"><span class="header-section-number">51</span> Text-Based Firm Similarity and Peer Identification</a>
  <ul class="collapse">
  <li><a href="#sec-textual-tfidf-similarity" id="toc-sec-textual-tfidf-similarity" class="nav-link" data-scroll-target="#sec-textual-tfidf-similarity"><span class="header-section-number">51.1</span> Cosine Similarity on TF-IDF Vectors</a></li>
  <li><a href="#sec-textual-embedding-similarity" id="toc-sec-textual-embedding-similarity" class="nav-link" data-scroll-target="#sec-textual-embedding-similarity"><span class="header-section-number">51.2</span> Embedding-Based Similarity</a></li>
  <li><a href="#sec-textual-doc2vec" id="toc-sec-textual-doc2vec" class="nav-link" data-scroll-target="#sec-textual-doc2vec"><span class="header-section-number">51.3</span> Doc2Vec</a></li>
  </ul></li>
  <li><a href="#sec-textual-deep-learning" id="toc-sec-textual-deep-learning" class="nav-link" data-scroll-target="#sec-textual-deep-learning"><span class="header-section-number">52</span> Deep Learning Approaches</a>
  <ul class="collapse">
  <li><a href="#sec-textual-phobert" id="toc-sec-textual-phobert" class="nav-link" data-scroll-target="#sec-textual-phobert"><span class="header-section-number">52.1</span> PhoBERT Embeddings for Financial Text</a></li>
  <li><a href="#sec-textual-llm" id="toc-sec-textual-llm" class="nav-link" data-scroll-target="#sec-textual-llm"><span class="header-section-number">52.2</span> Large Language Model Applications</a>
  <ul class="collapse">
  <li><a href="#sec-textual-zero-shot" id="toc-sec-textual-zero-shot" class="nav-link" data-scroll-target="#sec-textual-zero-shot"><span class="header-section-number">52.2.1</span> Zero-Shot Financial Classification</a></li>
  <li><a href="#sec-textual-extraction" id="toc-sec-textual-extraction" class="nav-link" data-scroll-target="#sec-textual-extraction"><span class="header-section-number">52.2.2</span> Structured Information Extraction</a></li>
  <li><a href="#sec-textual-esg" id="toc-sec-textual-esg" class="nav-link" data-scroll-target="#sec-textual-esg"><span class="header-section-number">52.2.3</span> Automated ESG Scoring</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-textual-empirical" id="toc-sec-textual-empirical" class="nav-link" data-scroll-target="#sec-textual-empirical"><span class="header-section-number">53</span> Empirical Applications</a>
  <ul class="collapse">
  <li><a href="#sec-textual-sentiment-returns" id="toc-sec-textual-sentiment-returns" class="nav-link" data-scroll-target="#sec-textual-sentiment-returns"><span class="header-section-number">53.1</span> Textual Sentiment and Stock Returns</a></li>
  <li><a href="#sec-textual-tnic" id="toc-sec-textual-tnic" class="nav-link" data-scroll-target="#sec-textual-tnic"><span class="header-section-number">53.2</span> Text-Based Industry Classification</a></li>
  <li><a href="#sec-textual-event-study" id="toc-sec-textual-event-study" class="nav-link" data-scroll-target="#sec-textual-event-study"><span class="header-section-number">53.3</span> Measuring Textual Similarity Changes Around Corporate Events</a></li>
  </ul></li>
  <li><a href="#sec-textual-comparison" id="toc-sec-textual-comparison" class="nav-link" data-scroll-target="#sec-textual-comparison"><span class="header-section-number">54</span> Method Comparison and Best Practices</a></li>
  <li><a href="#sec-textual-conclusion" id="toc-sec-textual-conclusion" class="nav-link" data-scroll-target="#sec-textual-conclusion"><span class="header-section-number">55</span> Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/mikenguyen13/tidy_finance_vn_vi/edit/main/70_textual.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mikenguyen13/tidy_finance_vn_vi/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./70_textual.html">D·ªØ li·ªáu thay th·∫ø v√† Tr√≠ tu·ªá nh√¢n t·∫°o trong t√†i ch√≠nh</a></li><li class="breadcrumb-item"><a href="./70_textual.html"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Textual Analysis</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Textual Analysis</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Textual analysis has emerged as one of the most productive research frontiers in empirical finance over the past two decades. The insight that unstructured text, such as corporate filings, earnings calls, analyst reports, and news articles, contains economically meaningful information beyond what is captured in structured numerical data has reshaped how researchers and practitioners understand financial markets. This chapter introduces the full pipeline of textual analysis methods as applied to Vietnamese listed firms, progressing from classical bag-of-words approaches through modern transformer-based language models.</p>
<p>The Vietnamese equity market presents unique opportunities and challenges for textual analysis. As of 2024, the Ho Chi Minh Stock Exchange (HOSE) and the Hanoi Stock Exchange (HNX) together list over 1,600 securities with a combined market capitalization exceeding VND 6,000 trillion (approximately USD 240 billion). Corporate disclosures are filed in Vietnamese, a tonal language with compound-word morphology that demands specialized natural language processing (NLP) tools.</p>
<p>We build on the seminal contributions of <span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span> in domain-specific sentiment lexicons, <span class="citation" data-cites="hoberg2016text">Hoberg and Phillips (<a href="references.html#ref-hoberg2016text" role="doc-biblioref">2016</a>)</span> in text-based industry classification, and the modern deep learning revolution initiated by <span class="citation" data-cites="devlin2019bert">Devlin et al. (<a href="references.html#ref-devlin2019bert" role="doc-biblioref">2019</a>)</span>. This chapter covers the following topics:</p>
<ol type="1">
<li>Constructing the universe of HOSE/HNX listed firms and retrieving their business descriptions and annual report text.</li>
<li>Vietnamese-specific text preprocessing, including word segmentation using VnCoreNLP and underthesea.</li>
<li>Classical document representation via bag-of-words, TF-IDF, and LDA topic models.</li>
<li>Financial sentiment analysis using both dictionary-based and machine learning approaches adapted for Vietnamese.</li>
<li>Text-based firm similarity and peer identification using cosine similarity.</li>
<li>Modern deep learning approaches including Word2Vec, Doc2Vec, PhoBERT embeddings, and sentence transformers.</li>
<li>Large language model (LLM) applications, including zero-shot classification, named entity recognition, and information extraction using Vietnamese-capable models.</li>
<li>Empirical applications linking textual measures to stock returns, volatility, and corporate events.</li>
</ol>
<section id="sec-textual-why-vietnam" class="level2" data-number="44.1">
<h2 data-number="44.1" class="anchored" data-anchor-id="sec-textual-why-vietnam"><span class="header-section-number">44.1</span> Why Textual Analysis for Vietnamese Finance?</h2>
<p>The Vietnamese financial market has several characteristics that make textual analysis particularly valuable. First, analyst coverage is sparse (fewer than 30% of listed firms receive regular coverage from sell-side analysts), making alternative information sources critical. Second, the regulatory environment is evolving rapidly, with the State Securities Commission (SSC) continuously updating disclosure requirements, creating rich variation in information environments across firms and time. Third, the market is dominated by retail investors (accounting for roughly 80% of trading volume), who may process textual information differently than institutional investors, creating potential mispricings that text-based strategies could exploit.</p>
<p>From a methodological standpoint, Vietnamese poses interesting NLP challenges. Unlike English, Vietnamese is an isolating language where word boundaries are not always delimited by spaces. A single Vietnamese ‚Äúword‚Äù may consist of multiple syllables separated by spaces (e.g., ‚Äúc√¥ng ty‚Äù for ‚Äúcompany,‚Äù ‚Äúth·ªã tr∆∞·ªùng‚Äù for ‚Äúmarket‚Äù). This requires a word segmentation step before standard NLP pipelines can be applied.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</section>
<section id="sec-textual-literature" class="level1" data-number="45">
<h1 data-number="45"><span class="header-section-number">45</span> Literature Review</h1>
<section id="sec-textual-lit-finance" class="level2" data-number="45.1">
<h2 data-number="45.1" class="anchored" data-anchor-id="sec-textual-lit-finance"><span class="header-section-number">45.1</span> Textual Analysis in Finance</h2>
<p>The application of textual analysis to financial data has a rich history. <span class="citation" data-cites="tetlock2007giving">Tetlock (<a href="references.html#ref-tetlock2007giving" role="doc-biblioref">2007</a>)</span> demonstrated that the pessimism content of a Wall Street Journal column predicts aggregate market activity, providing early evidence that textual content moves prices. <span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span> showed that the widely-used Harvard General Inquirer sentiment dictionary produces misleading results when applied to financial text because words like ‚Äúliability,‚Äù ‚Äútax,‚Äù and ‚Äúcapital‚Äù are classified as negative in general English but carry neutral or even positive connotations in finance. Their domain-specific word lists have become the standard for financial sentiment analysis.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p><span class="citation" data-cites="hoberg2010product">Hoberg and Phillips (<a href="references.html#ref-hoberg2010product" role="doc-biblioref">2010</a>)</span> and <span class="citation" data-cites="hoberg2016text">Hoberg and Phillips (<a href="references.html#ref-hoberg2016text" role="doc-biblioref">2016</a>)</span> pioneered the use of product descriptions from 10-K filings to construct text-based industry classifications (TNIC), demonstrating that these dynamic, firm-specific industry definitions outperform static SIC and NAICS codes in explaining firm behavior, including profitability, stock returns, and M&amp;A activity. Subsequent work by <span class="citation" data-cites="hoberg2018text">Hoberg and Phillips (<a href="references.html#ref-hoberg2018text" role="doc-biblioref">2018</a>)</span> extended this to assess competitive threats and product-market fluidity.</p>
<p>More recent work has leveraged advances in deep learning. <span class="citation" data-cites="huang2023finbert">Huang, Wang, and Yang (<a href="references.html#ref-huang2023finbert" role="doc-biblioref">2023</a>)</span> apply BERT-based models to earnings call transcripts and show that contextual embeddings capture information about future earnings that traditional bag-of-words measures miss. <span class="citation" data-cites="jha2024chatgpt">Jha et al. (<a href="references.html#ref-jha2024chatgpt" role="doc-biblioref">2024</a>)</span> use GPT-based models for zero-shot financial text classification and demonstrate that LLMs can match or exceed purpose-built classifiers on standard benchmarks.</p>
</section>
<section id="sec-textual-lit-vnlp" class="level2" data-number="45.2">
<h2 data-number="45.2" class="anchored" data-anchor-id="sec-textual-lit-vnlp"><span class="header-section-number">45.2</span> NLP for Vietnamese Language</h2>
<p>Vietnamese NLP has advanced significantly with the development of VnCoreNLP <span class="citation" data-cites="vu2018vncorenlp">(<a href="references.html#ref-vu2018vncorenlp" role="doc-biblioref">Vu et al. 2018</a>)</span>, a Java-based toolkit providing word segmentation, POS tagging, named entity recognition, and dependency parsing. The underthesea library offers a Python-native alternative. Most critically for financial applications, PhoBERT <span class="citation" data-cites="nguyen2020phobert">(<a href="references.html#ref-nguyen2020phobert" role="doc-biblioref">Nguyen and Nguyen 2020</a>)</span> provides Vietnamese-specific BERT pre-training on a 20GB corpus, achieving state-of-the-art results on multiple Vietnamese NLP tasks.</p>
<div id="tbl-literature" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-literature-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;45.1: Key Literature on Textual Analysis in Finance
</figcaption>
<div aria-describedby="tbl-literature-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Study</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Key Finding</th>
<th style="text-align: left;">Relevance to Vietnam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="tetlock2007giving">Tetlock (<a href="references.html#ref-tetlock2007giving" role="doc-biblioref">2007</a>)</span></td>
<td style="text-align: left;">Dictionary-based sentiment from WSJ column</td>
<td style="text-align: left;">Media pessimism predicts market activity and returns</td>
<td style="text-align: left;">Baseline for Vietnamese financial news sentiment</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span></td>
<td style="text-align: left;">Domain-specific financial dictionaries</td>
<td style="text-align: left;">General dictionaries misclassify 73% of negative financial words</td>
<td style="text-align: left;">Need for Vietnamese financial sentiment lexicon</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="hoberg2016text">Hoberg and Phillips (<a href="references.html#ref-hoberg2016text" role="doc-biblioref">2016</a>)</span></td>
<td style="text-align: left;">Cosine similarity on 10-K product descriptions</td>
<td style="text-align: left;">Text-based industries outperform SIC/NAICS</td>
<td style="text-align: left;">Peer identification for Vietnamese firms using business descriptions</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="citation" data-cites="nguyen2020phobert">Nguyen and Nguyen (<a href="references.html#ref-nguyen2020phobert" role="doc-biblioref">2020</a>)</span></td>
<td style="text-align: left;">PhoBERT: Vietnamese BERT pre-training</td>
<td style="text-align: left;">SOTA on Vietnamese NLP benchmarks</td>
<td style="text-align: left;">Foundation model for Vietnamese financial NLP</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="huang2023finbert">Huang, Wang, and Yang (<a href="references.html#ref-huang2023finbert" role="doc-biblioref">2023</a>)</span></td>
<td style="text-align: left;">BERT embeddings on earnings calls</td>
<td style="text-align: left;">Contextual embeddings predict future earnings beyond BoW</td>
<td style="text-align: left;">Apply to Vietnamese earnings call transcripts</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="citation" data-cites="jha2024chatgpt">Jha et al. (<a href="references.html#ref-jha2024chatgpt" role="doc-biblioref">2024</a>)</span></td>
<td style="text-align: left;">GPT-based zero-shot financial classification</td>
<td style="text-align: left;">LLMs match fine-tuned classifiers</td>
<td style="text-align: left;">Zero-shot Vietnamese financial text classification via multilingual LLMs</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-textual-data" class="level1" data-number="46">
<h1 data-number="46"><span class="header-section-number">46</span> Data: Vietnamese Listed Firms from DataCore.vn</h1>
<section id="sec-textual-universe" class="level2" data-number="46.1">
<h2 data-number="46.1" class="anchored" data-anchor-id="sec-textual-universe"><span class="header-section-number">46.1</span> Constructing the Universe</h2>
<p>We construct the universe of Vietnamese listed firms. The universe includes all firms listed on HOSE, HNX, and UPCoM as of the analysis date.</p>
<div id="setup" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> unicodedata</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Tuple, Optional</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting configuration</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.size'</span>] <span class="op">=</span> <span class="dv">11</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="build-universe" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datacore <span class="im">import</span> DataCoreAPI  <span class="co"># DataCore.vn Python client</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize connection</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>dc <span class="op">=</span> DataCoreAPI(api_key<span class="op">=</span><span class="st">'YOUR_API_KEY'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve universe of all listed firms</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>universe <span class="op">=</span> dc.get_listed_firms(</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    exchanges<span class="op">=</span>[<span class="st">'HOSE'</span>, <span class="st">'HNX'</span>, <span class="st">'UPCOM'</span>],</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    as_of<span class="op">=</span><span class="st">'2024-12-31'</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    fields<span class="op">=</span>[</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ticker'</span>, <span class="st">'company_name'</span>, <span class="st">'company_name_en'</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'exchange'</span>, <span class="st">'listing_date'</span>, <span class="st">'delisting_date'</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'icb_industry'</span>, <span class="st">'icb_sector'</span>, <span class="st">'icb_subsector'</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'market_cap'</span>, <span class="st">'total_assets'</span>, <span class="st">'revenue'</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total listed firms: </span><span class="sc">{</span><span class="bu">len</span>(universe)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'HOSE: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"HOSE"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'HNX: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"HNX"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'UPCoM: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"UPCOM"</span>])<span class="sc">}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-universe" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-universe-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;46.1: Universe of Vietnamese Listed Firms by Exchange (as of December 2024)
</figcaption>
<div aria-describedby="tbl-universe-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Exchange</th>
<th style="text-align: right;">N Firms</th>
<th style="text-align: right;">Avg Mkt Cap (VND bn)</th>
<th style="text-align: right;">Median Mkt Cap (VND bn)</th>
<th style="text-align: right;">Total Mkt Cap (VND tn)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">HOSE</td>
<td style="text-align: right;">403</td>
<td style="text-align: right;">12,847</td>
<td style="text-align: right;">3,215</td>
<td style="text-align: right;">5,177</td>
</tr>
<tr class="even">
<td style="text-align: left;">HNX</td>
<td style="text-align: right;">334</td>
<td style="text-align: right;">2,156</td>
<td style="text-align: right;">687</td>
<td style="text-align: right;">720</td>
</tr>
<tr class="odd">
<td style="text-align: left;">UPCoM</td>
<td style="text-align: right;">868</td>
<td style="text-align: right;">1,043</td>
<td style="text-align: right;">298</td>
<td style="text-align: right;">905</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Total</strong></td>
<td style="text-align: right;"><strong>1,605</strong></td>
<td style="text-align: right;"><strong>4,239</strong></td>
<td style="text-align: right;"><strong>712</strong></td>
<td style="text-align: right;"><strong>6,802</strong></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-textual-bus-desc" class="level2" data-number="46.2">
<h2 data-number="46.2" class="anchored" data-anchor-id="sec-textual-bus-desc"><span class="header-section-number">46.2</span> Retrieving Business Descriptions</h2>
<p>Business descriptions for all listed firms can be in both Vietnamese and English. We retrieve both versions for our analysis. The Vietnamese text will serve as the primary corpus, while English descriptions provide a useful cross-validation.</p>
<div id="get-bus-desc" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get business descriptions (Vietnamese and English)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>bus_desc <span class="op">=</span> dc.get_business_descriptions(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    fields<span class="op">=</span>[</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ticker'</span>, <span class="st">'bus_desc_vi'</span>, <span class="st">'bus_desc_en'</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'main_business'</span>, <span class="st">'products_services'</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year_established'</span>, <span class="st">'num_employees'</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge with universe</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>corpus_df <span class="op">=</span> universe.merge(bus_desc, on<span class="op">=</span><span class="st">'ticker'</span>, how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary statistics on text length</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'desc_len_vi'</span>] <span class="op">=</span> corpus_df.bus_desc_vi.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'desc_len_en'</span>] <span class="op">=</span> corpus_df.bus_desc_en.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'word_count_vi'</span>] <span class="op">=</span> corpus_df.bus_desc_vi.<span class="bu">str</span>.split().<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus_df[[<span class="st">'desc_len_vi'</span>, <span class="st">'desc_len_en'</span>, <span class="st">'word_count_vi'</span>]]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>      .describe().<span class="bu">round</span>(<span class="dv">0</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-desc-stats" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-desc-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;46.2: Descriptive Statistics of Business Description Text
</figcaption>
<div aria-describedby="tbl-desc-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Statistic</th>
<th style="text-align: right;">Mean</th>
<th style="text-align: right;">Median</th>
<th style="text-align: right;">Std Dev</th>
<th style="text-align: right;">Min</th>
<th style="text-align: right;">Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Characters (VN)</td>
<td style="text-align: right;">2,847</td>
<td style="text-align: right;">2,156</td>
<td style="text-align: right;">1,923</td>
<td style="text-align: right;">87</td>
<td style="text-align: right;">18,432</td>
</tr>
<tr class="even">
<td style="text-align: left;">Characters (EN)</td>
<td style="text-align: right;">3,412</td>
<td style="text-align: right;">2,689</td>
<td style="text-align: right;">2,245</td>
<td style="text-align: right;">102</td>
<td style="text-align: right;">22,156</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Words (VN)</td>
<td style="text-align: right;">487</td>
<td style="text-align: right;">372</td>
<td style="text-align: right;">318</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">3,216</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-textual-annual-text" class="level2" data-number="46.3">
<h2 data-number="46.3" class="anchored" data-anchor-id="sec-textual-annual-text"><span class="header-section-number">46.3</span> Retrieving Annual Report Text</h2>
<p>Beyond business descriptions, annual or quarterly reports provide richer and more time-varying textual data. We extract the Management Discussion and Analysis (MD&amp;A) sections, which are most informative for financial analysis <span class="citation" data-cites="li2010textual bonsall2017plain">(<a href="references.html#ref-li2010textual" role="doc-biblioref">Li et al. 2010</a>; <a href="references.html#ref-bonsall2017plain" role="doc-biblioref">Bonsall IV et al. 2017</a>)</span>. The MD&amp;A section, known in Vietnamese annual reports as ‚ÄúB√°o c√°o c·ªßa Ban Gi√°m ƒë·ªëc‚Äù or ‚ÄúB√°o c√°o c·ªßa H·ªôi ƒë·ªìng qu·∫£n tr·ªã,‚Äù discusses business performance, outlook, and risk factors.</p>
<div id="get-annual-text" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get annual report MD&amp;A sections (2015-2024)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> dc.get_annual_report_text(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    years<span class="op">=</span><span class="bu">range</span>(<span class="dv">2015</span>, <span class="dv">2025</span>),</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    sections<span class="op">=</span>[<span class="st">'mda'</span>, <span class="st">'risk_factors'</span>, <span class="st">'business_overview'</span>],</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    language<span class="op">=</span><span class="st">'vi'</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel structure: ticker x year x section</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total firm-year-section observations: </span><span class="sc">{</span><span class="bu">len</span>(annual_text)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Unique firms: </span><span class="sc">{</span>annual_text<span class="sc">.</span>ticker<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Year range: </span><span class="sc">{</span>annual_text<span class="sc">.</span>year<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>annual_text<span class="sc">.</span>year<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate text changes year-over-year</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> annual_text.sort_values([<span class="st">'ticker'</span>, <span class="st">'year'</span>])</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>annual_text[<span class="st">'text_len'</span>] <span class="op">=</span> annual_text.text.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>annual_text[<span class="st">'text_change_pct'</span>] <span class="op">=</span> (</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    annual_text.groupby(<span class="st">'ticker'</span>)[<span class="st">'text_len'</span>]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    .pct_change() <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="sec-textual-preprocessing" class="level1" data-number="47">
<h1 data-number="47"><span class="header-section-number">47</span> Text Preprocessing for Vietnamese</h1>
<section id="sec-textual-segmentation" class="level2" data-number="47.1">
<h2 data-number="47.1" class="anchored" data-anchor-id="sec-textual-segmentation"><span class="header-section-number">47.1</span> Vietnamese Word Segmentation</h2>
<p>The most critical preprocessing step for Vietnamese text is word segmentation (ph√¢n ƒëo·∫°n t·ª´). Unlike English where spaces reliably separate words, Vietnamese uses spaces between syllables, not between words. For example, the phrase ‚Äúc√¥ng ty c·ªï ph·∫ßn b·∫•t ƒë·ªông s·∫£n‚Äù (real estate joint stock company) contains five syllables separated by spaces but consists of only two compound words: ‚Äúc√¥ng_ty c·ªï_ph·∫ßn‚Äù (joint stock company) and ‚Äúb·∫•t_ƒë·ªông_s·∫£n‚Äù (real estate). Failing to perform word segmentation leads to severe vocabulary fragmentation and loss of semantic meaning.</p>
<div id="tbl-segmentation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-segmentation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.1: Vietnamese Word Segmentation Example
</figcaption>
<div aria-describedby="tbl-segmentation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 26%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Stage</th>
<th style="text-align: left;">Text</th>
<th style="text-align: left;">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Raw</td>
<td style="text-align: left;"><code>c√¥ng ty c·ªï ph·∫ßn th∆∞∆°ng m·∫°i d·ªãch v·ª•</code></td>
<td style="text-align: left;">7 syllables, ambiguous boundaries</td>
</tr>
<tr class="even">
<td style="text-align: left;">Segmented</td>
<td style="text-align: left;"><code>c√¥ng_ty c·ªï_ph·∫ßn th∆∞∆°ng_m·∫°i d·ªãch_v·ª•</code></td>
<td style="text-align: left;">4 words: company | joint-stock | commerce | services</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="word-segmentation" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> underthesea <span class="im">import</span> word_tokenize</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> segment_vietnamese(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Segment Vietnamese text into words using underthesea."""</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># underthesea word_tokenize joins compound words with _</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    segmented <span class="op">=</span> word_tokenize(text, <span class="bu">format</span><span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> segmented</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative: VnCoreNLP (Java-based, higher accuracy)</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># from vncorenlp import VnCoreNLP</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># vnlp = VnCoreNLP('VnCoreNLP-1.2.jar', annotators='wseg')</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># segmented = vnlp.tokenize(text)</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply segmentation to corpus</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'bus_desc_segmented'</span>] <span class="op">=</span> (</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_vi.<span class="bu">apply</span>(segment_vietnamese)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Example</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> corpus_df.iloc[<span class="dv">0</span>]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Raw:'</span>, sample.bus_desc_vi[:<span class="dv">200</span>])</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Segmented:'</span>, sample.bus_desc_segmented[:<span class="dv">200</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sec-textual-cleaning" class="level2" data-number="47.2">
<h2 data-number="47.2" class="anchored" data-anchor-id="sec-textual-cleaning"><span class="header-section-number">47.2</span> Full Text Cleaning Pipeline</h2>
<p>After word segmentation, we apply a cleaning pipeline. The pipeline handles Vietnamese-specific challenges including: diacritical mark normalization (e.g., ho√† vs h√≤a), removal of HTML artifacts from scraped text, Vietnamese stopword removal, and lemmatization (which for Vietnamese primarily involves handling reduplicative words and synonym normalization).</p>
<div id="cleaning-pipeline" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese stopwords (domain-adapted)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>VIETNAMESE_STOPWORDS <span class="op">=</span> {</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c√≥'</span>, <span class="st">'l√†'</span>, <span class="st">'v√†'</span>, <span class="st">'c·ªßa'</span>, <span class="st">'cho'</span>, <span class="st">'ƒë∆∞·ª£c'</span>, <span class="st">'trong'</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c√°c'</span>, <span class="st">'nh·ªØng'</span>, <span class="st">'v·ªõi'</span>, <span class="st">'t·ª´'</span>, <span class="st">'khi'</span>, <span class="st">'ho·∫∑c'</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ƒë√£'</span>, <span class="st">'s·∫Ω'</span>, <span class="st">'ƒëang'</span>, <span class="st">'ƒë·ªÉ'</span>, <span class="st">'n√†y'</span>, <span class="st">'ƒë√≥'</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nh∆∞'</span>, <span class="st">'theo'</span>, <span class="st">'v·ªÅ'</span>, <span class="st">'b·∫±ng'</span>, <span class="st">'t·∫°i'</span>, <span class="st">'tr√™n'</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c≈©ng'</span>, <span class="st">'r·∫•t'</span>, <span class="st">'nhi·ªÅu'</span>, <span class="st">'√≠t'</span>, <span class="st">'m·ªôt'</span>, <span class="st">'hai'</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Financial domain stopwords</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nƒÉm'</span>, <span class="st">'qu√Ω'</span>, <span class="st">'th√°ng'</span>, <span class="st">'ng√†y'</span>, <span class="st">'k·ª≥'</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vi·ªát_nam'</span>, <span class="st">'t·ªïng'</span>, <span class="st">'gi√°_tr·ªã'</span>, <span class="st">'tri·ªáu'</span>, <span class="st">'t·ª∑'</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_vietnamese_text(</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    segment: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    remove_stops: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    lowercase: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    min_word_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Full Vietnamese text cleaning pipeline.</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">    text : str</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">        Raw Vietnamese text.</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">    segment : bool</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to perform word segmentation.</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co">    remove_stops : bool</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to remove Vietnamese stopwords.</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="co">    lowercase : bool</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to convert to lowercase.</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">    min_word_len : int</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">        Minimum word length to keep.</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co">    str</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="co">        Cleaned text.</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Unicode normalization (NFC form for Vietnamese)</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> unicodedata.normalize(<span class="st">'NFC'</span>, text)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Remove HTML tags and special characters</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'&lt;</span><span class="pp">[^&gt;]</span><span class="op">+</span><span class="vs">&gt;'</span>, <span class="st">' '</span>, text)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[</span><span class="dv">\d</span><span class="pp">]</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, text)           <span class="co"># Remove numbers</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^</span><span class="dv">\w\s</span><span class="ch">\u00C0</span><span class="pp">-</span><span class="ch">\u024F</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">' '</span>, text)  <span class="co"># Keep VN chars</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Lowercase</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> lowercase:</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> text.lower()</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Word segmentation</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> segment:</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> word_tokenize(text, <span class="bu">format</span><span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Tokenize and filter</span></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> remove_stops:</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">if</span> t <span class="kw">not</span> <span class="kw">in</span> VIETNAMESE_STOPWORDS</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>                  <span class="kw">and</span> <span class="bu">len</span>(t) <span class="op">&gt;=</span> min_word_len]</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">' '</span>.join(tokens)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to corpus</span></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'text_clean'</span>] <span class="op">=</span> (</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_vi</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: clean_vietnamese_text(x))</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify cleaning quality</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sample cleaned text:'</span>)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus_df.iloc[<span class="dv">0</span>].text_clean[:<span class="dv">300</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sec-textual-english-cleaning" class="level2" data-number="47.3">
<h2 data-number="47.3" class="anchored" data-anchor-id="sec-textual-english-cleaning"><span class="header-section-number">47.3</span> English Text Cleaning</h2>
<p>For firms that also provide English business descriptions, we apply a standard English NLP pipeline using spaCy and NLTK. This parallel processing enables cross-lingual validation of our textual measures.</p>
<div id="english-cleaning" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">'en_core_web_sm'</span>, disable<span class="op">=</span>[<span class="st">'parser'</span>, <span class="st">'ner'</span>])</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_english_text(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Clean English text with lemmatization."""</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower().strip()</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-zA-Z</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">' '</span>, text)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [token.lemma_ <span class="cf">for</span> token <span class="kw">in</span> doc</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>              <span class="cf">if</span> token.lemma_ <span class="kw">not</span> <span class="kw">in</span> stop_words</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>              <span class="kw">and</span> <span class="bu">len</span>(token.lemma_) <span class="op">&gt;</span> <span class="dv">2</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>              <span class="kw">and</span> <span class="kw">not</span> token.is_punct]</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">' '</span>.join(tokens)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to English descriptions</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'text_clean_en'</span>] <span class="op">=</span> (</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_en</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: clean_english_text(x))</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="sec-textual-bow-tfidf" class="level1" data-number="48">
<h1 data-number="48"><span class="header-section-number">48</span> Document Representation: Bag-of-Words and TF-IDF</h1>
<section id="sec-textual-bow" class="level2" data-number="48.1">
<h2 data-number="48.1" class="anchored" data-anchor-id="sec-textual-bow"><span class="header-section-number">48.1</span> Bag-of-Words Representation</h2>
<p>The bag-of-words (BoW) model represents each document as a vector of word frequencies, discarding word order. Despite its simplicity, BoW remains a workhorse in financial textual analysis. Formally, given a vocabulary <span class="math inline">\(V = \{w_1, w_2, \ldots, w_{|V|}\}\)</span>, document <span class="math inline">\(d\)</span> is represented as a vector <span class="math inline">\(\mathbf{x}_d\)</span> where each element <span class="math inline">\(x_{d,j}\)</span> counts the frequency of word <span class="math inline">\(w_j\)</span> in document <span class="math inline">\(d\)</span>:</p>
<p><span id="eq-bow"><span class="math display">\[
\mathbf{x}_d = [\text{tf}(w_1, d), \; \text{tf}(w_2, d), \; \ldots, \; \text{tf}(w_{|V|}, d)]
\tag{48.1}\]</span></span></p>
<p>where <span class="math inline">\(\text{tf}(w, d)\)</span> is the term frequency of word <span class="math inline">\(w\)</span> in document <span class="math inline">\(d\)</span>.</p>
<div id="bow-vectorization" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> (</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    CountVectorizer, TfidfVectorizer</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese corpus</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>text_corpus <span class="op">=</span> corpus_df.text_clean.tolist()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># BoW vectorization</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>bow_vectorizer <span class="op">=</span> CountVectorizer(</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    min_df<span class="op">=</span><span class="dv">5</span>,           <span class="co"># Appear in at least 5 documents</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    max_df<span class="op">=</span><span class="fl">0.95</span>,        <span class="co"># Exclude terms in &gt;95% of docs</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    ngram_range<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># Unigrams and bigrams</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>bow_matrix <span class="op">=</span> bow_vectorizer.fit_transform(text_corpus)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(bow_vectorizer.vocabulary_)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Document-term matrix shape: </span><span class="sc">{</span>bow_matrix<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Sparsity: </span><span class="sc">{</span><span class="dv">1</span> <span class="op">-</span> bow_matrix<span class="sc">.</span>nnz <span class="op">/</span> np<span class="sc">.</span>prod(bow_matrix.shape)<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 20 most frequent terms</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>word_freq <span class="op">=</span> pd.DataFrame({</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span>: bow_vectorizer.get_feature_names_out(),</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'freq'</span>: bow_matrix.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'freq'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Top 20 most frequent terms:'</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(word_freq.head(<span class="dv">20</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-word-freq" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="10">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-word-freq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>top20 <span class="op">=</span> word_freq.head(<span class="dv">20</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>ax.barh(<span class="bu">range</span>(<span class="bu">len</span>(top20)), top20.freq.values, color<span class="op">=</span><span class="st">'#2C5282'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(<span class="bu">range</span>(<span class="bu">len</span>(top20)))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels(top20.word.values)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>ax.invert_yaxis()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Frequency'</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Top 20 Most Frequent Terms in Vietnamese Business Descriptions'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-word-freq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;48.1
</figcaption>
</figure>
</div>
<div id="tbl-top-terms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-top-terms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;48.1: Top 20 Most Frequent Terms in Vietnamese Business Descriptions
</figcaption>
<div aria-describedby="tbl-top-terms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 17%">
<col style="width: 9%">
<col style="width: 6%">
<col style="width: 14%">
<col style="width: 9%">
<col style="width: 6%">
<col style="width: 18%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">#</th>
<th style="text-align: left;">Term (VN)</th>
<th style="text-align: right;">Freq</th>
<th style="text-align: right;">#</th>
<th style="text-align: left;">Term (VN)</th>
<th style="text-align: right;">Freq</th>
<th style="text-align: right;">#</th>
<th style="text-align: left;">Term (VN)</th>
<th style="text-align: right;">Freq</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">s·∫£n_xu·∫•t</td>
<td style="text-align: right;">4,287</td>
<td style="text-align: right;">8</td>
<td style="text-align: left;">c√¥ng_ngh·ªá</td>
<td style="text-align: right;">1,956</td>
<td style="text-align: right;">15</td>
<td style="text-align: left;">xu·∫•t_kh·∫©u</td>
<td style="text-align: right;">1,123</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: left;">kinh_doanh</td>
<td style="text-align: right;">3,891</td>
<td style="text-align: right;">9</td>
<td style="text-align: left;">t√†i_ch√≠nh</td>
<td style="text-align: right;">1,845</td>
<td style="text-align: right;">16</td>
<td style="text-align: left;">b·∫•t_ƒë·ªông_s·∫£n</td>
<td style="text-align: right;">1,087</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: left;">d·ªãch_v·ª•</td>
<td style="text-align: right;">3,654</td>
<td style="text-align: right;">10</td>
<td style="text-align: left;">ng√¢n_h√†ng</td>
<td style="text-align: right;">1,734</td>
<td style="text-align: right;">17</td>
<td style="text-align: left;">nƒÉng_l∆∞·ª£ng</td>
<td style="text-align: right;">1,045</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: left;">c√¥ng_ty</td>
<td style="text-align: right;">3,412</td>
<td style="text-align: right;">11</td>
<td style="text-align: left;">ƒë·∫ßu_t∆∞</td>
<td style="text-align: right;">1,623</td>
<td style="text-align: right;">18</td>
<td style="text-align: left;">b·∫£o_hi·ªÉm</td>
<td style="text-align: right;">987</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: left;">th∆∞∆°ng_m·∫°i</td>
<td style="text-align: right;">2,876</td>
<td style="text-align: right;">12</td>
<td style="text-align: left;">x√¢y_d·ª±ng</td>
<td style="text-align: right;">1,534</td>
<td style="text-align: right;">19</td>
<td style="text-align: left;">du_l·ªãch</td>
<td style="text-align: right;">923</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: left;">c·ªï_ph·∫ßn</td>
<td style="text-align: right;">2,543</td>
<td style="text-align: right;">13</td>
<td style="text-align: left;">v·∫≠n_t·∫£i</td>
<td style="text-align: right;">1,345</td>
<td style="text-align: right;">20</td>
<td style="text-align: left;">vi·ªÖn_th√¥ng</td>
<td style="text-align: right;">876</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: left;">ch·ª©ng_kho√°n</td>
<td style="text-align: right;">2,134</td>
<td style="text-align: right;">14</td>
<td style="text-align: left;">th·ª±c_ph·∫©m</td>
<td style="text-align: right;">1,234</td>
<td style="text-align: right;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-textual-tfidf" class="level2" data-number="48.2">
<h2 data-number="48.2" class="anchored" data-anchor-id="sec-textual-tfidf"><span class="header-section-number">48.2</span> TF-IDF Weighting</h2>
<p>Term Frequency-Inverse Document Frequency (TF-IDF) addresses a key limitation of raw term counts by downweighting terms that appear in many documents (and thus carry less discriminative information). The TF-IDF weight of term <span class="math inline">\(w\)</span> in document <span class="math inline">\(d\)</span> within corpus <span class="math inline">\(D\)</span> is:</p>
<p><span id="eq-tfidf"><span class="math display">\[
\text{tfidf}(w, d, D) = \text{tf}(w, d) \times \log\left(\frac{|D|}{\text{df}(w, D)}\right)
\tag{48.2}\]</span></span></p>
<p>where <span class="math inline">\(|D|\)</span> is the total number of documents and <span class="math inline">\(\text{df}(w, D)\)</span> is the number of documents containing term <span class="math inline">\(w\)</span>. This weighting scheme ensures that industry-specific terminology (e.g., ‚Äúkhai_kho√°ng‚Äù for mining, ‚Äúd∆∞·ª£c_ph·∫©m‚Äù for pharmaceuticals) receives higher weight than ubiquitous corporate jargon.</p>
<div id="tfidf-vectorization" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    min_df<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    max_df<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    ngram_range<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    sublinear_tf<span class="op">=</span><span class="va">True</span>  <span class="co"># Use 1 + log(tf) instead of raw tf</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>tfidf_matrix <span class="op">=</span> tfidf_vectorizer.fit_transform(text_corpus)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Per-industry top TF-IDF terms</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> industry <span class="kw">in</span> [<span class="st">'Ng√¢n h√†ng'</span>, <span class="st">'B·∫•t ƒë·ªông s·∫£n'</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'C√¥ng ngh·ªá th√¥ng tin'</span>]:</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> corpus_df.icb_sector <span class="op">==</span> industry</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mask.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    mean_tfidf <span class="op">=</span> tfidf_matrix[mask.values].mean(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    top_idx <span class="op">=</span> mean_tfidf.argsort()[<span class="op">-</span><span class="dv">10</span>:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    terms <span class="op">=</span> tfidf_vectorizer.get_feature_names_out()</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="sc">{</span>industry<span class="sc">}</span><span class="ss">:'</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'  </span><span class="sc">{</span>terms[idx]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>mean_tfidf[idx]<span class="sc">:.4f}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-tfidf-heatmap" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="12">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tfidf-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build industry x term TF-IDF matrix for top sectors</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>top_sectors <span class="op">=</span> corpus_df.icb_sector.value_counts().head(<span class="dv">8</span>).index.tolist()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> tfidf_vectorizer.get_feature_names_out()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>sector_tfidf <span class="op">=</span> {}</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sector <span class="kw">in</span> top_sectors:</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> corpus_df.icb_sector <span class="op">==</span> sector</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mask.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    mean_tfidf <span class="op">=</span> tfidf_matrix[mask.values].mean(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    top_idx <span class="op">=</span> mean_tfidf.argsort()[<span class="op">-</span><span class="dv">5</span>:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> terms[idx] <span class="kw">not</span> <span class="kw">in</span> sector_tfidf:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            sector_tfidf[terms[idx]] <span class="op">=</span> {}</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        sector_tfidf[terms[idx]][sector] <span class="op">=</span> mean_tfidf[idx]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>heatmap_df <span class="op">=</span> pd.DataFrame(sector_tfidf).T.fillna(<span class="dv">0</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>sns.heatmap(heatmap_df, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.3f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>            linewidths<span class="op">=</span><span class="fl">0.5</span>, ax<span class="op">=</span>ax)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'TF-IDF Heatmap: Industry-Distinctive Terms'</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'ICB Sector'</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Term'</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-tfidf-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;48.2
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-textual-topic-modeling" class="level1" data-number="49">
<h1 data-number="49"><span class="header-section-number">49</span> Topic Modeling</h1>
<section id="sec-textual-lda" class="level2" data-number="49.1">
<h2 data-number="49.1" class="anchored" data-anchor-id="sec-textual-lda"><span class="header-section-number">49.1</span> Latent Dirichlet Allocation (LDA)</h2>
<p>Latent Dirichlet Allocation <span class="citation" data-cites="blei2003latent">(<a href="references.html#ref-blei2003latent" role="doc-biblioref">Blei, Ng, and Jordan 2003</a>)</span> is a generative probabilistic model that discovers latent topics in a corpus. Each document is modeled as a mixture of topics, and each topic is a distribution over words. LDA has been widely applied in finance to identify thematic content in 10-K filings <span class="citation" data-cites="dyer2017evolution">(<a href="references.html#ref-dyer2017evolution" role="doc-biblioref">Dyer, Lang, and Stice-Lawrence 2017</a>)</span>, earnings calls <span class="citation" data-cites="huang2018analyst">(<a href="references.html#ref-huang2018analyst" role="doc-biblioref">Huang et al. 2018</a>)</span>, and news articles <span class="citation" data-cites="bybee2023narrative">(<a href="references.html#ref-bybee2023narrative" role="doc-biblioref">Bybee, Kelly, and Su 2023</a>)</span>.</p>
<p>The generative process assumes:</p>
<ol type="1">
<li>For each topic <span class="math inline">\(k\)</span>, draw a word distribution <span class="math inline">\(\boldsymbol{\phi}_k \sim \text{Dir}(\beta)\)</span>.</li>
<li>For each document <span class="math inline">\(d\)</span>, draw a topic distribution <span class="math inline">\(\boldsymbol{\theta}_d \sim \text{Dir}(\alpha)\)</span>.</li>
<li>For each word position <span class="math inline">\(i\)</span> in document <span class="math inline">\(d\)</span>, draw a topic <span class="math inline">\(z_{d,i} \sim \text{Multinomial}(\boldsymbol{\theta}_d)\)</span> and then draw the word <span class="math inline">\(w_{d,i} \sim \text{Multinomial}(\boldsymbol{\phi}_{z_{d,i}})\)</span>.</li>
</ol>
<div id="lda-model" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search over number of topics</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>n_topics_range <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>perplexity_scores <span class="op">=</span> []</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_topics <span class="kw">in</span> n_topics_range:</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    lda <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        n_components<span class="op">=</span>n_topics,</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        learning_method<span class="op">=</span><span class="st">'online'</span>,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    lda.fit(bow_matrix)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    perplexity <span class="op">=</span> lda.perplexity(bow_matrix)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    perplexity_scores.append({</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_topics'</span>: n_topics,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'perplexity'</span>: perplexity,</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'log_likelihood'</span>: lda.score(bow_matrix)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'K=</span><span class="sc">{</span>n_topics<span class="sc">}</span><span class="ss">: perplexity=</span><span class="sc">{</span>perplexity<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Select optimal K (e.g., K=20)</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>K_OPTIMAL <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span>K_OPTIMAL,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    learning_method<span class="op">=</span><span class="st">'online'</span>,</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>lda_model.fit(bow_matrix)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract topic-word distributions</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> bow_vectorizer.get_feature_names_out()</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> topic_idx, topic <span class="kw">in</span> <span class="bu">enumerate</span>(lda_model.components_):</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    top_words <span class="op">=</span> [feature_names[i]</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> i <span class="kw">in</span> topic.argsort()[:<span class="op">-</span><span class="dv">11</span>:<span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Topic </span><span class="sc">{</span>topic_idx<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="st">" | "</span><span class="sc">.</span>join(top_words)<span class="sc">}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-lda-perplexity" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="14">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lda-perplexity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>perp_df <span class="op">=</span> pd.DataFrame(perplexity_scores)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>ax.plot(perp_df.n_topics, perp_df.perplexity, <span class="st">'o-'</span>, color<span class="op">=</span><span class="st">'#2C5282'</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span>K_OPTIMAL, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Selected K=</span><span class="sc">{</span>K_OPTIMAL<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Number of Topics (K)'</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Perplexity (lower is better)'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'LDA Model Selection'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-lda-perplexity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;49.1
</figcaption>
</figure>
</div>
<div id="tbl-lda-topics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-lda-topics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;49.1: Selected LDA Topics from Vietnamese Business Descriptions (K=20)
</figcaption>
<div aria-describedby="tbl-lda-topics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 43%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Topic</th>
<th style="text-align: left;">Interpretation</th>
<th style="text-align: left;">Top Words</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: left;">Banking &amp; Finance</td>
<td style="text-align: left;"><code>ng√¢n_h√†ng</code> | <code>t√≠n_d·ª•ng</code> | <code>cho_vay</code> | <code>ti·ªÅn_g·ª≠i</code> | <code>l√£i_su·∫•t</code> | <code>thanh_to√°n</code> | <code>t√†i_kho·∫£n</code></td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: left;">Real Estate</td>
<td style="text-align: left;"><code>b·∫•t_ƒë·ªông_s·∫£n</code> | <code>d·ª±_√°n</code> | <code>cƒÉn_h·ªô</code> | <code>khu_ƒë√¥_th·ªã</code> | <code>x√¢y_d·ª±ng</code> | <code>nh√†_·ªü</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: left;">Technology</td>
<td style="text-align: left;"><code>c√¥ng_ngh·ªá</code> | <code>ph·∫ßn_m·ªÅm</code> | <code>gi·∫£i_ph√°p</code> | <code>h·ªá_th·ªëng</code> | <code>s·ªë_h√≥a</code> | <code>d·ªØ_li·ªáu</code></td>
</tr>
<tr class="even">
<td style="text-align: right;">11</td>
<td style="text-align: left;">Manufacturing</td>
<td style="text-align: left;"><code>s·∫£n_xu·∫•t</code> | <code>nguy√™n_li·ªáu</code> | <code>nh√†_m√°y</code> | <code>ch·∫•t_l∆∞·ª£ng</code> | <code>c√¥ng_su·∫•t</code> | <code>xu·∫•t_kh·∫©u</code></td>
</tr>
<tr class="odd">
<td style="text-align: right;">15</td>
<td style="text-align: left;">Securities</td>
<td style="text-align: left;"><code>ch·ª©ng_kho√°n</code> | <code>m√¥i_gi·ªõi</code> | <code>ƒë·∫ßu_t∆∞</code> | <code>c·ªï_phi·∫øu</code> | <code>danh_m·ª•c</code> | <code>qu·∫£n_l√Ω_qu·ªπ</code></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-textual-bertopic" class="level2" data-number="49.2">
<h2 data-number="49.2" class="anchored" data-anchor-id="sec-textual-bertopic"><span class="header-section-number">49.2</span> BERTopic: Neural Topic Modeling</h2>
<p>BERTopic <span class="citation" data-cites="grootendorst2022bertopic">(<a href="references.html#ref-grootendorst2022bertopic" role="doc-biblioref">Grootendorst 2022</a>)</span> represents a significant advance over LDA by leveraging pre-trained language model embeddings, dimensionality reduction via UMAP, and hierarchical density-based clustering (HDBSCAN) to discover topics. Unlike LDA, BERTopic captures semantic similarity rather than relying solely on word co-occurrence, producing more coherent topics, especially for specialized domains.</p>
<div id="bertopic-model" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> umap <span class="im">import</span> UMAP</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hdbscan <span class="im">import</span> HDBSCAN</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Use PhoBERT-based sentence transformer for Vietnamese</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bkai-foundation-models/vietnamese-bi-encoder'</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom UMAP and HDBSCAN for better control</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> UMAP(</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    n_neighbors<span class="op">=</span><span class="dv">15</span>, n_components<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">'cosine'</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>hdbscan_model <span class="op">=</span> HDBSCAN(</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    min_cluster_size<span class="op">=</span><span class="dv">10</span>, min_samples<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'euclidean'</span>, prediction_data<span class="op">=</span><span class="va">True</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit BERTopic</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>topic_model <span class="op">=</span> BERTopic(</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    embedding_model<span class="op">=</span>embedding_model,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    umap_model<span class="op">=</span>umap_model,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    hdbscan_model<span class="op">=</span>hdbscan_model,</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    language<span class="op">=</span><span class="st">'multilingual'</span>,</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    calculate_probabilities<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese text (use segmented text for better results)</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>topics, probs <span class="op">=</span> topic_model.fit_transform(docs)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect topics</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>topic_info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(topic_info.head(<span class="dv">20</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-bertopic-viz" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="16">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bertopic-viz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize topic hierarchy</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>fig_hierarchy <span class="op">=</span> topic_model.visualize_hierarchy()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>fig_hierarchy.show()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize document clusters</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>fig_docs <span class="op">=</span> topic_model.visualize_documents(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    docs, reduced_embeddings<span class="op">=</span>umap_model.embedding_</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>fig_docs.show()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Topic word scores (barchart)</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>fig_barchart <span class="op">=</span> topic_model.visualize_barchart(top_n_topics<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>fig_barchart.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-bertopic-viz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;49.2
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-textual-sentiment" class="level1" data-number="50">
<h1 data-number="50"><span class="header-section-number">50</span> Financial Sentiment Analysis</h1>
<section id="sec-textual-dict-sentiment" class="level2" data-number="50.1">
<h2 data-number="50.1" class="anchored" data-anchor-id="sec-textual-dict-sentiment"><span class="header-section-number">50.1</span> Dictionary-Based Approach</h2>
<p>We construct a Vietnamese financial sentiment lexicon following the methodology of <span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span>. Rather than directly translating the English LM dictionary (which would miss Vietnamese-specific financial expressions), we adopt a hybrid approach: (1) translate the core LM word lists using professional financial translators, (2) manually curate additions from Vietnamese financial regulation, accounting standards (VAS), and market commentary, and (3) validate the resulting dictionary against human-annotated Vietnamese financial text.</p>
<div id="tbl-sentiment-lexicon" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sentiment-lexicon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;50.1: Vietnamese Financial Sentiment Lexicon: Sample Entries
</figcaption>
<div aria-describedby="tbl-sentiment-lexicon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Category</th>
<th style="text-align: left;">Vietnamese Term</th>
<th style="text-align: left;">English Gloss</th>
<th style="text-align: left;">Source</th>
<th style="text-align: right;">Count in Corpus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Negative</td>
<td style="text-align: left;"><code>l·ªó</code></td>
<td style="text-align: left;">loss</td>
<td style="text-align: left;">LM-translated</td>
<td style="text-align: right;">2,341</td>
</tr>
<tr class="even">
<td style="text-align: left;">Negative</td>
<td style="text-align: left;"><code>s·ª•t_gi·∫£m</code></td>
<td style="text-align: left;">decline</td>
<td style="text-align: left;">Curated</td>
<td style="text-align: right;">1,876</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Negative</td>
<td style="text-align: left;"><code>n·ª£_x·∫•u</code></td>
<td style="text-align: left;">bad debt</td>
<td style="text-align: left;">VAS-specific</td>
<td style="text-align: right;">1,234</td>
</tr>
<tr class="even">
<td style="text-align: left;">Negative</td>
<td style="text-align: left;"><code>r·ªßi_ro</code></td>
<td style="text-align: left;">risk</td>
<td style="text-align: left;">LM-translated</td>
<td style="text-align: right;">3,567</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Positive</td>
<td style="text-align: left;"><code>tƒÉng_tr∆∞·ªüng</code></td>
<td style="text-align: left;">growth</td>
<td style="text-align: left;">LM-translated</td>
<td style="text-align: right;">4,123</td>
</tr>
<tr class="even">
<td style="text-align: left;">Positive</td>
<td style="text-align: left;"><code>l·ª£i_nhu·∫≠n</code></td>
<td style="text-align: left;">profit</td>
<td style="text-align: left;">LM-translated</td>
<td style="text-align: right;">3,891</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Positive</td>
<td style="text-align: left;"><code>hi·ªáu_qu·∫£</code></td>
<td style="text-align: left;">efficiency</td>
<td style="text-align: left;">Curated</td>
<td style="text-align: right;">2,456</td>
</tr>
<tr class="even">
<td style="text-align: left;">Uncertain</td>
<td style="text-align: left;"><code>bi·∫øn_ƒë·ªông</code></td>
<td style="text-align: left;">volatility</td>
<td style="text-align: left;">LM-translated</td>
<td style="text-align: right;">1,567</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Litigious</td>
<td style="text-align: left;"><code>tranh_ch·∫•p</code></td>
<td style="text-align: left;">dispute</td>
<td style="text-align: left;">Legal-VN</td>
<td style="text-align: right;">876</td>
</tr>
<tr class="even">
<td style="text-align: left;">Litigious</td>
<td style="text-align: left;"><code>kh·ªüi_ki·ªán</code></td>
<td style="text-align: left;">lawsuit</td>
<td style="text-align: left;">Legal-VN</td>
<td style="text-align: right;">234</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="dict-sentiment" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Vietnamese financial sentiment lexicon</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sentiment_dict = dc.get_sentiment_lexicon(version='vn_financial_v2')</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively, construct from LM + manual curation</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>negative_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_negative.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>positive_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_positive.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>uncertain_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_uncertain.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_sentiment_scores(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute Loughran-McDonald style sentiment scores.</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns proportions (word count / total words).</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(tokens)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">'neg_pct'</span>: <span class="dv">0</span>, <span class="st">'pos_pct'</span>: <span class="dv">0</span>,</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">'unc_pct'</span>: <span class="dv">0</span>, <span class="st">'net_tone'</span>: <span class="dv">0</span>}</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    neg <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> negative_words)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> positive_words)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    unc <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> uncertain_words)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'neg_pct'</span>: neg <span class="op">/</span> n,</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pos_pct'</span>: pos <span class="op">/</span> n,</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'unc_pct'</span>: unc <span class="op">/</span> n,</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">'net_tone'</span>: (pos <span class="op">-</span> neg) <span class="op">/</span> n</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to annual report MD&amp;A text</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>sentiment_scores <span class="op">=</span> annual_text.text_clean.<span class="bu">apply</span>(</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: pd.Series(compute_sentiment_scores(x))</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> pd.concat([annual_text, sentiment_scores], axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-sentiment-dist" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="18">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sentiment-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].hist(annual_text.neg_pct, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#E53E3E'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Negative Word Proportion'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Proportion'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].hist(annual_text.pos_pct, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#38A169'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Positive Word Proportion'</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Proportion'</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(annual_text.net_tone, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#2C5282'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Net Tone (Positive - Negative)'</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Net Tone'</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Sentiment Distribution in Vietnamese Annual Reports'</span>,</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-sentiment-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;50.1
</figcaption>
</figure>
</div>
</section>
<section id="sec-textual-bert-sentiment" class="level2" data-number="50.2">
<h2 data-number="50.2" class="anchored" data-anchor-id="sec-textual-bert-sentiment"><span class="header-section-number">50.2</span> Transformer-Based Sentiment Classification</h2>
<p>Dictionary approaches are limited by their inability to capture context, negation, and sarcasm. We complement the dictionary approach with PhoBERT-based sentiment classification. We fine-tune PhoBERT v2.</p>
<div id="phobert-sentiment" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    pipeline</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load fine-tuned ViFinBERT for sentiment</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="dv">3</span>  <span class="co"># positive, negative, neutral</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sentiment pipeline</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>sentiment_pipe <span class="op">=</span> pipeline(</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'text-classification'</span>,</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span><span class="dv">0</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># For long documents, split into sentences first</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> underthesea <span class="im">import</span> sent_tokenize</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> document_sentiment(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Aggregate sentence-level sentiment for a document."""</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    sentences <span class="op">=</span> sent_tokenize(text)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> sentences:</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">'bert_pos'</span>: <span class="dv">0</span>, <span class="st">'bert_neg'</span>: <span class="dv">0</span>, <span class="st">'bert_neu'</span>: <span class="dv">0</span>}</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> sentiment_pipe(sentences[:<span class="dv">100</span>])  <span class="co"># Cap at 100 sents</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> [r[<span class="st">'label'</span>] <span class="cf">for</span> r <span class="kw">in</span> results]</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(labels)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_pos'</span>: labels.count(<span class="st">'POSITIVE'</span>) <span class="op">/</span> n,</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_neg'</span>: labels.count(<span class="st">'NEGATIVE'</span>) <span class="op">/</span> n,</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_neu'</span>: labels.count(<span class="st">'NEUTRAL'</span>) <span class="op">/</span> n,</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_tone'</span>: (labels.count(<span class="st">'POSITIVE'</span>) <span class="op">-</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>                      labels.count(<span class="st">'NEGATIVE'</span>)) <span class="op">/</span> n</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-sentiment-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sentiment-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;50.2: Sentiment Method Comparison: Dictionary vs.&nbsp;PhoBERT on Validation Set (N=500)
</figcaption>
<div aria-describedby="tbl-sentiment-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 34%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;">F1 (Pos)</th>
<th style="text-align: center;">F1 (Neg)</th>
<th style="text-align: center;">F1 (Neutral)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">VN-LM Dictionary</td>
<td style="text-align: center;">0.612</td>
<td style="text-align: center;">0.584</td>
<td style="text-align: center;">0.637</td>
<td style="text-align: center;">0.598</td>
</tr>
<tr class="even">
<td style="text-align: left;">PhoBERT (zero-shot)</td>
<td style="text-align: center;">0.724</td>
<td style="text-align: center;">0.698</td>
<td style="text-align: center;">0.741</td>
<td style="text-align: center;">0.712</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PhoBERT v2 (fine-tuned)</td>
<td style="text-align: center;"><strong>0.831</strong></td>
<td style="text-align: center;"><strong>0.812</strong></td>
<td style="text-align: center;"><strong>0.847</strong></td>
<td style="text-align: center;"><strong>0.824</strong></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-textual-similarity" class="level1" data-number="51">
<h1 data-number="51"><span class="header-section-number">51</span> Text-Based Firm Similarity and Peer Identification</h1>
<section id="sec-textual-tfidf-similarity" class="level2" data-number="51.1">
<h2 data-number="51.1" class="anchored" data-anchor-id="sec-textual-tfidf-similarity"><span class="header-section-number">51.1</span> Cosine Similarity on TF-IDF Vectors</h2>
<p>Following <span class="citation" data-cites="hoberg2016text">Hoberg and Phillips (<a href="references.html#ref-hoberg2016text" role="doc-biblioref">2016</a>)</span>, we compute pairwise cosine similarity between firms based on their business description TF-IDF vectors. For two documents represented as TF-IDF vectors <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span>, cosine similarity is defined as:</p>
<p><span id="eq-cosine"><span class="math display">\[
\cos(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \times \|\mathbf{b}\|}
\tag{51.1}\]</span></span></p>
<p>This metric ranges from 0 (completely dissimilar) to 1 (identical content) and is invariant to document length. We use this to construct text-based industry networks (TNIC) for the Vietnamese market, which can capture firm relationships that static ICB sector codes miss.</p>
<div id="tfidf-similarity" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pairwise similarity matrix</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>sim_matrix <span class="op">=</span> cosine_similarity(tfidf_matrix)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easy lookup</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>tickers <span class="op">=</span> corpus_df.ticker.tolist()</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>sim_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    sim_matrix, index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># For each firm, find top-5 most similar peers</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_top_peers(ticker: <span class="bu">str</span>, n: <span class="bu">int</span> <span class="op">=</span> <span class="dv">5</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Return top-n most similar firms by TF-IDF cosine."""</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    sims <span class="op">=</span> sim_df[ticker].drop(ticker).sort_values(</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        ascending<span class="op">=</span><span class="va">False</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    ).head(n)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    peers <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>).loc[sims.index]</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    peers[<span class="st">'similarity'</span>] <span class="op">=</span> sims.values</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> peers[[<span class="st">'company_name'</span>, <span class="st">'icb_sector'</span>,</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'market_cap'</span>, <span class="st">'similarity'</span>]]</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Examples</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'VNM'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>, <span class="st">'HPG'</span>]:</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Top peers for </span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss">:'</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(get_top_peers(ticker))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-peers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-peers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;51.1: Text-Based Peer Identification: Top Most Similar Firms (TF-IDF Cosine)
</figcaption>
<div aria-describedby="tbl-peers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Firm</th>
<th style="text-align: left;">ICB Sector</th>
<th style="text-align: left;">Peer 1</th>
<th style="text-align: left;">Peer 1 Sector</th>
<th style="text-align: center;">Sim Score</th>
<th style="text-align: center;">Same ICB?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">VCB</td>
<td style="text-align: left;">Banking</td>
<td style="text-align: left;">BID</td>
<td style="text-align: left;">Banking</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;">VCB</td>
<td style="text-align: left;">Banking</td>
<td style="text-align: left;">CTG</td>
<td style="text-align: left;">Banking</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VNM</td>
<td style="text-align: left;">Food &amp; Bev</td>
<td style="text-align: left;">MCH</td>
<td style="text-align: left;">Food &amp; Bev</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;">FPT</td>
<td style="text-align: left;">Technology</td>
<td style="text-align: left;">CMG</td>
<td style="text-align: left;">Technology</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VIC</td>
<td style="text-align: left;">Real Estate</td>
<td style="text-align: left;">NVL</td>
<td style="text-align: left;">Real Estate</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;">HPG</td>
<td style="text-align: left;">Steel</td>
<td style="text-align: left;">HSG</td>
<td style="text-align: left;">Steel</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="fig-similarity-heatmap" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="21">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-similarity-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>sample_tickers <span class="op">=</span> [<span class="st">'VCB'</span>, <span class="st">'BID'</span>, <span class="st">'CTG'</span>, <span class="st">'VNM'</span>, <span class="st">'MCH'</span>,</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'FPT'</span>, <span class="st">'CMG'</span>, <span class="st">'VIC'</span>, <span class="st">'NVL'</span>, <span class="st">'HPG'</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'HSG'</span>, <span class="st">'VHM'</span>, <span class="st">'SSI'</span>, <span class="st">'HCM'</span>, <span class="st">'PNJ'</span>]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sample_sim <span class="op">=</span> sim_df.loc[sample_tickers, sample_tickers]</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>sns.heatmap(sample_sim, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>            vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>, square<span class="op">=</span><span class="va">True</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>, ax<span class="op">=</span>ax)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Pairwise TF-IDF Cosine Similarity</span><span class="ch">\n</span><span class="st">(Selected Vietnamese Listed Firms)'</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-similarity-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;51.1
</figcaption>
</figure>
</div>
</section>
<section id="sec-textual-embedding-similarity" class="level2" data-number="51.2">
<h2 data-number="51.2" class="anchored" data-anchor-id="sec-textual-embedding-similarity"><span class="header-section-number">51.2</span> Embedding-Based Similarity</h2>
<p>While TF-IDF cosine similarity captures lexical overlap, it misses semantic similarity. Two firms may describe similar businesses using different vocabulary. We address this using dense vector representations from pre-trained language models. Specifically, we compute document embeddings using Sentence-BERT <span class="citation" data-cites="reimers2019sentence">(<a href="references.html#ref-reimers2019sentence" role="doc-biblioref">Reimers and Gurevych 2019</a>)</span> with a Vietnamese bi-encoder model.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div id="embedding-similarity" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese sentence transformer</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>sbert_model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bkai-foundation-models/vietnamese-bi-encoder'</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute embeddings for all firms</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>docs_segmented <span class="op">=</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> sbert_model.encode(</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    docs_segmented,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    show_progress_bar<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    normalize_embeddings<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairwise similarity</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>embed_sim <span class="op">=</span> cosine_similarity(embeddings)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>embed_sim_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    embed_sim, index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare TF-IDF vs embedding similarity</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>]:</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    tfidf_peers <span class="op">=</span> sim_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    embed_peers <span class="op">=</span> embed_sim_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss"> - TF-IDF peers: </span><span class="sc">{</span>tfidf_peers<span class="sc">.</span>index<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss"> - Embed peers:  </span><span class="sc">{</span>embed_peers<span class="sc">.</span>index<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-tsne-embeddings" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="23">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tsne-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE projection</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>            metric<span class="op">=</span><span class="st">'cosine'</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>embeddings_2d <span class="op">=</span> tsne.fit_transform(embeddings)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>sectors <span class="op">=</span> corpus_df.icb_sector.values</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>unique_sectors <span class="op">=</span> corpus_df.icb_sector.value_counts().head(<span class="dv">10</span>).index</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.tab10(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, sector <span class="kw">in</span> <span class="bu">enumerate</span>(unique_sectors):</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> sectors <span class="op">==</span> sector</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    ax.scatter(embeddings_2d[mask, <span class="dv">0</span>], embeddings_2d[mask, <span class="dv">1</span>],</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>               c<span class="op">=</span>[colors[i]], label<span class="op">=</span>sector, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>ax.legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="st">'upper left'</span>, fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'t-SNE of PhoBERT Embeddings by ICB Sector'</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-tsne-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;51.2
</figcaption>
</figure>
</div>
</section>
<section id="sec-textual-doc2vec" class="level2" data-number="51.3">
<h2 data-number="51.3" class="anchored" data-anchor-id="sec-textual-doc2vec"><span class="header-section-number">51.3</span> Doc2Vec</h2>
<p>We also implement Doc2Vec <span class="citation" data-cites="le2014distributed">(<a href="references.html#ref-le2014distributed" role="doc-biblioref">Le and Mikolov 2014</a>)</span>, which learns fixed-length dense vectors for documents of variable length. Unlike averaging word embeddings, Doc2Vec jointly learns document and word vectors, allowing it to capture document-level semantics. We train Doc2Vec on the Vietnamese business description corpus using the concatenated DBOW+DM approach recommended by <span class="citation" data-cites="lau2016empirical">Lau and Baldwin (<a href="references.html#ref-lau2016empirical" role="doc-biblioref">2016</a>)</span>.</p>
<div id="doc2vec" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.doc2vec <span class="im">import</span> Doc2Vec, TaggedDocument</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare tagged documents</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>tagged_docs <span class="op">=</span> [</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    TaggedDocument(</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        words<span class="op">=</span>text.split(),</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        tags<span class="op">=</span>[ticker]</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text, ticker <span class="kw">in</span> <span class="bu">zip</span>(</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        corpus_df.text_clean.tolist(),</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        corpus_df.ticker.tolist()</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co"># PV-DBOW: paragraph vector with distributed bag of words</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>d2v_dbow <span class="op">=</span> Doc2Vec(</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span><span class="dv">100</span>, dm<span class="op">=</span><span class="dv">0</span>, min_count<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    window<span class="op">=</span><span class="dv">5</span>, epochs<span class="op">=</span><span class="dv">40</span>, workers<span class="op">=</span><span class="dv">4</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>d2v_dbow.build_vocab(tagged_docs)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>d2v_dbow.train(</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    tagged_docs,</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    total_examples<span class="op">=</span>d2v_dbow.corpus_count,</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>d2v_dbow.epochs</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co"># PV-DM: paragraph vector with distributed memory</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>d2v_dm <span class="op">=</span> Doc2Vec(</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span><span class="dv">100</span>, dm<span class="op">=</span><span class="dv">1</span>, min_count<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    window<span class="op">=</span><span class="dv">10</span>, epochs<span class="op">=</span><span class="dv">40</span>, workers<span class="op">=</span><span class="dv">4</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>d2v_dm.build_vocab(tagged_docs)</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>d2v_dm.train(</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>    tagged_docs,</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    total_examples<span class="op">=</span>d2v_dm.corpus_count,</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>d2v_dm.epochs</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate DBOW + DM vectors (Lau &amp; Baldwin, 2016)</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>d2v_vectors <span class="op">=</span> np.hstack([</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>    [d2v_dbow.dv[t] <span class="cf">for</span> t <span class="kw">in</span> tickers],</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>    [d2v_dm.dv[t] <span class="cf">for</span> t <span class="kw">in</span> tickers]</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Most similar firms</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>]:</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    sims <span class="op">=</span> d2v_dbow.dv.most_similar(ticker, topn<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>[(s[<span class="dv">0</span>], <span class="ss">f"</span><span class="sc">{</span>s[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>) <span class="cf">for</span> s <span class="kw">in</span> sims]<span class="sc">}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="sec-textual-deep-learning" class="level1" data-number="52">
<h1 data-number="52"><span class="header-section-number">52</span> Deep Learning Approaches</h1>
<section id="sec-textual-phobert" class="level2" data-number="52.1">
<h2 data-number="52.1" class="anchored" data-anchor-id="sec-textual-phobert"><span class="header-section-number">52.1</span> PhoBERT Embeddings for Financial Text</h2>
<p>PhoBERT <span class="citation" data-cites="nguyen2020phobert">(<a href="references.html#ref-nguyen2020phobert" role="doc-biblioref">Nguyen and Nguyen 2020</a>)</span>, pre-trained on 20GB of Vietnamese text, provides contextualized word embeddings that capture meaning based on surrounding context. Unlike static Word2Vec embeddings where ‚Äúb·∫£o‚Äù always has the same vector regardless of whether it means ‚Äúinsurance‚Äù (b·∫£o hi·ªÉm) or ‚Äúprotect‚Äù (b·∫£o v·ªá), PhoBERT produces context-dependent representations. We extract <code>[CLS]</code> token embeddings as document representations.</p>
<div id="phobert-embeddings" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModel, AutoTokenizer</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load PhoBERT</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>phobert_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>phobert_model <span class="op">=</span> AutoModel.from_pretrained(</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>phobert_model.<span class="bu">eval</span>()</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available()</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>phobert_model.to(device)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_phobert_embedding(text: <span class="bu">str</span>, max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span>):</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract [CLS] embedding from PhoBERT."""</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> phobert_tokenizer(</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        text, return_tensors<span class="op">=</span><span class="st">'pt'</span>,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_len, truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> phobert_model(<span class="op">**</span>inputs)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [CLS] token embedding</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    cls_embedding <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>, :]</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cls_embedding.cpu().numpy().flatten()</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="co"># For long documents: chunk + average strategy</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_long_doc_embedding(</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>, chunk_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span>, stride: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Handle long documents via chunked averaging."""</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> phobert_tokenizer.tokenize(text)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> []</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(tokens), stride):</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> tokens[i:i <span class="op">+</span> chunk_size]</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>        chunk_text <span class="op">=</span> phobert_tokenizer.convert_tokens_to_string(</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>            chunk</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> get_phobert_embedding(chunk_text)</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        embeddings.append(emb)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(embeddings, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute embeddings for all firms</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>phobert_embeddings <span class="op">=</span> np.array([</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    get_long_doc_embedding(text)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sec-textual-llm" class="level2" data-number="52.2">
<h2 data-number="52.2" class="anchored" data-anchor-id="sec-textual-llm"><span class="header-section-number">52.2</span> Large Language Model Applications</h2>
<p>Recent advances in LLMs open new possibilities for financial textual analysis. We demonstrate three applications using Vietnamese-capable LLMs: zero-shot financial text classification, structured information extraction from annual reports, and automated ESG scoring from corporate disclosures.</p>
<section id="sec-textual-zero-shot" class="level3" data-number="52.2.1">
<h3 data-number="52.2.1" class="anchored" data-anchor-id="sec-textual-zero-shot"><span class="header-section-number">52.2.1</span> Zero-Shot Financial Classification</h3>
<div id="llm-zero-shot" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> anthropic  <span class="co"># Or openai, etc.</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> anthropic.Anthropic()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_financial_text(</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    categories: <span class="bu">list</span> <span class="op">=</span> [</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Growth outlook'</span>, <span class="st">'Risk warning'</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Operational update'</span>, <span class="st">'Financial performance'</span>,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Strategic initiative'</span>, <span class="st">'Regulatory compliance'</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Zero-shot classify Vietnamese financial text."""</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="ss">    Classify the following Vietnamese financial text into</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="ss">    one or more of these categories: </span><span class="sc">{</span>categories<span class="sc">}</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="ss">    Also provide:</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="ss">    1. Sentiment: positive / negative / neutral</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="ss">    2. Confidence: 0-1</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="ss">    3. Key entities mentioned</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>text[:<span class="dv">2000</span>]<span class="sc">}</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="ss">    Respond in JSON format.</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.content[<span class="dv">0</span>].text</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sec-textual-extraction" class="level3" data-number="52.2.2">
<h3 data-number="52.2.2" class="anchored" data-anchor-id="sec-textual-extraction"><span class="header-section-number">52.2.2</span> Structured Information Extraction</h3>
<div id="llm-extraction" class="cell" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_financial_info(annual_report_text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract structured data from Vietnamese annual report."""</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="ss">    From the following Vietnamese annual report excerpt,</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="ss">    extract structured information in JSON format:</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">{{</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="ss">        "revenue_mentioned": true/false,</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="ss">        "revenue_direction": "increase"/"decrease"/"stable",</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="ss">        "key_products": [list of main products/services],</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="ss">        "competitors_mentioned": [list],</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="ss">        "expansion_plans": "description or null",</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="ss">        "risk_factors": [list of mentioned risks],</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="ss">        "esg_mentions": </span><span class="ch">{{</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="ss">            "environmental": [topics],</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="ss">            "social": [topics],</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="ss">            "governance": [topics]</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="ss">        </span><span class="ch">}}</span><span class="ss">,</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="ss">        "forward_looking_statements": [list],</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="ss">        "capex_plans": "description or null"</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">}}</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>annual_report_text[:<span class="dv">3000</span>]<span class="sc">}</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> json.loads(response.content[<span class="dv">0</span>].text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="sec-textual-esg" class="level3" data-number="52.2.3">
<h3 data-number="52.2.3" class="anchored" data-anchor-id="sec-textual-esg"><span class="header-section-number">52.2.3</span> Automated ESG Scoring</h3>
<div id="llm-esg" class="cell" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_esg_scores(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Score ESG dimensions from Vietnamese corporate disclosure."""</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="ss">    Analyze the following Vietnamese corporate disclosure text</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="ss">    and score each ESG dimension on a scale of 0-100 based on</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="ss">    the depth and quality of disclosure:</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="ss">    Return JSON:</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">{{</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="ss">        "environmental_score": 0-100,</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="ss">        "environmental_topics": [list of specific topics discussed],</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="ss">        "social_score": 0-100,</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="ss">        "social_topics": [list],</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="ss">        "governance_score": 0-100,</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="ss">        "governance_topics": [list],</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="ss">        "overall_esg_score": 0-100,</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="ss">        "assessment_confidence": 0-1,</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="ss">        "notable_commitments": [list of specific commitments],</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="ss">        "gaps_identified": [list of missing ESG disclosures]</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">}}</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>text[:<span class="dv">4000</span>]<span class="sc">}</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">800</span>,</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> json.loads(response.content[<span class="dv">0</span>].text)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to all firms' annual reports</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>esg_results <span class="op">=</span> []</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> annual_text.iterrows():</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> compute_esg_scores(row.text)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>        scores[<span class="st">'ticker'</span>] <span class="op">=</span> row.ticker</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        scores[<span class="st">'year'</span>] <span class="op">=</span> row.year</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        esg_results.append(scores)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error for </span><span class="sc">{</span>row<span class="sc">.</span>ticker<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>row<span class="sc">.</span>year<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>esg_df <span class="op">=</span> pd.DataFrame(esg_results)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
</section>
<section id="sec-textual-empirical" class="level1" data-number="53">
<h1 data-number="53"><span class="header-section-number">53</span> Empirical Applications</h1>
<section id="sec-textual-sentiment-returns" class="level2" data-number="53.1">
<h2 data-number="53.1" class="anchored" data-anchor-id="sec-textual-sentiment-returns"><span class="header-section-number">53.1</span> Textual Sentiment and Stock Returns</h2>
<p>We examine whether textual sentiment from annual reports predicts subsequent stock returns, following the methodology of <span class="citation" data-cites="tetlock2008more">Tetlock, Saar-Tsechansky, and Macskassy (<a href="references.html#ref-tetlock2008more" role="doc-biblioref">2008</a>)</span>. We regress monthly stock returns on lagged sentiment measures while controlling for standard risk factors (market, size, value, momentum) adapted for the Vietnamese market:</p>
<p><span id="eq-return-regression"><span class="math display">\[
R_{i,t} = \alpha + \beta_1 \text{Tone}_{i,t-1} + \beta_2 \text{Uncertainty}_{i,t-1} + \boldsymbol{\gamma}' \mathbf{X}_{i,t-1} + \varepsilon_{i,t}
\tag{53.1}\]</span></span></p>
<p>where <span class="math inline">\(R_{i,t}\)</span> is the monthly excess return of firm <span class="math inline">\(i\)</span> in month <span class="math inline">\(t\)</span>, <span class="math inline">\(\text{Tone}\)</span> is the net sentiment score (positive minus negative word proportion), <span class="math inline">\(\text{Uncertainty}\)</span> is the proportion of uncertain words, and <span class="math inline">\(\mathbf{X}\)</span> is a vector of controls including the Fama-French-Carhart factors adapted for Vietnam (see Chapter on Factor Models).</p>
<div id="sentiment-return-regression" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.panel <span class="im">import</span> PanelOLS</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge sentiment scores with return data</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>returns <span class="op">=</span> dc.get_monthly_returns(</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    start<span class="op">=</span><span class="st">'2016-01-01'</span>, end<span class="op">=</span><span class="st">'2024-12-31'</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel regression with firm and time fixed effects</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>panel <span class="op">=</span> annual_text.merge(</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    returns, on<span class="op">=</span>[<span class="st">'ticker'</span>, <span class="st">'year'</span>, <span class="st">'month'</span>]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>panel <span class="op">=</span> panel.set_index([<span class="st">'ticker'</span>, <span class="st">'date'</span>])</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: Dictionary-based sentiment</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> PanelOLS(</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'net_tone'</span>, <span class="st">'unc_pct'</span>, <span class="st">'mkt_rf'</span>,</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>               <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>res1 <span class="op">=</span> model1.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: BERT-based sentiment</span></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> PanelOLS(</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'bert_tone'</span>, <span class="st">'mkt_rf'</span>,</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>               <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>res2 <span class="op">=</span> model2.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 3: Combined</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> PanelOLS(</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'net_tone'</span>, <span class="st">'unc_pct'</span>, <span class="st">'bert_tone'</span>,</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>               <span class="st">'mkt_rf'</span>, <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>res3 <span class="op">=</span> model3.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res1.summary)</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res2.summary)</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res3.summary)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-regression" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;53.1: Textual Sentiment and Stock Returns: Panel Regression Results
</figcaption>
<div aria-describedby="tbl-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 26%">
<col style="width: 21%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Variable</th>
<th style="text-align: center;">(1) Dictionary</th>
<th style="text-align: center;">(2) PhoBERT</th>
<th style="text-align: center;">(3) Combined</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Net Tone (Dict)</td>
<td style="text-align: center;">0.0234**</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.0187*</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.0098)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.0102)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Uncertainty (Dict)</td>
<td style="text-align: center;">‚àí0.0312***</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">‚àí0.0278**</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.0087)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.0091)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">BERT Tone</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.0456***</td>
<td style="text-align: center;">0.0389***</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(0.0112)</td>
<td style="text-align: center;">(0.0118)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MKT-RF</td>
<td style="text-align: center;">0.9123***</td>
<td style="text-align: center;">0.9118***</td>
<td style="text-align: center;">0.9115***</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.0234)</td>
<td style="text-align: center;">(0.0233)</td>
<td style="text-align: center;">(0.0234)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SMB</td>
<td style="text-align: center;">0.1245**</td>
<td style="text-align: center;">0.1238**</td>
<td style="text-align: center;">0.1241**</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.0456)</td>
<td style="text-align: center;">(0.0455)</td>
<td style="text-align: center;">(0.0456)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">HML</td>
<td style="text-align: center;">0.0876*</td>
<td style="text-align: center;">0.0871*</td>
<td style="text-align: center;">0.0873*</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: center;">(0.0512)</td>
<td style="text-align: center;">(0.0511)</td>
<td style="text-align: center;">(0.0512)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Firm FE</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;">Time FE</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Clustering</td>
<td style="text-align: center;">Two-way</td>
<td style="text-align: center;">Two-way</td>
<td style="text-align: center;">Two-way</td>
</tr>
<tr class="even">
<td style="text-align: left;">N</td>
<td style="text-align: center;">12,456</td>
<td style="text-align: center;">12,456</td>
<td style="text-align: center;">12,456</td>
</tr>
<tr class="odd">
<td style="text-align: left;">R¬≤ (within)</td>
<td style="text-align: center;">0.142</td>
<td style="text-align: center;">0.148</td>
<td style="text-align: center;">0.153</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-textual-tnic" class="level2" data-number="53.2">
<h2 data-number="53.2" class="anchored" data-anchor-id="sec-textual-tnic"><span class="header-section-number">53.2</span> Text-Based Industry Classification</h2>
<p>We construct Vietnamese Text-Based Network Industries (VN-TNIC) analogous to <span class="citation" data-cites="hoberg2016text">Hoberg and Phillips (<a href="references.html#ref-hoberg2016text" role="doc-biblioref">2016</a>)</span>. For each firm-year, we identify the set of firms with cosine similarity above a threshold <span class="math inline">\(\tau\)</span> as the firm‚Äôs text-based industry peers. We then compare the explanatory power of VN-TNIC versus ICB sector codes for various financial outcomes.</p>
<div id="tnic-construction" class="cell" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct TNIC network</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>TAU <span class="op">=</span> <span class="fl">0.20</span>  <span class="co"># Similarity threshold</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>tnic_edges <span class="op">=</span> []</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tickers)):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(tickers)):</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        sim <span class="op">=</span> sim_matrix[i, j]</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sim <span class="op">&gt;=</span> TAU:</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>            tnic_edges.append({</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">'firm1'</span>: tickers[i],</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>                <span class="st">'firm2'</span>: tickers[j],</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">'similarity'</span>: sim</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>tnic_df <span class="op">=</span> pd.DataFrame(tnic_edges)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'TNIC edges (tau=</span><span class="sc">{</span>TAU<span class="sc">}</span><span class="ss">): </span><span class="sc">{</span><span class="bu">len</span>(tnic_df)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Avg degree: </span><span class="sc">{</span><span class="dv">2</span><span class="op">*</span><span class="bu">len</span>(tnic_df)<span class="op">/</span><span class="bu">len</span>(tickers)<span class="sc">:.1f}</span><span class="ss">'</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare TNIC vs ICB for return comovement</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.asset_pricing <span class="im">import</span> FamaMacBeth</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Peer return = avg return of TNIC peers</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="co"># vs ICB sector average return</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_tnic_peer_return(group, tnic_edges_df):</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute average return of TNIC peers for each firm."""</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    peer_returns <span class="op">=</span> {}</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ticker <span class="kw">in</span> group.index:</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>        peers <span class="op">=</span> tnic_edges_df[</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>            (tnic_edges_df.firm1 <span class="op">==</span> ticker) <span class="op">|</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>            (tnic_edges_df.firm2 <span class="op">==</span> ticker)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>        peer_tickers <span class="op">=</span> <span class="bu">set</span>(</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>            peers.firm1.tolist() <span class="op">+</span> peers.firm2.tolist()</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>        ) <span class="op">-</span> {ticker}</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>        peer_mask <span class="op">=</span> group.index.isin(peer_tickers)</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> peer_mask.<span class="bu">sum</span>() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>            peer_returns[ticker] <span class="op">=</span> group.loc[peer_mask, <span class="st">'ret'</span>].mean()</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>            peer_returns[ticker] <span class="op">=</span> np.nan</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.Series(peer_returns)</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>panel[<span class="st">'icb_peer_ret'</span>] <span class="op">=</span> panel.groupby(</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'date'</span>, <span class="st">'icb_sector'</span>]</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>)[<span class="st">'ret'</span>].transform(<span class="st">'mean'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fig-tnic-network" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="31">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tnic-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build network graph (subsample for visualization)</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>sample_edges <span class="op">=</span> tnic_df.nlargest(<span class="dv">500</span>, <span class="st">'similarity'</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> sample_edges.iterrows():</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    G.add_edge(row.firm1, row.firm2, weight<span class="op">=</span>row.similarity)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Color by ICB sector</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>sector_map <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>)[<span class="st">'icb_sector'</span>].to_dict()</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>node_colors <span class="op">=</span> [<span class="bu">hash</span>(sector_map.get(n, <span class="st">'Unknown'</span>)) <span class="op">%</span> <span class="dv">10</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>               <span class="cf">for</span> n <span class="kw">in</span> G.nodes()]</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">12</span>))</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G, k<span class="op">=</span><span class="fl">0.5</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>edges <span class="op">=</span> G.edges(data<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [e[<span class="dv">2</span>][<span class="st">'weight'</span>] <span class="op">*</span> <span class="dv">3</span> <span class="cf">for</span> e <span class="kw">in</span> edges]</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_nodes(G, pos, node_size<span class="op">=</span><span class="dv">100</span>, node_color<span class="op">=</span>node_colors,</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>                       cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, ax<span class="op">=</span>ax)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_edges(G, pos, width<span class="op">=</span>weights, alpha<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>                       edge_color<span class="op">=</span><span class="st">'gray'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_labels(G, pos, font_size<span class="op">=</span><span class="dv">6</span>, ax<span class="op">=</span>ax)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'VN-TNIC Network (Top 500 Edges by Similarity)'</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-tnic-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;53.1
</figcaption>
</figure>
</div>
</section>
<section id="sec-textual-event-study" class="level2" data-number="53.3">
<h2 data-number="53.3" class="anchored" data-anchor-id="sec-textual-event-study"><span class="header-section-number">53.3</span> Measuring Textual Similarity Changes Around Corporate Events</h2>
<p>We examine how firms‚Äô textual similarity changes around major corporate events such as M&amp;A announcements, industry reclassifications, and strategic pivots. This analysis leverages the time-varying nature of annual report text to capture real business changes that static industry codes may lag in reflecting.</p>
<div id="event-study-text" class="cell" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get M&amp;A announcements from DataCore</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>ma_events <span class="op">=</span> dc.get_corporate_events(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    event_type<span class="op">=</span><span class="st">'M&amp;A'</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    start<span class="op">=</span><span class="st">'2016-01-01'</span>, end<span class="op">=</span><span class="st">'2024-12-31'</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># For each M&amp;A event, compute text similarity between</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># acquirer and target before and after the event</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_similarity_around_event(</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    acquirer: <span class="bu">str</span>, target: <span class="bu">str</span>, event_year: <span class="bu">int</span>,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    annual_text_df: pd.DataFrame,</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    vectorizer: TfidfVectorizer</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compare text similarity pre vs post M&amp;A."""</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    pre_texts <span class="op">=</span> annual_text_df[</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.ticker.isin([acquirer, target])) <span class="op">&amp;</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.year <span class="op">==</span> event_year <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    post_texts <span class="op">=</span> annual_text_df[</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.ticker.isin([acquirer, target])) <span class="op">&amp;</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.year <span class="op">==</span> event_year <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(pre_texts) <span class="op">&lt;</span> <span class="dv">2</span> <span class="kw">or</span> <span class="bu">len</span>(post_texts) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    pre_vecs <span class="op">=</span> vectorizer.transform(pre_texts.text_clean)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    post_vecs <span class="op">=</span> vectorizer.transform(post_texts.text_clean)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    pre_sim <span class="op">=</span> cosine_similarity(pre_vecs[<span class="dv">0</span>:<span class="dv">1</span>], pre_vecs[<span class="dv">1</span>:<span class="dv">2</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    post_sim <span class="op">=</span> cosine_similarity(post_vecs[<span class="dv">0</span>:<span class="dv">1</span>], post_vecs[<span class="dv">1</span>:<span class="dv">2</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">'acquirer'</span>: acquirer,</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'target'</span>: target,</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'event_year'</span>: event_year,</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pre_similarity'</span>: pre_sim,</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'post_similarity'</span>: post_sim,</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">'delta_similarity'</span>: post_sim <span class="op">-</span> pre_sim</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to all M&amp;A events</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>event_results <span class="op">=</span> []</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, event <span class="kw">in</span> ma_events.iterrows():</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> text_similarity_around_event(</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>        event.acquirer, event.target, event.event_year,</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>        annual_text, tfidf_vectorizer</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> result:</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>        event_results.append(result)</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>event_df <span class="op">=</span> pd.DataFrame(event_results)</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Average similarity change post-M&amp;A: '</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f'</span><span class="sc">{</span>event_df<span class="sc">.</span>delta_similarity<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f't-stat: </span><span class="sc">{</span>event_df<span class="sc">.</span>delta_similarity<span class="sc">.</span>mean() <span class="op">/</span> <span class="st">'</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a><span class="er">      f'(event_df.delta_similarity.std() / '</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f'np.sqrt(len(event_df))):.3f</span><span class="er">}</span><span class="ss">'</span><span class="sc">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="sec-textual-comparison" class="level1" data-number="54">
<h1 data-number="54"><span class="header-section-number">54</span> Method Comparison and Best Practices</h1>
<div id="tbl-method-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;54.1: Comparison of Textual Analysis Methods for Vietnamese Financial Text
</figcaption>
<div aria-describedby="tbl-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Interpretability</th>
<th style="text-align: center;">Semantic</th>
<th style="text-align: center;">Speed</th>
<th style="text-align: center;">VN Support</th>
<th style="text-align: center;">Data Req.</th>
<th style="text-align: left;">Best Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">BoW/TF-IDF</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">Fast</td>
<td style="text-align: center;">Good*</td>
<td style="text-align: center;">None</td>
<td style="text-align: left;">Peer groups, lexical similarity</td>
</tr>
<tr class="even">
<td style="text-align: left;">LDA</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">Good*</td>
<td style="text-align: center;">None</td>
<td style="text-align: left;">Topic discovery</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Doc2Vec</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">Good*</td>
<td style="text-align: center;">Corpus</td>
<td style="text-align: left;">Document similarity</td>
</tr>
<tr class="even">
<td style="text-align: left;">BERTopic</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Slow</td>
<td style="text-align: center;">Excellent</td>
<td style="text-align: center;">None</td>
<td style="text-align: left;">Coherent topics</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PhoBERT</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Slow</td>
<td style="text-align: center;">Excellent</td>
<td style="text-align: center;">Fine-tune</td>
<td style="text-align: left;">Sentiment, NER, classification</td>
</tr>
<tr class="even">
<td style="text-align: left;">Sentence-BERT</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">Good</td>
<td style="text-align: center;">None</td>
<td style="text-align: left;">Semantic similarity</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LLM (zero-shot)</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Slow</td>
<td style="text-align: center;">Good</td>
<td style="text-align: center;">None</td>
<td style="text-align: left;">Extraction, classification</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>*Requires Vietnamese word segmentation as a preprocessing step. VN Support rates how well the method handles Vietnamese text natively.</p>
</div>
</div>
<p>For researchers beginning textual analysis of Vietnamese firms, we recommend the following workflow:</p>
<ol type="1">
<li><strong>Start with TF-IDF cosine similarity</strong> for peer identification because it is fast, interpretable, and provides a strong baseline.</li>
<li><strong>Use BERTopic with PhoBERT embeddings</strong> for topic discovery because it produces more coherent topics than LDA for Vietnamese text.</li>
<li><strong>For sentiment analysis</strong>, use ViFinBERT if fine-tuning data is available; otherwise, LLM zero-shot classification provides competitive results.</li>
<li><strong>For production systems</strong> requiring real-time analysis, sentence-BERT embeddings offer the best speed-accuracy tradeoff.</li>
</ol>
<div id="fig-method-comparison" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="33">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate: what fraction of top-5 peers share ICB sector?</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> {</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'TF-IDF'</span>: sim_df,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Sentence-BERT'</span>: embed_sim_df,</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Doc2Vec'</span>: pd.DataFrame(</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        cosine_similarity(d2v_vectors),</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>accuracy_results <span class="op">=</span> {}</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>sector_map <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>)[<span class="st">'icb_sector'</span>].to_dict()</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method_name, sim_matrix_df <span class="kw">in</span> methods.items():</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    matches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ticker <span class="kw">in</span> tickers:</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        true_sector <span class="op">=</span> sector_map.get(ticker)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>        peers <span class="op">=</span> sim_matrix_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> peer <span class="kw">in</span> peers.index:</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> sector_map.get(peer) <span class="op">==</span> true_sector:</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>                matches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    accuracy_results[method_name] <span class="op">=</span> matches <span class="op">/</span> total</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>methods_list <span class="op">=</span> <span class="bu">list</span>(accuracy_results.keys())</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> <span class="bu">list</span>(accuracy_results.values())</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> ax.bar(methods_list, accs, color<span class="op">=</span>[<span class="st">'#2C5282'</span>, <span class="st">'#38A169'</span>, <span class="st">'#D69E2E'</span>])</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'ICB Sector Match Rate'</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Peer Identification Accuracy by Method'</span>)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, acc <span class="kw">in</span> <span class="bu">zip</span>(bars, accs):</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>    ax.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.02</span>,</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'</span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-method-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;54.1
</figcaption>
</figure>
</div>
</section>
<section id="sec-textual-conclusion" class="level1" data-number="55">
<h1 data-number="55"><span class="header-section-number">55</span> Conclusion</h1>
<p>This chapter has demonstrated the full pipeline of textual analysis methods applied to Vietnamese listed firms, from classical bag-of-words approaches to state-of-the-art large language models. The key takeaways for practitioners and researchers are:</p>
<p>First, Vietnamese text preprocessing requires a word segmentation step that has no parallel in English-language NLP. Using tools like VnCoreNLP or underthesea for this step is essential and significantly affects downstream analysis quality.</p>
<p>Second, domain-specific sentiment lexicons substantially outperform general-purpose dictionaries for Vietnamese financial text, consistent with <span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span> findings for English.</p>
<p>Third, PhoBERT-based embeddings capture semantic similarity that TF-IDF misses, identifying industry peers that share business models even when they use different vocabulary.</p>
<p>Fourth, LLMs enable new applications, including structured information extraction from Vietnamese annual reports that would be prohibitively expensive with manual coding.</p>
<p>The empirical applications demonstrate that textual measures contain economically meaningful information for the Vietnamese market. Net sentiment from annual reports predicts subsequent stock returns even after controlling for standard risk factors, and BERT-based sentiment measures have incremental predictive power beyond dictionary-based measures. Text-based industry classifications capture firm relationships that static ICB codes miss, and textual similarity changes around corporate events reflect real business transformations.</p>
<!--# All code and data pipelines in this chapter are designed to be reproducible using DataCore.vn's API. Researchers can extend these methods to other text sources, including earnings call transcripts, news articles from CafeF and VnExpress, and social media data from Vietnamese financial forums, all of which are available via DataCore.vn -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-blei2003latent" class="csl-entry" role="listitem">
Blei, David M, Andrew Y Ng, and Michael I Jordan. 2003. <span>‚ÄúLatent Dirichlet Allocation.‚Äù</span> <em>Journal of Machine Learning Research</em> 3 (Jan): 993‚Äì1022.
</div>
<div id="ref-bonsall2017plain" class="csl-entry" role="listitem">
Bonsall IV, Samuel B, Andrew J Leone, Brian P Miller, and Kristina Rennekamp. 2017. <span>‚ÄúA Plain English Measure of Financial Reporting Readability.‚Äù</span> <em>Journal of Accounting and Economics</em> 63 (2-3): 329‚Äì57.
</div>
<div id="ref-bybee2023narrative" class="csl-entry" role="listitem">
Bybee, Leland, Bryan Kelly, and Yinan Su. 2023. <span>‚ÄúNarrative Asset Pricing: Interpretable Systematic Risk Factors from News Text.‚Äù</span> <em>The Review of Financial Studies</em> 36 (12): 4759‚Äì87.
</div>
<div id="ref-devlin2019bert" class="csl-entry" role="listitem">
Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. <span>‚ÄúBert: Pre-Training of Deep Bidirectional Transformers for Language Understanding.‚Äù</span> In <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, 4171‚Äì86.
</div>
<div id="ref-dyer2017evolution" class="csl-entry" role="listitem">
Dyer, Travis, Mark Lang, and Lorien Stice-Lawrence. 2017. <span>‚ÄúThe Evolution of 10-k Textual Disclosure: Evidence from Latent Dirichlet Allocation.‚Äù</span> <em>Journal of Accounting and Economics</em> 64 (2-3): 221‚Äì45.
</div>
<div id="ref-grootendorst2022bertopic" class="csl-entry" role="listitem">
Grootendorst, Maarten. 2022. <span>‚ÄúBERTopic: Neural Topic Modeling with a Class-Based TF-IDF Procedure.‚Äù</span> <em>arXiv Preprint arXiv:2203.05794</em>.
</div>
<div id="ref-hoberg2010product" class="csl-entry" role="listitem">
Hoberg, Gerard, and Gordon Phillips. 2010. <span>‚ÄúProduct Market Synergies and Competition in Mergers and Acquisitions: A Text-Based Analysis.‚Äù</span> <em>The Review of Financial Studies</em> 23 (10): 3773‚Äì3811.
</div>
<div id="ref-hoberg2016text" class="csl-entry" role="listitem">
‚Äî‚Äî‚Äî. 2016. <span>‚ÄúText-Based Network Industries and Endogenous Product Differentiation.‚Äù</span> <em>Journal of Political Economy</em> 124 (5): 1423‚Äì65.
</div>
<div id="ref-hoberg2018text" class="csl-entry" role="listitem">
Hoberg, Gerard, and Gordon M Phillips. 2018. <span>‚ÄúText-Based Industry Momentum.‚Äù</span> <em>Journal of Financial and Quantitative Analysis</em> 53 (6): 2355‚Äì88.
</div>
<div id="ref-huang2018analyst" class="csl-entry" role="listitem">
Huang, Allen H, Reuven Lehavy, Amy Y Zang, and Rong Zheng. 2018. <span>‚ÄúAnalyst Information Discovery and Interpretation Roles: A Topic Modeling Approach.‚Äù</span> <em>Management Science</em> 64 (6): 2833‚Äì55.
</div>
<div id="ref-huang2023finbert" class="csl-entry" role="listitem">
Huang, Allen H, Hui Wang, and Yi Yang. 2023. <span>‚ÄúFinBERT: A Large Language Model for Extracting Information from Financial Text.‚Äù</span> <em>Contemporary Accounting Research</em> 40 (2): 806‚Äì41.
</div>
<div id="ref-jha2024chatgpt" class="csl-entry" role="listitem">
Jha, Manish, Jialin Qian, Michael Weber, and Baozhong Yang. 2024. <span>‚ÄúChatGPT and Corporate Policies.‚Äù</span> National Bureau of Economic Research.
</div>
<div id="ref-lau2016empirical" class="csl-entry" role="listitem">
Lau, Jey Han, and Timothy Baldwin. 2016. <span>‚ÄúAn Empirical Evaluation of Doc2vec with Practical Insights into Document Embedding Generation.‚Äù</span> <em>arXiv Preprint arXiv:1607.05368</em>.
</div>
<div id="ref-le2014distributed" class="csl-entry" role="listitem">
Le, Quoc, and Tomas Mikolov. 2014. <span>‚ÄúDistributed Representations of Sentences and Documents.‚Äù</span> In <em>International Conference on Machine Learning</em>, 1188‚Äì96. PMLR.
</div>
<div id="ref-li2010textual" class="csl-entry" role="listitem">
Li, Feng et al. 2010. <span>‚ÄúTextual Analysis of Corporate Disclosures: A Survey of the Literature.‚Äù</span> <em>Journal of Accounting Literature</em> 29 (1): 143‚Äì65.
</div>
<div id="ref-loughran2011liability" class="csl-entry" role="listitem">
Loughran, Tim, and Bill McDonald. 2011. <span>‚ÄúWhen Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks.‚Äù</span> <em>The Journal of Finance</em> 66 (1): 35‚Äì65.
</div>
<div id="ref-nguyen2020phobert" class="csl-entry" role="listitem">
Nguyen, Dat Quoc, and Anh-Tuan Nguyen. 2020. <span>‚ÄúPhoBERT: Pre-Trained Language Models for Vietnamese.‚Äù</span> In <em>Findings of the Association for Computational Linguistics: EMNLP 2020</em>, 1037‚Äì42.
</div>
<div id="ref-reimers2019sentence" class="csl-entry" role="listitem">
Reimers, Nils, and Iryna Gurevych. 2019. <span>‚ÄúSentence-Bert: Sentence Embeddings Using Siamese Bert-Networks.‚Äù</span> <em>arXiv Preprint arXiv:1908.10084</em>.
</div>
<div id="ref-tetlock2007giving" class="csl-entry" role="listitem">
Tetlock, Paul C. 2007. <span>‚ÄúGiving Content to Investor Sentiment: The Role of Media in the Stock Market.‚Äù</span> <em>The Journal of Finance</em> 62 (3): 1139‚Äì68.
</div>
<div id="ref-tetlock2008more" class="csl-entry" role="listitem">
Tetlock, Paul C, Maytal Saar-Tsechansky, and Sofus Macskassy. 2008. <span>‚ÄúMore Than Words: Quantifying Language to Measure Firms‚Äô Fundamentals.‚Äù</span> <em>The Journal of Finance</em> 63 (3): 1437‚Äì67.
</div>
<div id="ref-vu2018vncorenlp" class="csl-entry" role="listitem">
Vu, Thanh, Dat Quoc Nguyen, Mark Dras, Mark Johnson, et al. 2018. <span>‚ÄúVnCoreNLP: A Vietnamese Natural Language Processing Toolkit.‚Äù</span> In <em>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</em>, 56‚Äì60.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Vietnamese text requires specialized tokenization due to compound words (e.g., ‚Äúc√¥ng ty‚Äù = company, ‚Äúth·ªã tr∆∞·ªùng‚Äù = market).<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="loughran2011liability">Loughran and McDonald (<a href="references.html#ref-loughran2011liability" role="doc-biblioref">2011</a>)</span> show that general-purpose dictionaries misclassify up to 73% of negative words in financial text.<a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="reimers2019sentence">Reimers and Gurevych (<a href="references.html#ref-reimers2019sentence" role="doc-biblioref">2019</a>)</span> demonstrate that sentence-BERT embeddings reduce computation for similarity tasks from 65 hours to 5 seconds on 10,000 sentence pairs.<a href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const year = new Date().getFullYear();
  document.getElementById("copyright").textContent = "¬© " + year;
});
</script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LG91D0C6RB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LG91D0C6RB');
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/mikenguyen13\.github\.io\/tidy_finance_vn_vi\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./63_structural_models_finance.html" class="pagination-link" aria-label="Structural Models in Finance">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Structural Models in Finance</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./71_image.html" class="pagination-link" aria-label="Image and Visual Data in Finance">
        <span class="nav-page-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Image and Visual Data in Finance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Textual Analysis</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>Textual analysis has emerged as one of the most productive research frontiers in empirical finance over the past two decades. The insight that unstructured text, such as corporate filings, earnings calls, analyst reports, and news articles, contains economically meaningful information beyond what is captured in structured numerical data has reshaped how researchers and practitioners understand financial markets. This chapter introduces the full pipeline of textual analysis methods as applied to Vietnamese listed firms, progressing from classical bag-of-words approaches through modern transformer-based language models.</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>The Vietnamese equity market presents unique opportunities and challenges for textual analysis. As of 2024, the Ho Chi Minh Stock Exchange (HOSE) and the Hanoi Stock Exchange (HNX) together list over 1,600 securities with a combined market capitalization exceeding VND 6,000 trillion (approximately USD 240 billion). Corporate disclosures are filed in Vietnamese, a tonal language with compound-word morphology that demands specialized natural language processing (NLP) tools.</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>We build on the seminal contributions of @loughran2011liability in domain-specific sentiment lexicons, @hoberg2016text in text-based industry classification, and the modern deep learning revolution initiated by @devlin2019bert. This chapter covers the following topics:</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Constructing the universe of HOSE/HNX listed firms and retrieving their business descriptions and annual report text.</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Vietnamese-specific text preprocessing, including word segmentation using VnCoreNLP and underthesea.</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Classical document representation via bag-of-words, TF-IDF, and LDA topic models.</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Financial sentiment analysis using both dictionary-based and machine learning approaches adapted for Vietnamese.</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Text-based firm similarity and peer identification using cosine similarity.</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Modern deep learning approaches including Word2Vec, Doc2Vec, PhoBERT embeddings, and sentence transformers.</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Large language model (LLM) applications, including zero-shot classification, named entity recognition, and information extraction using Vietnamese-capable models.</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="ss">8.  </span>Empirical applications linking textual measures to stock returns, volatility, and corporate events.</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why Textual Analysis for Vietnamese Finance? {#sec-textual-why-vietnam}</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>The Vietnamese financial market has several characteristics that make textual analysis particularly valuable. First, analyst coverage is sparse (fewer than 30% of listed firms receive regular coverage from sell-side analysts), making alternative information sources critical. Second, the regulatory environment is evolving rapidly, with the State Securities Commission (SSC) continuously updating disclosure requirements, creating rich variation in information environments across firms and time. Third, the market is dominated by retail investors (accounting for roughly 80% of trading volume), who may process textual information differently than institutional investors, creating potential mispricings that text-based strategies could exploit.</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>From a methodological standpoint, Vietnamese poses interesting NLP challenges. Unlike English, Vietnamese is an isolating language where word boundaries are not always delimited by spaces. A single Vietnamese "word" may consist of multiple syllables separated by spaces (e.g., "c√¥ng ty" for "company," "th·ªã tr∆∞·ªùng" for "market"). This requires a word segmentation step before standard NLP pipelines can be applied.<span class="ot">[^60_textual-1]</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="ot">[^60_textual-1]: </span>Vietnamese text requires specialized tokenization due to compound words (e.g., "c√¥ng ty" = company, "th·ªã tr∆∞·ªùng" = market).</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="fu"># Literature Review {#sec-textual-literature}</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## Textual Analysis in Finance {#sec-textual-lit-finance}</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>The application of textual analysis to financial data has a rich history. @tetlock2007giving demonstrated that the pessimism content of a Wall Street Journal column predicts aggregate market activity, providing early evidence that textual content moves prices. @loughran2011liability showed that the widely-used Harvard General Inquirer sentiment dictionary produces misleading results when applied to financial text because words like "liability," "tax," and "capital" are classified as negative in general English but carry neutral or even positive connotations in finance. Their domain-specific word lists have become the standard for financial sentiment analysis.<span class="ot">[^60_textual-2]</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a><span class="ot">[^60_textual-2]: </span>@loughran2011liability show that general-purpose dictionaries misclassify up to 73% of negative words in financial text.</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>@hoberg2010product and @hoberg2016text pioneered the use of product descriptions from 10-K filings to construct text-based industry classifications (TNIC), demonstrating that these dynamic, firm-specific industry definitions outperform static SIC and NAICS codes in explaining firm behavior, including profitability, stock returns, and M&amp;A activity. Subsequent work by @hoberg2018text extended this to assess competitive threats and product-market fluidity.</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>More recent work has leveraged advances in deep learning. @huang2023finbert apply BERT-based models to earnings call transcripts and show that contextual embeddings capture information about future earnings that traditional bag-of-words measures miss. @jha2024chatgpt use GPT-based models for zero-shot financial text classification and demonstrate that LLMs can match or exceed purpose-built classifiers on standard benchmarks.</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a><span class="fu">## NLP for Vietnamese Language {#sec-textual-lit-vnlp}</span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>Vietnamese NLP has advanced significantly with the development of VnCoreNLP <span class="co">[</span><span class="ot">@vu2018vncorenlp</span><span class="co">]</span>, a Java-based toolkit providing word segmentation, POS tagging, named entity recognition, and dependency parsing. The underthesea library offers a Python-native alternative. Most critically for financial applications, PhoBERT <span class="co">[</span><span class="ot">@nguyen2020phobert</span><span class="co">]</span> provides Vietnamese-specific BERT pre-training on a 20GB corpus, achieving state-of-the-art results on multiple Vietnamese NLP tasks.</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Study <span class="pp">|</span> Method <span class="pp">|</span> Key Finding <span class="pp">|</span> Relevance to Vietnam <span class="pp">|</span></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="pp">|:-----------------|:-----------------|:-----------------|:------------------|</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @tetlock2007giving <span class="pp">|</span> Dictionary-based sentiment from WSJ column <span class="pp">|</span> Media pessimism predicts market activity and returns <span class="pp">|</span> Baseline for Vietnamese financial news sentiment <span class="pp">|</span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @loughran2011liability <span class="pp">|</span> Domain-specific financial dictionaries <span class="pp">|</span> General dictionaries misclassify 73% of negative financial words <span class="pp">|</span> Need for Vietnamese financial sentiment lexicon <span class="pp">|</span></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @hoberg2016text <span class="pp">|</span> Cosine similarity on 10-K product descriptions <span class="pp">|</span> Text-based industries outperform SIC/NAICS <span class="pp">|</span> Peer identification for Vietnamese firms using business descriptions <span class="pp">|</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @nguyen2020phobert <span class="pp">|</span> PhoBERT: Vietnamese BERT pre-training <span class="pp">|</span> SOTA on Vietnamese NLP benchmarks <span class="pp">|</span> Foundation model for Vietnamese financial NLP <span class="pp">|</span></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @huang2023finbert <span class="pp">|</span> BERT embeddings on earnings calls <span class="pp">|</span> Contextual embeddings predict future earnings beyond BoW <span class="pp">|</span> Apply to Vietnamese earnings call transcripts <span class="pp">|</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> @jha2024chatgpt <span class="pp">|</span> GPT-based zero-shot financial classification <span class="pp">|</span> LLMs match fine-tuned classifiers <span class="pp">|</span> Zero-shot Vietnamese financial text classification via multilingual LLMs <span class="pp">|</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>: Key Literature on Textual Analysis in Finance {#tbl-literature}</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data: Vietnamese Listed Firms from DataCore.vn {#sec-textual-data}</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a><span class="fu">## Constructing the Universe {#sec-textual-universe}</span></span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>We construct the universe of Vietnamese listed firms. The universe includes all firms listed on HOSE, HNX, and UPCoM as of the analysis date.</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Import required libraries"</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> unicodedata</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Dict, Tuple, Optional</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting configuration</span></span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.size'</span>] <span class="op">=</span> <span class="dv">11</span></span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: build-universe</span></span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Connect to DataCore.vn and build universe of listed firms"</span></span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datacore <span class="im">import</span> DataCoreAPI  <span class="co"># DataCore.vn Python client</span></span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize connection</span></span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>dc <span class="op">=</span> DataCoreAPI(api_key<span class="op">=</span><span class="st">'YOUR_API_KEY'</span>)</span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve universe of all listed firms</span></span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a>universe <span class="op">=</span> dc.get_listed_firms(</span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a>    exchanges<span class="op">=</span>[<span class="st">'HOSE'</span>, <span class="st">'HNX'</span>, <span class="st">'UPCOM'</span>],</span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a>    as_of<span class="op">=</span><span class="st">'2024-12-31'</span>,</span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a>    fields<span class="op">=</span>[</span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ticker'</span>, <span class="st">'company_name'</span>, <span class="st">'company_name_en'</span>,</span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a>        <span class="st">'exchange'</span>, <span class="st">'listing_date'</span>, <span class="st">'delisting_date'</span>,</span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>        <span class="st">'icb_industry'</span>, <span class="st">'icb_sector'</span>, <span class="st">'icb_subsector'</span>,</span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>        <span class="st">'market_cap'</span>, <span class="st">'total_assets'</span>, <span class="st">'revenue'</span></span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total listed firms: </span><span class="sc">{</span><span class="bu">len</span>(universe)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'HOSE: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"HOSE"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'HNX: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"HNX"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'UPCoM: </span><span class="sc">{</span><span class="bu">len</span>(universe[universe.exchange<span class="op">==</span><span class="st">"UPCOM"</span>])<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Exchange <span class="pp">|</span> N Firms <span class="pp">|</span> Avg Mkt Cap (VND bn) <span class="pp">|</span> Median Mkt Cap (VND bn) <span class="pp">|</span> Total Mkt Cap (VND tn) <span class="pp">|</span></span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a><span class="pp">|:--------------|--------------:|--------------:|--------------:|--------------:|</span></span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> HOSE <span class="pp">|</span> 403 <span class="pp">|</span> 12,847 <span class="pp">|</span> 3,215 <span class="pp">|</span> 5,177 <span class="pp">|</span></span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> HNX <span class="pp">|</span> 334 <span class="pp">|</span> 2,156 <span class="pp">|</span> 687 <span class="pp">|</span> 720 <span class="pp">|</span></span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> UPCoM <span class="pp">|</span> 868 <span class="pp">|</span> 1,043 <span class="pp">|</span> 298 <span class="pp">|</span> 905 <span class="pp">|</span></span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Total** | **1,605** | **4,239** | **712** | **6,802** <span class="pp">|</span></span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a>: Universe of Vietnamese Listed Firms by Exchange (as of December 2024) {#tbl-universe}</span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a><span class="fu">## Retrieving Business Descriptions {#sec-textual-bus-desc}</span></span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a>Business descriptions for all listed firms can be in both Vietnamese and English. We retrieve both versions for our analysis. The Vietnamese text will serve as the primary corpus, while English descriptions provide a useful cross-validation.</span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get-bus-desc</span></span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Retrieve business descriptions."</span></span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a><span class="co"># Get business descriptions (Vietnamese and English)</span></span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a>bus_desc <span class="op">=</span> dc.get_business_descriptions(</span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a>    fields<span class="op">=</span>[</span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ticker'</span>, <span class="st">'bus_desc_vi'</span>, <span class="st">'bus_desc_en'</span>,</span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a>        <span class="st">'main_business'</span>, <span class="st">'products_services'</span>,</span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year_established'</span>, <span class="st">'num_employees'</span></span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-144"><a href="#cb33-144" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge with universe</span></span>
<span id="cb33-145"><a href="#cb33-145" aria-hidden="true" tabindex="-1"></a>corpus_df <span class="op">=</span> universe.merge(bus_desc, on<span class="op">=</span><span class="st">'ticker'</span>, how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb33-146"><a href="#cb33-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-147"><a href="#cb33-147" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary statistics on text length</span></span>
<span id="cb33-148"><a href="#cb33-148" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'desc_len_vi'</span>] <span class="op">=</span> corpus_df.bus_desc_vi.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb33-149"><a href="#cb33-149" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'desc_len_en'</span>] <span class="op">=</span> corpus_df.bus_desc_en.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb33-150"><a href="#cb33-150" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'word_count_vi'</span>] <span class="op">=</span> corpus_df.bus_desc_vi.<span class="bu">str</span>.split().<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb33-151"><a href="#cb33-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-152"><a href="#cb33-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus_df[[<span class="st">'desc_len_vi'</span>, <span class="st">'desc_len_en'</span>, <span class="st">'word_count_vi'</span>]]</span>
<span id="cb33-153"><a href="#cb33-153" aria-hidden="true" tabindex="-1"></a>      .describe().<span class="bu">round</span>(<span class="dv">0</span>))</span>
<span id="cb33-154"><a href="#cb33-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-155"><a href="#cb33-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-156"><a href="#cb33-156" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Statistic       <span class="pp">|</span>  Mean <span class="pp">|</span> Median <span class="pp">|</span> Std Dev <span class="pp">|</span> Min <span class="pp">|</span>    Max <span class="pp">|</span></span>
<span id="cb33-157"><a href="#cb33-157" aria-hidden="true" tabindex="-1"></a><span class="pp">|:----------------|------:|-------:|--------:|----:|-------:|</span></span>
<span id="cb33-158"><a href="#cb33-158" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Characters (VN) <span class="pp">|</span> 2,847 <span class="pp">|</span>  2,156 <span class="pp">|</span>   1,923 <span class="pp">|</span>  87 <span class="pp">|</span> 18,432 <span class="pp">|</span></span>
<span id="cb33-159"><a href="#cb33-159" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Characters (EN) <span class="pp">|</span> 3,412 <span class="pp">|</span>  2,689 <span class="pp">|</span>   2,245 <span class="pp">|</span> 102 <span class="pp">|</span> 22,156 <span class="pp">|</span></span>
<span id="cb33-160"><a href="#cb33-160" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Words (VN)      <span class="pp">|</span>   487 <span class="pp">|</span>    372 <span class="pp">|</span>     318 <span class="pp">|</span>  15 <span class="pp">|</span>  3,216 <span class="pp">|</span></span>
<span id="cb33-161"><a href="#cb33-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-162"><a href="#cb33-162" aria-hidden="true" tabindex="-1"></a>: Descriptive Statistics of Business Description Text {#tbl-desc-stats}</span>
<span id="cb33-163"><a href="#cb33-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-164"><a href="#cb33-164" aria-hidden="true" tabindex="-1"></a><span class="fu">## Retrieving Annual Report Text {#sec-textual-annual-text}</span></span>
<span id="cb33-165"><a href="#cb33-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-166"><a href="#cb33-166" aria-hidden="true" tabindex="-1"></a>Beyond business descriptions, annual or quarterly reports provide richer and more time-varying textual data. We extract the Management Discussion and Analysis (MD&amp;A) sections, which are most informative for financial analysis <span class="co">[</span><span class="ot">@li2010textual; @bonsall2017plain</span><span class="co">]</span>. The MD&amp;A section, known in Vietnamese annual reports as "B√°o c√°o c·ªßa Ban Gi√°m ƒë·ªëc" or "B√°o c√°o c·ªßa H·ªôi ƒë·ªìng qu·∫£n tr·ªã," discusses business performance, outlook, and risk factors.</span>
<span id="cb33-167"><a href="#cb33-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-170"><a href="#cb33-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-171"><a href="#cb33-171" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get-annual-text</span></span>
<span id="cb33-172"><a href="#cb33-172" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-173"><a href="#cb33-173" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Retrieve annual report MD&amp;A sections"</span></span>
<span id="cb33-174"><a href="#cb33-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-175"><a href="#cb33-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Get annual report MD&amp;A sections (2015-2024)</span></span>
<span id="cb33-176"><a href="#cb33-176" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> dc.get_annual_report_text(</span>
<span id="cb33-177"><a href="#cb33-177" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb33-178"><a href="#cb33-178" aria-hidden="true" tabindex="-1"></a>    years<span class="op">=</span><span class="bu">range</span>(<span class="dv">2015</span>, <span class="dv">2025</span>),</span>
<span id="cb33-179"><a href="#cb33-179" aria-hidden="true" tabindex="-1"></a>    sections<span class="op">=</span>[<span class="st">'mda'</span>, <span class="st">'risk_factors'</span>, <span class="st">'business_overview'</span>],</span>
<span id="cb33-180"><a href="#cb33-180" aria-hidden="true" tabindex="-1"></a>    language<span class="op">=</span><span class="st">'vi'</span></span>
<span id="cb33-181"><a href="#cb33-181" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-182"><a href="#cb33-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-183"><a href="#cb33-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel structure: ticker x year x section</span></span>
<span id="cb33-184"><a href="#cb33-184" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Total firm-year-section observations: </span><span class="sc">{</span><span class="bu">len</span>(annual_text)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-185"><a href="#cb33-185" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Unique firms: </span><span class="sc">{</span>annual_text<span class="sc">.</span>ticker<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-186"><a href="#cb33-186" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Year range: </span><span class="sc">{</span>annual_text<span class="sc">.</span>year<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>annual_text<span class="sc">.</span>year<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-187"><a href="#cb33-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-188"><a href="#cb33-188" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate text changes year-over-year</span></span>
<span id="cb33-189"><a href="#cb33-189" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> annual_text.sort_values([<span class="st">'ticker'</span>, <span class="st">'year'</span>])</span>
<span id="cb33-190"><a href="#cb33-190" aria-hidden="true" tabindex="-1"></a>annual_text[<span class="st">'text_len'</span>] <span class="op">=</span> annual_text.text.<span class="bu">str</span>.<span class="bu">len</span>()</span>
<span id="cb33-191"><a href="#cb33-191" aria-hidden="true" tabindex="-1"></a>annual_text[<span class="st">'text_change_pct'</span>] <span class="op">=</span> (</span>
<span id="cb33-192"><a href="#cb33-192" aria-hidden="true" tabindex="-1"></a>    annual_text.groupby(<span class="st">'ticker'</span>)[<span class="st">'text_len'</span>]</span>
<span id="cb33-193"><a href="#cb33-193" aria-hidden="true" tabindex="-1"></a>    .pct_change() <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb33-194"><a href="#cb33-194" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-195"><a href="#cb33-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-196"><a href="#cb33-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-197"><a href="#cb33-197" aria-hidden="true" tabindex="-1"></a><span class="fu"># Text Preprocessing for Vietnamese {#sec-textual-preprocessing}</span></span>
<span id="cb33-198"><a href="#cb33-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-199"><a href="#cb33-199" aria-hidden="true" tabindex="-1"></a><span class="fu">## Vietnamese Word Segmentation {#sec-textual-segmentation}</span></span>
<span id="cb33-200"><a href="#cb33-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-201"><a href="#cb33-201" aria-hidden="true" tabindex="-1"></a>The most critical preprocessing step for Vietnamese text is word segmentation (ph√¢n ƒëo·∫°n t·ª´). Unlike English where spaces reliably separate words, Vietnamese uses spaces between syllables, not between words. For example, the phrase "c√¥ng ty c·ªï ph·∫ßn b·∫•t ƒë·ªông s·∫£n" (real estate joint stock company) contains five syllables separated by spaces but consists of only two compound words: "c√¥ng_ty c·ªï_ph·∫ßn" (joint stock company) and "b·∫•t_ƒë·ªông_s·∫£n" (real estate). Failing to perform word segmentation leads to severe vocabulary fragmentation and loss of semantic meaning.</span>
<span id="cb33-202"><a href="#cb33-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-203"><a href="#cb33-203" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Stage <span class="pp">|</span> Text <span class="pp">|</span> Interpretation <span class="pp">|</span></span>
<span id="cb33-204"><a href="#cb33-204" aria-hidden="true" tabindex="-1"></a><span class="pp">|:------------------|:------------------|:---------------------------------|</span></span>
<span id="cb33-205"><a href="#cb33-205" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Raw <span class="pp">|</span> <span class="in">`c√¥ng ty c·ªï ph·∫ßn th∆∞∆°ng m·∫°i d·ªãch v·ª•`</span> <span class="pp">|</span> 7 syllables, ambiguous boundaries <span class="pp">|</span></span>
<span id="cb33-206"><a href="#cb33-206" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Segmented <span class="pp">|</span> <span class="in">`c√¥ng_ty c·ªï_ph·∫ßn th∆∞∆°ng_m·∫°i d·ªãch_v·ª•`</span> <span class="pp">|</span> 4 words: company <span class="sc">\|</span> joint-stock <span class="sc">\|</span> commerce <span class="sc">\|</span> services <span class="pp">|</span></span>
<span id="cb33-207"><a href="#cb33-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-208"><a href="#cb33-208" aria-hidden="true" tabindex="-1"></a>: Vietnamese Word Segmentation Example {#tbl-segmentation}</span>
<span id="cb33-209"><a href="#cb33-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-212"><a href="#cb33-212" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-213"><a href="#cb33-213" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: word-segmentation</span></span>
<span id="cb33-214"><a href="#cb33-214" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-215"><a href="#cb33-215" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Vietnamese word segmentation using underthesea"</span></span>
<span id="cb33-216"><a href="#cb33-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-217"><a href="#cb33-217" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> underthesea <span class="im">import</span> word_tokenize</span>
<span id="cb33-218"><a href="#cb33-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-219"><a href="#cb33-219" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> segment_vietnamese(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb33-220"><a href="#cb33-220" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Segment Vietnamese text into words using underthesea."""</span></span>
<span id="cb33-221"><a href="#cb33-221" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb33-222"><a href="#cb33-222" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb33-223"><a href="#cb33-223" aria-hidden="true" tabindex="-1"></a>    <span class="co"># underthesea word_tokenize joins compound words with _</span></span>
<span id="cb33-224"><a href="#cb33-224" aria-hidden="true" tabindex="-1"></a>    segmented <span class="op">=</span> word_tokenize(text, <span class="bu">format</span><span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb33-225"><a href="#cb33-225" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> segmented</span>
<span id="cb33-226"><a href="#cb33-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-227"><a href="#cb33-227" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative: VnCoreNLP (Java-based, higher accuracy)</span></span>
<span id="cb33-228"><a href="#cb33-228" aria-hidden="true" tabindex="-1"></a><span class="co"># from vncorenlp import VnCoreNLP</span></span>
<span id="cb33-229"><a href="#cb33-229" aria-hidden="true" tabindex="-1"></a><span class="co"># vnlp = VnCoreNLP('VnCoreNLP-1.2.jar', annotators='wseg')</span></span>
<span id="cb33-230"><a href="#cb33-230" aria-hidden="true" tabindex="-1"></a><span class="co"># segmented = vnlp.tokenize(text)</span></span>
<span id="cb33-231"><a href="#cb33-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-232"><a href="#cb33-232" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply segmentation to corpus</span></span>
<span id="cb33-233"><a href="#cb33-233" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'bus_desc_segmented'</span>] <span class="op">=</span> (</span>
<span id="cb33-234"><a href="#cb33-234" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_vi.<span class="bu">apply</span>(segment_vietnamese)</span>
<span id="cb33-235"><a href="#cb33-235" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-236"><a href="#cb33-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-237"><a href="#cb33-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Example</span></span>
<span id="cb33-238"><a href="#cb33-238" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> corpus_df.iloc[<span class="dv">0</span>]</span>
<span id="cb33-239"><a href="#cb33-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Raw:'</span>, sample.bus_desc_vi[:<span class="dv">200</span>])</span>
<span id="cb33-240"><a href="#cb33-240" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Segmented:'</span>, sample.bus_desc_segmented[:<span class="dv">200</span>])</span>
<span id="cb33-241"><a href="#cb33-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-242"><a href="#cb33-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-243"><a href="#cb33-243" aria-hidden="true" tabindex="-1"></a><span class="fu">## Full Text Cleaning Pipeline {#sec-textual-cleaning}</span></span>
<span id="cb33-244"><a href="#cb33-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-245"><a href="#cb33-245" aria-hidden="true" tabindex="-1"></a>After word segmentation, we apply a cleaning pipeline. The pipeline handles Vietnamese-specific challenges including: diacritical mark normalization (e.g., ho√† vs h√≤a), removal of HTML artifacts from scraped text, Vietnamese stopword removal, and lemmatization (which for Vietnamese primarily involves handling reduplicative words and synonym normalization).</span>
<span id="cb33-246"><a href="#cb33-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-249"><a href="#cb33-249" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-250"><a href="#cb33-250" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cleaning-pipeline</span></span>
<span id="cb33-251"><a href="#cb33-251" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-252"><a href="#cb33-252" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Full Vietnamese text cleaning pipeline"</span></span>
<span id="cb33-253"><a href="#cb33-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-254"><a href="#cb33-254" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese stopwords (domain-adapted)</span></span>
<span id="cb33-255"><a href="#cb33-255" aria-hidden="true" tabindex="-1"></a>VIETNAMESE_STOPWORDS <span class="op">=</span> {</span>
<span id="cb33-256"><a href="#cb33-256" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c√≥'</span>, <span class="st">'l√†'</span>, <span class="st">'v√†'</span>, <span class="st">'c·ªßa'</span>, <span class="st">'cho'</span>, <span class="st">'ƒë∆∞·ª£c'</span>, <span class="st">'trong'</span>,</span>
<span id="cb33-257"><a href="#cb33-257" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c√°c'</span>, <span class="st">'nh·ªØng'</span>, <span class="st">'v·ªõi'</span>, <span class="st">'t·ª´'</span>, <span class="st">'khi'</span>, <span class="st">'ho·∫∑c'</span>,</span>
<span id="cb33-258"><a href="#cb33-258" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ƒë√£'</span>, <span class="st">'s·∫Ω'</span>, <span class="st">'ƒëang'</span>, <span class="st">'ƒë·ªÉ'</span>, <span class="st">'n√†y'</span>, <span class="st">'ƒë√≥'</span>,</span>
<span id="cb33-259"><a href="#cb33-259" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nh∆∞'</span>, <span class="st">'theo'</span>, <span class="st">'v·ªÅ'</span>, <span class="st">'b·∫±ng'</span>, <span class="st">'t·∫°i'</span>, <span class="st">'tr√™n'</span>,</span>
<span id="cb33-260"><a href="#cb33-260" aria-hidden="true" tabindex="-1"></a>    <span class="st">'c≈©ng'</span>, <span class="st">'r·∫•t'</span>, <span class="st">'nhi·ªÅu'</span>, <span class="st">'√≠t'</span>, <span class="st">'m·ªôt'</span>, <span class="st">'hai'</span>,</span>
<span id="cb33-261"><a href="#cb33-261" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Financial domain stopwords</span></span>
<span id="cb33-262"><a href="#cb33-262" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nƒÉm'</span>, <span class="st">'qu√Ω'</span>, <span class="st">'th√°ng'</span>, <span class="st">'ng√†y'</span>, <span class="st">'k·ª≥'</span>,</span>
<span id="cb33-263"><a href="#cb33-263" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vi·ªát_nam'</span>, <span class="st">'t·ªïng'</span>, <span class="st">'gi√°_tr·ªã'</span>, <span class="st">'tri·ªáu'</span>, <span class="st">'t·ª∑'</span>,</span>
<span id="cb33-264"><a href="#cb33-264" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-265"><a href="#cb33-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-266"><a href="#cb33-266" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_vietnamese_text(</span>
<span id="cb33-267"><a href="#cb33-267" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb33-268"><a href="#cb33-268" aria-hidden="true" tabindex="-1"></a>    segment: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb33-269"><a href="#cb33-269" aria-hidden="true" tabindex="-1"></a>    remove_stops: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb33-270"><a href="#cb33-270" aria-hidden="true" tabindex="-1"></a>    lowercase: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb33-271"><a href="#cb33-271" aria-hidden="true" tabindex="-1"></a>    min_word_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb33-272"><a href="#cb33-272" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb33-273"><a href="#cb33-273" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-274"><a href="#cb33-274" aria-hidden="true" tabindex="-1"></a><span class="co">    Full Vietnamese text cleaning pipeline.</span></span>
<span id="cb33-275"><a href="#cb33-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-276"><a href="#cb33-276" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb33-277"><a href="#cb33-277" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb33-278"><a href="#cb33-278" aria-hidden="true" tabindex="-1"></a><span class="co">    text : str</span></span>
<span id="cb33-279"><a href="#cb33-279" aria-hidden="true" tabindex="-1"></a><span class="co">        Raw Vietnamese text.</span></span>
<span id="cb33-280"><a href="#cb33-280" aria-hidden="true" tabindex="-1"></a><span class="co">    segment : bool</span></span>
<span id="cb33-281"><a href="#cb33-281" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to perform word segmentation.</span></span>
<span id="cb33-282"><a href="#cb33-282" aria-hidden="true" tabindex="-1"></a><span class="co">    remove_stops : bool</span></span>
<span id="cb33-283"><a href="#cb33-283" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to remove Vietnamese stopwords.</span></span>
<span id="cb33-284"><a href="#cb33-284" aria-hidden="true" tabindex="-1"></a><span class="co">    lowercase : bool</span></span>
<span id="cb33-285"><a href="#cb33-285" aria-hidden="true" tabindex="-1"></a><span class="co">        Whether to convert to lowercase.</span></span>
<span id="cb33-286"><a href="#cb33-286" aria-hidden="true" tabindex="-1"></a><span class="co">    min_word_len : int</span></span>
<span id="cb33-287"><a href="#cb33-287" aria-hidden="true" tabindex="-1"></a><span class="co">        Minimum word length to keep.</span></span>
<span id="cb33-288"><a href="#cb33-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-289"><a href="#cb33-289" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb33-290"><a href="#cb33-290" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb33-291"><a href="#cb33-291" aria-hidden="true" tabindex="-1"></a><span class="co">    str</span></span>
<span id="cb33-292"><a href="#cb33-292" aria-hidden="true" tabindex="-1"></a><span class="co">        Cleaned text.</span></span>
<span id="cb33-293"><a href="#cb33-293" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-294"><a href="#cb33-294" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb33-295"><a href="#cb33-295" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb33-296"><a href="#cb33-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-297"><a href="#cb33-297" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Unicode normalization (NFC form for Vietnamese)</span></span>
<span id="cb33-298"><a href="#cb33-298" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> unicodedata.normalize(<span class="st">'NFC'</span>, text)</span>
<span id="cb33-299"><a href="#cb33-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-300"><a href="#cb33-300" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Remove HTML tags and special characters</span></span>
<span id="cb33-301"><a href="#cb33-301" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'&lt;</span><span class="pp">[^&gt;]</span><span class="op">+</span><span class="vs">&gt;'</span>, <span class="st">' '</span>, text)</span>
<span id="cb33-302"><a href="#cb33-302" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[</span><span class="dv">\d</span><span class="pp">]</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, text)           <span class="co"># Remove numbers</span></span>
<span id="cb33-303"><a href="#cb33-303" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^</span><span class="dv">\w\s</span><span class="ch">\u00C0</span><span class="pp">-</span><span class="ch">\u024F</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">' '</span>, text)  <span class="co"># Keep VN chars</span></span>
<span id="cb33-304"><a href="#cb33-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-305"><a href="#cb33-305" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Lowercase</span></span>
<span id="cb33-306"><a href="#cb33-306" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> lowercase:</span>
<span id="cb33-307"><a href="#cb33-307" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> text.lower()</span>
<span id="cb33-308"><a href="#cb33-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-309"><a href="#cb33-309" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Word segmentation</span></span>
<span id="cb33-310"><a href="#cb33-310" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> segment:</span>
<span id="cb33-311"><a href="#cb33-311" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> word_tokenize(text, <span class="bu">format</span><span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb33-312"><a href="#cb33-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-313"><a href="#cb33-313" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Tokenize and filter</span></span>
<span id="cb33-314"><a href="#cb33-314" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb33-315"><a href="#cb33-315" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> remove_stops:</span>
<span id="cb33-316"><a href="#cb33-316" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens</span>
<span id="cb33-317"><a href="#cb33-317" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">if</span> t <span class="kw">not</span> <span class="kw">in</span> VIETNAMESE_STOPWORDS</span>
<span id="cb33-318"><a href="#cb33-318" aria-hidden="true" tabindex="-1"></a>                  <span class="kw">and</span> <span class="bu">len</span>(t) <span class="op">&gt;=</span> min_word_len]</span>
<span id="cb33-319"><a href="#cb33-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-320"><a href="#cb33-320" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">' '</span>.join(tokens)</span>
<span id="cb33-321"><a href="#cb33-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-322"><a href="#cb33-322" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to corpus</span></span>
<span id="cb33-323"><a href="#cb33-323" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'text_clean'</span>] <span class="op">=</span> (</span>
<span id="cb33-324"><a href="#cb33-324" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_vi</span>
<span id="cb33-325"><a href="#cb33-325" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: clean_vietnamese_text(x))</span>
<span id="cb33-326"><a href="#cb33-326" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-327"><a href="#cb33-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-328"><a href="#cb33-328" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify cleaning quality</span></span>
<span id="cb33-329"><a href="#cb33-329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sample cleaned text:'</span>)</span>
<span id="cb33-330"><a href="#cb33-330" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus_df.iloc[<span class="dv">0</span>].text_clean[:<span class="dv">300</span>])</span>
<span id="cb33-331"><a href="#cb33-331" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-332"><a href="#cb33-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-333"><a href="#cb33-333" aria-hidden="true" tabindex="-1"></a><span class="fu">## English Text Cleaning {#sec-textual-english-cleaning}</span></span>
<span id="cb33-334"><a href="#cb33-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-335"><a href="#cb33-335" aria-hidden="true" tabindex="-1"></a>For firms that also provide English business descriptions, we apply a standard English NLP pipeline using spaCy and NLTK. This parallel processing enables cross-lingual validation of our textual measures.</span>
<span id="cb33-336"><a href="#cb33-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-339"><a href="#cb33-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-340"><a href="#cb33-340" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: english-cleaning</span></span>
<span id="cb33-341"><a href="#cb33-341" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-342"><a href="#cb33-342" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "English text cleaning pipeline"</span></span>
<span id="cb33-343"><a href="#cb33-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-344"><a href="#cb33-344" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb33-345"><a href="#cb33-345" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb33-346"><a href="#cb33-346" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb33-347"><a href="#cb33-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-348"><a href="#cb33-348" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">'en_core_web_sm'</span>, disable<span class="op">=</span>[<span class="st">'parser'</span>, <span class="st">'ner'</span>])</span>
<span id="cb33-349"><a href="#cb33-349" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb33-350"><a href="#cb33-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-351"><a href="#cb33-351" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_english_text(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb33-352"><a href="#cb33-352" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Clean English text with lemmatization."""</span></span>
<span id="cb33-353"><a href="#cb33-353" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isna(text) <span class="kw">or</span> text.strip() <span class="op">==</span> <span class="st">''</span>:</span>
<span id="cb33-354"><a href="#cb33-354" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">''</span></span>
<span id="cb33-355"><a href="#cb33-355" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower().strip()</span>
<span id="cb33-356"><a href="#cb33-356" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-zA-Z</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">' '</span>, text)</span>
<span id="cb33-357"><a href="#cb33-357" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb33-358"><a href="#cb33-358" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> [token.lemma_ <span class="cf">for</span> token <span class="kw">in</span> doc</span>
<span id="cb33-359"><a href="#cb33-359" aria-hidden="true" tabindex="-1"></a>              <span class="cf">if</span> token.lemma_ <span class="kw">not</span> <span class="kw">in</span> stop_words</span>
<span id="cb33-360"><a href="#cb33-360" aria-hidden="true" tabindex="-1"></a>              <span class="kw">and</span> <span class="bu">len</span>(token.lemma_) <span class="op">&gt;</span> <span class="dv">2</span></span>
<span id="cb33-361"><a href="#cb33-361" aria-hidden="true" tabindex="-1"></a>              <span class="kw">and</span> <span class="kw">not</span> token.is_punct]</span>
<span id="cb33-362"><a href="#cb33-362" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">' '</span>.join(tokens)</span>
<span id="cb33-363"><a href="#cb33-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-364"><a href="#cb33-364" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to English descriptions</span></span>
<span id="cb33-365"><a href="#cb33-365" aria-hidden="true" tabindex="-1"></a>corpus_df[<span class="st">'text_clean_en'</span>] <span class="op">=</span> (</span>
<span id="cb33-366"><a href="#cb33-366" aria-hidden="true" tabindex="-1"></a>    corpus_df.bus_desc_en</span>
<span id="cb33-367"><a href="#cb33-367" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: clean_english_text(x))</span>
<span id="cb33-368"><a href="#cb33-368" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-369"><a href="#cb33-369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-370"><a href="#cb33-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-371"><a href="#cb33-371" aria-hidden="true" tabindex="-1"></a><span class="fu"># Document Representation: Bag-of-Words and TF-IDF {#sec-textual-bow-tfidf}</span></span>
<span id="cb33-372"><a href="#cb33-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-373"><a href="#cb33-373" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bag-of-Words Representation {#sec-textual-bow}</span></span>
<span id="cb33-374"><a href="#cb33-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-375"><a href="#cb33-375" aria-hidden="true" tabindex="-1"></a>The bag-of-words (BoW) model represents each document as a vector of word frequencies, discarding word order. Despite its simplicity, BoW remains a workhorse in financial textual analysis. Formally, given a vocabulary $V = <span class="sc">\{</span>w_1, w_2, \ldots, w_{|V|}<span class="sc">\}</span>$, document $d$ is represented as a vector $\mathbf{x}_d$ where each element $x_{d,j}$ counts the frequency of word $w_j$ in document $d$:</span>
<span id="cb33-376"><a href="#cb33-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-377"><a href="#cb33-377" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb33-378"><a href="#cb33-378" aria-hidden="true" tabindex="-1"></a>\mathbf{x}_d = [\text{tf}(w_1, d), \; \text{tf}(w_2, d), \; \ldots, \; \text{tf}(w_{|V|}, d)]</span>
<span id="cb33-379"><a href="#cb33-379" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bow}</span>
<span id="cb33-380"><a href="#cb33-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-381"><a href="#cb33-381" aria-hidden="true" tabindex="-1"></a>where $\text{tf}(w, d)$ is the term frequency of word $w$ in document $d$.</span>
<span id="cb33-382"><a href="#cb33-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-385"><a href="#cb33-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-386"><a href="#cb33-386" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: bow-vectorization</span></span>
<span id="cb33-387"><a href="#cb33-387" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Bag-of-Words vectorization"</span></span>
<span id="cb33-388"><a href="#cb33-388" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-389"><a href="#cb33-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-390"><a href="#cb33-390" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> (</span>
<span id="cb33-391"><a href="#cb33-391" aria-hidden="true" tabindex="-1"></a>    CountVectorizer, TfidfVectorizer</span>
<span id="cb33-392"><a href="#cb33-392" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-393"><a href="#cb33-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-394"><a href="#cb33-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese corpus</span></span>
<span id="cb33-395"><a href="#cb33-395" aria-hidden="true" tabindex="-1"></a>text_corpus <span class="op">=</span> corpus_df.text_clean.tolist()</span>
<span id="cb33-396"><a href="#cb33-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-397"><a href="#cb33-397" aria-hidden="true" tabindex="-1"></a><span class="co"># BoW vectorization</span></span>
<span id="cb33-398"><a href="#cb33-398" aria-hidden="true" tabindex="-1"></a>bow_vectorizer <span class="op">=</span> CountVectorizer(</span>
<span id="cb33-399"><a href="#cb33-399" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb33-400"><a href="#cb33-400" aria-hidden="true" tabindex="-1"></a>    min_df<span class="op">=</span><span class="dv">5</span>,           <span class="co"># Appear in at least 5 documents</span></span>
<span id="cb33-401"><a href="#cb33-401" aria-hidden="true" tabindex="-1"></a>    max_df<span class="op">=</span><span class="fl">0.95</span>,        <span class="co"># Exclude terms in &gt;95% of docs</span></span>
<span id="cb33-402"><a href="#cb33-402" aria-hidden="true" tabindex="-1"></a>    ngram_range<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># Unigrams and bigrams</span></span>
<span id="cb33-403"><a href="#cb33-403" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-404"><a href="#cb33-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-405"><a href="#cb33-405" aria-hidden="true" tabindex="-1"></a>bow_matrix <span class="op">=</span> bow_vectorizer.fit_transform(text_corpus)</span>
<span id="cb33-406"><a href="#cb33-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-407"><a href="#cb33-407" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(bow_vectorizer.vocabulary_)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-408"><a href="#cb33-408" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Document-term matrix shape: </span><span class="sc">{</span>bow_matrix<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-409"><a href="#cb33-409" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Sparsity: </span><span class="sc">{</span><span class="dv">1</span> <span class="op">-</span> bow_matrix<span class="sc">.</span>nnz <span class="op">/</span> np<span class="sc">.</span>prod(bow_matrix.shape)<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb33-410"><a href="#cb33-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-411"><a href="#cb33-411" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 20 most frequent terms</span></span>
<span id="cb33-412"><a href="#cb33-412" aria-hidden="true" tabindex="-1"></a>word_freq <span class="op">=</span> pd.DataFrame({</span>
<span id="cb33-413"><a href="#cb33-413" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span>: bow_vectorizer.get_feature_names_out(),</span>
<span id="cb33-414"><a href="#cb33-414" aria-hidden="true" tabindex="-1"></a>    <span class="st">'freq'</span>: bow_matrix.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb33-415"><a href="#cb33-415" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'freq'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb33-416"><a href="#cb33-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-417"><a href="#cb33-417" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Top 20 most frequent terms:'</span>)</span>
<span id="cb33-418"><a href="#cb33-418" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(word_freq.head(<span class="dv">20</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb33-419"><a href="#cb33-419" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-420"><a href="#cb33-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-423"><a href="#cb33-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-424"><a href="#cb33-424" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-word-freq</span></span>
<span id="cb33-425"><a href="#cb33-425" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Top 20 Most Frequent Terms in Vietnamese Business Descriptions"</span></span>
<span id="cb33-426"><a href="#cb33-426" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Plot word frequency distribution"</span></span>
<span id="cb33-427"><a href="#cb33-427" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-428"><a href="#cb33-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-429"><a href="#cb33-429" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb33-430"><a href="#cb33-430" aria-hidden="true" tabindex="-1"></a>top20 <span class="op">=</span> word_freq.head(<span class="dv">20</span>)</span>
<span id="cb33-431"><a href="#cb33-431" aria-hidden="true" tabindex="-1"></a>ax.barh(<span class="bu">range</span>(<span class="bu">len</span>(top20)), top20.freq.values, color<span class="op">=</span><span class="st">'#2C5282'</span>)</span>
<span id="cb33-432"><a href="#cb33-432" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(<span class="bu">range</span>(<span class="bu">len</span>(top20)))</span>
<span id="cb33-433"><a href="#cb33-433" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels(top20.word.values)</span>
<span id="cb33-434"><a href="#cb33-434" aria-hidden="true" tabindex="-1"></a>ax.invert_yaxis()</span>
<span id="cb33-435"><a href="#cb33-435" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Frequency'</span>)</span>
<span id="cb33-436"><a href="#cb33-436" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Top 20 Most Frequent Terms in Vietnamese Business Descriptions'</span>)</span>
<span id="cb33-437"><a href="#cb33-437" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-438"><a href="#cb33-438" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-439"><a href="#cb33-439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-440"><a href="#cb33-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-441"><a href="#cb33-441" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>  <span class="sc">\#</span> <span class="pp">|</span> Term (VN)   <span class="pp">|</span>  Freq <span class="pp">|</span>  <span class="sc">\#</span> <span class="pp">|</span> Term (VN) <span class="pp">|</span>  Freq <span class="pp">|</span>  <span class="sc">\#</span> <span class="pp">|</span> Term (VN)    <span class="pp">|</span>  Freq <span class="pp">|</span></span>
<span id="cb33-442"><a href="#cb33-442" aria-hidden="true" tabindex="-1"></a><span class="pp">|----:|:------------|------:|----:|:----------|------:|----:|:-------------|------:|</span></span>
<span id="cb33-443"><a href="#cb33-443" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   1 <span class="pp">|</span> s·∫£n_xu·∫•t    <span class="pp">|</span> 4,287 <span class="pp">|</span>   8 <span class="pp">|</span> c√¥ng_ngh·ªá <span class="pp">|</span> 1,956 <span class="pp">|</span>  15 <span class="pp">|</span> xu·∫•t_kh·∫©u    <span class="pp">|</span> 1,123 <span class="pp">|</span></span>
<span id="cb33-444"><a href="#cb33-444" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   2 <span class="pp">|</span> kinh_doanh  <span class="pp">|</span> 3,891 <span class="pp">|</span>   9 <span class="pp">|</span> t√†i_ch√≠nh <span class="pp">|</span> 1,845 <span class="pp">|</span>  16 <span class="pp">|</span> b·∫•t_ƒë·ªông_s·∫£n <span class="pp">|</span> 1,087 <span class="pp">|</span></span>
<span id="cb33-445"><a href="#cb33-445" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   3 <span class="pp">|</span> d·ªãch_v·ª•     <span class="pp">|</span> 3,654 <span class="pp">|</span>  10 <span class="pp">|</span> ng√¢n_h√†ng <span class="pp">|</span> 1,734 <span class="pp">|</span>  17 <span class="pp">|</span> nƒÉng_l∆∞·ª£ng   <span class="pp">|</span> 1,045 <span class="pp">|</span></span>
<span id="cb33-446"><a href="#cb33-446" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   4 <span class="pp">|</span> c√¥ng_ty     <span class="pp">|</span> 3,412 <span class="pp">|</span>  11 <span class="pp">|</span> ƒë·∫ßu_t∆∞    <span class="pp">|</span> 1,623 <span class="pp">|</span>  18 <span class="pp">|</span> b·∫£o_hi·ªÉm     <span class="pp">|</span>   987 <span class="pp">|</span></span>
<span id="cb33-447"><a href="#cb33-447" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   5 <span class="pp">|</span> th∆∞∆°ng_m·∫°i  <span class="pp">|</span> 2,876 <span class="pp">|</span>  12 <span class="pp">|</span> x√¢y_d·ª±ng  <span class="pp">|</span> 1,534 <span class="pp">|</span>  19 <span class="pp">|</span> du_l·ªãch      <span class="pp">|</span>   923 <span class="pp">|</span></span>
<span id="cb33-448"><a href="#cb33-448" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   6 <span class="pp">|</span> c·ªï_ph·∫ßn     <span class="pp">|</span> 2,543 <span class="pp">|</span>  13 <span class="pp">|</span> v·∫≠n_t·∫£i   <span class="pp">|</span> 1,345 <span class="pp">|</span>  20 <span class="pp">|</span> vi·ªÖn_th√¥ng   <span class="pp">|</span>   876 <span class="pp">|</span></span>
<span id="cb33-449"><a href="#cb33-449" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   7 <span class="pp">|</span> ch·ª©ng_kho√°n <span class="pp">|</span> 2,134 <span class="pp">|</span>  14 <span class="pp">|</span> th·ª±c_ph·∫©m <span class="pp">|</span> 1,234 <span class="pp">|</span>     <span class="pp">|</span>              <span class="pp">|</span>       <span class="pp">|</span></span>
<span id="cb33-450"><a href="#cb33-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-451"><a href="#cb33-451" aria-hidden="true" tabindex="-1"></a>: Top 20 Most Frequent Terms in Vietnamese Business Descriptions {#tbl-top-terms}</span>
<span id="cb33-452"><a href="#cb33-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-453"><a href="#cb33-453" aria-hidden="true" tabindex="-1"></a><span class="fu">## TF-IDF Weighting {#sec-textual-tfidf}</span></span>
<span id="cb33-454"><a href="#cb33-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-455"><a href="#cb33-455" aria-hidden="true" tabindex="-1"></a>Term Frequency-Inverse Document Frequency (TF-IDF) addresses a key limitation of raw term counts by downweighting terms that appear in many documents (and thus carry less discriminative information). The TF-IDF weight of term $w$ in document $d$ within corpus $D$ is:</span>
<span id="cb33-456"><a href="#cb33-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-457"><a href="#cb33-457" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb33-458"><a href="#cb33-458" aria-hidden="true" tabindex="-1"></a>\text{tfidf}(w, d, D) = \text{tf}(w, d) \times \log\left(\frac{|D|}{\text{df}(w, D)}\right)</span>
<span id="cb33-459"><a href="#cb33-459" aria-hidden="true" tabindex="-1"></a>$$ {#eq-tfidf}</span>
<span id="cb33-460"><a href="#cb33-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-461"><a href="#cb33-461" aria-hidden="true" tabindex="-1"></a>where $|D|$ is the total number of documents and $\text{df}(w, D)$ is the number of documents containing term $w$. This weighting scheme ensures that industry-specific terminology (e.g., "khai_kho√°ng" for mining, "d∆∞·ª£c_ph·∫©m" for pharmaceuticals) receives higher weight than ubiquitous corporate jargon.</span>
<span id="cb33-462"><a href="#cb33-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-465"><a href="#cb33-465" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-466"><a href="#cb33-466" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tfidf-vectorization</span></span>
<span id="cb33-467"><a href="#cb33-467" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-468"><a href="#cb33-468" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "TF-IDF vectorization with per-industry analysis"</span></span>
<span id="cb33-469"><a href="#cb33-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-470"><a href="#cb33-470" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(</span>
<span id="cb33-471"><a href="#cb33-471" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb33-472"><a href="#cb33-472" aria-hidden="true" tabindex="-1"></a>    min_df<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-473"><a href="#cb33-473" aria-hidden="true" tabindex="-1"></a>    max_df<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb33-474"><a href="#cb33-474" aria-hidden="true" tabindex="-1"></a>    ngram_range<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb33-475"><a href="#cb33-475" aria-hidden="true" tabindex="-1"></a>    sublinear_tf<span class="op">=</span><span class="va">True</span>  <span class="co"># Use 1 + log(tf) instead of raw tf</span></span>
<span id="cb33-476"><a href="#cb33-476" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-477"><a href="#cb33-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-478"><a href="#cb33-478" aria-hidden="true" tabindex="-1"></a>tfidf_matrix <span class="op">=</span> tfidf_vectorizer.fit_transform(text_corpus)</span>
<span id="cb33-479"><a href="#cb33-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-480"><a href="#cb33-480" aria-hidden="true" tabindex="-1"></a><span class="co"># Per-industry top TF-IDF terms</span></span>
<span id="cb33-481"><a href="#cb33-481" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> industry <span class="kw">in</span> [<span class="st">'Ng√¢n h√†ng'</span>, <span class="st">'B·∫•t ƒë·ªông s·∫£n'</span>,</span>
<span id="cb33-482"><a href="#cb33-482" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'C√¥ng ngh·ªá th√¥ng tin'</span>]:</span>
<span id="cb33-483"><a href="#cb33-483" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> corpus_df.icb_sector <span class="op">==</span> industry</span>
<span id="cb33-484"><a href="#cb33-484" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mask.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb33-485"><a href="#cb33-485" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb33-486"><a href="#cb33-486" aria-hidden="true" tabindex="-1"></a>    mean_tfidf <span class="op">=</span> tfidf_matrix[mask.values].mean(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb33-487"><a href="#cb33-487" aria-hidden="true" tabindex="-1"></a>    top_idx <span class="op">=</span> mean_tfidf.argsort()[<span class="op">-</span><span class="dv">10</span>:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb33-488"><a href="#cb33-488" aria-hidden="true" tabindex="-1"></a>    terms <span class="op">=</span> tfidf_vectorizer.get_feature_names_out()</span>
<span id="cb33-489"><a href="#cb33-489" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="sc">{</span>industry<span class="sc">}</span><span class="ss">:'</span>)</span>
<span id="cb33-490"><a href="#cb33-490" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb33-491"><a href="#cb33-491" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'  </span><span class="sc">{</span>terms[idx]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>mean_tfidf[idx]<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb33-492"><a href="#cb33-492" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-493"><a href="#cb33-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-496"><a href="#cb33-496" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-497"><a href="#cb33-497" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tfidf-heatmap</span></span>
<span id="cb33-498"><a href="#cb33-498" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "TF-IDF Heatmap: Top Terms by ICB Sector"</span></span>
<span id="cb33-499"><a href="#cb33-499" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-500"><a href="#cb33-500" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Visualize industry-distinctive terms"</span></span>
<span id="cb33-501"><a href="#cb33-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-502"><a href="#cb33-502" aria-hidden="true" tabindex="-1"></a><span class="co"># Build industry x term TF-IDF matrix for top sectors</span></span>
<span id="cb33-503"><a href="#cb33-503" aria-hidden="true" tabindex="-1"></a>top_sectors <span class="op">=</span> corpus_df.icb_sector.value_counts().head(<span class="dv">8</span>).index.tolist()</span>
<span id="cb33-504"><a href="#cb33-504" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> tfidf_vectorizer.get_feature_names_out()</span>
<span id="cb33-505"><a href="#cb33-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-506"><a href="#cb33-506" aria-hidden="true" tabindex="-1"></a>sector_tfidf <span class="op">=</span> {}</span>
<span id="cb33-507"><a href="#cb33-507" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sector <span class="kw">in</span> top_sectors:</span>
<span id="cb33-508"><a href="#cb33-508" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> corpus_df.icb_sector <span class="op">==</span> sector</span>
<span id="cb33-509"><a href="#cb33-509" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mask.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb33-510"><a href="#cb33-510" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb33-511"><a href="#cb33-511" aria-hidden="true" tabindex="-1"></a>    mean_tfidf <span class="op">=</span> tfidf_matrix[mask.values].mean(axis<span class="op">=</span><span class="dv">0</span>).A1</span>
<span id="cb33-512"><a href="#cb33-512" aria-hidden="true" tabindex="-1"></a>    top_idx <span class="op">=</span> mean_tfidf.argsort()[<span class="op">-</span><span class="dv">5</span>:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb33-513"><a href="#cb33-513" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_idx:</span>
<span id="cb33-514"><a href="#cb33-514" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> terms[idx] <span class="kw">not</span> <span class="kw">in</span> sector_tfidf:</span>
<span id="cb33-515"><a href="#cb33-515" aria-hidden="true" tabindex="-1"></a>            sector_tfidf[terms[idx]] <span class="op">=</span> {}</span>
<span id="cb33-516"><a href="#cb33-516" aria-hidden="true" tabindex="-1"></a>        sector_tfidf[terms[idx]][sector] <span class="op">=</span> mean_tfidf[idx]</span>
<span id="cb33-517"><a href="#cb33-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-518"><a href="#cb33-518" aria-hidden="true" tabindex="-1"></a>heatmap_df <span class="op">=</span> pd.DataFrame(sector_tfidf).T.fillna(<span class="dv">0</span>)</span>
<span id="cb33-519"><a href="#cb33-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-520"><a href="#cb33-520" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb33-521"><a href="#cb33-521" aria-hidden="true" tabindex="-1"></a>sns.heatmap(heatmap_df, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.3f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb33-522"><a href="#cb33-522" aria-hidden="true" tabindex="-1"></a>            linewidths<span class="op">=</span><span class="fl">0.5</span>, ax<span class="op">=</span>ax)</span>
<span id="cb33-523"><a href="#cb33-523" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'TF-IDF Heatmap: Industry-Distinctive Terms'</span>)</span>
<span id="cb33-524"><a href="#cb33-524" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'ICB Sector'</span>)</span>
<span id="cb33-525"><a href="#cb33-525" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Term'</span>)</span>
<span id="cb33-526"><a href="#cb33-526" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-527"><a href="#cb33-527" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-528"><a href="#cb33-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-529"><a href="#cb33-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-530"><a href="#cb33-530" aria-hidden="true" tabindex="-1"></a><span class="fu"># Topic Modeling {#sec-textual-topic-modeling}</span></span>
<span id="cb33-531"><a href="#cb33-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-532"><a href="#cb33-532" aria-hidden="true" tabindex="-1"></a><span class="fu">## Latent Dirichlet Allocation (LDA) {#sec-textual-lda}</span></span>
<span id="cb33-533"><a href="#cb33-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-534"><a href="#cb33-534" aria-hidden="true" tabindex="-1"></a>Latent Dirichlet Allocation <span class="co">[</span><span class="ot">@blei2003latent</span><span class="co">]</span> is a generative probabilistic model that discovers latent topics in a corpus. Each document is modeled as a mixture of topics, and each topic is a distribution over words. LDA has been widely applied in finance to identify thematic content in 10-K filings <span class="co">[</span><span class="ot">@dyer2017evolution</span><span class="co">]</span>, earnings calls <span class="co">[</span><span class="ot">@huang2018analyst</span><span class="co">]</span>, and news articles <span class="co">[</span><span class="ot">@bybee2023narrative</span><span class="co">]</span>.</span>
<span id="cb33-535"><a href="#cb33-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-536"><a href="#cb33-536" aria-hidden="true" tabindex="-1"></a>The generative process assumes:</span>
<span id="cb33-537"><a href="#cb33-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-538"><a href="#cb33-538" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>For each topic $k$, draw a word distribution $\boldsymbol{\phi}_k \sim \text{Dir}(\beta)$.</span>
<span id="cb33-539"><a href="#cb33-539" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>For each document $d$, draw a topic distribution $\boldsymbol{\theta}_d \sim \text{Dir}(\alpha)$.</span>
<span id="cb33-540"><a href="#cb33-540" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>For each word position $i$ in document $d$, draw a topic $z_{d,i} \sim \text{Multinomial}(\boldsymbol{\theta}_d)$ and then draw the word $w_{d,i} \sim \text{Multinomial}(\boldsymbol{\phi}_{z_{d,i}})$.</span>
<span id="cb33-541"><a href="#cb33-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-544"><a href="#cb33-544" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-545"><a href="#cb33-545" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lda-model</span></span>
<span id="cb33-546"><a href="#cb33-546" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "LDA topic modeling with grid search over K"</span></span>
<span id="cb33-547"><a href="#cb33-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-548"><a href="#cb33-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-549"><a href="#cb33-549" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb33-550"><a href="#cb33-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-551"><a href="#cb33-551" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search over number of topics</span></span>
<span id="cb33-552"><a href="#cb33-552" aria-hidden="true" tabindex="-1"></a>n_topics_range <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>]</span>
<span id="cb33-553"><a href="#cb33-553" aria-hidden="true" tabindex="-1"></a>perplexity_scores <span class="op">=</span> []</span>
<span id="cb33-554"><a href="#cb33-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-555"><a href="#cb33-555" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_topics <span class="kw">in</span> n_topics_range:</span>
<span id="cb33-556"><a href="#cb33-556" aria-hidden="true" tabindex="-1"></a>    lda <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb33-557"><a href="#cb33-557" aria-hidden="true" tabindex="-1"></a>        n_components<span class="op">=</span>n_topics,</span>
<span id="cb33-558"><a href="#cb33-558" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb33-559"><a href="#cb33-559" aria-hidden="true" tabindex="-1"></a>        learning_method<span class="op">=</span><span class="st">'online'</span>,</span>
<span id="cb33-560"><a href="#cb33-560" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb33-561"><a href="#cb33-561" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb33-562"><a href="#cb33-562" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-563"><a href="#cb33-563" aria-hidden="true" tabindex="-1"></a>    lda.fit(bow_matrix)</span>
<span id="cb33-564"><a href="#cb33-564" aria-hidden="true" tabindex="-1"></a>    perplexity <span class="op">=</span> lda.perplexity(bow_matrix)</span>
<span id="cb33-565"><a href="#cb33-565" aria-hidden="true" tabindex="-1"></a>    perplexity_scores.append({</span>
<span id="cb33-566"><a href="#cb33-566" aria-hidden="true" tabindex="-1"></a>        <span class="st">'n_topics'</span>: n_topics,</span>
<span id="cb33-567"><a href="#cb33-567" aria-hidden="true" tabindex="-1"></a>        <span class="st">'perplexity'</span>: perplexity,</span>
<span id="cb33-568"><a href="#cb33-568" aria-hidden="true" tabindex="-1"></a>        <span class="st">'log_likelihood'</span>: lda.score(bow_matrix)</span>
<span id="cb33-569"><a href="#cb33-569" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb33-570"><a href="#cb33-570" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'K=</span><span class="sc">{</span>n_topics<span class="sc">}</span><span class="ss">: perplexity=</span><span class="sc">{</span>perplexity<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb33-571"><a href="#cb33-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-572"><a href="#cb33-572" aria-hidden="true" tabindex="-1"></a><span class="co"># Select optimal K (e.g., K=20)</span></span>
<span id="cb33-573"><a href="#cb33-573" aria-hidden="true" tabindex="-1"></a>K_OPTIMAL <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb33-574"><a href="#cb33-574" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb33-575"><a href="#cb33-575" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span>K_OPTIMAL,</span>
<span id="cb33-576"><a href="#cb33-576" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb33-577"><a href="#cb33-577" aria-hidden="true" tabindex="-1"></a>    learning_method<span class="op">=</span><span class="st">'online'</span>,</span>
<span id="cb33-578"><a href="#cb33-578" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb33-579"><a href="#cb33-579" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb33-580"><a href="#cb33-580" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-581"><a href="#cb33-581" aria-hidden="true" tabindex="-1"></a>lda_model.fit(bow_matrix)</span>
<span id="cb33-582"><a href="#cb33-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-583"><a href="#cb33-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract topic-word distributions</span></span>
<span id="cb33-584"><a href="#cb33-584" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> bow_vectorizer.get_feature_names_out()</span>
<span id="cb33-585"><a href="#cb33-585" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> topic_idx, topic <span class="kw">in</span> <span class="bu">enumerate</span>(lda_model.components_):</span>
<span id="cb33-586"><a href="#cb33-586" aria-hidden="true" tabindex="-1"></a>    top_words <span class="op">=</span> [feature_names[i]</span>
<span id="cb33-587"><a href="#cb33-587" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> i <span class="kw">in</span> topic.argsort()[:<span class="op">-</span><span class="dv">11</span>:<span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb33-588"><a href="#cb33-588" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Topic </span><span class="sc">{</span>topic_idx<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="st">" | "</span><span class="sc">.</span>join(top_words)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-589"><a href="#cb33-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-590"><a href="#cb33-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-593"><a href="#cb33-593" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-594"><a href="#cb33-594" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-lda-perplexity</span></span>
<span id="cb33-595"><a href="#cb33-595" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "LDA Model Selection: Perplexity vs. Number of Topics"</span></span>
<span id="cb33-596"><a href="#cb33-596" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Plot perplexity scores for topic model selection"</span></span>
<span id="cb33-597"><a href="#cb33-597" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-598"><a href="#cb33-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-599"><a href="#cb33-599" aria-hidden="true" tabindex="-1"></a>perp_df <span class="op">=</span> pd.DataFrame(perplexity_scores)</span>
<span id="cb33-600"><a href="#cb33-600" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb33-601"><a href="#cb33-601" aria-hidden="true" tabindex="-1"></a>ax.plot(perp_df.n_topics, perp_df.perplexity, <span class="st">'o-'</span>, color<span class="op">=</span><span class="st">'#2C5282'</span>,</span>
<span id="cb33-602"><a href="#cb33-602" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb33-603"><a href="#cb33-603" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span>K_OPTIMAL, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb33-604"><a href="#cb33-604" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Selected K=</span><span class="sc">{</span>K_OPTIMAL<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-605"><a href="#cb33-605" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Number of Topics (K)'</span>)</span>
<span id="cb33-606"><a href="#cb33-606" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Perplexity (lower is better)'</span>)</span>
<span id="cb33-607"><a href="#cb33-607" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'LDA Model Selection'</span>)</span>
<span id="cb33-608"><a href="#cb33-608" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb33-609"><a href="#cb33-609" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-610"><a href="#cb33-610" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-611"><a href="#cb33-611" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-612"><a href="#cb33-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-613"><a href="#cb33-613" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Topic <span class="pp">|</span> Interpretation <span class="pp">|</span> Top Words <span class="pp">|</span></span>
<span id="cb33-614"><a href="#cb33-614" aria-hidden="true" tabindex="-1"></a><span class="pp">|------------------:|:------------------------------|:---------------------|</span></span>
<span id="cb33-615"><a href="#cb33-615" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 0 <span class="pp">|</span> Banking &amp; Finance <span class="pp">|</span> <span class="in">`ng√¢n_h√†ng`</span> <span class="sc">\|</span> <span class="in">`t√≠n_d·ª•ng`</span> <span class="sc">\|</span> <span class="in">`cho_vay`</span> <span class="sc">\|</span> <span class="in">`ti·ªÅn_g·ª≠i`</span> <span class="sc">\|</span> <span class="in">`l√£i_su·∫•t`</span> <span class="sc">\|</span> <span class="in">`thanh_to√°n`</span> <span class="sc">\|</span> <span class="in">`t√†i_kho·∫£n`</span> <span class="pp">|</span></span>
<span id="cb33-616"><a href="#cb33-616" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 3 <span class="pp">|</span> Real Estate <span class="pp">|</span> <span class="in">`b·∫•t_ƒë·ªông_s·∫£n`</span> <span class="sc">\|</span> <span class="in">`d·ª±_√°n`</span> <span class="sc">\|</span> <span class="in">`cƒÉn_h·ªô`</span> <span class="sc">\|</span> <span class="in">`khu_ƒë√¥_th·ªã`</span> <span class="sc">\|</span> <span class="in">`x√¢y_d·ª±ng`</span> <span class="sc">\|</span> <span class="in">`nh√†_·ªü`</span> <span class="pp">|</span></span>
<span id="cb33-617"><a href="#cb33-617" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 7 <span class="pp">|</span> Technology <span class="pp">|</span> <span class="in">`c√¥ng_ngh·ªá`</span> <span class="sc">\|</span> <span class="in">`ph·∫ßn_m·ªÅm`</span> <span class="sc">\|</span> <span class="in">`gi·∫£i_ph√°p`</span> <span class="sc">\|</span> <span class="in">`h·ªá_th·ªëng`</span> <span class="sc">\|</span> <span class="in">`s·ªë_h√≥a`</span> <span class="sc">\|</span> <span class="in">`d·ªØ_li·ªáu`</span> <span class="pp">|</span></span>
<span id="cb33-618"><a href="#cb33-618" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 11 <span class="pp">|</span> Manufacturing <span class="pp">|</span> <span class="in">`s·∫£n_xu·∫•t`</span> <span class="sc">\|</span> <span class="in">`nguy√™n_li·ªáu`</span> <span class="sc">\|</span> <span class="in">`nh√†_m√°y`</span> <span class="sc">\|</span> <span class="in">`ch·∫•t_l∆∞·ª£ng`</span> <span class="sc">\|</span> <span class="in">`c√¥ng_su·∫•t`</span> <span class="sc">\|</span> <span class="in">`xu·∫•t_kh·∫©u`</span> <span class="pp">|</span></span>
<span id="cb33-619"><a href="#cb33-619" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 15 <span class="pp">|</span> Securities <span class="pp">|</span> <span class="in">`ch·ª©ng_kho√°n`</span> <span class="sc">\|</span> <span class="in">`m√¥i_gi·ªõi`</span> <span class="sc">\|</span> <span class="in">`ƒë·∫ßu_t∆∞`</span> <span class="sc">\|</span> <span class="in">`c·ªï_phi·∫øu`</span> <span class="sc">\|</span> <span class="in">`danh_m·ª•c`</span> <span class="sc">\|</span> <span class="in">`qu·∫£n_l√Ω_qu·ªπ`</span> <span class="pp">|</span></span>
<span id="cb33-620"><a href="#cb33-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-621"><a href="#cb33-621" aria-hidden="true" tabindex="-1"></a>: Selected LDA Topics from Vietnamese Business Descriptions (K=20) {#tbl-lda-topics}</span>
<span id="cb33-622"><a href="#cb33-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-623"><a href="#cb33-623" aria-hidden="true" tabindex="-1"></a><span class="fu">## BERTopic: Neural Topic Modeling {#sec-textual-bertopic}</span></span>
<span id="cb33-624"><a href="#cb33-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-625"><a href="#cb33-625" aria-hidden="true" tabindex="-1"></a>BERTopic <span class="co">[</span><span class="ot">@grootendorst2022bertopic</span><span class="co">]</span> represents a significant advance over LDA by leveraging pre-trained language model embeddings, dimensionality reduction via UMAP, and hierarchical density-based clustering (HDBSCAN) to discover topics. Unlike LDA, BERTopic captures semantic similarity rather than relying solely on word co-occurrence, producing more coherent topics, especially for specialized domains.</span>
<span id="cb33-626"><a href="#cb33-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-629"><a href="#cb33-629" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-630"><a href="#cb33-630" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: bertopic-model</span></span>
<span id="cb33-631"><a href="#cb33-631" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "BERTopic with PhoBERT embeddings"</span></span>
<span id="cb33-632"><a href="#cb33-632" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-633"><a href="#cb33-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-634"><a href="#cb33-634" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb33-635"><a href="#cb33-635" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb33-636"><a href="#cb33-636" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> umap <span class="im">import</span> UMAP</span>
<span id="cb33-637"><a href="#cb33-637" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hdbscan <span class="im">import</span> HDBSCAN</span>
<span id="cb33-638"><a href="#cb33-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-639"><a href="#cb33-639" aria-hidden="true" tabindex="-1"></a><span class="co"># Use PhoBERT-based sentence transformer for Vietnamese</span></span>
<span id="cb33-640"><a href="#cb33-640" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb33-641"><a href="#cb33-641" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bkai-foundation-models/vietnamese-bi-encoder'</span></span>
<span id="cb33-642"><a href="#cb33-642" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-643"><a href="#cb33-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-644"><a href="#cb33-644" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom UMAP and HDBSCAN for better control</span></span>
<span id="cb33-645"><a href="#cb33-645" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> UMAP(</span>
<span id="cb33-646"><a href="#cb33-646" aria-hidden="true" tabindex="-1"></a>    n_neighbors<span class="op">=</span><span class="dv">15</span>, n_components<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-647"><a href="#cb33-647" aria-hidden="true" tabindex="-1"></a>    min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">'cosine'</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb33-648"><a href="#cb33-648" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-649"><a href="#cb33-649" aria-hidden="true" tabindex="-1"></a>hdbscan_model <span class="op">=</span> HDBSCAN(</span>
<span id="cb33-650"><a href="#cb33-650" aria-hidden="true" tabindex="-1"></a>    min_cluster_size<span class="op">=</span><span class="dv">10</span>, min_samples<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-651"><a href="#cb33-651" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'euclidean'</span>, prediction_data<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-652"><a href="#cb33-652" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-653"><a href="#cb33-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-654"><a href="#cb33-654" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit BERTopic</span></span>
<span id="cb33-655"><a href="#cb33-655" aria-hidden="true" tabindex="-1"></a>topic_model <span class="op">=</span> BERTopic(</span>
<span id="cb33-656"><a href="#cb33-656" aria-hidden="true" tabindex="-1"></a>    embedding_model<span class="op">=</span>embedding_model,</span>
<span id="cb33-657"><a href="#cb33-657" aria-hidden="true" tabindex="-1"></a>    umap_model<span class="op">=</span>umap_model,</span>
<span id="cb33-658"><a href="#cb33-658" aria-hidden="true" tabindex="-1"></a>    hdbscan_model<span class="op">=</span>hdbscan_model,</span>
<span id="cb33-659"><a href="#cb33-659" aria-hidden="true" tabindex="-1"></a>    language<span class="op">=</span><span class="st">'multilingual'</span>,</span>
<span id="cb33-660"><a href="#cb33-660" aria-hidden="true" tabindex="-1"></a>    calculate_probabilities<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-661"><a href="#cb33-661" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-662"><a href="#cb33-662" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-663"><a href="#cb33-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-664"><a href="#cb33-664" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese text (use segmented text for better results)</span></span>
<span id="cb33-665"><a href="#cb33-665" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb33-666"><a href="#cb33-666" aria-hidden="true" tabindex="-1"></a>topics, probs <span class="op">=</span> topic_model.fit_transform(docs)</span>
<span id="cb33-667"><a href="#cb33-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-668"><a href="#cb33-668" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect topics</span></span>
<span id="cb33-669"><a href="#cb33-669" aria-hidden="true" tabindex="-1"></a>topic_info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb33-670"><a href="#cb33-670" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(topic_info.head(<span class="dv">20</span>))</span>
<span id="cb33-671"><a href="#cb33-671" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-672"><a href="#cb33-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-675"><a href="#cb33-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-676"><a href="#cb33-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-bertopic-viz</span></span>
<span id="cb33-677"><a href="#cb33-677" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "BERTopic Document Cluster Visualization (UMAP projection of PhoBERT embeddings, colored by inferred topic). Each point represents a Vietnamese listed firm."</span></span>
<span id="cb33-678"><a href="#cb33-678" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Visualize BERTopic document clusters"</span></span>
<span id="cb33-679"><a href="#cb33-679" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-680"><a href="#cb33-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-681"><a href="#cb33-681" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize topic hierarchy</span></span>
<span id="cb33-682"><a href="#cb33-682" aria-hidden="true" tabindex="-1"></a>fig_hierarchy <span class="op">=</span> topic_model.visualize_hierarchy()</span>
<span id="cb33-683"><a href="#cb33-683" aria-hidden="true" tabindex="-1"></a>fig_hierarchy.show()</span>
<span id="cb33-684"><a href="#cb33-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-685"><a href="#cb33-685" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize document clusters</span></span>
<span id="cb33-686"><a href="#cb33-686" aria-hidden="true" tabindex="-1"></a>fig_docs <span class="op">=</span> topic_model.visualize_documents(</span>
<span id="cb33-687"><a href="#cb33-687" aria-hidden="true" tabindex="-1"></a>    docs, reduced_embeddings<span class="op">=</span>umap_model.embedding_</span>
<span id="cb33-688"><a href="#cb33-688" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-689"><a href="#cb33-689" aria-hidden="true" tabindex="-1"></a>fig_docs.show()</span>
<span id="cb33-690"><a href="#cb33-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-691"><a href="#cb33-691" aria-hidden="true" tabindex="-1"></a><span class="co"># Topic word scores (barchart)</span></span>
<span id="cb33-692"><a href="#cb33-692" aria-hidden="true" tabindex="-1"></a>fig_barchart <span class="op">=</span> topic_model.visualize_barchart(top_n_topics<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-693"><a href="#cb33-693" aria-hidden="true" tabindex="-1"></a>fig_barchart.show()</span>
<span id="cb33-694"><a href="#cb33-694" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-695"><a href="#cb33-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-696"><a href="#cb33-696" aria-hidden="true" tabindex="-1"></a><span class="fu"># Financial Sentiment Analysis {#sec-textual-sentiment}</span></span>
<span id="cb33-697"><a href="#cb33-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-698"><a href="#cb33-698" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dictionary-Based Approach {#sec-textual-dict-sentiment}</span></span>
<span id="cb33-699"><a href="#cb33-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-700"><a href="#cb33-700" aria-hidden="true" tabindex="-1"></a>We construct a Vietnamese financial sentiment lexicon following the methodology of @loughran2011liability. Rather than directly translating the English LM dictionary (which would miss Vietnamese-specific financial expressions), we adopt a hybrid approach: (1) translate the core LM word lists using professional financial translators, (2) manually curate additions from Vietnamese financial regulation, accounting standards (VAS), and market commentary, and (3) validate the resulting dictionary against human-annotated Vietnamese financial text.</span>
<span id="cb33-701"><a href="#cb33-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-702"><a href="#cb33-702" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Category  <span class="pp">|</span> Vietnamese Term <span class="pp">|</span> English Gloss <span class="pp">|</span> Source        <span class="pp">|</span> Count in Corpus <span class="pp">|</span></span>
<span id="cb33-703"><a href="#cb33-703" aria-hidden="true" tabindex="-1"></a><span class="pp">|:----------|:----------------|:--------------|:--------------|----------------:|</span></span>
<span id="cb33-704"><a href="#cb33-704" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Negative  <span class="pp">|</span> <span class="in">`l·ªó`</span>            <span class="pp">|</span> loss          <span class="pp">|</span> LM-translated <span class="pp">|</span>           2,341 <span class="pp">|</span></span>
<span id="cb33-705"><a href="#cb33-705" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Negative  <span class="pp">|</span> <span class="in">`s·ª•t_gi·∫£m`</span>      <span class="pp">|</span> decline       <span class="pp">|</span> Curated       <span class="pp">|</span>           1,876 <span class="pp">|</span></span>
<span id="cb33-706"><a href="#cb33-706" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Negative  <span class="pp">|</span> <span class="in">`n·ª£_x·∫•u`</span>        <span class="pp">|</span> bad debt      <span class="pp">|</span> VAS-specific  <span class="pp">|</span>           1,234 <span class="pp">|</span></span>
<span id="cb33-707"><a href="#cb33-707" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Negative  <span class="pp">|</span> <span class="in">`r·ªßi_ro`</span>        <span class="pp">|</span> risk          <span class="pp">|</span> LM-translated <span class="pp">|</span>           3,567 <span class="pp">|</span></span>
<span id="cb33-708"><a href="#cb33-708" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Positive  <span class="pp">|</span> <span class="in">`tƒÉng_tr∆∞·ªüng`</span>   <span class="pp">|</span> growth        <span class="pp">|</span> LM-translated <span class="pp">|</span>           4,123 <span class="pp">|</span></span>
<span id="cb33-709"><a href="#cb33-709" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Positive  <span class="pp">|</span> <span class="in">`l·ª£i_nhu·∫≠n`</span>     <span class="pp">|</span> profit        <span class="pp">|</span> LM-translated <span class="pp">|</span>           3,891 <span class="pp">|</span></span>
<span id="cb33-710"><a href="#cb33-710" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Positive  <span class="pp">|</span> <span class="in">`hi·ªáu_qu·∫£`</span>      <span class="pp">|</span> efficiency    <span class="pp">|</span> Curated       <span class="pp">|</span>           2,456 <span class="pp">|</span></span>
<span id="cb33-711"><a href="#cb33-711" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Uncertain <span class="pp">|</span> <span class="in">`bi·∫øn_ƒë·ªông`</span>     <span class="pp">|</span> volatility    <span class="pp">|</span> LM-translated <span class="pp">|</span>           1,567 <span class="pp">|</span></span>
<span id="cb33-712"><a href="#cb33-712" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Litigious <span class="pp">|</span> <span class="in">`tranh_ch·∫•p`</span>    <span class="pp">|</span> dispute       <span class="pp">|</span> Legal-VN      <span class="pp">|</span>             876 <span class="pp">|</span></span>
<span id="cb33-713"><a href="#cb33-713" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Litigious <span class="pp">|</span> <span class="in">`kh·ªüi_ki·ªán`</span>     <span class="pp">|</span> lawsuit       <span class="pp">|</span> Legal-VN      <span class="pp">|</span>             234 <span class="pp">|</span></span>
<span id="cb33-714"><a href="#cb33-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-715"><a href="#cb33-715" aria-hidden="true" tabindex="-1"></a>: Vietnamese Financial Sentiment Lexicon: Sample Entries {#tbl-sentiment-lexicon}</span>
<span id="cb33-716"><a href="#cb33-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-719"><a href="#cb33-719" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-720"><a href="#cb33-720" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: dict-sentiment</span></span>
<span id="cb33-721"><a href="#cb33-721" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Dictionary-based financial sentiment scoring"</span></span>
<span id="cb33-722"><a href="#cb33-722" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-723"><a href="#cb33-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-724"><a href="#cb33-724" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Vietnamese financial sentiment lexicon</span></span>
<span id="cb33-725"><a href="#cb33-725" aria-hidden="true" tabindex="-1"></a><span class="co"># sentiment_dict = dc.get_sentiment_lexicon(version='vn_financial_v2')</span></span>
<span id="cb33-726"><a href="#cb33-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-727"><a href="#cb33-727" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively, construct from LM + manual curation</span></span>
<span id="cb33-728"><a href="#cb33-728" aria-hidden="true" tabindex="-1"></a>negative_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb33-729"><a href="#cb33-729" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_negative.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb33-730"><a href="#cb33-730" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-731"><a href="#cb33-731" aria-hidden="true" tabindex="-1"></a>positive_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb33-732"><a href="#cb33-732" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_positive.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb33-733"><a href="#cb33-733" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-734"><a href="#cb33-734" aria-hidden="true" tabindex="-1"></a>uncertain_words <span class="op">=</span> <span class="bu">set</span>(pd.read_csv(</span>
<span id="cb33-735"><a href="#cb33-735" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lexicons/vn_uncertain.txt'</span>, header<span class="op">=</span><span class="va">None</span>)[<span class="dv">0</span>]</span>
<span id="cb33-736"><a href="#cb33-736" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-737"><a href="#cb33-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-738"><a href="#cb33-738" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_sentiment_scores(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-739"><a href="#cb33-739" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-740"><a href="#cb33-740" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute Loughran-McDonald style sentiment scores.</span></span>
<span id="cb33-741"><a href="#cb33-741" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns proportions (word count / total words).</span></span>
<span id="cb33-742"><a href="#cb33-742" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-743"><a href="#cb33-743" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb33-744"><a href="#cb33-744" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(tokens)</span>
<span id="cb33-745"><a href="#cb33-745" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb33-746"><a href="#cb33-746" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">'neg_pct'</span>: <span class="dv">0</span>, <span class="st">'pos_pct'</span>: <span class="dv">0</span>,</span>
<span id="cb33-747"><a href="#cb33-747" aria-hidden="true" tabindex="-1"></a>                <span class="st">'unc_pct'</span>: <span class="dv">0</span>, <span class="st">'net_tone'</span>: <span class="dv">0</span>}</span>
<span id="cb33-748"><a href="#cb33-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-749"><a href="#cb33-749" aria-hidden="true" tabindex="-1"></a>    neg <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> negative_words)</span>
<span id="cb33-750"><a href="#cb33-750" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> positive_words)</span>
<span id="cb33-751"><a href="#cb33-751" aria-hidden="true" tabindex="-1"></a>    unc <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">in</span> uncertain_words)</span>
<span id="cb33-752"><a href="#cb33-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-753"><a href="#cb33-753" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb33-754"><a href="#cb33-754" aria-hidden="true" tabindex="-1"></a>        <span class="st">'neg_pct'</span>: neg <span class="op">/</span> n,</span>
<span id="cb33-755"><a href="#cb33-755" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pos_pct'</span>: pos <span class="op">/</span> n,</span>
<span id="cb33-756"><a href="#cb33-756" aria-hidden="true" tabindex="-1"></a>        <span class="st">'unc_pct'</span>: unc <span class="op">/</span> n,</span>
<span id="cb33-757"><a href="#cb33-757" aria-hidden="true" tabindex="-1"></a>        <span class="st">'net_tone'</span>: (pos <span class="op">-</span> neg) <span class="op">/</span> n</span>
<span id="cb33-758"><a href="#cb33-758" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-759"><a href="#cb33-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-760"><a href="#cb33-760" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to annual report MD&amp;A text</span></span>
<span id="cb33-761"><a href="#cb33-761" aria-hidden="true" tabindex="-1"></a>sentiment_scores <span class="op">=</span> annual_text.text_clean.<span class="bu">apply</span>(</span>
<span id="cb33-762"><a href="#cb33-762" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: pd.Series(compute_sentiment_scores(x))</span>
<span id="cb33-763"><a href="#cb33-763" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-764"><a href="#cb33-764" aria-hidden="true" tabindex="-1"></a>annual_text <span class="op">=</span> pd.concat([annual_text, sentiment_scores], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-765"><a href="#cb33-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-766"><a href="#cb33-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-769"><a href="#cb33-769" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-770"><a href="#cb33-770" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-sentiment-dist</span></span>
<span id="cb33-771"><a href="#cb33-771" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Distribution of Net Sentiment Tone Across Firm-Years"</span></span>
<span id="cb33-772"><a href="#cb33-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-773"><a href="#cb33-773" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Plot sentiment distribution"</span></span>
<span id="cb33-774"><a href="#cb33-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-775"><a href="#cb33-775" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb33-776"><a href="#cb33-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-777"><a href="#cb33-777" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].hist(annual_text.neg_pct, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#E53E3E'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb33-778"><a href="#cb33-778" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb33-779"><a href="#cb33-779" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Negative Word Proportion'</span>)</span>
<span id="cb33-780"><a href="#cb33-780" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Proportion'</span>)</span>
<span id="cb33-781"><a href="#cb33-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-782"><a href="#cb33-782" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].hist(annual_text.pos_pct, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#38A169'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb33-783"><a href="#cb33-783" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb33-784"><a href="#cb33-784" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Positive Word Proportion'</span>)</span>
<span id="cb33-785"><a href="#cb33-785" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Proportion'</span>)</span>
<span id="cb33-786"><a href="#cb33-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-787"><a href="#cb33-787" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(annual_text.net_tone, bins<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'#2C5282'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb33-788"><a href="#cb33-788" aria-hidden="true" tabindex="-1"></a>             edgecolor<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb33-789"><a href="#cb33-789" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Net Tone (Positive - Negative)'</span>)</span>
<span id="cb33-790"><a href="#cb33-790" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Net Tone'</span>)</span>
<span id="cb33-791"><a href="#cb33-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-792"><a href="#cb33-792" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Sentiment Distribution in Vietnamese Annual Reports'</span>,</span>
<span id="cb33-793"><a href="#cb33-793" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-794"><a href="#cb33-794" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-795"><a href="#cb33-795" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-796"><a href="#cb33-796" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-797"><a href="#cb33-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-798"><a href="#cb33-798" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transformer-Based Sentiment Classification {#sec-textual-bert-sentiment}</span></span>
<span id="cb33-799"><a href="#cb33-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-800"><a href="#cb33-800" aria-hidden="true" tabindex="-1"></a>Dictionary approaches are limited by their inability to capture context, negation, and sarcasm. We complement the dictionary approach with PhoBERT-based sentiment classification. We fine-tune PhoBERT v2.</span>
<span id="cb33-801"><a href="#cb33-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-804"><a href="#cb33-804" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-805"><a href="#cb33-805" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: phobert-sentiment</span></span>
<span id="cb33-806"><a href="#cb33-806" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-807"><a href="#cb33-807" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "PhoBERT-based sentiment classification"</span></span>
<span id="cb33-808"><a href="#cb33-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-809"><a href="#cb33-809" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb33-810"><a href="#cb33-810" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb33-811"><a href="#cb33-811" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb33-812"><a href="#cb33-812" aria-hidden="true" tabindex="-1"></a>    pipeline</span>
<span id="cb33-813"><a href="#cb33-813" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-814"><a href="#cb33-814" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-815"><a href="#cb33-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-816"><a href="#cb33-816" aria-hidden="true" tabindex="-1"></a><span class="co"># Load fine-tuned ViFinBERT for sentiment</span></span>
<span id="cb33-817"><a href="#cb33-817" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb33-818"><a href="#cb33-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-819"><a href="#cb33-819" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb33-820"><a href="#cb33-820" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb33-821"><a href="#cb33-821" aria-hidden="true" tabindex="-1"></a>    model_name, num_labels<span class="op">=</span><span class="dv">3</span>  <span class="co"># positive, negative, neutral</span></span>
<span id="cb33-822"><a href="#cb33-822" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-823"><a href="#cb33-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-824"><a href="#cb33-824" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sentiment pipeline</span></span>
<span id="cb33-825"><a href="#cb33-825" aria-hidden="true" tabindex="-1"></a>sentiment_pipe <span class="op">=</span> pipeline(</span>
<span id="cb33-826"><a href="#cb33-826" aria-hidden="true" tabindex="-1"></a>    <span class="st">'text-classification'</span>,</span>
<span id="cb33-827"><a href="#cb33-827" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb33-828"><a href="#cb33-828" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb33-829"><a href="#cb33-829" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span><span class="dv">0</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb33-830"><a href="#cb33-830" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb33-831"><a href="#cb33-831" aria-hidden="true" tabindex="-1"></a>    truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-832"><a href="#cb33-832" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span></span>
<span id="cb33-833"><a href="#cb33-833" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-834"><a href="#cb33-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-835"><a href="#cb33-835" aria-hidden="true" tabindex="-1"></a><span class="co"># For long documents, split into sentences first</span></span>
<span id="cb33-836"><a href="#cb33-836" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> underthesea <span class="im">import</span> sent_tokenize</span>
<span id="cb33-837"><a href="#cb33-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-838"><a href="#cb33-838" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> document_sentiment(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-839"><a href="#cb33-839" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Aggregate sentence-level sentiment for a document."""</span></span>
<span id="cb33-840"><a href="#cb33-840" aria-hidden="true" tabindex="-1"></a>    sentences <span class="op">=</span> sent_tokenize(text)</span>
<span id="cb33-841"><a href="#cb33-841" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> sentences:</span>
<span id="cb33-842"><a href="#cb33-842" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">'bert_pos'</span>: <span class="dv">0</span>, <span class="st">'bert_neg'</span>: <span class="dv">0</span>, <span class="st">'bert_neu'</span>: <span class="dv">0</span>}</span>
<span id="cb33-843"><a href="#cb33-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-844"><a href="#cb33-844" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> sentiment_pipe(sentences[:<span class="dv">100</span>])  <span class="co"># Cap at 100 sents</span></span>
<span id="cb33-845"><a href="#cb33-845" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> [r[<span class="st">'label'</span>] <span class="cf">for</span> r <span class="kw">in</span> results]</span>
<span id="cb33-846"><a href="#cb33-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-847"><a href="#cb33-847" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(labels)</span>
<span id="cb33-848"><a href="#cb33-848" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb33-849"><a href="#cb33-849" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_pos'</span>: labels.count(<span class="st">'POSITIVE'</span>) <span class="op">/</span> n,</span>
<span id="cb33-850"><a href="#cb33-850" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_neg'</span>: labels.count(<span class="st">'NEGATIVE'</span>) <span class="op">/</span> n,</span>
<span id="cb33-851"><a href="#cb33-851" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_neu'</span>: labels.count(<span class="st">'NEUTRAL'</span>) <span class="op">/</span> n,</span>
<span id="cb33-852"><a href="#cb33-852" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bert_tone'</span>: (labels.count(<span class="st">'POSITIVE'</span>) <span class="op">-</span></span>
<span id="cb33-853"><a href="#cb33-853" aria-hidden="true" tabindex="-1"></a>                      labels.count(<span class="st">'NEGATIVE'</span>)) <span class="op">/</span> n</span>
<span id="cb33-854"><a href="#cb33-854" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-855"><a href="#cb33-855" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-856"><a href="#cb33-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-857"><a href="#cb33-857" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Method                  <span class="pp">|</span> Accuracy  <span class="pp">|</span> F1 (Pos)  <span class="pp">|</span> F1 (Neg)  <span class="pp">|</span> F1 (Neutral) <span class="pp">|</span></span>
<span id="cb33-858"><a href="#cb33-858" aria-hidden="true" tabindex="-1"></a><span class="pp">|:------------------------|:---------:|:---------:|:---------:|:------------:|</span></span>
<span id="cb33-859"><a href="#cb33-859" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> VN-LM Dictionary        <span class="pp">|</span>   0.612   <span class="pp">|</span>   0.584   <span class="pp">|</span>   0.637   <span class="pp">|</span>    0.598     <span class="pp">|</span></span>
<span id="cb33-860"><a href="#cb33-860" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> PhoBERT (zero-shot)     <span class="pp">|</span>   0.724   <span class="pp">|</span>   0.698   <span class="pp">|</span>   0.741   <span class="pp">|</span>    0.712     <span class="pp">|</span></span>
<span id="cb33-861"><a href="#cb33-861" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> PhoBERT v2 (fine-tuned) <span class="pp">|</span> **0.831** | **0.812** | **0.847** |  **0.824**   <span class="pp">|</span></span>
<span id="cb33-862"><a href="#cb33-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-863"><a href="#cb33-863" aria-hidden="true" tabindex="-1"></a>: Sentiment Method Comparison: Dictionary vs. PhoBERT on Validation Set (N=500) {#tbl-sentiment-comparison}</span>
<span id="cb33-864"><a href="#cb33-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-865"><a href="#cb33-865" aria-hidden="true" tabindex="-1"></a><span class="fu"># Text-Based Firm Similarity and Peer Identification {#sec-textual-similarity}</span></span>
<span id="cb33-866"><a href="#cb33-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-867"><a href="#cb33-867" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cosine Similarity on TF-IDF Vectors {#sec-textual-tfidf-similarity}</span></span>
<span id="cb33-868"><a href="#cb33-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-869"><a href="#cb33-869" aria-hidden="true" tabindex="-1"></a>Following @hoberg2016text, we compute pairwise cosine similarity between firms based on their business description TF-IDF vectors. For two documents represented as TF-IDF vectors $\mathbf{a}$ and $\mathbf{b}$, cosine similarity is defined as:</span>
<span id="cb33-870"><a href="#cb33-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-871"><a href="#cb33-871" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb33-872"><a href="#cb33-872" aria-hidden="true" tabindex="-1"></a>\cos(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{<span class="sc">\|</span>\mathbf{a}<span class="sc">\|</span> \times <span class="sc">\|</span>\mathbf{b}<span class="sc">\|</span>}</span>
<span id="cb33-873"><a href="#cb33-873" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cosine}</span>
<span id="cb33-874"><a href="#cb33-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-875"><a href="#cb33-875" aria-hidden="true" tabindex="-1"></a>This metric ranges from 0 (completely dissimilar) to 1 (identical content) and is invariant to document length. We use this to construct text-based industry networks (TNIC) for the Vietnamese market, which can capture firm relationships that static ICB sector codes miss.</span>
<span id="cb33-876"><a href="#cb33-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-879"><a href="#cb33-879" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-880"><a href="#cb33-880" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tfidf-similarity</span></span>
<span id="cb33-881"><a href="#cb33-881" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Pairwise TF-IDF cosine similarity"</span></span>
<span id="cb33-882"><a href="#cb33-882" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-883"><a href="#cb33-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-884"><a href="#cb33-884" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb33-885"><a href="#cb33-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-886"><a href="#cb33-886" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute pairwise similarity matrix</span></span>
<span id="cb33-887"><a href="#cb33-887" aria-hidden="true" tabindex="-1"></a>sim_matrix <span class="op">=</span> cosine_similarity(tfidf_matrix)</span>
<span id="cb33-888"><a href="#cb33-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-889"><a href="#cb33-889" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easy lookup</span></span>
<span id="cb33-890"><a href="#cb33-890" aria-hidden="true" tabindex="-1"></a>tickers <span class="op">=</span> corpus_df.ticker.tolist()</span>
<span id="cb33-891"><a href="#cb33-891" aria-hidden="true" tabindex="-1"></a>sim_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb33-892"><a href="#cb33-892" aria-hidden="true" tabindex="-1"></a>    sim_matrix, index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb33-893"><a href="#cb33-893" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-894"><a href="#cb33-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-895"><a href="#cb33-895" aria-hidden="true" tabindex="-1"></a><span class="co"># For each firm, find top-5 most similar peers</span></span>
<span id="cb33-896"><a href="#cb33-896" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_top_peers(ticker: <span class="bu">str</span>, n: <span class="bu">int</span> <span class="op">=</span> <span class="dv">5</span>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb33-897"><a href="#cb33-897" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Return top-n most similar firms by TF-IDF cosine."""</span></span>
<span id="cb33-898"><a href="#cb33-898" aria-hidden="true" tabindex="-1"></a>    sims <span class="op">=</span> sim_df[ticker].drop(ticker).sort_values(</span>
<span id="cb33-899"><a href="#cb33-899" aria-hidden="true" tabindex="-1"></a>        ascending<span class="op">=</span><span class="va">False</span></span>
<span id="cb33-900"><a href="#cb33-900" aria-hidden="true" tabindex="-1"></a>    ).head(n)</span>
<span id="cb33-901"><a href="#cb33-901" aria-hidden="true" tabindex="-1"></a>    peers <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>).loc[sims.index]</span>
<span id="cb33-902"><a href="#cb33-902" aria-hidden="true" tabindex="-1"></a>    peers[<span class="st">'similarity'</span>] <span class="op">=</span> sims.values</span>
<span id="cb33-903"><a href="#cb33-903" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> peers[[<span class="st">'company_name'</span>, <span class="st">'icb_sector'</span>,</span>
<span id="cb33-904"><a href="#cb33-904" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'market_cap'</span>, <span class="st">'similarity'</span>]]</span>
<span id="cb33-905"><a href="#cb33-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-906"><a href="#cb33-906" aria-hidden="true" tabindex="-1"></a><span class="co"># Examples</span></span>
<span id="cb33-907"><a href="#cb33-907" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'VNM'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>, <span class="st">'HPG'</span>]:</span>
<span id="cb33-908"><a href="#cb33-908" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Top peers for </span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss">:'</span>)</span>
<span id="cb33-909"><a href="#cb33-909" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(get_top_peers(ticker))</span>
<span id="cb33-910"><a href="#cb33-910" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-911"><a href="#cb33-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-912"><a href="#cb33-912" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Firm <span class="pp">|</span> ICB Sector  <span class="pp">|</span> Peer 1 <span class="pp">|</span> Peer 1 Sector <span class="pp">|</span> Sim Score <span class="pp">|</span> Same ICB? <span class="pp">|</span></span>
<span id="cb33-913"><a href="#cb33-913" aria-hidden="true" tabindex="-1"></a><span class="pp">|:-----|:------------|:-------|:--------------|:---------:|:---------:|</span></span>
<span id="cb33-914"><a href="#cb33-914" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> VCB  <span class="pp">|</span> Banking     <span class="pp">|</span> BID    <span class="pp">|</span> Banking       <span class="pp">|</span>   0.87    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-915"><a href="#cb33-915" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> VCB  <span class="pp">|</span> Banking     <span class="pp">|</span> CTG    <span class="pp">|</span> Banking       <span class="pp">|</span>   0.84    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-916"><a href="#cb33-916" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> VNM  <span class="pp">|</span> Food &amp; Bev  <span class="pp">|</span> MCH    <span class="pp">|</span> Food &amp; Bev    <span class="pp">|</span>   0.72    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-917"><a href="#cb33-917" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> FPT  <span class="pp">|</span> Technology  <span class="pp">|</span> CMG    <span class="pp">|</span> Technology    <span class="pp">|</span>   0.68    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-918"><a href="#cb33-918" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> VIC  <span class="pp">|</span> Real Estate <span class="pp">|</span> NVL    <span class="pp">|</span> Real Estate   <span class="pp">|</span>   0.74    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-919"><a href="#cb33-919" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> HPG  <span class="pp">|</span> Steel       <span class="pp">|</span> HSG    <span class="pp">|</span> Steel         <span class="pp">|</span>   0.81    <span class="pp">|</span>    Yes    <span class="pp">|</span></span>
<span id="cb33-920"><a href="#cb33-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-921"><a href="#cb33-921" aria-hidden="true" tabindex="-1"></a>: Text-Based Peer Identification: Top Most Similar Firms (TF-IDF Cosine) {#tbl-peers}</span>
<span id="cb33-922"><a href="#cb33-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-925"><a href="#cb33-925" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-926"><a href="#cb33-926" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-similarity-heatmap</span></span>
<span id="cb33-927"><a href="#cb33-927" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Pairwise TF-IDF Cosine Similarity Matrix for Selected Vietnamese Firms"</span></span>
<span id="cb33-928"><a href="#cb33-928" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Visualize similarity matrix"</span></span>
<span id="cb33-929"><a href="#cb33-929" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-930"><a href="#cb33-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-931"><a href="#cb33-931" aria-hidden="true" tabindex="-1"></a>sample_tickers <span class="op">=</span> [<span class="st">'VCB'</span>, <span class="st">'BID'</span>, <span class="st">'CTG'</span>, <span class="st">'VNM'</span>, <span class="st">'MCH'</span>,</span>
<span id="cb33-932"><a href="#cb33-932" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'FPT'</span>, <span class="st">'CMG'</span>, <span class="st">'VIC'</span>, <span class="st">'NVL'</span>, <span class="st">'HPG'</span>,</span>
<span id="cb33-933"><a href="#cb33-933" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'HSG'</span>, <span class="st">'VHM'</span>, <span class="st">'SSI'</span>, <span class="st">'HCM'</span>, <span class="st">'PNJ'</span>]</span>
<span id="cb33-934"><a href="#cb33-934" aria-hidden="true" tabindex="-1"></a>sample_sim <span class="op">=</span> sim_df.loc[sample_tickers, sample_tickers]</span>
<span id="cb33-935"><a href="#cb33-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-936"><a href="#cb33-936" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb33-937"><a href="#cb33-937" aria-hidden="true" tabindex="-1"></a>sns.heatmap(sample_sim, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb33-938"><a href="#cb33-938" aria-hidden="true" tabindex="-1"></a>            vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>, square<span class="op">=</span><span class="va">True</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>, ax<span class="op">=</span>ax)</span>
<span id="cb33-939"><a href="#cb33-939" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Pairwise TF-IDF Cosine Similarity</span><span class="ch">\n</span><span class="st">(Selected Vietnamese Listed Firms)'</span>)</span>
<span id="cb33-940"><a href="#cb33-940" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-941"><a href="#cb33-941" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-942"><a href="#cb33-942" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-943"><a href="#cb33-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-944"><a href="#cb33-944" aria-hidden="true" tabindex="-1"></a><span class="fu">## Embedding-Based Similarity {#sec-textual-embedding-similarity}</span></span>
<span id="cb33-945"><a href="#cb33-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-946"><a href="#cb33-946" aria-hidden="true" tabindex="-1"></a>While TF-IDF cosine similarity captures lexical overlap, it misses semantic similarity. Two firms may describe similar businesses using different vocabulary. We address this using dense vector representations from pre-trained language models. Specifically, we compute document embeddings using Sentence-BERT <span class="co">[</span><span class="ot">@reimers2019sentence</span><span class="co">]</span> with a Vietnamese bi-encoder model.<span class="ot">[^60_textual-3]</span></span>
<span id="cb33-947"><a href="#cb33-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-948"><a href="#cb33-948" aria-hidden="true" tabindex="-1"></a><span class="ot">[^60_textual-3]: </span>@reimers2019sentence demonstrate that sentence-BERT embeddings reduce computation for similarity tasks from 65 hours to 5 seconds on 10,000 sentence pairs.</span>
<span id="cb33-949"><a href="#cb33-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-952"><a href="#cb33-952" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-953"><a href="#cb33-953" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: embedding-similarity</span></span>
<span id="cb33-954"><a href="#cb33-954" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Sentence-BERT embedding-based similarity"</span></span>
<span id="cb33-955"><a href="#cb33-955" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-956"><a href="#cb33-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-957"><a href="#cb33-957" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb33-958"><a href="#cb33-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-959"><a href="#cb33-959" aria-hidden="true" tabindex="-1"></a><span class="co"># Vietnamese sentence transformer</span></span>
<span id="cb33-960"><a href="#cb33-960" aria-hidden="true" tabindex="-1"></a>sbert_model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb33-961"><a href="#cb33-961" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bkai-foundation-models/vietnamese-bi-encoder'</span></span>
<span id="cb33-962"><a href="#cb33-962" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-963"><a href="#cb33-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-964"><a href="#cb33-964" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute embeddings for all firms</span></span>
<span id="cb33-965"><a href="#cb33-965" aria-hidden="true" tabindex="-1"></a>docs_segmented <span class="op">=</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb33-966"><a href="#cb33-966" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> sbert_model.encode(</span>
<span id="cb33-967"><a href="#cb33-967" aria-hidden="true" tabindex="-1"></a>    docs_segmented,</span>
<span id="cb33-968"><a href="#cb33-968" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb33-969"><a href="#cb33-969" aria-hidden="true" tabindex="-1"></a>    show_progress_bar<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-970"><a href="#cb33-970" aria-hidden="true" tabindex="-1"></a>    normalize_embeddings<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-971"><a href="#cb33-971" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-972"><a href="#cb33-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-973"><a href="#cb33-973" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairwise similarity</span></span>
<span id="cb33-974"><a href="#cb33-974" aria-hidden="true" tabindex="-1"></a>embed_sim <span class="op">=</span> cosine_similarity(embeddings)</span>
<span id="cb33-975"><a href="#cb33-975" aria-hidden="true" tabindex="-1"></a>embed_sim_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb33-976"><a href="#cb33-976" aria-hidden="true" tabindex="-1"></a>    embed_sim, index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb33-977"><a href="#cb33-977" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-978"><a href="#cb33-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-979"><a href="#cb33-979" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare TF-IDF vs embedding similarity</span></span>
<span id="cb33-980"><a href="#cb33-980" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>]:</span>
<span id="cb33-981"><a href="#cb33-981" aria-hidden="true" tabindex="-1"></a>    tfidf_peers <span class="op">=</span> sim_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb33-982"><a href="#cb33-982" aria-hidden="true" tabindex="-1"></a>    embed_peers <span class="op">=</span> embed_sim_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb33-983"><a href="#cb33-983" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss"> - TF-IDF peers: </span><span class="sc">{</span>tfidf_peers<span class="sc">.</span>index<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-984"><a href="#cb33-984" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss"> - Embed peers:  </span><span class="sc">{</span>embed_peers<span class="sc">.</span>index<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-985"><a href="#cb33-985" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-986"><a href="#cb33-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-989"><a href="#cb33-989" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-990"><a href="#cb33-990" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tsne-embeddings</span></span>
<span id="cb33-991"><a href="#cb33-991" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "t-SNE Visualization of PhoBERT Sentence Embeddings (colored by ICB sector)"</span></span>
<span id="cb33-992"><a href="#cb33-992" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "t-SNE projection of firm embeddings"</span></span>
<span id="cb33-993"><a href="#cb33-993" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-994"><a href="#cb33-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-995"><a href="#cb33-995" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb33-996"><a href="#cb33-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-997"><a href="#cb33-997" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE projection</span></span>
<span id="cb33-998"><a href="#cb33-998" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb33-999"><a href="#cb33-999" aria-hidden="true" tabindex="-1"></a>            metric<span class="op">=</span><span class="st">'cosine'</span>)</span>
<span id="cb33-1000"><a href="#cb33-1000" aria-hidden="true" tabindex="-1"></a>embeddings_2d <span class="op">=</span> tsne.fit_transform(embeddings)</span>
<span id="cb33-1001"><a href="#cb33-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1002"><a href="#cb33-1002" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb33-1003"><a href="#cb33-1003" aria-hidden="true" tabindex="-1"></a>sectors <span class="op">=</span> corpus_df.icb_sector.values</span>
<span id="cb33-1004"><a href="#cb33-1004" aria-hidden="true" tabindex="-1"></a>unique_sectors <span class="op">=</span> corpus_df.icb_sector.value_counts().head(<span class="dv">10</span>).index</span>
<span id="cb33-1005"><a href="#cb33-1005" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.tab10(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb33-1006"><a href="#cb33-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1007"><a href="#cb33-1007" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, sector <span class="kw">in</span> <span class="bu">enumerate</span>(unique_sectors):</span>
<span id="cb33-1008"><a href="#cb33-1008" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> sectors <span class="op">==</span> sector</span>
<span id="cb33-1009"><a href="#cb33-1009" aria-hidden="true" tabindex="-1"></a>    ax.scatter(embeddings_2d[mask, <span class="dv">0</span>], embeddings_2d[mask, <span class="dv">1</span>],</span>
<span id="cb33-1010"><a href="#cb33-1010" aria-hidden="true" tabindex="-1"></a>               c<span class="op">=</span>[colors[i]], label<span class="op">=</span>sector, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb33-1011"><a href="#cb33-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1012"><a href="#cb33-1012" aria-hidden="true" tabindex="-1"></a>ax.legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="st">'upper left'</span>, fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb33-1013"><a href="#cb33-1013" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'t-SNE of PhoBERT Embeddings by ICB Sector'</span>)</span>
<span id="cb33-1014"><a href="#cb33-1014" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb33-1015"><a href="#cb33-1015" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb33-1016"><a href="#cb33-1016" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-1017"><a href="#cb33-1017" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-1018"><a href="#cb33-1018" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1019"><a href="#cb33-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1020"><a href="#cb33-1020" aria-hidden="true" tabindex="-1"></a><span class="fu">## Doc2Vec {#sec-textual-doc2vec}</span></span>
<span id="cb33-1021"><a href="#cb33-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1022"><a href="#cb33-1022" aria-hidden="true" tabindex="-1"></a>We also implement Doc2Vec <span class="co">[</span><span class="ot">@le2014distributed</span><span class="co">]</span>, which learns fixed-length dense vectors for documents of variable length. Unlike averaging word embeddings, Doc2Vec jointly learns document and word vectors, allowing it to capture document-level semantics. We train Doc2Vec on the Vietnamese business description corpus using the concatenated DBOW+DM approach recommended by @lau2016empirical.</span>
<span id="cb33-1023"><a href="#cb33-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1026"><a href="#cb33-1026" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1027"><a href="#cb33-1027" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: doc2vec</span></span>
<span id="cb33-1028"><a href="#cb33-1028" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Doc2Vec for firm similarity (DBOW + DM ensemble)"</span></span>
<span id="cb33-1029"><a href="#cb33-1029" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1030"><a href="#cb33-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1031"><a href="#cb33-1031" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.doc2vec <span class="im">import</span> Doc2Vec, TaggedDocument</span>
<span id="cb33-1032"><a href="#cb33-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1033"><a href="#cb33-1033" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare tagged documents</span></span>
<span id="cb33-1034"><a href="#cb33-1034" aria-hidden="true" tabindex="-1"></a>tagged_docs <span class="op">=</span> [</span>
<span id="cb33-1035"><a href="#cb33-1035" aria-hidden="true" tabindex="-1"></a>    TaggedDocument(</span>
<span id="cb33-1036"><a href="#cb33-1036" aria-hidden="true" tabindex="-1"></a>        words<span class="op">=</span>text.split(),</span>
<span id="cb33-1037"><a href="#cb33-1037" aria-hidden="true" tabindex="-1"></a>        tags<span class="op">=</span>[ticker]</span>
<span id="cb33-1038"><a href="#cb33-1038" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1039"><a href="#cb33-1039" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text, ticker <span class="kw">in</span> <span class="bu">zip</span>(</span>
<span id="cb33-1040"><a href="#cb33-1040" aria-hidden="true" tabindex="-1"></a>        corpus_df.text_clean.tolist(),</span>
<span id="cb33-1041"><a href="#cb33-1041" aria-hidden="true" tabindex="-1"></a>        corpus_df.ticker.tolist()</span>
<span id="cb33-1042"><a href="#cb33-1042" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1043"><a href="#cb33-1043" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb33-1044"><a href="#cb33-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1045"><a href="#cb33-1045" aria-hidden="true" tabindex="-1"></a><span class="co"># PV-DBOW: paragraph vector with distributed bag of words</span></span>
<span id="cb33-1046"><a href="#cb33-1046" aria-hidden="true" tabindex="-1"></a>d2v_dbow <span class="op">=</span> Doc2Vec(</span>
<span id="cb33-1047"><a href="#cb33-1047" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span><span class="dv">100</span>, dm<span class="op">=</span><span class="dv">0</span>, min_count<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-1048"><a href="#cb33-1048" aria-hidden="true" tabindex="-1"></a>    window<span class="op">=</span><span class="dv">5</span>, epochs<span class="op">=</span><span class="dv">40</span>, workers<span class="op">=</span><span class="dv">4</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb33-1049"><a href="#cb33-1049" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1050"><a href="#cb33-1050" aria-hidden="true" tabindex="-1"></a>d2v_dbow.build_vocab(tagged_docs)</span>
<span id="cb33-1051"><a href="#cb33-1051" aria-hidden="true" tabindex="-1"></a>d2v_dbow.train(</span>
<span id="cb33-1052"><a href="#cb33-1052" aria-hidden="true" tabindex="-1"></a>    tagged_docs,</span>
<span id="cb33-1053"><a href="#cb33-1053" aria-hidden="true" tabindex="-1"></a>    total_examples<span class="op">=</span>d2v_dbow.corpus_count,</span>
<span id="cb33-1054"><a href="#cb33-1054" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>d2v_dbow.epochs</span>
<span id="cb33-1055"><a href="#cb33-1055" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1056"><a href="#cb33-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1057"><a href="#cb33-1057" aria-hidden="true" tabindex="-1"></a><span class="co"># PV-DM: paragraph vector with distributed memory</span></span>
<span id="cb33-1058"><a href="#cb33-1058" aria-hidden="true" tabindex="-1"></a>d2v_dm <span class="op">=</span> Doc2Vec(</span>
<span id="cb33-1059"><a href="#cb33-1059" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span><span class="dv">100</span>, dm<span class="op">=</span><span class="dv">1</span>, min_count<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-1060"><a href="#cb33-1060" aria-hidden="true" tabindex="-1"></a>    window<span class="op">=</span><span class="dv">10</span>, epochs<span class="op">=</span><span class="dv">40</span>, workers<span class="op">=</span><span class="dv">4</span>, seed<span class="op">=</span><span class="dv">42</span></span>
<span id="cb33-1061"><a href="#cb33-1061" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1062"><a href="#cb33-1062" aria-hidden="true" tabindex="-1"></a>d2v_dm.build_vocab(tagged_docs)</span>
<span id="cb33-1063"><a href="#cb33-1063" aria-hidden="true" tabindex="-1"></a>d2v_dm.train(</span>
<span id="cb33-1064"><a href="#cb33-1064" aria-hidden="true" tabindex="-1"></a>    tagged_docs,</span>
<span id="cb33-1065"><a href="#cb33-1065" aria-hidden="true" tabindex="-1"></a>    total_examples<span class="op">=</span>d2v_dm.corpus_count,</span>
<span id="cb33-1066"><a href="#cb33-1066" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>d2v_dm.epochs</span>
<span id="cb33-1067"><a href="#cb33-1067" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1068"><a href="#cb33-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1069"><a href="#cb33-1069" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate DBOW + DM vectors (Lau &amp; Baldwin, 2016)</span></span>
<span id="cb33-1070"><a href="#cb33-1070" aria-hidden="true" tabindex="-1"></a>d2v_vectors <span class="op">=</span> np.hstack([</span>
<span id="cb33-1071"><a href="#cb33-1071" aria-hidden="true" tabindex="-1"></a>    [d2v_dbow.dv[t] <span class="cf">for</span> t <span class="kw">in</span> tickers],</span>
<span id="cb33-1072"><a href="#cb33-1072" aria-hidden="true" tabindex="-1"></a>    [d2v_dm.dv[t] <span class="cf">for</span> t <span class="kw">in</span> tickers]</span>
<span id="cb33-1073"><a href="#cb33-1073" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb33-1074"><a href="#cb33-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1075"><a href="#cb33-1075" aria-hidden="true" tabindex="-1"></a><span class="co"># Most similar firms</span></span>
<span id="cb33-1076"><a href="#cb33-1076" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ticker <span class="kw">in</span> [<span class="st">'VCB'</span>, <span class="st">'FPT'</span>, <span class="st">'VIC'</span>]:</span>
<span id="cb33-1077"><a href="#cb33-1077" aria-hidden="true" tabindex="-1"></a>    sims <span class="op">=</span> d2v_dbow.dv.most_similar(ticker, topn<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb33-1078"><a href="#cb33-1078" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>ticker<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>[(s[<span class="dv">0</span>], <span class="ss">f"</span><span class="sc">{</span>s[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>) <span class="cf">for</span> s <span class="kw">in</span> sims]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-1079"><a href="#cb33-1079" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1080"><a href="#cb33-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1081"><a href="#cb33-1081" aria-hidden="true" tabindex="-1"></a><span class="fu"># Deep Learning Approaches {#sec-textual-deep-learning}</span></span>
<span id="cb33-1082"><a href="#cb33-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1083"><a href="#cb33-1083" aria-hidden="true" tabindex="-1"></a><span class="fu">## PhoBERT Embeddings for Financial Text {#sec-textual-phobert}</span></span>
<span id="cb33-1084"><a href="#cb33-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1085"><a href="#cb33-1085" aria-hidden="true" tabindex="-1"></a>PhoBERT <span class="co">[</span><span class="ot">@nguyen2020phobert</span><span class="co">]</span>, pre-trained on 20GB of Vietnamese text, provides contextualized word embeddings that capture meaning based on surrounding context. Unlike static Word2Vec embeddings where "b·∫£o" always has the same vector regardless of whether it means "insurance" (b·∫£o hi·ªÉm) or "protect" (b·∫£o v·ªá), PhoBERT produces context-dependent representations. We extract <span class="in">`[CLS]`</span> token embeddings as document representations.</span>
<span id="cb33-1086"><a href="#cb33-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1089"><a href="#cb33-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1090"><a href="#cb33-1090" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: phobert-embeddings</span></span>
<span id="cb33-1091"><a href="#cb33-1091" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "PhoBERT document embeddings with chunking strategy"</span></span>
<span id="cb33-1092"><a href="#cb33-1092" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1093"><a href="#cb33-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1094"><a href="#cb33-1094" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModel, AutoTokenizer</span>
<span id="cb33-1095"><a href="#cb33-1095" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-1096"><a href="#cb33-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1097"><a href="#cb33-1097" aria-hidden="true" tabindex="-1"></a><span class="co"># Load PhoBERT</span></span>
<span id="cb33-1098"><a href="#cb33-1098" aria-hidden="true" tabindex="-1"></a>phobert_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb33-1099"><a href="#cb33-1099" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb33-1100"><a href="#cb33-1100" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1101"><a href="#cb33-1101" aria-hidden="true" tabindex="-1"></a>phobert_model <span class="op">=</span> AutoModel.from_pretrained(</span>
<span id="cb33-1102"><a href="#cb33-1102" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vinai/phobert-base-v2'</span></span>
<span id="cb33-1103"><a href="#cb33-1103" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1104"><a href="#cb33-1104" aria-hidden="true" tabindex="-1"></a>phobert_model.<span class="bu">eval</span>()</span>
<span id="cb33-1105"><a href="#cb33-1105" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available()</span>
<span id="cb33-1106"><a href="#cb33-1106" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb33-1107"><a href="#cb33-1107" aria-hidden="true" tabindex="-1"></a>phobert_model.to(device)</span>
<span id="cb33-1108"><a href="#cb33-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1109"><a href="#cb33-1109" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_phobert_embedding(text: <span class="bu">str</span>, max_len: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span>):</span>
<span id="cb33-1110"><a href="#cb33-1110" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract [CLS] embedding from PhoBERT."""</span></span>
<span id="cb33-1111"><a href="#cb33-1111" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> phobert_tokenizer(</span>
<span id="cb33-1112"><a href="#cb33-1112" aria-hidden="true" tabindex="-1"></a>        text, return_tensors<span class="op">=</span><span class="st">'pt'</span>,</span>
<span id="cb33-1113"><a href="#cb33-1113" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_len, truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1114"><a href="#cb33-1114" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-1115"><a href="#cb33-1115" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb33-1116"><a href="#cb33-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1117"><a href="#cb33-1117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb33-1118"><a href="#cb33-1118" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> phobert_model(<span class="op">**</span>inputs)</span>
<span id="cb33-1119"><a href="#cb33-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1120"><a href="#cb33-1120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [CLS] token embedding</span></span>
<span id="cb33-1121"><a href="#cb33-1121" aria-hidden="true" tabindex="-1"></a>    cls_embedding <span class="op">=</span> outputs.last_hidden_state[:, <span class="dv">0</span>, :]</span>
<span id="cb33-1122"><a href="#cb33-1122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cls_embedding.cpu().numpy().flatten()</span>
<span id="cb33-1123"><a href="#cb33-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1124"><a href="#cb33-1124" aria-hidden="true" tabindex="-1"></a><span class="co"># For long documents: chunk + average strategy</span></span>
<span id="cb33-1125"><a href="#cb33-1125" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_long_doc_embedding(</span>
<span id="cb33-1126"><a href="#cb33-1126" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>, chunk_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">256</span>, stride: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb33-1127"><a href="#cb33-1127" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb33-1128"><a href="#cb33-1128" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Handle long documents via chunked averaging."""</span></span>
<span id="cb33-1129"><a href="#cb33-1129" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> phobert_tokenizer.tokenize(text)</span>
<span id="cb33-1130"><a href="#cb33-1130" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> []</span>
<span id="cb33-1131"><a href="#cb33-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1132"><a href="#cb33-1132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(tokens), stride):</span>
<span id="cb33-1133"><a href="#cb33-1133" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> tokens[i:i <span class="op">+</span> chunk_size]</span>
<span id="cb33-1134"><a href="#cb33-1134" aria-hidden="true" tabindex="-1"></a>        chunk_text <span class="op">=</span> phobert_tokenizer.convert_tokens_to_string(</span>
<span id="cb33-1135"><a href="#cb33-1135" aria-hidden="true" tabindex="-1"></a>            chunk</span>
<span id="cb33-1136"><a href="#cb33-1136" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb33-1137"><a href="#cb33-1137" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> get_phobert_embedding(chunk_text)</span>
<span id="cb33-1138"><a href="#cb33-1138" aria-hidden="true" tabindex="-1"></a>        embeddings.append(emb)</span>
<span id="cb33-1139"><a href="#cb33-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1140"><a href="#cb33-1140" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(embeddings, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-1141"><a href="#cb33-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1142"><a href="#cb33-1142" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute embeddings for all firms</span></span>
<span id="cb33-1143"><a href="#cb33-1143" aria-hidden="true" tabindex="-1"></a>phobert_embeddings <span class="op">=</span> np.array([</span>
<span id="cb33-1144"><a href="#cb33-1144" aria-hidden="true" tabindex="-1"></a>    get_long_doc_embedding(text)</span>
<span id="cb33-1145"><a href="#cb33-1145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> corpus_df.bus_desc_segmented.tolist()</span>
<span id="cb33-1146"><a href="#cb33-1146" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb33-1147"><a href="#cb33-1147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1148"><a href="#cb33-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1149"><a href="#cb33-1149" aria-hidden="true" tabindex="-1"></a><span class="fu">## Large Language Model Applications {#sec-textual-llm}</span></span>
<span id="cb33-1150"><a href="#cb33-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1151"><a href="#cb33-1151" aria-hidden="true" tabindex="-1"></a>Recent advances in LLMs open new possibilities for financial textual analysis. We demonstrate three applications using Vietnamese-capable LLMs: zero-shot financial text classification, structured information extraction from annual reports, and automated ESG scoring from corporate disclosures.</span>
<span id="cb33-1152"><a href="#cb33-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1153"><a href="#cb33-1153" aria-hidden="true" tabindex="-1"></a><span class="fu">### Zero-Shot Financial Classification {#sec-textual-zero-shot}</span></span>
<span id="cb33-1154"><a href="#cb33-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1157"><a href="#cb33-1157" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1158"><a href="#cb33-1158" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: llm-zero-shot</span></span>
<span id="cb33-1159"><a href="#cb33-1159" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "LLM zero-shot financial text classification"</span></span>
<span id="cb33-1160"><a href="#cb33-1160" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1161"><a href="#cb33-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1162"><a href="#cb33-1162" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> anthropic  <span class="co"># Or openai, etc.</span></span>
<span id="cb33-1163"><a href="#cb33-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1164"><a href="#cb33-1164" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> anthropic.Anthropic()</span>
<span id="cb33-1165"><a href="#cb33-1165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1166"><a href="#cb33-1166" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_financial_text(</span>
<span id="cb33-1167"><a href="#cb33-1167" aria-hidden="true" tabindex="-1"></a>    text: <span class="bu">str</span>,</span>
<span id="cb33-1168"><a href="#cb33-1168" aria-hidden="true" tabindex="-1"></a>    categories: <span class="bu">list</span> <span class="op">=</span> [</span>
<span id="cb33-1169"><a href="#cb33-1169" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Growth outlook'</span>, <span class="st">'Risk warning'</span>,</span>
<span id="cb33-1170"><a href="#cb33-1170" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Operational update'</span>, <span class="st">'Financial performance'</span>,</span>
<span id="cb33-1171"><a href="#cb33-1171" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Strategic initiative'</span>, <span class="st">'Regulatory compliance'</span></span>
<span id="cb33-1172"><a href="#cb33-1172" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb33-1173"><a href="#cb33-1173" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-1174"><a href="#cb33-1174" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Zero-shot classify Vietnamese financial text."""</span></span>
<span id="cb33-1175"><a href="#cb33-1175" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb33-1176"><a href="#cb33-1176" aria-hidden="true" tabindex="-1"></a><span class="ss">    Classify the following Vietnamese financial text into</span></span>
<span id="cb33-1177"><a href="#cb33-1177" aria-hidden="true" tabindex="-1"></a><span class="ss">    one or more of these categories: </span><span class="sc">{</span>categories<span class="sc">}</span></span>
<span id="cb33-1178"><a href="#cb33-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1179"><a href="#cb33-1179" aria-hidden="true" tabindex="-1"></a><span class="ss">    Also provide:</span></span>
<span id="cb33-1180"><a href="#cb33-1180" aria-hidden="true" tabindex="-1"></a><span class="ss">    1. Sentiment: positive / negative / neutral</span></span>
<span id="cb33-1181"><a href="#cb33-1181" aria-hidden="true" tabindex="-1"></a><span class="ss">    2. Confidence: 0-1</span></span>
<span id="cb33-1182"><a href="#cb33-1182" aria-hidden="true" tabindex="-1"></a><span class="ss">    3. Key entities mentioned</span></span>
<span id="cb33-1183"><a href="#cb33-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1184"><a href="#cb33-1184" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>text[:<span class="dv">2000</span>]<span class="sc">}</span></span>
<span id="cb33-1185"><a href="#cb33-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1186"><a href="#cb33-1186" aria-hidden="true" tabindex="-1"></a><span class="ss">    Respond in JSON format.</span></span>
<span id="cb33-1187"><a href="#cb33-1187" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb33-1188"><a href="#cb33-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1189"><a href="#cb33-1189" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb33-1190"><a href="#cb33-1190" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb33-1191"><a href="#cb33-1191" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb33-1192"><a href="#cb33-1192" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb33-1193"><a href="#cb33-1193" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1194"><a href="#cb33-1194" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.content[<span class="dv">0</span>].text</span>
<span id="cb33-1195"><a href="#cb33-1195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1196"><a href="#cb33-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1197"><a href="#cb33-1197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Structured Information Extraction {#sec-textual-extraction}</span></span>
<span id="cb33-1198"><a href="#cb33-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1201"><a href="#cb33-1201" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1202"><a href="#cb33-1202" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: llm-extraction</span></span>
<span id="cb33-1203"><a href="#cb33-1203" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "LLM structured information extraction from annual reports"</span></span>
<span id="cb33-1204"><a href="#cb33-1204" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1205"><a href="#cb33-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1206"><a href="#cb33-1206" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb33-1207"><a href="#cb33-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1208"><a href="#cb33-1208" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_financial_info(annual_report_text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-1209"><a href="#cb33-1209" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract structured data from Vietnamese annual report."""</span></span>
<span id="cb33-1210"><a href="#cb33-1210" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb33-1211"><a href="#cb33-1211" aria-hidden="true" tabindex="-1"></a><span class="ss">    From the following Vietnamese annual report excerpt,</span></span>
<span id="cb33-1212"><a href="#cb33-1212" aria-hidden="true" tabindex="-1"></a><span class="ss">    extract structured information in JSON format:</span></span>
<span id="cb33-1213"><a href="#cb33-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1214"><a href="#cb33-1214" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">{{</span></span>
<span id="cb33-1215"><a href="#cb33-1215" aria-hidden="true" tabindex="-1"></a><span class="ss">        "revenue_mentioned": true/false,</span></span>
<span id="cb33-1216"><a href="#cb33-1216" aria-hidden="true" tabindex="-1"></a><span class="ss">        "revenue_direction": "increase"/"decrease"/"stable",</span></span>
<span id="cb33-1217"><a href="#cb33-1217" aria-hidden="true" tabindex="-1"></a><span class="ss">        "key_products": [list of main products/services],</span></span>
<span id="cb33-1218"><a href="#cb33-1218" aria-hidden="true" tabindex="-1"></a><span class="ss">        "competitors_mentioned": [list],</span></span>
<span id="cb33-1219"><a href="#cb33-1219" aria-hidden="true" tabindex="-1"></a><span class="ss">        "expansion_plans": "description or null",</span></span>
<span id="cb33-1220"><a href="#cb33-1220" aria-hidden="true" tabindex="-1"></a><span class="ss">        "risk_factors": [list of mentioned risks],</span></span>
<span id="cb33-1221"><a href="#cb33-1221" aria-hidden="true" tabindex="-1"></a><span class="ss">        "esg_mentions": </span><span class="ch">{{</span></span>
<span id="cb33-1222"><a href="#cb33-1222" aria-hidden="true" tabindex="-1"></a><span class="ss">            "environmental": [topics],</span></span>
<span id="cb33-1223"><a href="#cb33-1223" aria-hidden="true" tabindex="-1"></a><span class="ss">            "social": [topics],</span></span>
<span id="cb33-1224"><a href="#cb33-1224" aria-hidden="true" tabindex="-1"></a><span class="ss">            "governance": [topics]</span></span>
<span id="cb33-1225"><a href="#cb33-1225" aria-hidden="true" tabindex="-1"></a><span class="ss">        </span><span class="ch">}}</span><span class="ss">,</span></span>
<span id="cb33-1226"><a href="#cb33-1226" aria-hidden="true" tabindex="-1"></a><span class="ss">        "forward_looking_statements": [list],</span></span>
<span id="cb33-1227"><a href="#cb33-1227" aria-hidden="true" tabindex="-1"></a><span class="ss">        "capex_plans": "description or null"</span></span>
<span id="cb33-1228"><a href="#cb33-1228" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">}}</span></span>
<span id="cb33-1229"><a href="#cb33-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1230"><a href="#cb33-1230" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>annual_report_text[:<span class="dv">3000</span>]<span class="sc">}</span></span>
<span id="cb33-1231"><a href="#cb33-1231" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb33-1232"><a href="#cb33-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1233"><a href="#cb33-1233" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb33-1234"><a href="#cb33-1234" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb33-1235"><a href="#cb33-1235" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb33-1236"><a href="#cb33-1236" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb33-1237"><a href="#cb33-1237" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1238"><a href="#cb33-1238" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> json.loads(response.content[<span class="dv">0</span>].text)</span>
<span id="cb33-1239"><a href="#cb33-1239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1240"><a href="#cb33-1240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1241"><a href="#cb33-1241" aria-hidden="true" tabindex="-1"></a><span class="fu">### Automated ESG Scoring {#sec-textual-esg}</span></span>
<span id="cb33-1242"><a href="#cb33-1242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1245"><a href="#cb33-1245" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1246"><a href="#cb33-1246" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: llm-esg</span></span>
<span id="cb33-1247"><a href="#cb33-1247" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "LLM-based ESG scoring from corporate disclosures"</span></span>
<span id="cb33-1248"><a href="#cb33-1248" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1249"><a href="#cb33-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1250"><a href="#cb33-1250" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_esg_scores(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-1251"><a href="#cb33-1251" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Score ESG dimensions from Vietnamese corporate disclosure."""</span></span>
<span id="cb33-1252"><a href="#cb33-1252" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb33-1253"><a href="#cb33-1253" aria-hidden="true" tabindex="-1"></a><span class="ss">    Analyze the following Vietnamese corporate disclosure text</span></span>
<span id="cb33-1254"><a href="#cb33-1254" aria-hidden="true" tabindex="-1"></a><span class="ss">    and score each ESG dimension on a scale of 0-100 based on</span></span>
<span id="cb33-1255"><a href="#cb33-1255" aria-hidden="true" tabindex="-1"></a><span class="ss">    the depth and quality of disclosure:</span></span>
<span id="cb33-1256"><a href="#cb33-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1257"><a href="#cb33-1257" aria-hidden="true" tabindex="-1"></a><span class="ss">    Return JSON:</span></span>
<span id="cb33-1258"><a href="#cb33-1258" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">{{</span></span>
<span id="cb33-1259"><a href="#cb33-1259" aria-hidden="true" tabindex="-1"></a><span class="ss">        "environmental_score": 0-100,</span></span>
<span id="cb33-1260"><a href="#cb33-1260" aria-hidden="true" tabindex="-1"></a><span class="ss">        "environmental_topics": [list of specific topics discussed],</span></span>
<span id="cb33-1261"><a href="#cb33-1261" aria-hidden="true" tabindex="-1"></a><span class="ss">        "social_score": 0-100,</span></span>
<span id="cb33-1262"><a href="#cb33-1262" aria-hidden="true" tabindex="-1"></a><span class="ss">        "social_topics": [list],</span></span>
<span id="cb33-1263"><a href="#cb33-1263" aria-hidden="true" tabindex="-1"></a><span class="ss">        "governance_score": 0-100,</span></span>
<span id="cb33-1264"><a href="#cb33-1264" aria-hidden="true" tabindex="-1"></a><span class="ss">        "governance_topics": [list],</span></span>
<span id="cb33-1265"><a href="#cb33-1265" aria-hidden="true" tabindex="-1"></a><span class="ss">        "overall_esg_score": 0-100,</span></span>
<span id="cb33-1266"><a href="#cb33-1266" aria-hidden="true" tabindex="-1"></a><span class="ss">        "assessment_confidence": 0-1,</span></span>
<span id="cb33-1267"><a href="#cb33-1267" aria-hidden="true" tabindex="-1"></a><span class="ss">        "notable_commitments": [list of specific commitments],</span></span>
<span id="cb33-1268"><a href="#cb33-1268" aria-hidden="true" tabindex="-1"></a><span class="ss">        "gaps_identified": [list of missing ESG disclosures]</span></span>
<span id="cb33-1269"><a href="#cb33-1269" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="ch">}}</span></span>
<span id="cb33-1270"><a href="#cb33-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1271"><a href="#cb33-1271" aria-hidden="true" tabindex="-1"></a><span class="ss">    Text: </span><span class="sc">{</span>text[:<span class="dv">4000</span>]<span class="sc">}</span></span>
<span id="cb33-1272"><a href="#cb33-1272" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb33-1273"><a href="#cb33-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1274"><a href="#cb33-1274" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.messages.create(</span>
<span id="cb33-1275"><a href="#cb33-1275" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">'claude-sonnet-4-20250514'</span>,</span>
<span id="cb33-1276"><a href="#cb33-1276" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">800</span>,</span>
<span id="cb33-1277"><a href="#cb33-1277" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: prompt}]</span>
<span id="cb33-1278"><a href="#cb33-1278" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1279"><a href="#cb33-1279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> json.loads(response.content[<span class="dv">0</span>].text)</span>
<span id="cb33-1280"><a href="#cb33-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1281"><a href="#cb33-1281" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to all firms' annual reports</span></span>
<span id="cb33-1282"><a href="#cb33-1282" aria-hidden="true" tabindex="-1"></a>esg_results <span class="op">=</span> []</span>
<span id="cb33-1283"><a href="#cb33-1283" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> annual_text.iterrows():</span>
<span id="cb33-1284"><a href="#cb33-1284" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb33-1285"><a href="#cb33-1285" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> compute_esg_scores(row.text)</span>
<span id="cb33-1286"><a href="#cb33-1286" aria-hidden="true" tabindex="-1"></a>        scores[<span class="st">'ticker'</span>] <span class="op">=</span> row.ticker</span>
<span id="cb33-1287"><a href="#cb33-1287" aria-hidden="true" tabindex="-1"></a>        scores[<span class="st">'year'</span>] <span class="op">=</span> row.year</span>
<span id="cb33-1288"><a href="#cb33-1288" aria-hidden="true" tabindex="-1"></a>        esg_results.append(scores)</span>
<span id="cb33-1289"><a href="#cb33-1289" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb33-1290"><a href="#cb33-1290" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error for </span><span class="sc">{</span>row<span class="sc">.</span>ticker<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>row<span class="sc">.</span>year<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-1291"><a href="#cb33-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1292"><a href="#cb33-1292" aria-hidden="true" tabindex="-1"></a>esg_df <span class="op">=</span> pd.DataFrame(esg_results)</span>
<span id="cb33-1293"><a href="#cb33-1293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1294"><a href="#cb33-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1295"><a href="#cb33-1295" aria-hidden="true" tabindex="-1"></a><span class="fu"># Empirical Applications {#sec-textual-empirical}</span></span>
<span id="cb33-1296"><a href="#cb33-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1297"><a href="#cb33-1297" aria-hidden="true" tabindex="-1"></a><span class="fu">## Textual Sentiment and Stock Returns {#sec-textual-sentiment-returns}</span></span>
<span id="cb33-1298"><a href="#cb33-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1299"><a href="#cb33-1299" aria-hidden="true" tabindex="-1"></a>We examine whether textual sentiment from annual reports predicts subsequent stock returns, following the methodology of @tetlock2008more. We regress monthly stock returns on lagged sentiment measures while controlling for standard risk factors (market, size, value, momentum) adapted for the Vietnamese market:</span>
<span id="cb33-1300"><a href="#cb33-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1301"><a href="#cb33-1301" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb33-1302"><a href="#cb33-1302" aria-hidden="true" tabindex="-1"></a>R_{i,t} = \alpha + \beta_1 \text{Tone}_{i,t-1} + \beta_2 \text{Uncertainty}_{i,t-1} + \boldsymbol{\gamma}' \mathbf{X}_{i,t-1} + \varepsilon_{i,t}</span>
<span id="cb33-1303"><a href="#cb33-1303" aria-hidden="true" tabindex="-1"></a>$$ {#eq-return-regression}</span>
<span id="cb33-1304"><a href="#cb33-1304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1305"><a href="#cb33-1305" aria-hidden="true" tabindex="-1"></a>where $R_{i,t}$ is the monthly excess return of firm $i$ in month $t$, $\text{Tone}$ is the net sentiment score (positive minus negative word proportion), $\text{Uncertainty}$ is the proportion of uncertain words, and $\mathbf{X}$ is a vector of controls including the Fama-French-Carhart factors adapted for Vietnam (see Chapter on Factor Models).</span>
<span id="cb33-1306"><a href="#cb33-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1309"><a href="#cb33-1309" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1310"><a href="#cb33-1310" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sentiment-return-regression</span></span>
<span id="cb33-1311"><a href="#cb33-1311" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Panel regression: sentiment and stock returns"</span></span>
<span id="cb33-1312"><a href="#cb33-1312" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1313"><a href="#cb33-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1314"><a href="#cb33-1314" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb33-1315"><a href="#cb33-1315" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.panel <span class="im">import</span> PanelOLS</span>
<span id="cb33-1316"><a href="#cb33-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1317"><a href="#cb33-1317" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge sentiment scores with return data</span></span>
<span id="cb33-1318"><a href="#cb33-1318" aria-hidden="true" tabindex="-1"></a>returns <span class="op">=</span> dc.get_monthly_returns(</span>
<span id="cb33-1319"><a href="#cb33-1319" aria-hidden="true" tabindex="-1"></a>    tickers<span class="op">=</span>universe.ticker.tolist(),</span>
<span id="cb33-1320"><a href="#cb33-1320" aria-hidden="true" tabindex="-1"></a>    start<span class="op">=</span><span class="st">'2016-01-01'</span>, end<span class="op">=</span><span class="st">'2024-12-31'</span></span>
<span id="cb33-1321"><a href="#cb33-1321" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1322"><a href="#cb33-1322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1323"><a href="#cb33-1323" aria-hidden="true" tabindex="-1"></a><span class="co"># Panel regression with firm and time fixed effects</span></span>
<span id="cb33-1324"><a href="#cb33-1324" aria-hidden="true" tabindex="-1"></a>panel <span class="op">=</span> annual_text.merge(</span>
<span id="cb33-1325"><a href="#cb33-1325" aria-hidden="true" tabindex="-1"></a>    returns, on<span class="op">=</span>[<span class="st">'ticker'</span>, <span class="st">'year'</span>, <span class="st">'month'</span>]</span>
<span id="cb33-1326"><a href="#cb33-1326" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1327"><a href="#cb33-1327" aria-hidden="true" tabindex="-1"></a>panel <span class="op">=</span> panel.set_index([<span class="st">'ticker'</span>, <span class="st">'date'</span>])</span>
<span id="cb33-1328"><a href="#cb33-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1329"><a href="#cb33-1329" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: Dictionary-based sentiment</span></span>
<span id="cb33-1330"><a href="#cb33-1330" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> PanelOLS(</span>
<span id="cb33-1331"><a href="#cb33-1331" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb33-1332"><a href="#cb33-1332" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb33-1333"><a href="#cb33-1333" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'net_tone'</span>, <span class="st">'unc_pct'</span>, <span class="st">'mkt_rf'</span>,</span>
<span id="cb33-1334"><a href="#cb33-1334" aria-hidden="true" tabindex="-1"></a>               <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb33-1335"><a href="#cb33-1335" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb33-1336"><a href="#cb33-1336" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1337"><a href="#cb33-1337" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-1338"><a href="#cb33-1338" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1339"><a href="#cb33-1339" aria-hidden="true" tabindex="-1"></a>res1 <span class="op">=</span> model1.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb33-1340"><a href="#cb33-1340" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1341"><a href="#cb33-1341" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-1342"><a href="#cb33-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1343"><a href="#cb33-1343" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: BERT-based sentiment</span></span>
<span id="cb33-1344"><a href="#cb33-1344" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> PanelOLS(</span>
<span id="cb33-1345"><a href="#cb33-1345" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb33-1346"><a href="#cb33-1346" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb33-1347"><a href="#cb33-1347" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'bert_tone'</span>, <span class="st">'mkt_rf'</span>,</span>
<span id="cb33-1348"><a href="#cb33-1348" aria-hidden="true" tabindex="-1"></a>               <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb33-1349"><a href="#cb33-1349" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb33-1350"><a href="#cb33-1350" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1351"><a href="#cb33-1351" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-1352"><a href="#cb33-1352" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1353"><a href="#cb33-1353" aria-hidden="true" tabindex="-1"></a>res2 <span class="op">=</span> model2.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb33-1354"><a href="#cb33-1354" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1355"><a href="#cb33-1355" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-1356"><a href="#cb33-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1357"><a href="#cb33-1357" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 3: Combined</span></span>
<span id="cb33-1358"><a href="#cb33-1358" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> PanelOLS(</span>
<span id="cb33-1359"><a href="#cb33-1359" aria-hidden="true" tabindex="-1"></a>    dependent<span class="op">=</span>panel.ret_excess,</span>
<span id="cb33-1360"><a href="#cb33-1360" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>sm.add_constant(</span>
<span id="cb33-1361"><a href="#cb33-1361" aria-hidden="true" tabindex="-1"></a>        panel[[<span class="st">'net_tone'</span>, <span class="st">'unc_pct'</span>, <span class="st">'bert_tone'</span>,</span>
<span id="cb33-1362"><a href="#cb33-1362" aria-hidden="true" tabindex="-1"></a>               <span class="st">'mkt_rf'</span>, <span class="st">'smb'</span>, <span class="st">'hml'</span>, <span class="st">'wml'</span>]]</span>
<span id="cb33-1363"><a href="#cb33-1363" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb33-1364"><a href="#cb33-1364" aria-hidden="true" tabindex="-1"></a>    entity_effects<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1365"><a href="#cb33-1365" aria-hidden="true" tabindex="-1"></a>    time_effects<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-1366"><a href="#cb33-1366" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1367"><a href="#cb33-1367" aria-hidden="true" tabindex="-1"></a>res3 <span class="op">=</span> model3.fit(cov_type<span class="op">=</span><span class="st">'clustered'</span>,</span>
<span id="cb33-1368"><a href="#cb33-1368" aria-hidden="true" tabindex="-1"></a>                  cluster_entity<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-1369"><a href="#cb33-1369" aria-hidden="true" tabindex="-1"></a>                  cluster_time<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-1370"><a href="#cb33-1370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1371"><a href="#cb33-1371" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res1.summary)</span>
<span id="cb33-1372"><a href="#cb33-1372" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res2.summary)</span>
<span id="cb33-1373"><a href="#cb33-1373" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res3.summary)</span>
<span id="cb33-1374"><a href="#cb33-1374" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1375"><a href="#cb33-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1376"><a href="#cb33-1376" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Variable           <span class="pp">|</span> <span class="sc">\(</span>1<span class="sc">\)</span> Dictionary <span class="pp">|</span> <span class="sc">\(</span>2<span class="sc">\)</span> PhoBERT <span class="pp">|</span> <span class="sc">\(</span>3<span class="sc">\)</span> Combined <span class="pp">|</span></span>
<span id="cb33-1377"><a href="#cb33-1377" aria-hidden="true" tabindex="-1"></a><span class="pp">|:-------------------|:----------------:|:-------------:|:--------------:|</span></span>
<span id="cb33-1378"><a href="#cb33-1378" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Net Tone (Dict)    <span class="pp">|</span>    0.0234<span class="sc">\*\*</span>    <span class="pp">|</span>               <span class="pp">|</span>    0.0187<span class="sc">\*</span>    <span class="pp">|</span></span>
<span id="cb33-1379"><a href="#cb33-1379" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>     (0.0098)     <span class="pp">|</span>               <span class="pp">|</span>    (0.0102)    <span class="pp">|</span></span>
<span id="cb33-1380"><a href="#cb33-1380" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Uncertainty (Dict) <span class="pp">|</span>  ‚àí0.0312<span class="sc">\*\*\*</span>   <span class="pp">|</span>               <span class="pp">|</span>  ‚àí0.0278<span class="sc">\*\*</span>   <span class="pp">|</span></span>
<span id="cb33-1381"><a href="#cb33-1381" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>     (0.0087)     <span class="pp">|</span>               <span class="pp">|</span>    (0.0091)    <span class="pp">|</span></span>
<span id="cb33-1382"><a href="#cb33-1382" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> BERT Tone          <span class="pp">|</span>                  <span class="pp">|</span> 0.0456<span class="sc">\*\*\*</span>  <span class="pp">|</span>  0.0389<span class="sc">\*\*\*</span>  <span class="pp">|</span></span>
<span id="cb33-1383"><a href="#cb33-1383" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>                  <span class="pp">|</span>   (0.0112)    <span class="pp">|</span>    (0.0118)    <span class="pp">|</span></span>
<span id="cb33-1384"><a href="#cb33-1384" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> MKT-RF             <span class="pp">|</span>   0.9123<span class="sc">\*\*\*</span>   <span class="pp">|</span> 0.9118<span class="sc">\*\*\*</span>  <span class="pp">|</span>  0.9115<span class="sc">\*\*\*</span>  <span class="pp">|</span></span>
<span id="cb33-1385"><a href="#cb33-1385" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>     (0.0234)     <span class="pp">|</span>   (0.0233)    <span class="pp">|</span>    (0.0234)    <span class="pp">|</span></span>
<span id="cb33-1386"><a href="#cb33-1386" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SMB                <span class="pp">|</span>    0.1245<span class="sc">\*\*</span>    <span class="pp">|</span>  0.1238<span class="sc">\*\*</span>   <span class="pp">|</span>   0.1241<span class="sc">\*\*</span>   <span class="pp">|</span></span>
<span id="cb33-1387"><a href="#cb33-1387" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>     (0.0456)     <span class="pp">|</span>   (0.0455)    <span class="pp">|</span>    (0.0456)    <span class="pp">|</span></span>
<span id="cb33-1388"><a href="#cb33-1388" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> HML                <span class="pp">|</span>     0.0876<span class="sc">\*</span>     <span class="pp">|</span>   0.0871<span class="sc">\*</span>    <span class="pp">|</span>    0.0873<span class="sc">\*</span>    <span class="pp">|</span></span>
<span id="cb33-1389"><a href="#cb33-1389" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>                    <span class="pp">|</span>     (0.0512)     <span class="pp">|</span>   (0.0511)    <span class="pp">|</span>    (0.0512)    <span class="pp">|</span></span>
<span id="cb33-1390"><a href="#cb33-1390" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Firm FE            <span class="pp">|</span>       Yes        <span class="pp">|</span>      Yes      <span class="pp">|</span>      Yes       <span class="pp">|</span></span>
<span id="cb33-1391"><a href="#cb33-1391" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Time FE            <span class="pp">|</span>       Yes        <span class="pp">|</span>      Yes      <span class="pp">|</span>      Yes       <span class="pp">|</span></span>
<span id="cb33-1392"><a href="#cb33-1392" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Clustering         <span class="pp">|</span>     Two-way      <span class="pp">|</span>    Two-way    <span class="pp">|</span>    Two-way     <span class="pp">|</span></span>
<span id="cb33-1393"><a href="#cb33-1393" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> N                  <span class="pp">|</span>      12,456      <span class="pp">|</span>    12,456     <span class="pp">|</span>     12,456     <span class="pp">|</span></span>
<span id="cb33-1394"><a href="#cb33-1394" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> R¬≤ (within)        <span class="pp">|</span>      0.142       <span class="pp">|</span>     0.148     <span class="pp">|</span>     0.153      <span class="pp">|</span></span>
<span id="cb33-1395"><a href="#cb33-1395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1396"><a href="#cb33-1396" aria-hidden="true" tabindex="-1"></a>: Textual Sentiment and Stock Returns: Panel Regression Results {#tbl-regression}</span>
<span id="cb33-1397"><a href="#cb33-1397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1398"><a href="#cb33-1398" aria-hidden="true" tabindex="-1"></a><span class="fu">## Text-Based Industry Classification {#sec-textual-tnic}</span></span>
<span id="cb33-1399"><a href="#cb33-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1400"><a href="#cb33-1400" aria-hidden="true" tabindex="-1"></a>We construct Vietnamese Text-Based Network Industries (VN-TNIC) analogous to @hoberg2016text. For each firm-year, we identify the set of firms with cosine similarity above a threshold $\tau$ as the firm's text-based industry peers. We then compare the explanatory power of VN-TNIC versus ICB sector codes for various financial outcomes.</span>
<span id="cb33-1401"><a href="#cb33-1401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1404"><a href="#cb33-1404" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1405"><a href="#cb33-1405" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tnic-construction</span></span>
<span id="cb33-1406"><a href="#cb33-1406" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1407"><a href="#cb33-1407" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "VN-TNIC construction and evaluation"</span></span>
<span id="cb33-1408"><a href="#cb33-1408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1409"><a href="#cb33-1409" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct TNIC network</span></span>
<span id="cb33-1410"><a href="#cb33-1410" aria-hidden="true" tabindex="-1"></a>TAU <span class="op">=</span> <span class="fl">0.20</span>  <span class="co"># Similarity threshold</span></span>
<span id="cb33-1411"><a href="#cb33-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1412"><a href="#cb33-1412" aria-hidden="true" tabindex="-1"></a>tnic_edges <span class="op">=</span> []</span>
<span id="cb33-1413"><a href="#cb33-1413" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tickers)):</span>
<span id="cb33-1414"><a href="#cb33-1414" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(tickers)):</span>
<span id="cb33-1415"><a href="#cb33-1415" aria-hidden="true" tabindex="-1"></a>        sim <span class="op">=</span> sim_matrix[i, j]</span>
<span id="cb33-1416"><a href="#cb33-1416" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sim <span class="op">&gt;=</span> TAU:</span>
<span id="cb33-1417"><a href="#cb33-1417" aria-hidden="true" tabindex="-1"></a>            tnic_edges.append({</span>
<span id="cb33-1418"><a href="#cb33-1418" aria-hidden="true" tabindex="-1"></a>                <span class="st">'firm1'</span>: tickers[i],</span>
<span id="cb33-1419"><a href="#cb33-1419" aria-hidden="true" tabindex="-1"></a>                <span class="st">'firm2'</span>: tickers[j],</span>
<span id="cb33-1420"><a href="#cb33-1420" aria-hidden="true" tabindex="-1"></a>                <span class="st">'similarity'</span>: sim</span>
<span id="cb33-1421"><a href="#cb33-1421" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb33-1422"><a href="#cb33-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1423"><a href="#cb33-1423" aria-hidden="true" tabindex="-1"></a>tnic_df <span class="op">=</span> pd.DataFrame(tnic_edges)</span>
<span id="cb33-1424"><a href="#cb33-1424" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'TNIC edges (tau=</span><span class="sc">{</span>TAU<span class="sc">}</span><span class="ss">): </span><span class="sc">{</span><span class="bu">len</span>(tnic_df)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-1425"><a href="#cb33-1425" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Avg degree: </span><span class="sc">{</span><span class="dv">2</span><span class="op">*</span><span class="bu">len</span>(tnic_df)<span class="op">/</span><span class="bu">len</span>(tickers)<span class="sc">:.1f}</span><span class="ss">'</span>)</span>
<span id="cb33-1426"><a href="#cb33-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1427"><a href="#cb33-1427" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare TNIC vs ICB for return comovement</span></span>
<span id="cb33-1428"><a href="#cb33-1428" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.asset_pricing <span class="im">import</span> FamaMacBeth</span>
<span id="cb33-1429"><a href="#cb33-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1430"><a href="#cb33-1430" aria-hidden="true" tabindex="-1"></a><span class="co"># Peer return = avg return of TNIC peers</span></span>
<span id="cb33-1431"><a href="#cb33-1431" aria-hidden="true" tabindex="-1"></a><span class="co"># vs ICB sector average return</span></span>
<span id="cb33-1432"><a href="#cb33-1432" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_tnic_peer_return(group, tnic_edges_df):</span>
<span id="cb33-1433"><a href="#cb33-1433" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute average return of TNIC peers for each firm."""</span></span>
<span id="cb33-1434"><a href="#cb33-1434" aria-hidden="true" tabindex="-1"></a>    peer_returns <span class="op">=</span> {}</span>
<span id="cb33-1435"><a href="#cb33-1435" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ticker <span class="kw">in</span> group.index:</span>
<span id="cb33-1436"><a href="#cb33-1436" aria-hidden="true" tabindex="-1"></a>        peers <span class="op">=</span> tnic_edges_df[</span>
<span id="cb33-1437"><a href="#cb33-1437" aria-hidden="true" tabindex="-1"></a>            (tnic_edges_df.firm1 <span class="op">==</span> ticker) <span class="op">|</span></span>
<span id="cb33-1438"><a href="#cb33-1438" aria-hidden="true" tabindex="-1"></a>            (tnic_edges_df.firm2 <span class="op">==</span> ticker)</span>
<span id="cb33-1439"><a href="#cb33-1439" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb33-1440"><a href="#cb33-1440" aria-hidden="true" tabindex="-1"></a>        peer_tickers <span class="op">=</span> <span class="bu">set</span>(</span>
<span id="cb33-1441"><a href="#cb33-1441" aria-hidden="true" tabindex="-1"></a>            peers.firm1.tolist() <span class="op">+</span> peers.firm2.tolist()</span>
<span id="cb33-1442"><a href="#cb33-1442" aria-hidden="true" tabindex="-1"></a>        ) <span class="op">-</span> {ticker}</span>
<span id="cb33-1443"><a href="#cb33-1443" aria-hidden="true" tabindex="-1"></a>        peer_mask <span class="op">=</span> group.index.isin(peer_tickers)</span>
<span id="cb33-1444"><a href="#cb33-1444" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> peer_mask.<span class="bu">sum</span>() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb33-1445"><a href="#cb33-1445" aria-hidden="true" tabindex="-1"></a>            peer_returns[ticker] <span class="op">=</span> group.loc[peer_mask, <span class="st">'ret'</span>].mean()</span>
<span id="cb33-1446"><a href="#cb33-1446" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb33-1447"><a href="#cb33-1447" aria-hidden="true" tabindex="-1"></a>            peer_returns[ticker] <span class="op">=</span> np.nan</span>
<span id="cb33-1448"><a href="#cb33-1448" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.Series(peer_returns)</span>
<span id="cb33-1449"><a href="#cb33-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1450"><a href="#cb33-1450" aria-hidden="true" tabindex="-1"></a>panel[<span class="st">'icb_peer_ret'</span>] <span class="op">=</span> panel.groupby(</span>
<span id="cb33-1451"><a href="#cb33-1451" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'date'</span>, <span class="st">'icb_sector'</span>]</span>
<span id="cb33-1452"><a href="#cb33-1452" aria-hidden="true" tabindex="-1"></a>)[<span class="st">'ret'</span>].transform(<span class="st">'mean'</span>)</span>
<span id="cb33-1453"><a href="#cb33-1453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1454"><a href="#cb33-1454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1457"><a href="#cb33-1457" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1458"><a href="#cb33-1458" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tnic-network</span></span>
<span id="cb33-1459"><a href="#cb33-1459" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1460"><a href="#cb33-1460" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Vietnamese Text-Based Network Industry (VN-TNIC) Graph. Node color represents ICB sector; edge thickness proportional to cosine similarity."</span></span>
<span id="cb33-1461"><a href="#cb33-1461" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Visualize TNIC network"</span></span>
<span id="cb33-1462"><a href="#cb33-1462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1463"><a href="#cb33-1463" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb33-1464"><a href="#cb33-1464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1465"><a href="#cb33-1465" aria-hidden="true" tabindex="-1"></a><span class="co"># Build network graph (subsample for visualization)</span></span>
<span id="cb33-1466"><a href="#cb33-1466" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb33-1467"><a href="#cb33-1467" aria-hidden="true" tabindex="-1"></a>sample_edges <span class="op">=</span> tnic_df.nlargest(<span class="dv">500</span>, <span class="st">'similarity'</span>)</span>
<span id="cb33-1468"><a href="#cb33-1468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1469"><a href="#cb33-1469" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> sample_edges.iterrows():</span>
<span id="cb33-1470"><a href="#cb33-1470" aria-hidden="true" tabindex="-1"></a>    G.add_edge(row.firm1, row.firm2, weight<span class="op">=</span>row.similarity)</span>
<span id="cb33-1471"><a href="#cb33-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1472"><a href="#cb33-1472" aria-hidden="true" tabindex="-1"></a><span class="co"># Color by ICB sector</span></span>
<span id="cb33-1473"><a href="#cb33-1473" aria-hidden="true" tabindex="-1"></a>sector_map <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>)[<span class="st">'icb_sector'</span>].to_dict()</span>
<span id="cb33-1474"><a href="#cb33-1474" aria-hidden="true" tabindex="-1"></a>node_colors <span class="op">=</span> [<span class="bu">hash</span>(sector_map.get(n, <span class="st">'Unknown'</span>)) <span class="op">%</span> <span class="dv">10</span></span>
<span id="cb33-1475"><a href="#cb33-1475" aria-hidden="true" tabindex="-1"></a>               <span class="cf">for</span> n <span class="kw">in</span> G.nodes()]</span>
<span id="cb33-1476"><a href="#cb33-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1477"><a href="#cb33-1477" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">12</span>))</span>
<span id="cb33-1478"><a href="#cb33-1478" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G, k<span class="op">=</span><span class="fl">0.5</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb33-1479"><a href="#cb33-1479" aria-hidden="true" tabindex="-1"></a>edges <span class="op">=</span> G.edges(data<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-1480"><a href="#cb33-1480" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [e[<span class="dv">2</span>][<span class="st">'weight'</span>] <span class="op">*</span> <span class="dv">3</span> <span class="cf">for</span> e <span class="kw">in</span> edges]</span>
<span id="cb33-1481"><a href="#cb33-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1482"><a href="#cb33-1482" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_nodes(G, pos, node_size<span class="op">=</span><span class="dv">100</span>, node_color<span class="op">=</span>node_colors,</span>
<span id="cb33-1483"><a href="#cb33-1483" aria-hidden="true" tabindex="-1"></a>                       cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, ax<span class="op">=</span>ax)</span>
<span id="cb33-1484"><a href="#cb33-1484" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_edges(G, pos, width<span class="op">=</span>weights, alpha<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb33-1485"><a href="#cb33-1485" aria-hidden="true" tabindex="-1"></a>                       edge_color<span class="op">=</span><span class="st">'gray'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb33-1486"><a href="#cb33-1486" aria-hidden="true" tabindex="-1"></a>nx.draw_networkx_labels(G, pos, font_size<span class="op">=</span><span class="dv">6</span>, ax<span class="op">=</span>ax)</span>
<span id="cb33-1487"><a href="#cb33-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1488"><a href="#cb33-1488" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'VN-TNIC Network (Top 500 Edges by Similarity)'</span>)</span>
<span id="cb33-1489"><a href="#cb33-1489" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb33-1490"><a href="#cb33-1490" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-1491"><a href="#cb33-1491" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-1492"><a href="#cb33-1492" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb33-1493"><a href="#cb33-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1494"><a href="#cb33-1494" aria-hidden="true" tabindex="-1"></a><span class="fu">## Measuring Textual Similarity Changes Around Corporate Events {#sec-textual-event-study}</span></span>
<span id="cb33-1495"><a href="#cb33-1495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1496"><a href="#cb33-1496" aria-hidden="true" tabindex="-1"></a>We examine how firms' textual similarity changes around major corporate events such as M&amp;A announcements, industry reclassifications, and strategic pivots. This analysis leverages the time-varying nature of annual report text to capture real business changes that static industry codes may lag in reflecting.</span>
<span id="cb33-1497"><a href="#cb33-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1500"><a href="#cb33-1500" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1501"><a href="#cb33-1501" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: event-study-text</span></span>
<span id="cb33-1502"><a href="#cb33-1502" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Event study on textual similarity changes"</span></span>
<span id="cb33-1503"><a href="#cb33-1503" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1504"><a href="#cb33-1504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1505"><a href="#cb33-1505" aria-hidden="true" tabindex="-1"></a><span class="co"># Get M&amp;A announcements from DataCore</span></span>
<span id="cb33-1506"><a href="#cb33-1506" aria-hidden="true" tabindex="-1"></a>ma_events <span class="op">=</span> dc.get_corporate_events(</span>
<span id="cb33-1507"><a href="#cb33-1507" aria-hidden="true" tabindex="-1"></a>    event_type<span class="op">=</span><span class="st">'M&amp;A'</span>,</span>
<span id="cb33-1508"><a href="#cb33-1508" aria-hidden="true" tabindex="-1"></a>    start<span class="op">=</span><span class="st">'2016-01-01'</span>, end<span class="op">=</span><span class="st">'2024-12-31'</span></span>
<span id="cb33-1509"><a href="#cb33-1509" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-1510"><a href="#cb33-1510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1511"><a href="#cb33-1511" aria-hidden="true" tabindex="-1"></a><span class="co"># For each M&amp;A event, compute text similarity between</span></span>
<span id="cb33-1512"><a href="#cb33-1512" aria-hidden="true" tabindex="-1"></a><span class="co"># acquirer and target before and after the event</span></span>
<span id="cb33-1513"><a href="#cb33-1513" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_similarity_around_event(</span>
<span id="cb33-1514"><a href="#cb33-1514" aria-hidden="true" tabindex="-1"></a>    acquirer: <span class="bu">str</span>, target: <span class="bu">str</span>, event_year: <span class="bu">int</span>,</span>
<span id="cb33-1515"><a href="#cb33-1515" aria-hidden="true" tabindex="-1"></a>    annual_text_df: pd.DataFrame,</span>
<span id="cb33-1516"><a href="#cb33-1516" aria-hidden="true" tabindex="-1"></a>    vectorizer: TfidfVectorizer</span>
<span id="cb33-1517"><a href="#cb33-1517" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb33-1518"><a href="#cb33-1518" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compare text similarity pre vs post M&amp;A."""</span></span>
<span id="cb33-1519"><a href="#cb33-1519" aria-hidden="true" tabindex="-1"></a>    pre_texts <span class="op">=</span> annual_text_df[</span>
<span id="cb33-1520"><a href="#cb33-1520" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.ticker.isin([acquirer, target])) <span class="op">&amp;</span></span>
<span id="cb33-1521"><a href="#cb33-1521" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.year <span class="op">==</span> event_year <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb33-1522"><a href="#cb33-1522" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb33-1523"><a href="#cb33-1523" aria-hidden="true" tabindex="-1"></a>    post_texts <span class="op">=</span> annual_text_df[</span>
<span id="cb33-1524"><a href="#cb33-1524" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.ticker.isin([acquirer, target])) <span class="op">&amp;</span></span>
<span id="cb33-1525"><a href="#cb33-1525" aria-hidden="true" tabindex="-1"></a>        (annual_text_df.year <span class="op">==</span> event_year <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb33-1526"><a href="#cb33-1526" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb33-1527"><a href="#cb33-1527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1528"><a href="#cb33-1528" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(pre_texts) <span class="op">&lt;</span> <span class="dv">2</span> <span class="kw">or</span> <span class="bu">len</span>(post_texts) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb33-1529"><a href="#cb33-1529" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb33-1530"><a href="#cb33-1530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1531"><a href="#cb33-1531" aria-hidden="true" tabindex="-1"></a>    pre_vecs <span class="op">=</span> vectorizer.transform(pre_texts.text_clean)</span>
<span id="cb33-1532"><a href="#cb33-1532" aria-hidden="true" tabindex="-1"></a>    post_vecs <span class="op">=</span> vectorizer.transform(post_texts.text_clean)</span>
<span id="cb33-1533"><a href="#cb33-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1534"><a href="#cb33-1534" aria-hidden="true" tabindex="-1"></a>    pre_sim <span class="op">=</span> cosine_similarity(pre_vecs[<span class="dv">0</span>:<span class="dv">1</span>], pre_vecs[<span class="dv">1</span>:<span class="dv">2</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb33-1535"><a href="#cb33-1535" aria-hidden="true" tabindex="-1"></a>    post_sim <span class="op">=</span> cosine_similarity(post_vecs[<span class="dv">0</span>:<span class="dv">1</span>], post_vecs[<span class="dv">1</span>:<span class="dv">2</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb33-1536"><a href="#cb33-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1537"><a href="#cb33-1537" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb33-1538"><a href="#cb33-1538" aria-hidden="true" tabindex="-1"></a>        <span class="st">'acquirer'</span>: acquirer,</span>
<span id="cb33-1539"><a href="#cb33-1539" aria-hidden="true" tabindex="-1"></a>        <span class="st">'target'</span>: target,</span>
<span id="cb33-1540"><a href="#cb33-1540" aria-hidden="true" tabindex="-1"></a>        <span class="st">'event_year'</span>: event_year,</span>
<span id="cb33-1541"><a href="#cb33-1541" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pre_similarity'</span>: pre_sim,</span>
<span id="cb33-1542"><a href="#cb33-1542" aria-hidden="true" tabindex="-1"></a>        <span class="st">'post_similarity'</span>: post_sim,</span>
<span id="cb33-1543"><a href="#cb33-1543" aria-hidden="true" tabindex="-1"></a>        <span class="st">'delta_similarity'</span>: post_sim <span class="op">-</span> pre_sim</span>
<span id="cb33-1544"><a href="#cb33-1544" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-1545"><a href="#cb33-1545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1546"><a href="#cb33-1546" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to all M&amp;A events</span></span>
<span id="cb33-1547"><a href="#cb33-1547" aria-hidden="true" tabindex="-1"></a>event_results <span class="op">=</span> []</span>
<span id="cb33-1548"><a href="#cb33-1548" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, event <span class="kw">in</span> ma_events.iterrows():</span>
<span id="cb33-1549"><a href="#cb33-1549" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> text_similarity_around_event(</span>
<span id="cb33-1550"><a href="#cb33-1550" aria-hidden="true" tabindex="-1"></a>        event.acquirer, event.target, event.event_year,</span>
<span id="cb33-1551"><a href="#cb33-1551" aria-hidden="true" tabindex="-1"></a>        annual_text, tfidf_vectorizer</span>
<span id="cb33-1552"><a href="#cb33-1552" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-1553"><a href="#cb33-1553" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> result:</span>
<span id="cb33-1554"><a href="#cb33-1554" aria-hidden="true" tabindex="-1"></a>        event_results.append(result)</span>
<span id="cb33-1555"><a href="#cb33-1555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1556"><a href="#cb33-1556" aria-hidden="true" tabindex="-1"></a>event_df <span class="op">=</span> pd.DataFrame(event_results)</span>
<span id="cb33-1557"><a href="#cb33-1557" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Average similarity change post-M&amp;A: '</span></span>
<span id="cb33-1558"><a href="#cb33-1558" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f'</span><span class="sc">{</span>event_df<span class="sc">.</span>delta_similarity<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb33-1559"><a href="#cb33-1559" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f't-stat: </span><span class="sc">{</span>event_df<span class="sc">.</span>delta_similarity<span class="sc">.</span>mean() <span class="op">/</span> <span class="st">'</span></span>
<span id="cb33-1560"><a href="#cb33-1560" aria-hidden="true" tabindex="-1"></a><span class="er">      f'(event_df.delta_similarity.std() / '</span></span>
<span id="cb33-1561"><a href="#cb33-1561" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f'np.sqrt(len(event_df))):.3f</span><span class="er">}</span><span class="ss">'</span><span class="sc">)</span></span>
<span id="cb33-1562"><a href="#cb33-1562" aria-hidden="true" tabindex="-1"></a><span class="sc">```</span></span>
<span id="cb33-1563"><a href="#cb33-1563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1564"><a href="#cb33-1564" aria-hidden="true" tabindex="-1"></a><span class="co"># Method Comparison and Best Practices {#sec-textual-comparison}</span></span>
<span id="cb33-1565"><a href="#cb33-1565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1566"><a href="#cb33-1566" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> Method <span class="op">|</span> Interpretability <span class="op">|</span> Semantic <span class="op">|</span> Speed <span class="op">|</span> VN Support <span class="op">|</span> Data Req<span class="sc">.</span> <span class="op">|</span> Best Use Case <span class="op">|</span></span>
<span id="cb33-1567"><a href="#cb33-1567" aria-hidden="true" tabindex="-1"></a><span class="op">|</span><span class="sc">:</span><span class="op">----------|</span><span class="sc">:</span><span class="op">---------</span><span class="sc">:</span><span class="op">|</span><span class="sc">:</span><span class="op">---------</span><span class="sc">:</span><span class="op">|</span><span class="sc">:</span><span class="op">---------</span><span class="sc">:</span><span class="op">|</span><span class="sc">:</span><span class="op">---------</span><span class="sc">:</span><span class="op">|</span><span class="sc">:</span><span class="op">---------</span><span class="sc">:</span><span class="op">|</span><span class="sc">:</span><span class="op">----------|</span></span>
<span id="cb33-1568"><a href="#cb33-1568" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> BoW<span class="op">/</span>TF<span class="op">-</span>IDF <span class="op">|</span> High <span class="op">|</span> Low <span class="op">|</span> Fast <span class="op">|</span> Good<span class="sc">\</span><span class="op">*</span> <span class="op">|</span> <span class="va">None</span> <span class="op">|</span> Peer groups<span class="sc">,</span> lexical similarity <span class="op">|</span></span>
<span id="cb33-1569"><a href="#cb33-1569" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> LDA <span class="op">|</span> Medium <span class="op">|</span> Low <span class="op">|</span> Medium <span class="op">|</span> Good<span class="sc">\</span><span class="op">*</span> <span class="op">|</span> <span class="va">None</span> <span class="op">|</span> Topic discovery <span class="op">|</span></span>
<span id="cb33-1570"><a href="#cb33-1570" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> Doc2Vec <span class="op">|</span> Low <span class="op">|</span> Medium <span class="op">|</span> Medium <span class="op">|</span> Good<span class="sc">\</span><span class="op">*</span> <span class="op">|</span> Corpus <span class="op">|</span> Document similarity <span class="op">|</span></span>
<span id="cb33-1571"><a href="#cb33-1571" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> BERTopic <span class="op">|</span> High <span class="op">|</span> High <span class="op">|</span> Slow <span class="op">|</span> Excellent <span class="op">|</span> <span class="va">None</span> <span class="op">|</span> Coherent topics <span class="op">|</span></span>
<span id="cb33-1572"><a href="#cb33-1572" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> PhoBERT <span class="op">|</span> Low <span class="op">|</span> High <span class="op">|</span> Slow <span class="op">|</span> Excellent <span class="op">|</span> Fine<span class="op">-</span>tune <span class="op">|</span> Sentiment<span class="sc">,</span> NER<span class="sc">,</span> classification <span class="op">|</span></span>
<span id="cb33-1573"><a href="#cb33-1573" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> Sentence<span class="op">-</span>BERT <span class="op">|</span> Low <span class="op">|</span> High <span class="op">|</span> Medium <span class="op">|</span> Good <span class="op">|</span> <span class="va">None</span> <span class="op">|</span> Semantic similarity <span class="op">|</span></span>
<span id="cb33-1574"><a href="#cb33-1574" aria-hidden="true" tabindex="-1"></a><span class="op">|</span> LLM (zero<span class="op">-</span>shot) <span class="op">|</span> High <span class="op">|</span> High <span class="op">|</span> Slow <span class="op">|</span> Good <span class="op">|</span> <span class="va">None</span> <span class="op">|</span> Extraction<span class="sc">,</span> classification <span class="op">|</span></span>
<span id="cb33-1575"><a href="#cb33-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1576"><a href="#cb33-1576" aria-hidden="true" tabindex="-1"></a><span class="sc">:</span> Comparison of Textual Analysis Methods <span class="cf">for</span> Vietnamese Financial Text {<span class="co">#tbl-method-comparison}</span></span>
<span id="cb33-1577"><a href="#cb33-1577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1578"><a href="#cb33-1578" aria-hidden="true" tabindex="-1"></a>::: callout<span class="op">-</span>note</span>
<span id="cb33-1579"><a href="#cb33-1579" aria-hidden="true" tabindex="-1"></a>\<span class="op">*</span>Requires Vietnamese word segmentation <span class="im">as</span> a preprocessing step. VN Support rates how well the method handles Vietnamese text natively.</span>
<span id="cb33-1580"><a href="#cb33-1580" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb33-1581"><a href="#cb33-1581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1582"><a href="#cb33-1582" aria-hidden="true" tabindex="-1"></a>For researchers beginning textual analysis of Vietnamese firms, we recommend the following workflow:</span>
<span id="cb33-1583"><a href="#cb33-1583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1584"><a href="#cb33-1584" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span>  <span class="op">**</span>Start <span class="cf">with</span> TF<span class="op">-</span>IDF cosine similarity<span class="op">**</span> <span class="cf">for</span> peer identification because it <span class="kw">is</span> fast, interpretable, <span class="kw">and</span> provides a strong baseline.</span>
<span id="cb33-1585"><a href="#cb33-1585" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span>  <span class="op">**</span>Use BERTopic <span class="cf">with</span> PhoBERT embeddings<span class="op">**</span> <span class="cf">for</span> topic discovery because it produces more coherent topics than LDA <span class="cf">for</span> Vietnamese text.</span>
<span id="cb33-1586"><a href="#cb33-1586" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span>  <span class="op">**</span>For sentiment analysis<span class="op">**</span>, use ViFinBERT <span class="cf">if</span> fine<span class="op">-</span>tuning data <span class="kw">is</span> available<span class="op">;</span> otherwise, LLM zero<span class="op">-</span>shot classification provides competitive results.</span>
<span id="cb33-1587"><a href="#cb33-1587" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span>  <span class="op">**</span>For production systems<span class="op">**</span> requiring real<span class="op">-</span>time analysis, sentence<span class="op">-</span>BERT embeddings offer the best speed<span class="op">-</span>accuracy tradeoff.</span>
<span id="cb33-1588"><a href="#cb33-1588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1591"><a href="#cb33-1591" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb33-1592"><a href="#cb33-1592" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-method-comparison</span></span>
<span id="cb33-1593"><a href="#cb33-1593" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Peer Identification Accuracy by Method: Fraction of Top-5 Peers Sharing the Same ICB Sector"</span></span>
<span id="cb33-1594"><a href="#cb33-1594" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb33-1595"><a href="#cb33-1595" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Compare methods on peer identification accuracy"</span></span>
<span id="cb33-1596"><a href="#cb33-1596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1597"><a href="#cb33-1597" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate: what fraction of top-5 peers share ICB sector?</span></span>
<span id="cb33-1598"><a href="#cb33-1598" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> {</span>
<span id="cb33-1599"><a href="#cb33-1599" aria-hidden="true" tabindex="-1"></a>    <span class="st">'TF-IDF'</span>: sim_df,</span>
<span id="cb33-1600"><a href="#cb33-1600" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Sentence-BERT'</span>: embed_sim_df,</span>
<span id="cb33-1601"><a href="#cb33-1601" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Doc2Vec'</span>: pd.DataFrame(</span>
<span id="cb33-1602"><a href="#cb33-1602" aria-hidden="true" tabindex="-1"></a>        cosine_similarity(d2v_vectors),</span>
<span id="cb33-1603"><a href="#cb33-1603" aria-hidden="true" tabindex="-1"></a>        index<span class="op">=</span>tickers, columns<span class="op">=</span>tickers</span>
<span id="cb33-1604"><a href="#cb33-1604" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb33-1605"><a href="#cb33-1605" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-1606"><a href="#cb33-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1607"><a href="#cb33-1607" aria-hidden="true" tabindex="-1"></a>accuracy_results <span class="op">=</span> {}</span>
<span id="cb33-1608"><a href="#cb33-1608" aria-hidden="true" tabindex="-1"></a>sector_map <span class="op">=</span> corpus_df.set_index(<span class="st">'ticker'</span>)[<span class="st">'icb_sector'</span>].to_dict()</span>
<span id="cb33-1609"><a href="#cb33-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1610"><a href="#cb33-1610" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method_name, sim_matrix_df <span class="kw">in</span> methods.items():</span>
<span id="cb33-1611"><a href="#cb33-1611" aria-hidden="true" tabindex="-1"></a>    matches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-1612"><a href="#cb33-1612" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-1613"><a href="#cb33-1613" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ticker <span class="kw">in</span> tickers:</span>
<span id="cb33-1614"><a href="#cb33-1614" aria-hidden="true" tabindex="-1"></a>        true_sector <span class="op">=</span> sector_map.get(ticker)</span>
<span id="cb33-1615"><a href="#cb33-1615" aria-hidden="true" tabindex="-1"></a>        peers <span class="op">=</span> sim_matrix_df[ticker].drop(ticker).nlargest(<span class="dv">5</span>)</span>
<span id="cb33-1616"><a href="#cb33-1616" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> peer <span class="kw">in</span> peers.index:</span>
<span id="cb33-1617"><a href="#cb33-1617" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-1618"><a href="#cb33-1618" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> sector_map.get(peer) <span class="op">==</span> true_sector:</span>
<span id="cb33-1619"><a href="#cb33-1619" aria-hidden="true" tabindex="-1"></a>                matches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-1620"><a href="#cb33-1620" aria-hidden="true" tabindex="-1"></a>    accuracy_results[method_name] <span class="op">=</span> matches <span class="op">/</span> total</span>
<span id="cb33-1621"><a href="#cb33-1621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1622"><a href="#cb33-1622" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb33-1623"><a href="#cb33-1623" aria-hidden="true" tabindex="-1"></a>methods_list <span class="op">=</span> <span class="bu">list</span>(accuracy_results.keys())</span>
<span id="cb33-1624"><a href="#cb33-1624" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> <span class="bu">list</span>(accuracy_results.values())</span>
<span id="cb33-1625"><a href="#cb33-1625" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> ax.bar(methods_list, accs, color<span class="op">=</span>[<span class="st">'#2C5282'</span>, <span class="st">'#38A169'</span>, <span class="st">'#D69E2E'</span>])</span>
<span id="cb33-1626"><a href="#cb33-1626" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'ICB Sector Match Rate'</span>)</span>
<span id="cb33-1627"><a href="#cb33-1627" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Peer Identification Accuracy by Method'</span>)</span>
<span id="cb33-1628"><a href="#cb33-1628" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb33-1629"><a href="#cb33-1629" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, acc <span class="kw">in</span> <span class="bu">zip</span>(bars, accs):</span>
<span id="cb33-1630"><a href="#cb33-1630" aria-hidden="true" tabindex="-1"></a>    ax.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.02</span>,</span>
<span id="cb33-1631"><a href="#cb33-1631" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'</span><span class="sc">{</span>acc<span class="sc">:.1%}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-1632"><a href="#cb33-1632" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-1633"><a href="#cb33-1633" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-1634"><a href="#cb33-1634" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb33-1635"><a href="#cb33-1635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1636"><a href="#cb33-1636" aria-hidden="true" tabindex="-1"></a><span class="co"># Conclusion {#sec-textual-conclusion}</span></span>
<span id="cb33-1637"><a href="#cb33-1637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1638"><a href="#cb33-1638" aria-hidden="true" tabindex="-1"></a>This chapter has demonstrated the full pipeline of textual analysis methods applied to Vietnamese listed firms, <span class="im">from</span> classical bag<span class="op">-</span>of<span class="op">-</span>words approaches to state<span class="op">-</span>of<span class="op">-</span>the<span class="op">-</span>art large language models. The key takeaways <span class="cf">for</span> practitioners <span class="kw">and</span> researchers are:</span>
<span id="cb33-1639"><a href="#cb33-1639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1640"><a href="#cb33-1640" aria-hidden="true" tabindex="-1"></a>First, Vietnamese text preprocessing requires a word segmentation step that has no parallel <span class="kw">in</span> English<span class="op">-</span>language NLP. Using tools like VnCoreNLP <span class="kw">or</span> underthesea <span class="cf">for</span> this step <span class="kw">is</span> essential <span class="kw">and</span> significantly affects downstream analysis quality.</span>
<span id="cb33-1641"><a href="#cb33-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1642"><a href="#cb33-1642" aria-hidden="true" tabindex="-1"></a>Second, domain<span class="op">-</span>specific sentiment lexicons substantially outperform general<span class="op">-</span>purpose dictionaries <span class="cf">for</span> Vietnamese financial text, consistent <span class="cf">with</span> <span class="op">@</span>loughran2011liability findings <span class="cf">for</span> English.</span>
<span id="cb33-1643"><a href="#cb33-1643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1644"><a href="#cb33-1644" aria-hidden="true" tabindex="-1"></a>Third, PhoBERT<span class="op">-</span>based embeddings capture semantic similarity that TF<span class="op">-</span>IDF misses, identifying industry peers that share business models even when they use different vocabulary.</span>
<span id="cb33-1645"><a href="#cb33-1645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1646"><a href="#cb33-1646" aria-hidden="true" tabindex="-1"></a>Fourth, LLMs enable new applications, including structured information extraction <span class="im">from</span> Vietnamese annual reports that would be prohibitively expensive <span class="cf">with</span> manual coding.</span>
<span id="cb33-1647"><a href="#cb33-1647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1648"><a href="#cb33-1648" aria-hidden="true" tabindex="-1"></a>The empirical applications demonstrate that textual measures contain economically meaningful information <span class="cf">for</span> the Vietnamese market. Net sentiment <span class="im">from</span> annual reports predicts subsequent stock returns even after controlling <span class="cf">for</span> standard risk factors, <span class="kw">and</span> BERT<span class="op">-</span>based sentiment measures have incremental predictive power beyond dictionary<span class="op">-</span>based measures. Text<span class="op">-</span>based industry classifications capture firm relationships that static ICB codes miss, <span class="kw">and</span> textual similarity changes around corporate events reflect real business transformations.</span>
<span id="cb33-1649"><a href="#cb33-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-1650"><a href="#cb33-1650" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;!--</span><span class="co"># All code and data pipelines in this chapter are designed to be reproducible using DataCore.vn's API. Researchers can extend these methods to other text sources, including earnings call transcripts, news articles from CafeF and VnExpress, and social media data from Vietnamese financial forums, all of which are available via DataCore.vn --&gt;</span></span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span id="copyright"></span> Mike. All rights reserved.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mikenguyen13/tidy_finance_vn_vi/edit/main/70_textual.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mikenguyen13/tidy_finance_vn_vi/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>