<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>47&nbsp; Multimodal Models in Finance – Applying Tidy Finance with Python to Vietnam</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./99_conclusion.html" rel="next">
<link href="./73_networks_graphs.html" rel="prev">
<link href="./favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-50a4fa9e9ef121803c2355a2deb1af4d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-d8431037eefe704a1e7a103aa5b75ea7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-50a4fa9e9ef121803c2355a2deb1af4d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="47&nbsp; Multimodal Models in Finance – Applying Tidy Finance with Python to Vietnam">
<meta property="og:description" content="">
<meta property="og:site_name" content="Applying Tidy Finance with Python to Vietnam">
<meta name="twitter:title" content="47&nbsp; Multimodal Models in Finance – Applying Tidy Finance with Python to Vietnam">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./70_textual.html">Alternative Data and AI for Finance</a></li><li class="breadcrumb-item"><a href="./74_multimodel.html"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Multimodal Models in Finance</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Applying Tidy Finance with Python to Vietnam</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/mikenguyen13/tidy_finance_vn" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Vietnam Financial Markets, Institutions, and Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_institutional_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Institutional Background and Market Structure of Vietnam’s Equity Market</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_accessing_and_managing_financial_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Accessing and Managing VN Financial Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_datacore_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Datacore Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_market_microstructure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Market Microstructure in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_risk_free_rate_construction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Risk-Free Rate Construction in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_working_with_stock_returns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Constructing and Analyzing Equity Return Series</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_compound_return.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Compound Returns</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Portfolio Construction, Risk, and Empirical Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_modern_portfolio_theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modern Portfolio Theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_univariate_portfolio_sort.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Univariate Portfolio Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_size_sorts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Size Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_value_bivariate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Value and Bivariate Sorts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_portfolio_weighting_and_rebalancing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Portfolio Weighting and Rebalancing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_missing_data_and_survivorship.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Missing Data and Survivorship Bias</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_liquidity_and_turnover_measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Liquidity and Turnover Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_beta_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Beta Estimation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Asset Pricing Models and Cross-Sectional Tests</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_capm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">The Capital Asset Pricing Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_fama_french.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Fama-French Factors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_momentum.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Momentum Strategies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_factor_construction_principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Factor Construction Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./24_fama_macbeth.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Fama-MacBeth Regressions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./25_factor_zoo_and_multiple_testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Factor Zoo and Multiple Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./26_time_series_vs_cross_section.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Time-Series vs.&nbsp;Cross-Sectional Factor Tests</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Firm Fundamentals, Valuation, and Corporate Signals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_financial_statement_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Financial Statement Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31_discounted_cash_flow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Discounted Cash Flow Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32_info_earnings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Information Content of Earnings Announcements</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33_accruals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Accruals, Earnings Persistence, and Market Efficiency</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./34_earning_management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Earnings Management: Detection and Measurement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./35_pe_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">P/E Ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./36_valuation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Firm Valuation, Financial Distress, and Company Maturity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./37_disclosure_quality_and_timing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Disclosure Quality and Timing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./38_sue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Standardized Earnings Surprises (SUE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./39_divop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Measuring Divergence of Investor Opinion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Ownership, Market Frictions, and International Exposure</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./50_institutional_ownership.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Institutional Ownership Analytics in Vietnam</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./52_institutional_trade_flow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Institutional Trades, Flows, and Turnover Ratios</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./53_governance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Corporate Governance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./54_return_gaps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Return Gap: Measuring Unobserved Actions of Fund Managers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./55_price_limits_and_volatility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Price Limits and Volatility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./56_market_integration_and_segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Market Integration and Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./57_exchange_rate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Exchange Rate Dynamics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Financial Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./60_event_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Event Studies in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./61_tail_risk_extreme_events.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Tail Risk and Extreme Events</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./62_corporate_finance_estimators.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Corporate Finance Estimators and Identification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./63_structural_models_finance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Structural Models in Finance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Alternative Data and AI for Finance</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./70_textual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Textual Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./71_image.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Image and Visual Data in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./73_networks_graphs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Networks and Graphs in Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./74_multimodel.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Multimodal Models in Finance</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#foundations-of-multimodal-learning" id="toc-foundations-of-multimodal-learning" class="nav-link active" data-scroll-target="#foundations-of-multimodal-learning"><span class="header-section-number">47.1</span> Foundations of Multimodal Learning</a>
  <ul class="collapse">
  <li><a href="#the-information-structure-of-financial-data" id="toc-the-information-structure-of-financial-data" class="nav-link" data-scroll-target="#the-information-structure-of-financial-data"><span class="header-section-number">47.1.1</span> The Information Structure of Financial Data</a></li>
  <li><a href="#taxonomies-of-fusion" id="toc-taxonomies-of-fusion" class="nav-link" data-scroll-target="#taxonomies-of-fusion"><span class="header-section-number">47.1.2</span> Taxonomies of Fusion</a></li>
  </ul></li>
  <li><a href="#representation-alignment" id="toc-representation-alignment" class="nav-link" data-scroll-target="#representation-alignment"><span class="header-section-number">47.2</span> Representation Alignment</a>
  <ul class="collapse">
  <li><a href="#the-alignment-problem" id="toc-the-alignment-problem" class="nav-link" data-scroll-target="#the-alignment-problem"><span class="header-section-number">47.2.1</span> The Alignment Problem</a></li>
  <li><a href="#contrastive-alignment-clip-for-finance" id="toc-contrastive-alignment-clip-for-finance" class="nav-link" data-scroll-target="#contrastive-alignment-clip-for-finance"><span class="header-section-number">47.2.2</span> Contrastive Alignment: CLIP for Finance</a></li>
  <li><a href="#projection-alignment-for-arbitrary-modalities" id="toc-projection-alignment-for-arbitrary-modalities" class="nav-link" data-scroll-target="#projection-alignment-for-arbitrary-modalities"><span class="header-section-number">47.2.3</span> Projection Alignment for Arbitrary Modalities</a></li>
  </ul></li>
  <li><a href="#fusion-architectures-for-return-prediction" id="toc-fusion-architectures-for-return-prediction" class="nav-link" data-scroll-target="#fusion-architectures-for-return-prediction"><span class="header-section-number">47.3</span> Fusion Architectures for Return Prediction</a>
  <ul class="collapse">
  <li><a href="#unimodal-encoders" id="toc-unimodal-encoders" class="nav-link" data-scroll-target="#unimodal-encoders"><span class="header-section-number">47.3.1</span> Unimodal Encoders</a></li>
  <li><a href="#early-fusion" id="toc-early-fusion" class="nav-link" data-scroll-target="#early-fusion"><span class="header-section-number">47.3.2</span> Early Fusion</a></li>
  <li><a href="#late-fusion" id="toc-late-fusion" class="nav-link" data-scroll-target="#late-fusion"><span class="header-section-number">47.3.3</span> Late Fusion</a></li>
  <li><a href="#cross-attention-fusion" id="toc-cross-attention-fusion" class="nav-link" data-scroll-target="#cross-attention-fusion"><span class="header-section-number">47.3.4</span> Cross-Attention Fusion</a></li>
  <li><a href="#comparison-experiment" id="toc-comparison-experiment" class="nav-link" data-scroll-target="#comparison-experiment"><span class="header-section-number">47.3.5</span> Comparison Experiment</a></li>
  </ul></li>
  <li><a href="#handling-missing-modalities" id="toc-handling-missing-modalities" class="nav-link" data-scroll-target="#handling-missing-modalities"><span class="header-section-number">47.4</span> Handling Missing Modalities</a>
  <ul class="collapse">
  <li><a href="#the-missing-modality-problem" id="toc-the-missing-modality-problem" class="nav-link" data-scroll-target="#the-missing-modality-problem"><span class="header-section-number">47.4.1</span> The Missing Modality Problem</a></li>
  <li><a href="#strategies-for-missing-modalities" id="toc-strategies-for-missing-modalities" class="nav-link" data-scroll-target="#strategies-for-missing-modalities"><span class="header-section-number">47.4.2</span> Strategies for Missing Modalities</a></li>
  </ul></li>
  <li><a href="#multimodal-document-understanding" id="toc-multimodal-document-understanding" class="nav-link" data-scroll-target="#multimodal-document-understanding"><span class="header-section-number">47.5</span> Multimodal Document Understanding</a>
  <ul class="collapse">
  <li><a href="#annual-report-as-a-multimodal-object" id="toc-annual-report-as-a-multimodal-object" class="nav-link" data-scroll-target="#annual-report-as-a-multimodal-object"><span class="header-section-number">47.5.1</span> Annual Report as a Multimodal Object</a></li>
  <li><a href="#extracting-structured-financials-from-multimodal-reports" id="toc-extracting-structured-financials-from-multimodal-reports" class="nav-link" data-scroll-target="#extracting-structured-financials-from-multimodal-reports"><span class="header-section-number">47.5.2</span> Extracting Structured Financials from Multimodal Reports</a></li>
  </ul></li>
  <li><a href="#multimodal-earnings-surprise-model" id="toc-multimodal-earnings-surprise-model" class="nav-link" data-scroll-target="#multimodal-earnings-surprise-model"><span class="header-section-number">47.6</span> Multimodal Earnings Surprise Model</a>
  <ul class="collapse">
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture"><span class="header-section-number">47.6.1</span> Architecture</a></li>
  <li><a href="#modality-importance-analysis" id="toc-modality-importance-analysis" class="nav-link" data-scroll-target="#modality-importance-analysis"><span class="header-section-number">47.6.2</span> Modality Importance Analysis</a></li>
  </ul></li>
  <li><a href="#large-multimodal-models-for-financial-analysis" id="toc-large-multimodal-models-for-financial-analysis" class="nav-link" data-scroll-target="#large-multimodal-models-for-financial-analysis"><span class="header-section-number">47.7</span> Large Multimodal Models for Financial Analysis</a>
  <ul class="collapse">
  <li><a href="#prompting-vision-language-models" id="toc-prompting-vision-language-models" class="nav-link" data-scroll-target="#prompting-vision-language-models"><span class="header-section-number">47.7.1</span> Prompting Vision-Language Models</a></li>
  <li><a href="#retrieval-augmented-multimodal-analysis" id="toc-retrieval-augmented-multimodal-analysis" class="nav-link" data-scroll-target="#retrieval-augmented-multimodal-analysis"><span class="header-section-number">47.7.2</span> Retrieval-Augmented Multimodal Analysis</a></li>
  </ul></li>
  <li><a href="#evaluation-and-deployment-considerations" id="toc-evaluation-and-deployment-considerations" class="nav-link" data-scroll-target="#evaluation-and-deployment-considerations"><span class="header-section-number">47.8</span> Evaluation and Deployment Considerations</a>
  <ul class="collapse">
  <li><a href="#evaluation-protocol-for-multimodal-financial-models" id="toc-evaluation-protocol-for-multimodal-financial-models" class="nav-link" data-scroll-target="#evaluation-protocol-for-multimodal-financial-models"><span class="header-section-number">47.8.1</span> Evaluation Protocol for Multimodal Financial Models</a></li>
  <li><a href="#computational-budget" id="toc-computational-budget" class="nav-link" data-scroll-target="#computational-budget"><span class="header-section-number">47.8.2</span> Computational Budget</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">47.9</span> Summary</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/mikenguyen13/tidy_finance_vn/edit/main/74_multimodel.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mikenguyen13/tidy_finance_vn/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./70_textual.html">Alternative Data and AI for Finance</a></li><li class="breadcrumb-item"><a href="./74_multimodel.html"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Multimodal Models in Finance</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Multimodal Models in Finance</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The preceding chapters treated text and images as isolated data modalities, but financial decision-making is inherently multimodal. An analyst evaluating a Vietnamese real estate developer simultaneously reads the annual report (text), inspects satellite imagery of construction sites (image), reviews quarterly financial statements (tabular), monitors the stock’s price and volume dynamics (time series), and perhaps listens to the earnings call (audio). No single modality captures the full information set. The question this chapter addresses is: can we build models that fuse multiple modalities in a principled way, and does the fusion yield economically meaningful improvements over the best single-modality model?</p>
<p>The answer from the recent machine learning literature is increasingly yes, but with important caveats. Multimodal models can exploit complementarities between modalities (e.g., text describes intentions and context; images reveal physical states; tabular data provides precise quantitative snapshots; time series captures dynamics). However, the gains are not automatic. Naive concatenation of heterogeneous features often degrades performance relative to the best unimodal model, a phenomenon known as the “modality laziness” problem <span class="citation" data-cites="huang2021makes">(<a href="references.html#ref-huang2021makes" role="doc-biblioref">Huang et al. 2021</a>)</span>. Effective fusion requires architectures that align representations across modalities, handle missing modalities gracefully (not every firm-quarter has satellite imagery and an earnings call), and avoid the dominant modality drowning out weaker but complementary signals.</p>
<p>This chapter develops the multimodal toolkit for Vietnamese financial markets across four progressively complex architectures. We begin with representation alignment (i.e., how to map different modalities into a shared embedding space). We then implement early, late, and cross-attention fusion for return prediction. We build a multimodal document understanding system that jointly processes the text, tables, and images within Vietnamese annual reports. We construct a multimodal earnings surprise model that combines pre-announcement text, satellite imagery, and financial time series. And we address the practical engineering challenges, including missing modalities, computational cost, and evaluation protocols that determine whether multimodal models work in production.</p>
<div id="setup" class="cell" data-message="false" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Deep learning</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># NLP</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer, AutoModel,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    CLIPProcessor, CLIPModel</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular and statistical</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> TimeSeriesSplit</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.panel <span class="im">import</span> PanelOLS</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotnine <span class="im">as</span> p9</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mizani.formatters <span class="im">import</span> percent_format</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="foundations-of-multimodal-learning" class="level2" data-number="47.1">
<h2 data-number="47.1" class="anchored" data-anchor-id="foundations-of-multimodal-learning"><span class="header-section-number">47.1</span> Foundations of Multimodal Learning</h2>
<section id="the-information-structure-of-financial-data" class="level3" data-number="47.1.1">
<h3 data-number="47.1.1" class="anchored" data-anchor-id="the-information-structure-of-financial-data"><span class="header-section-number">47.1.1</span> The Information Structure of Financial Data</h3>
<p>Financial data is naturally organized into modalities with distinct statistical properties, temporal frequencies, and information content. <a href="#tbl-modality-landscape" class="quarto-xref">Table&nbsp;<span>47.1</span></a> summarizes the modalities relevant to Vietnamese equity markets.</p>
<div id="tbl-modality-landscape" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-modality-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.1: Modality Landscape in Financial Data
</figcaption>
<div aria-describedby="tbl-modality-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Modality</th>
<th>Examples</th>
<th>Dimensionality</th>
<th>Frequency</th>
<th>Encoding</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tabular</td>
<td>Financial ratios, ownership, governance</td>
<td>Low (<span class="math inline">\(\sim\)</span> 50 features)</td>
<td>Quarterly/Annual</td>
<td>Structured numeric</td>
</tr>
<tr class="even">
<td>Text</td>
<td>Annual reports, news, filings, social media</td>
<td>High (<span class="math inline">\(\sim\)</span> 10k tokens)</td>
<td>Event-driven</td>
<td>Sequential tokens</td>
</tr>
<tr class="odd">
<td>Image</td>
<td>Satellite tiles, document scans, news photos</td>
<td>Very high (<span class="math inline">\(\sim\)</span> 150k pixels)</td>
<td>Daily to monthly</td>
<td>Spatial grid</td>
</tr>
<tr class="even">
<td>Time series</td>
<td>Price, volume, order flow, volatility</td>
<td>Moderate (<span class="math inline">\(\sim\)</span> 250 days × features)</td>
<td>Daily/Intraday</td>
<td>Temporal sequence</td>
</tr>
<tr class="odd">
<td>Audio</td>
<td>Earnings calls, conference presentations</td>
<td>Very high (waveform)</td>
<td>Quarterly</td>
<td>Temporal waveform</td>
</tr>
<tr class="even">
<td>Graph</td>
<td>Ownership networks, supply chains, co-holdings</td>
<td>Variable</td>
<td>Quarterly</td>
<td>Adjacency + node features</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Each modality carries both unique and redundant information relative to others. The value of multimodal fusion lies in the unique (complementary) information:</p>
<p><span id="eq-information-inequality"><span class="math display">\[
I(\text{Returns}; \text{Text}, \text{Image}, \text{Tabular}) \geq \max\left(I(\text{Returns}; \text{Text}), I(\text{Returns}; \text{Image}), I(\text{Returns}; \text{Tabular})\right)
\tag{47.1}\]</span></span></p>
<p>where <span class="math inline">\(I(\cdot; \cdot)\)</span> denotes mutual information. The inequality is strict whenever the modalities carry non-redundant predictive content. The goal of fusion is to design architectures that approach the left-hand side.</p>
</section>
<section id="taxonomies-of-fusion" class="level3" data-number="47.1.2">
<h3 data-number="47.1.2" class="anchored" data-anchor-id="taxonomies-of-fusion"><span class="header-section-number">47.1.2</span> Taxonomies of Fusion</h3>
<p>The multimodal learning literature <span class="citation" data-cites="baltruvsaitis2018multimodal liang2024foundations">(<a href="references.html#ref-baltruvsaitis2018multimodal" role="doc-biblioref">Baltrušaitis, Ahuja, and Morency 2018</a>; <a href="references.html#ref-liang2024foundations" role="doc-biblioref">Liang, Zadeh, and Morency 2024</a>)</span> organizes fusion strategies along three dimensions.</p>
<p><strong>By stage.</strong> Where in the processing pipeline are modalities combined?</p>
<ul>
<li><em>Input-level (early) fusion</em>: Concatenate raw or lightly processed features before any shared model.</li>
<li><em>Feature-level (intermediate) fusion</em>: Align learned representations in a shared latent space, then combine.</li>
<li><em>Decision-level (late) fusion</em>: Train separate models per modality, combine predictions.</li>
</ul>
<p><strong>By mechanism.</strong> How are representations combined?</p>
<ul>
<li><em>Concatenation</em>: <span class="math inline">\(\mathbf{z} = [\mathbf{z}^{(1)}; \mathbf{z}^{(2)}; \ldots; \mathbf{z}^{(M)}]\)</span>. Simple but ignores cross-modal interactions.</li>
<li><em>Attention-based</em>: One modality attends to another. Captures interactions but requires sufficient data.</li>
<li><em>Tensor product</em>: <span class="math inline">\(\mathbf{z} = \mathbf{z}^{(1)} \otimes \mathbf{z}^{(2)}\)</span>. Captures all pairwise interactions but scales quadratically.</li>
<li><em>Gating</em>: <span class="math inline">\(\mathbf{z} = g(\mathbf{z}^{(1)}) \odot \mathbf{z}^{(2)} + (1 - g(\mathbf{z}^{(1)})) \odot \mathbf{z}^{(3)}\)</span>. Modality selection.</li>
</ul>
<p><strong>By training.</strong> How are parameters learned?</p>
<ul>
<li><em>Joint training</em>: All modalities processed end-to-end.</li>
<li><em>Pre-train then fuse</em>: Train unimodal encoders separately, then learn the fusion layer.</li>
<li><em>Contrastive alignment</em>: Train modality encoders to produce similar representations for matched pairs (the CLIP approach of <span class="citation" data-cites="radford2021learning">Radford et al. (<a href="references.html#ref-radford2021learning" role="doc-biblioref">2021</a>)</span>).</li>
</ul>
<div id="load-multimodal-data" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DataCore.vn API</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datacore <span class="im">import</span> DataCore</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>dc <span class="op">=</span> DataCore()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load aligned multimodal dataset</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Each observation: firm × quarter with all available modalities</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular: financial statements</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>financials <span class="op">=</span> dc.get_firm_financials(</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    frequency<span class="op">=</span><span class="st">"quarterly"</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Text: management discussion from annual reports</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>report_text <span class="op">=</span> dc.get_annual_report_text(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span><span class="st">"management_discussion"</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Image: satellite nightlight features (from Chapter 61)</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>satellite_features <span class="op">=</span> dc.get_satellite_features(</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    feature_type<span class="op">=</span><span class="st">"cnn_resnet50"</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Time series: daily returns and volume</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>daily_data <span class="op">=</span> dc.get_daily_returns(</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Target: forward quarterly returns</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>quarterly_returns <span class="op">=</span> dc.get_quarterly_returns(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with financials: </span><span class="sc">{</span>financials[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with report text: </span><span class="sc">{</span>report_text[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with satellite data: </span><span class="sc">{</span>satellite_features[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="representation-alignment" class="level2" data-number="47.2">
<h2 data-number="47.2" class="anchored" data-anchor-id="representation-alignment"><span class="header-section-number">47.2</span> Representation Alignment</h2>
<section id="the-alignment-problem" class="level3" data-number="47.2.1">
<h3 data-number="47.2.1" class="anchored" data-anchor-id="the-alignment-problem"><span class="header-section-number">47.2.1</span> The Alignment Problem</h3>
<p>Different modalities produce embeddings in different vector spaces with different geometries. A PhoBERT text embedding lives in <span class="math inline">\(\mathbb{R}^{768}\)</span>; a ResNet50 image feature lives in <span class="math inline">\(\mathbb{R}^{2048}\)</span>; a tabular feature vector might have 50 dimensions with heterogeneous scales. Naively concatenating these into a single vector <span class="math inline">\([\mathbf{z}^{\text{text}}; \mathbf{z}^{\text{image}}; \mathbf{z}^{\text{tab}}] \in \mathbb{R}^{2866}\)</span> is problematic because the high-dimensional modalities dominate gradient flow, the scales are mismatched, and there is no mechanism for cross-modal interaction.</p>
<p>Alignment projects each modality into a shared latent space <span class="math inline">\(\mathbb{R}^d\)</span> where geometric relationships are semantically meaningful (i.e., similar firms should be nearby regardless of which modality is used to represent them).</p>
</section>
<section id="contrastive-alignment-clip-for-finance" class="level3" data-number="47.2.2">
<h3 data-number="47.2.2" class="anchored" data-anchor-id="contrastive-alignment-clip-for-finance"><span class="header-section-number">47.2.2</span> Contrastive Alignment: CLIP for Finance</h3>
<p>The Contrastive Language-Image Pre-training (CLIP) framework of <span class="citation" data-cites="radford2021learning">Radford et al. (<a href="references.html#ref-radford2021learning" role="doc-biblioref">2021</a>)</span> learns aligned representations by training on matched (text, image) pairs. We adapt this to financial data: for each firm-quarter, we have a textual description and a satellite image, and we train the encoders so that matched pairs produce similar embeddings while unmatched pairs produce dissimilar embeddings.</p>
<p>The contrastive loss is:</p>
<p><span id="eq-clip-loss"><span class="math display">\[
\mathcal{L}_{\text{CLIP}} = -\frac{1}{2N}\sum_{i=1}^{N}\left[\log\frac{\exp(\mathbf{z}_i^{\text{txt}} \cdot \mathbf{z}_i^{\text{img}} / \tau)}{\sum_{j=1}^{N}\exp(\mathbf{z}_i^{\text{txt}} \cdot \mathbf{z}_j^{\text{img}} / \tau)} + \log\frac{\exp(\mathbf{z}_i^{\text{img}} \cdot \mathbf{z}_i^{\text{txt}} / \tau)}{\sum_{j=1}^{N}\exp(\mathbf{z}_i^{\text{img}} \cdot \mathbf{z}_j^{\text{txt}} / \tau)}\right]
\tag{47.2}\]</span></span></p>
<p>where <span class="math inline">\(\tau\)</span> is a learnable temperature parameter and the embeddings are <span class="math inline">\(L_2\)</span>-normalized. This is a symmetric version of the InfoNCE loss <span class="citation" data-cites="oord2018representation">(<a href="references.html#ref-oord2018representation" role="doc-biblioref">Oord, Li, and Vinyals 2018</a>)</span> that simultaneously trains the text encoder to predict the correct image and vice versa.</p>
<div id="contrastive-alignment" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinancialCLIP(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Contrastive alignment of text and image embeddings</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    for Vietnamese financial data.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, text_dim<span class="op">=</span><span class="dv">768</span>, image_dim<span class="op">=</span><span class="dv">2048</span>, proj_dim<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text projection</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(text_dim, proj_dim),</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(proj_dim),</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            nn.Linear(proj_dim, proj_dim)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image projection</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            nn.Linear(image_dim, proj_dim),</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(proj_dim),</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            nn.Linear(proj_dim, proj_dim)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Learnable temperature</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_temp <span class="op">=</span> nn.Parameter(torch.tensor(np.log(<span class="dv">1</span> <span class="op">/</span> <span class="fl">0.07</span>)))</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, text_emb, image_emb):</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute aligned embeddings and contrastive loss."""</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Project and normalize</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        z_text <span class="op">=</span> F.normalize(<span class="va">self</span>.text_proj(text_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        z_image <span class="op">=</span> F.normalize(<span class="va">self</span>.image_proj(image_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Similarity matrix</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        temp <span class="op">=</span> <span class="va">self</span>.log_temp.exp()</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> z_text <span class="op">@</span> z_image.T <span class="op">*</span> temp</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Symmetric cross-entropy loss</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> torch.arange(<span class="bu">len</span>(text_emb), device<span class="op">=</span>text_emb.device)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        loss_t2i <span class="op">=</span> F.cross_entropy(logits, labels)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        loss_i2t <span class="op">=</span> F.cross_entropy(logits.T, labels)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> (loss_t2i <span class="op">+</span> loss_i2t) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> z_text, z_image, loss</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode_text(<span class="va">self</span>, text_emb):</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.normalize(<span class="va">self</span>.text_proj(text_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode_image(<span class="va">self</span>, image_emb):</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.normalize(<span class="va">self</span>.image_proj(image_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="projection-alignment-for-arbitrary-modalities" class="level3" data-number="47.2.3">
<h3 data-number="47.2.3" class="anchored" data-anchor-id="projection-alignment-for-arbitrary-modalities"><span class="header-section-number">47.2.3</span> Projection Alignment for Arbitrary Modalities</h3>
<p>For more than two modalities, we generalize to a shared projection space where each modality has its own encoder but all encoders map to the same target space:</p>
<p><span id="eq-projection"><span class="math display">\[
\mathbf{z}_i^{(m)} = f^{(m)}(\mathbf{x}_i^{(m)}; \boldsymbol{\theta}^{(m)}) \in \mathbb{R}^d, \qquad m = 1, \ldots, M
\tag{47.3}\]</span></span></p>
<p>The alignment loss encourages all modality embeddings for the same observation to be similar:</p>
<p><span id="eq-alignment-loss"><span class="math display">\[
\mathcal{L}_{\text{align}} = \sum_{m &lt; m'} \frac{1}{N}\sum_{i=1}^{N} \left\|\mathbf{z}_i^{(m)} - \mathbf{z}_i^{(m')}\right\|^2
\tag{47.4}\]</span></span></p>
<p>This MSE alignment is simpler than contrastive alignment but does not enforce the discriminative property (different observations should have dissimilar embeddings). In practice, we combine alignment with a prediction objective:</p>
<p><span id="eq-total-loss"><span class="math display">\[
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{predict}}(\hat{y}, y) + \lambda \cdot \mathcal{L}_{\text{align}}
\tag{47.5}\]</span></span></p>
<div id="multi-projection" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalProjector(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Project arbitrary modalities into a shared latent space.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Supports variable numbers of modalities per observation.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, modality_dims, proj_dim<span class="op">=</span><span class="dv">128</span>, dropout<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">        modality_dims : dict</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: input_dim}, e.g.,</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">            {'text': 768, 'image': 2048, 'tabular': 50, 'ts': 128}</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">        proj_dim : int</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">            Shared projection dimensionality.</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(modality_dims.keys())</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_dim <span class="op">=</span> proj_dim</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-modality encoders</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, dim <span class="kw">in</span> modality_dims.items():</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.encoders[name] <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>                nn.Linear(dim, proj_dim <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                nn.LayerNorm(proj_dim <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                nn.GELU(),</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(dropout),</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                nn.Linear(proj_dim <span class="op">*</span> <span class="dv">2</span>, proj_dim),</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                nn.LayerNorm(proj_dim)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modality_inputs):</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co">        modality_inputs : dict</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: tensor}, may be missing some modalities.</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="co">        -------</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co">        dict : {modality_name: projected_embedding}</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, x <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> <span class="va">self</span>.encoders <span class="kw">and</span> x <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> <span class="va">self</span>.encoders[name](x)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> embeddings</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_alignment_loss(<span class="va">self</span>, embeddings):</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Pairwise MSE alignment across all available modalities."""</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>        names <span class="op">=</span> <span class="bu">list</span>(embeddings.keys())</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(names) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.tensor(<span class="fl">0.0</span>, device<span class="op">=</span><span class="bu">next</span>(<span class="va">self</span>.parameters()).device)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, device<span class="op">=</span><span class="bu">next</span>(<span class="va">self</span>.parameters()).device)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>        n_pairs <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(names)):</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i <span class="op">+</span> <span class="dv">1</span>, <span class="bu">len</span>(names)):</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">+=</span> F.mse_loss(</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>                    embeddings[names[i]], embeddings[names[j]]</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>                n_pairs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss <span class="op">/</span> n_pairs <span class="cf">if</span> n_pairs <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="fusion-architectures-for-return-prediction" class="level2" data-number="47.3">
<h2 data-number="47.3" class="anchored" data-anchor-id="fusion-architectures-for-return-prediction"><span class="header-section-number">47.3</span> Fusion Architectures for Return Prediction</h2>
<section id="unimodal-encoders" class="level3" data-number="47.3.1">
<h3 data-number="47.3.1" class="anchored" data-anchor-id="unimodal-encoders"><span class="header-section-number">47.3.1</span> Unimodal Encoders</h3>
<p>Before fusing modalities, we need encoders that produce fixed-dimensional representations from each raw input. We build four encoders corresponding to the primary modalities in Vietnamese equity markets.</p>
<div id="unimodal-encoders" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TabularEncoder(nn.Module):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Encode financial statement features."""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hidden_dim<span class="op">=</span><span class="dv">128</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, hidden_dim),</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(hidden_dim),</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim),</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(hidden_dim),</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, output_dim)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TextEncoder(nn.Module):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode Vietnamese text using pre-extracted PhoBERT embeddings.</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: pre-computed [CLS] token embedding (768-d).</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">768</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">256</span>),</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(<span class="dv">256</span>),</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, output_dim)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageEncoder(nn.Module):</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode satellite / document image features.</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: pre-computed CNN features (e.g., ResNet50 2048-d).</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">2048</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">512</span>),</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(<span class="dv">512</span>),</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, output_dim)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimeSeriesEncoder(nn.Module):</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode price/volume time series using a 1D CNN + attention.</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: (batch, seq_len, n_features) tensor of daily data.</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features<span class="op">=</span><span class="dv">5</span>, seq_len<span class="op">=</span><span class="dv">60</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1D convolutional layers</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv1d(n_features, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv1d(<span class="dv">32</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.AdaptiveAvgPool1d(<span class="dv">1</span>)</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Temporal attention</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>            embed_dim<span class="op">=</span><span class="dv">64</span>, num_heads<span class="op">=</span><span class="dv">4</span>, batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(<span class="dv">64</span>, output_dim)</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x: (B, T, F) -&gt; (B, F, T) for Conv1d</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv1(x))</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv2(x))</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, 64, T) -&gt; (B, T, 64) for attention</span></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>        attn_out, _ <span class="op">=</span> <span class="va">self</span>.attn(x, x, x)</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pool over time</span></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> attn_out.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># (B, 64, T)</span></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(x).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B, 64)</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.fc(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="early-fusion" class="level3" data-number="47.3.2">
<h3 data-number="47.3.2" class="anchored" data-anchor-id="early-fusion"><span class="header-section-number">47.3.2</span> Early Fusion</h3>
<p>Early fusion concatenates modality embeddings before a shared prediction head. This is the simplest approach and serves as a natural baseline.</p>
<div id="early-fusion" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EarlyFusionModel(nn.Module):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Concatenate modality embeddings, then predict.</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, hidden_dim<span class="op">=</span><span class="dv">128</span>, output_dim<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">        encoders : dict</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: encoder_module}</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">            Each encoder outputs a vector of the same dimension.</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Infer encoder output dim from first encoder</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        sample_encoder <span class="op">=</span> <span class="bu">list</span>(encoders.values())[<span class="dv">0</span>]</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        enc_dim <span class="op">=</span> <span class="bu">list</span>(sample_encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, hidden_dim),</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim),</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, output_dim)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co">        inputs : dict</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: tensor}</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>                embeddings.append(encoder(inputs[name]))</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Zero-fill missing modalities</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>                embeddings.append(torch.zeros(</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>                    inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>],</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>                    enc_dim, device<span class="op">=</span>device</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>                ))</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat(embeddings, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="late-fusion" class="level3" data-number="47.3.3">
<h3 data-number="47.3.3" class="anchored" data-anchor-id="late-fusion"><span class="header-section-number">47.3.3</span> Late Fusion</h3>
<p>Late fusion trains independent models per modality and combines their predictions. The combination weights can be fixed (equal averaging), learned (linear), or adaptive (gating network).</p>
<div id="late-fusion" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LateFusionModel(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Independent prediction per modality, learned combination.</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, combination<span class="op">=</span><span class="st">"learned"</span>):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">        combination : str</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">            'average', 'learned', or 'gating'.</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.combination <span class="op">=</span> combination</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-modality prediction heads</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>            name: nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name <span class="kw">in</span> encoders</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights <span class="op">=</span> nn.Parameter(</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>                torch.ones(<span class="va">self</span>.n_modalities) <span class="op">/</span> <span class="va">self</span>.n_modalities</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> combination <span class="op">==</span> <span class="st">"gating"</span>:</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gating network takes all embeddings as input</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.gate <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>                nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, <span class="va">self</span>.n_modalities),</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>                nn.Softmax(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> {}</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> encoder(inputs[name])</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> <span class="va">self</span>.heads[name](emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                predictions[name] <span class="op">=</span> pred</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> emb</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>]</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>                predictions[name] <span class="op">=</span> torch.zeros(batch_size, device<span class="op">=</span>device)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> torch.zeros(</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>                    batch_size, enc_dim, device<span class="op">=</span>device</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        pred_stack <span class="op">=</span> torch.stack(<span class="bu">list</span>(predictions.values()), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"average"</span>:</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> pred_stack.mean(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>            weights <span class="op">=</span> F.softmax(<span class="va">self</span>.weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> (pred_stack <span class="op">*</span> weights).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"gating"</span>:</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>            all_emb <span class="op">=</span> torch.cat(<span class="bu">list</span>(embeddings.values()), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>            gate_weights <span class="op">=</span> <span class="va">self</span>.gate(all_emb)</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> (pred_stack <span class="op">*</span> gate_weights).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_modality_weights(<span class="va">self</span>):</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Return the contribution of each modality."""</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> F.softmax(<span class="va">self</span>.weights, dim<span class="op">=</span><span class="dv">0</span>).detach().cpu().numpy()</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="cross-attention-fusion" class="level3" data-number="47.3.4">
<h3 data-number="47.3.4" class="anchored" data-anchor-id="cross-attention-fusion"><span class="header-section-number">47.3.4</span> Cross-Attention Fusion</h3>
<p>Cross-attention fusion is the most expressive architecture. Each modality attends to every other modality, learning which cross-modal interactions are informative. This is the mechanism underlying modern vision-language models like Flamingo <span class="citation" data-cites="alayrac2022flamingo">(<a href="references.html#ref-alayrac2022flamingo" role="doc-biblioref">Alayrac et al. 2022</a>)</span> and GPT-4V.</p>
<p>The cross-attention operation for modality <span class="math inline">\(m\)</span> attending to modality <span class="math inline">\(m'\)</span> is:</p>
<p><span id="eq-cross-attention-detail"><span class="math display">\[
\text{CA}^{(m \to m')} = \text{softmax}\left(\frac{\mathbf{Q}^{(m)} \left(\mathbf{K}^{(m')}\right)^\top}{\sqrt{d_k}}\right) \mathbf{V}^{(m')}
\tag{47.6}\]</span></span></p>
<p>where <span class="math inline">\(\mathbf{Q}^{(m)} = \mathbf{z}^{(m)} W_Q\)</span>, <span class="math inline">\(\mathbf{K}^{(m')} = \mathbf{z}^{(m')} W_K\)</span>, <span class="math inline">\(\mathbf{V}^{(m')} = \mathbf{z}^{(m')} W_V\)</span>. The output enriches modality <span class="math inline">\(m\)</span>’s representation with information from modality <span class="math inline">\(m'\)</span>.</p>
<div id="cross-attention-fusion" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossAttentionBlock(nn.Module):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Single cross-attention block: query modality attends to key modality."""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, n_heads<span class="op">=</span><span class="dv">4</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>            embed_dim<span class="op">=</span>dim, num_heads<span class="op">=</span>n_heads,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span>dropout, batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ffn <span class="op">=</span> nn.Sequential(</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            nn.Linear(dim, dim <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout),</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            nn.Linear(dim <span class="op">*</span> <span class="dv">4</span>, dim),</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, query, key_value):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> query.unsqueeze(<span class="dv">1</span>) <span class="cf">if</span> query.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> query</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        kv <span class="op">=</span> key_value.unsqueeze(<span class="dv">1</span>) <span class="cf">if</span> key_value.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> key_value</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        attn_out, attn_weights <span class="op">=</span> <span class="va">self</span>.attn(q, kv, kv)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.norm1(q <span class="op">+</span> attn_out)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Feed-forward</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.norm2(q <span class="op">+</span> <span class="va">self</span>.ffn(q))</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out.squeeze(<span class="dv">1</span>) <span class="cf">if</span> query.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> out, attn_weights</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossAttentionFusionModel(nn.Module):</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Full cross-attention fusion across M modalities.</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Each modality attends to all others via cross-attention blocks.</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, n_layers<span class="op">=</span><span class="dv">2</span>, n_heads<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(encoders.keys())</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention blocks: each modality attends to each other</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cross_attn_layers <span class="op">=</span> nn.ModuleList()</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers):</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>            layer <span class="op">=</span> nn.ModuleDict()</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> m_prime <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> m <span class="op">!=</span> m_prime:</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>                        layer[<span class="ss">f"</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">_to_</span><span class="sc">{</span>m_prime<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> CrossAttentionBlock(</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>                            enc_dim, n_heads</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.cross_attn_layers.append(layer)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, enc_dim),</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(enc_dim),</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> encoder(inputs[name])</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>]</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> torch.zeros(</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>                    batch_size, enc_dim, device<span class="op">=</span>device</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention layers</span></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>        all_attn_weights <span class="op">=</span> {}</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.cross_attn_layers:</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>            new_embeddings <span class="op">=</span> {k: v.clone() <span class="cf">for</span> k, v <span class="kw">in</span> embeddings.items()}</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> key, block <span class="kw">in</span> layer.items():</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>                parts <span class="op">=</span> key.split(<span class="st">"_to_"</span>)</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a>                query_mod, kv_mod <span class="op">=</span> parts[<span class="dv">0</span>], parts[<span class="dv">1</span>]</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> query_mod <span class="kw">in</span> embeddings <span class="kw">and</span> kv_mod <span class="kw">in</span> embeddings:</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a>                    updated, weights <span class="op">=</span> block(</span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a>                        embeddings[query_mod],</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a>                        embeddings[kv_mod]</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>                    new_embeddings[query_mod] <span class="op">=</span> (</span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a>                        new_embeddings[query_mod] <span class="op">+</span> updated</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a>                    all_attn_weights[key] <span class="op">=</span> weights</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a>            embeddings <span class="op">=</span> new_embeddings</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate and predict</span></span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat(</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>            [embeddings[name] <span class="cf">for</span> name <span class="kw">in</span> <span class="va">self</span>.modality_names],</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>), all_attn_weights</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="comparison-experiment" class="level3" data-number="47.3.5">
<h3 data-number="47.3.5" class="anchored" data-anchor-id="comparison-experiment"><span class="header-section-number">47.3.5</span> Comparison Experiment</h3>
<p>We now compare the three fusion architectures against unimodal baselines on forward quarterly return prediction for Vietnamese equities.</p>
<div id="multimodal-dataset" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalFinanceDataset(Dataset):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Dataset that aligns multiple modalities per firm-quarter.</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Handles missing modalities with None values.</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tabular_df, text_embeddings, image_features,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>                 ts_features, returns, tickers, dates):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular <span class="op">=</span> tabular_df</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text <span class="op">=</span> text_embeddings</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image <span class="op">=</span> image_features</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ts <span class="op">=</span> ts_features</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.returns <span class="op">=</span> returns</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tickers <span class="op">=</span> tickers</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dates <span class="op">=</span> dates</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.returns)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> {</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">"tabular"</span>: torch.tensor(</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.tabular[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.tabular[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: torch.tensor(</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.text[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.text[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"image"</span>: torch.tensor(</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.image[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.image[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ts"</span>: torch.tensor(</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.ts[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.ts[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>            <span class="st">"return"</span>: torch.tensor(</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.returns[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ticker"</span>: <span class="va">self</span>.tickers[idx],</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">"date"</span>: <span class="va">self</span>.dates[idx]</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collate_multimodal(batch):</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Custom collate that handles None modalities."""</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> {<span class="st">"return"</span>: torch.stack([b[<span class="st">"return"</span>] <span class="cf">for</span> b <span class="kw">in</span> batch])}</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mod <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]:</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        values <span class="op">=</span> [b[mod] <span class="cf">for</span> b <span class="kw">in</span> batch]</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> values):</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> torch.stack(values)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">any</span>(v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> values):</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fill None with zeros, matching shape of non-None entries</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>            ref <span class="op">=</span> <span class="bu">next</span>(v <span class="cf">for</span> v <span class="kw">in</span> values <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>            filled <span class="op">=</span> [v <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> torch.zeros_like(ref)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">for</span> v <span class="kw">in</span> values]</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> torch.stack(filled)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="prepare-aligned-data" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare aligned firm-quarter dataset</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Financial ratios (tabular)</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>tabular_features <span class="op">=</span> [</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"roe"</span>, <span class="st">"roa"</span>, <span class="st">"book_to_market"</span>, <span class="st">"log_size"</span>, <span class="st">"leverage"</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"asset_growth"</span>, <span class="st">"gross_profitability"</span>, <span class="st">"capex_to_assets"</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cash_to_assets"</span>, <span class="st">"dividend_yield"</span>, <span class="st">"sales_growth"</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accruals"</span>, <span class="st">"earnings_volatility"</span>, <span class="st">"beta"</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>financials[<span class="st">"quarter_date"</span>] <span class="op">=</span> pd.to_datetime(</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    financials[<span class="st">"year"</span>].astype(<span class="bu">str</span>) <span class="op">+</span> <span class="st">"-"</span> <span class="op">+</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    (financials[<span class="st">"quarter"</span>] <span class="op">*</span> <span class="dv">3</span>).astype(<span class="bu">str</span>).<span class="bu">str</span>.zfill(<span class="dv">2</span>) <span class="op">+</span> <span class="st">"-01"</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Text embeddings from PhoBERT</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># (Pre-computed in Chapter 60)</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>text_emb <span class="op">=</span> dc.get_text_embeddings(</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"phobert"</span>,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span><span class="st">"management_discussion"</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Image features (pre-computed in Chapter 61)</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Satellite CNN features linked to firm headquarters province</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Time series features (60-day window before quarter end)</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_ts_features(ticker, date, daily_df, lookback<span class="op">=</span><span class="dv">60</span>):</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract time-series feature tensor for a firm-quarter."""</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> (</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"ticker"</span>] <span class="op">==</span> ticker) <span class="op">&amp;</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"date"</span>] <span class="op">&lt;=</span> date) <span class="op">&amp;</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"date"</span>] <span class="op">&gt;=</span> date <span class="op">-</span> pd.Timedelta(days<span class="op">=</span>lookback <span class="op">*</span> <span class="fl">1.5</span>))</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    subset <span class="op">=</span> daily_df[mask].sort_values(<span class="st">"date"</span>).tail(lookback)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(subset) <span class="op">&lt;</span> lookback <span class="op">//</span> <span class="dv">2</span>:</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> subset[[<span class="st">"ret"</span>, <span class="st">"volume_log"</span>, <span class="st">"volatility_20d"</span>,</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"spread"</span>, <span class="st">"turnover"</span>]].values</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pad if shorter than lookback</span></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(features) <span class="op">&lt;</span> lookback:</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>        padding <span class="op">=</span> np.zeros((lookback <span class="op">-</span> <span class="bu">len</span>(features), features.shape[<span class="dv">1</span>]))</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> np.vstack([padding, features])</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Forward quarterly returns (target)</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Align everything to quarter-end dates</span></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Preparing aligned multimodal dataset..."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="training-loop" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_multimodal_model(model, train_loader, val_loader,</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                            n_epochs<span class="op">=</span><span class="dv">50</span>, lr<span class="op">=</span><span class="fl">1e-3</span>, patience<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                            alignment_weight<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Train a multimodal model with early stopping.</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Multimodal fusion model.</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    alignment_weight : float</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Weight for modality alignment loss (0 = no alignment).</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : Training history and best validation metrics.</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr,</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>                                   weight_decay<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> torch.optim.lr_scheduler.ReduceLROnPlateau(</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        optimizer, mode<span class="op">=</span><span class="st">"min"</span>, patience<span class="op">=</span><span class="dv">5</span>, factor<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    epochs_no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_loss"</span>: [], <span class="st">"val_loss"</span>: [], <span class="st">"val_r2"</span>: []}</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        train_losses <span class="op">=</span> []</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {k: batch[k] <span class="cf">for</span> k <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]}</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass (handle both output types)</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(inputs)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>):</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>                predictions, attn_weights <span class="op">=</span> output</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>                predictions <span class="op">=</span> output</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.mse_loss(predictions, targets)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Optional alignment loss</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> alignment_weight <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> <span class="bu">hasattr</span>(model, <span class="st">"projector"</span>):</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>                embeddings <span class="op">=</span> model.projector(inputs)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>                align_loss <span class="op">=</span> model.projector.compute_alignment_loss(embeddings)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss <span class="op">+</span> alignment_weight <span class="op">*</span> align_loss</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>            train_losses.append(loss.item())</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation</span></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>        val_preds, val_targets <span class="op">=</span> [], []</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>        val_losses <span class="op">=</span> []</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> {k: batch[k]</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> k <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]}</span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> model(inputs)</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>):</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>                    predictions, _ <span class="op">=</span> output</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>                    predictions <span class="op">=</span> output</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>                val_losses.append(F.mse_loss(predictions, targets).item())</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>                val_preds.extend(predictions.cpu().numpy())</span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>                val_targets.extend(targets.cpu().numpy())</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> np.mean(val_losses)</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>        val_r2 <span class="op">=</span> r2_score(val_targets, val_preds) <span class="cf">if</span> <span class="bu">len</span>(val_preds) <span class="op">&gt;</span> <span class="dv">10</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_loss"</span>].append(np.mean(train_losses))</span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"val_loss"</span>].append(val_loss)</span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"val_r2"</span>].append(val_r2)</span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>        scheduler.step(val_loss)</span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early stopping</span></span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>            best_state <span class="op">=</span> {k: v.cpu().clone()</span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>            epochs_no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>            epochs_no_improve <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> epochs_no_improve <span class="op">&gt;=</span> patience:</span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Restore best model</span></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_state)</span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>        <span class="st">"history"</span>: history,</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_val_loss"</span>: best_val_loss,</span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_val_r2"</span>: <span class="bu">max</span>(history[<span class="st">"val_r2"</span>]),</span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a>        <span class="st">"epochs_trained"</span>: <span class="bu">len</span>(history[<span class="st">"train_loss"</span>])</span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="model-comparison" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_fusion_strategies(dataset, n_splits<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compare unimodal baselines and multimodal fusion strategies</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">    using expanding-window time-series cross-validation.</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame : Out-of-sample R², MSE, IC for each model.</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    tscv <span class="op">=</span> TimeSeriesSplit(n_splits<span class="op">=</span>n_splits)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    enc_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold, (train_idx, test_idx) <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        tscv.split(<span class="bu">range</span>(<span class="bu">len</span>(dataset)))</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create data loaders</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        train_subset <span class="op">=</span> torch.utils.data.Subset(dataset, train_idx)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        test_subset <span class="op">=</span> torch.utils.data.Subset(dataset, test_idx)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>            train_subset, batch_size<span class="op">=</span><span class="dv">128</span>, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>            collate_fn<span class="op">=</span>collate_multimodal</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>        test_loader <span class="op">=</span> DataLoader(</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            test_subset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>            collate_fn<span class="op">=</span>collate_multimodal</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define encoders</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> make_encoders():</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>                <span class="st">"tabular"</span>: TabularEncoder(<span class="bu">len</span>(tabular_features), <span class="dv">128</span>, enc_dim),</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"text"</span>: TextEncoder(<span class="dv">768</span>, enc_dim),</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"image"</span>: ImageEncoder(<span class="dv">2048</span>, enc_dim),</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ts"</span>: TimeSeriesEncoder(<span class="dv">5</span>, <span class="dv">60</span>, enc_dim)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unimodal baselines</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> mod_name <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]:</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>            single_encoder <span class="op">=</span> {mod_name: make_encoders()[mod_name]}</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> EarlyFusionModel(single_encoder, enc_dim, <span class="dv">1</span>)</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>                model, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>            results.append({</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>                <span class="st">"fold"</span>: fold,</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>                <span class="st">"model"</span>: <span class="ss">f"Unimodal (</span><span class="sc">{</span>mod_name<span class="sc">}</span><span class="ss">)"</span>,</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>                <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>                <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Early Fusion</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>        model_early <span class="op">=</span> EarlyFusionModel(make_encoders(), enc_dim <span class="op">*</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>            model_early, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Early Fusion"</span>,</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Late Fusion (gating)</span></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>        model_late <span class="op">=</span> LateFusionModel(</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>            make_encoders(), enc_dim, combination<span class="op">=</span><span class="st">"gating"</span></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>            model_late, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Late Fusion (Gating)"</span>,</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Cross-Attention</span></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a>        model_ca <span class="op">=</span> CrossAttentionFusionModel(</span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a>            make_encoders(), enc_dim, n_layers<span class="op">=</span><span class="dv">2</span>, n_heads<span class="op">=</span><span class="dv">4</span></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>            model_ca, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Cross-Attention Fusion"</span>,</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-fusion-comparison" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="13">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.2: Out-of-Sample Return Prediction: Unimodal vs.&nbsp;Multimodal
</figcaption>
<div aria-describedby="tbl-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># results_df = compare_fusion_strategies(dataset)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate across folds</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># summary = (</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     results_df.groupby("model")</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     .agg(</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         mean_r2=("val_r2", "mean"),</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         std_r2=("val_r2", "std"),</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">#         mean_loss=("val_loss", "mean")</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">#     .sort_values("mean_r2", ascending=False)</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">#     .round(4)</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># summary</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</figure>
</div>
<div id="fig-fusion-comparison" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="14">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># (</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     p9.ggplot(results_df, p9.aes(x="model", y="val_r2", fill="model"))</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.geom_boxplot(alpha=0.7)</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.coord_flip()</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.labs(</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="", y="Out-of-Sample R²",</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         title="Multimodal Fusion Improves Return Prediction"</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme_minimal()</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme(figure_size=(10, 6), legend_position="none")</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-fusion-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;47.1
</figcaption>
</figure>
</div>
</section>
</section>
<section id="handling-missing-modalities" class="level2" data-number="47.4">
<h2 data-number="47.4" class="anchored" data-anchor-id="handling-missing-modalities"><span class="header-section-number">47.4</span> Handling Missing Modalities</h2>
<section id="the-missing-modality-problem" class="level3" data-number="47.4.1">
<h3 data-number="47.4.1" class="anchored" data-anchor-id="the-missing-modality-problem"><span class="header-section-number">47.4.1</span> The Missing Modality Problem</h3>
<p>In practice, not every firm-quarter has every modality available. A firm may not have an earnings call transcript (no audio), its headquarters may be in a province where satellite coverage is intermittent (no image), or its annual report may not be publicly available in digital form (no text). This creates a missing modality problem that is structurally different from missing values in tabular data: an entire feature vector (hundreds or thousands of dimensions) is absent.</p>
<p>The fraction of observations with all four modalities available is typically much smaller than the fraction with at least one:</p>
<div id="tbl-modality-coverage" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-modality-coverage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.3: Modality Availability in Vietnamese Market Data
</figcaption>
<div aria-describedby="tbl-modality-coverage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Available Modalities</th>
<th>Typical Coverage (Vietnamese Firms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tabular only</td>
<td><span class="math inline">\(\sim\)</span> 95% of firm-quarters</td>
</tr>
<tr class="even">
<td>Tabular + Text</td>
<td><span class="math inline">\(\sim\)</span> 70%</td>
</tr>
<tr class="odd">
<td>Tabular + Text + Image</td>
<td><span class="math inline">\(\sim\)</span> 50%</td>
</tr>
<tr class="even">
<td>All four (+ time series)</td>
<td><span class="math inline">\(\sim\)</span> 45%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Restricting the sample to complete cases discards half the data and introduces selection bias (larger, more transparent firms are overrepresented). We need architectures that degrade gracefully when modalities are missing.</p>
</section>
<section id="strategies-for-missing-modalities" class="level3" data-number="47.4.2">
<h3 data-number="47.4.2" class="anchored" data-anchor-id="strategies-for-missing-modalities"><span class="header-section-number">47.4.2</span> Strategies for Missing Modalities</h3>
<ul>
<li><p><strong>Zero imputation.</strong> Replace missing modality embeddings with zeros. Simple but introduces bias: the model cannot distinguish “this modality is absent” from “this modality has zero signal.”</p></li>
<li><p><strong>Learned default embedding.</strong> Replace missing modalities with a learnable “default” vector <span class="math inline">\(\mathbf{d}^{(m)}\)</span> that is trained alongside the model. This allows the model to learn what the absence of a modality implies.</p></li>
<li><p><strong>Modality dropout.</strong> During training, randomly drop entire modalities with probability <span class="math inline">\(p\)</span> (analogous to dropout on neurons). This forces the model to perform well even when modalities are missing, and acts as regularization.</p></li>
<li><p><strong>Mixture of Experts (MoE).</strong> Route each observation to a fusion subnetwork specialized for its available modality combination. With <span class="math inline">\(M\)</span> modalities, there are <span class="math inline">\(2^M - 1\)</span> possible subsets, requiring efficient parameter sharing.</p></li>
</ul>
<div id="missing-modality-handler" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModalityDropout(nn.Module):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Randomly drop entire modalities during training.</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Forces robustness to missing inputs at test time.</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.drop_prob <span class="op">=</span> drop_prob</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modality_inputs):</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.training:</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> modality_inputs</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {}</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, tensor <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> tensor <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> torch.rand(<span class="dv">1</span>).item() <span class="op">&gt;</span> <span class="va">self</span>.drop_prob:</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>                result[name] <span class="op">=</span> tensor</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>                result[name] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure at least one modality remains</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(v <span class="kw">is</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> result.values()):</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Keep the first available modality</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name, tensor <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> tensor <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>                    result[name] <span class="op">=</span> tensor</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RobustFusionModel(nn.Module):</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Multimodal model robust to missing modalities.</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Uses learned default embeddings and modality dropout.</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(encoders.keys())</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_dim <span class="op">=</span> enc_dim</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Learned default embeddings for missing modalities</span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.defaults <span class="op">=</span> nn.ParameterDict({</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>            name: nn.Parameter(torch.randn(enc_dim) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name <span class="kw">in</span> encoders</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality presence indicator embedding</span></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.presence_proj <span class="op">=</span> nn.Linear(<span class="va">self</span>.n_modalities, enc_dim)</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality dropout</span></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mod_dropout <span class="op">=</span> ModalityDropout(drop_prob)</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Attention-based aggregation</span></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn_pool <span class="op">=</span> nn.Sequential(</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>),</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="dv">2</span>, enc_dim),</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(enc_dim),</span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply modality dropout during training</span></span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">self</span>.mod_dropout(inputs)</span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>        presence <span class="op">=</span> []</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> <span class="va">self</span>.encoders[name](inputs[name])</span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a>                embeddings.append(emb)</span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>                presence.append(<span class="fl">1.0</span>)</span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> <span class="bu">next</span>(</span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>                    v.shape[<span class="dv">0</span>] <span class="cf">for</span> v <span class="kw">in</span> inputs.values()</span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> <span class="va">self</span>.defaults[name].unsqueeze(<span class="dv">0</span>).expand(</span>
<span id="cb15-91"><a href="#cb15-91" aria-hidden="true" tabindex="-1"></a>                    batch_size, <span class="op">-</span><span class="dv">1</span></span>
<span id="cb15-92"><a href="#cb15-92" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb15-93"><a href="#cb15-93" aria-hidden="true" tabindex="-1"></a>                embeddings.append(emb)</span>
<span id="cb15-94"><a href="#cb15-94" aria-hidden="true" tabindex="-1"></a>                presence.append(<span class="fl">0.0</span>)</span>
<span id="cb15-95"><a href="#cb15-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-96"><a href="#cb15-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stack: (n_modalities, batch, enc_dim)</span></span>
<span id="cb15-97"><a href="#cb15-97" aria-hidden="true" tabindex="-1"></a>        emb_stack <span class="op">=</span> torch.stack(embeddings, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-98"><a href="#cb15-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-99"><a href="#cb15-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Attention-weighted aggregation</span></span>
<span id="cb15-100"><a href="#cb15-100" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> <span class="va">self</span>.attn_pool(emb_stack)  <span class="co"># (n_mod, batch, 1)</span></span>
<span id="cb15-101"><a href="#cb15-101" aria-hidden="true" tabindex="-1"></a>        aggregated <span class="op">=</span> (emb_stack <span class="op">*</span> attn_weights).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>)  <span class="co"># (batch, enc_dim)</span></span>
<span id="cb15-102"><a href="#cb15-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-103"><a href="#cb15-103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Presence indicator</span></span>
<span id="cb15-104"><a href="#cb15-104" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> aggregated.device</span>
<span id="cb15-105"><a href="#cb15-105" aria-hidden="true" tabindex="-1"></a>        presence_tensor <span class="op">=</span> torch.tensor(</span>
<span id="cb15-106"><a href="#cb15-106" aria-hidden="true" tabindex="-1"></a>            presence, device<span class="op">=</span>device</span>
<span id="cb15-107"><a href="#cb15-107" aria-hidden="true" tabindex="-1"></a>        ).unsqueeze(<span class="dv">0</span>).expand(aggregated.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb15-108"><a href="#cb15-108" aria-hidden="true" tabindex="-1"></a>        presence_emb <span class="op">=</span> <span class="va">self</span>.presence_proj(presence_tensor)</span>
<span id="cb15-109"><a href="#cb15-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-110"><a href="#cb15-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine</span></span>
<span id="cb15-111"><a href="#cb15-111" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([aggregated, presence_emb], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb15-112"><a href="#cb15-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="multimodal-document-understanding" class="level2" data-number="47.5">
<h2 data-number="47.5" class="anchored" data-anchor-id="multimodal-document-understanding"><span class="header-section-number">47.5</span> Multimodal Document Understanding</h2>
<section id="annual-report-as-a-multimodal-object" class="level3" data-number="47.5.1">
<h3 data-number="47.5.1" class="anchored" data-anchor-id="annual-report-as-a-multimodal-object"><span class="header-section-number">47.5.1</span> Annual Report as a Multimodal Object</h3>
<p>A Vietnamese annual report is inherently multimodal: it contains running text (management discussion, risk factors, strategy), tables (financial statements, segment data, shareholder structure), images (photographs of facilities, products, management), and charts (revenue trends, market share). Prior chapters treated these as separate extraction problems. Here we build a model that processes the entire report as a unified multimodal document.</p>
<p>The architecture follows the Document Understanding Transformer (Donut) approach of <span class="citation" data-cites="kim2022ocr">Kim et al. (<a href="references.html#ref-kim2022ocr" role="doc-biblioref">2022</a>)</span>, adapted for Vietnamese financial filings:</p>
<p><span id="eq-donut"><span class="math display">\[
\mathbf{h} = \text{Encoder}(\mathbf{I}_{\text{page}}) + \text{Encoder}(\mathbf{T}_{\text{ocr}}) + \text{Encoder}(\mathbf{L}_{\text{layout}})
\tag{47.7}\]</span></span></p>
<p>where <span class="math inline">\(\mathbf{I}\)</span> is the page image, <span class="math inline">\(\mathbf{T}\)</span> is the OCR text, and <span class="math inline">\(\mathbf{L}\)</span> is the spatial layout (bounding boxes). The joint representation <span class="math inline">\(\mathbf{h}\)</span> captures both what is written and where it appears on the page.</p>
<div id="multimodal-document" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalDocumentEncoder(nn.Module):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Joint encoder for Vietnamese annual report pages.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Processes text, layout, and page image simultaneously.</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size<span class="op">=</span><span class="dv">64000</span>, max_boxes<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>                 img_dim<span class="op">=</span><span class="dv">2048</span>, hidden_dim<span class="op">=</span><span class="dv">256</span>, n_layers<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>                 n_heads<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text embedding (Vietnamese tokens)</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_emb <span class="op">=</span> nn.Embedding(vocab_size, hidden_dim)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Layout embedding (bounding box coordinates)</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Each box: [x0, y0, x1, y1] normalized to [0, 1000]</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x_emb <span class="op">=</span> nn.Embedding(<span class="dv">1001</span>, hidden_dim <span class="op">//</span> <span class="dv">4</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_emb <span class="op">=</span> nn.Embedding(<span class="dv">1001</span>, hidden_dim <span class="op">//</span> <span class="dv">4</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image patch embedding</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>            nn.Linear(img_dim, hidden_dim),</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality type embedding</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_emb <span class="op">=</span> nn.Embedding(<span class="dv">3</span>, hidden_dim)  <span class="co"># text, layout, image</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer encoder</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        encoder_layer <span class="op">=</span> nn.TransformerEncoderLayer(</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>            d_model<span class="op">=</span>hidden_dim,</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>            nhead<span class="op">=</span>n_heads,</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>            dim_feedforward<span class="op">=</span>hidden_dim <span class="op">*</span> <span class="dv">4</span>,</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>            activation<span class="op">=</span><span class="st">"gelu"</span>,</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer <span class="op">=</span> nn.TransformerEncoder(</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>            encoder_layer, num_layers<span class="op">=</span>n_layers</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [CLS] token</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cls_token <span class="op">=</span> nn.Parameter(torch.randn(<span class="dv">1</span>, <span class="dv">1</span>, hidden_dim))</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> embed_layout(<span class="va">self</span>, boxes):</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Embed bounding box coordinates."""</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>        x0 <span class="op">=</span> <span class="va">self</span>.x_emb(boxes[:, :, <span class="dv">0</span>])</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>        y0 <span class="op">=</span> <span class="va">self</span>.y_emb(boxes[:, :, <span class="dv">1</span>])</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>        x1 <span class="op">=</span> <span class="va">self</span>.x_emb(boxes[:, :, <span class="dv">2</span>])</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>        y1 <span class="op">=</span> <span class="va">self</span>.y_emb(boxes[:, :, <span class="dv">3</span>])</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([x0, y0, x1, y1], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, token_ids, boxes, img_features,</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="co">        token_ids : LongTensor (B, T)</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="co">            OCR token IDs.</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="co">        boxes : LongTensor (B, T, 4)</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="co">            Bounding boxes for each token.</span></span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a><span class="co">        img_features : Tensor (B, P, img_dim)</span></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="co">            Image patch features from CNN.</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> token_ids.shape[<span class="dv">0</span>]</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text + layout</span></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>        text_h <span class="op">=</span> <span class="va">self</span>.text_emb(token_ids) <span class="op">+</span> <span class="va">self</span>.embed_layout(boxes)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>        text_h <span class="op">=</span> text_h <span class="op">+</span> <span class="va">self</span>.modality_emb(</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>            torch.zeros(batch_size, text_h.shape[<span class="dv">1</span>],</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>                       dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>text_h.device)</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image patches</span></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>        img_h <span class="op">=</span> <span class="va">self</span>.img_proj(img_features)</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>        img_h <span class="op">=</span> img_h <span class="op">+</span> <span class="va">self</span>.modality_emb(</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>            torch.full((batch_size, img_h.shape[<span class="dv">1</span>]), <span class="dv">2</span>,</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>                      dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>img_h.device)</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepend [CLS]</span></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>        cls <span class="op">=</span> <span class="va">self</span>.cls_token.expand(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate all modalities</span></span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>        sequence <span class="op">=</span> torch.cat([cls, text_h, img_h], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer encoding</span></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.transformer(sequence)</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return [CLS] representation</span></span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output[:, <span class="dv">0</span>, :]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="extracting-structured-financials-from-multimodal-reports" class="level3" data-number="47.5.2">
<h3 data-number="47.5.2" class="anchored" data-anchor-id="extracting-structured-financials-from-multimodal-reports"><span class="header-section-number">47.5.2</span> Extracting Structured Financials from Multimodal Reports</h3>
<p>With the document encoder, we can build extraction heads for specific financial fields. The key advantage over the OCR-only pipeline in previous chapter is that the multimodal encoder can resolve ambiguities using visual context (e.g., a number’s meaning depends on where it appears on the page and what headers and labels surround it).</p>
<div id="financial-extraction-head" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinancialFieldExtractor(nn.Module):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Extract specific financial fields from a document embedding.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Uses the multimodal document encoder as backbone.</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, doc_encoder, fields, hidden_dim<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">        doc_encoder : MultimodalDocumentEncoder</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">        fields : list</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">            Target field names, e.g.,</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">            ['revenue', 'net_income', 'total_assets', 'total_equity']</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.doc_encoder <span class="op">=</span> doc_encoder</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fields <span class="op">=</span> fields</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-field extraction heads</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.extractors <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>            field: nn.Sequential(</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>                nn.GELU(),</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> field <span class="kw">in</span> fields</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Confidence head</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.confidence <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>            field: nn.Sequential(</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim, <span class="dv">1</span>),</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>                nn.Sigmoid()</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> field <span class="kw">in</span> fields</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, token_ids, boxes, img_features):</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>        doc_emb <span class="op">=</span> <span class="va">self</span>.doc_encoder(token_ids, boxes, img_features)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> {}</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> field <span class="kw">in</span> <span class="va">self</span>.fields:</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>            value <span class="op">=</span> <span class="va">self</span>.extractors[field](doc_emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>            conf <span class="op">=</span> <span class="va">self</span>.confidence[field](doc_emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>            results[field] <span class="op">=</span> {<span class="st">"value"</span>: value, <span class="st">"confidence"</span>: conf}</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> results</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="multimodal-earnings-surprise-model" class="level2" data-number="47.6">
<h2 data-number="47.6" class="anchored" data-anchor-id="multimodal-earnings-surprise-model"><span class="header-section-number">47.6</span> Multimodal Earnings Surprise Model</h2>
<section id="architecture" class="level3" data-number="47.6.1">
<h3 data-number="47.6.1" class="anchored" data-anchor-id="architecture"><span class="header-section-number">47.6.1</span> Architecture</h3>
<p>We now build the chapter’s central empirical application: a multimodal model that predicts earnings surprises using all available modalities observed before the earnings announcement date.</p>
<p>The information set at time <span class="math inline">\(t^-\)</span> (just before the announcement) includes:</p>
<ul>
<li><strong>Tabular</strong>: Last reported financial ratios, analyst consensus forecasts</li>
<li><strong>Text</strong>: News articles and filings in the pre-announcement window</li>
<li><strong>Image</strong>: Satellite features of the firm’s operating region</li>
<li><strong>Time series</strong>: Price and volume dynamics in the 60 trading days before announcement</li>
</ul>
<p>The target is the standardized unexpected earnings (SUE):</p>
<p><span id="eq-sue"><span class="math display">\[
\text{SUE}_{i,q} = \frac{E_{i,q} - \hat{E}_{i,q}}{\sigma_{i,q}}
\tag{47.8}\]</span></span></p>
<p>where <span class="math inline">\(E_{i,q}\)</span> is actual earnings per share, <span class="math inline">\(\hat{E}_{i,q}\)</span> is the consensus forecast (or seasonal random walk forecast if analyst coverage is absent), and <span class="math inline">\(\sigma_{i,q}\)</span> is the standard deviation of forecast errors.</p>
<div id="earnings-surprise-data" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct earnings surprise dataset</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>earnings <span class="op">=</span> dc.get_earnings_announcements(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2016-01-01"</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized Unexpected Earnings</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>earnings[<span class="st">"sue"</span>] <span class="op">=</span> (</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    (earnings[<span class="st">"actual_eps"</span>] <span class="op">-</span> earnings[<span class="st">"consensus_eps"</span>]) <span class="op">/</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    earnings[<span class="st">"forecast_std"</span>].clip(lower<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-announcement features</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Text: aggregate PhoBERT sentiment of news in [-30, -1] window</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>pre_ann_text <span class="op">=</span> dc.get_pre_announcement_text_features(</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2016-01-01"</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    window_days<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"phobert"</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Image: satellite features at quarter end</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>pre_ann_image <span class="op">=</span> satellite_features.copy()</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Time series: 60 trading days before announcement</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co"># (Pre-computed above)</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular: most recent quarterly financials</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>pre_ann_tabular <span class="op">=</span> financials[tabular_features <span class="op">+</span> [<span class="st">"ticker"</span>, <span class="st">"quarter_date"</span>]]</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Earnings announcements: </span><span class="sc">{</span><span class="bu">len</span>(earnings)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"With text features: </span><span class="sc">{</span><span class="bu">len</span>(pre_ann_text)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="earnings-model" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalEarningsSurpriseModel(nn.Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Predict standardized unexpected earnings (SUE) from</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">    multimodal pre-announcement information.</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tab_dim, text_dim<span class="op">=</span><span class="dv">768</span>, img_dim<span class="op">=</span><span class="dv">2048</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>                 ts_features<span class="op">=</span><span class="dv">5</span>, ts_len<span class="op">=</span><span class="dv">60</span>, hidden_dim<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                 n_heads<span class="op">=</span><span class="dv">4</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unimodal encoders</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab_enc <span class="op">=</span> TabularEncoder(tab_dim, <span class="dv">128</span>, hidden_dim)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_enc <span class="op">=</span> TextEncoder(text_dim, hidden_dim)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_enc <span class="op">=</span> ImageEncoder(img_dim, hidden_dim)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ts_enc <span class="op">=</span> TimeSeriesEncoder(ts_features, ts_len, hidden_dim)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality dropout</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mod_dropout <span class="op">=</span> ModalityDropout(drop_prob)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention: text attends to time series</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (news context informs price dynamics interpretation)</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_ts_attn <span class="op">=</span> CrossAttentionBlock(hidden_dim, n_heads)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention: tabular attends to image</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (financial ratios contextualized by physical activity)</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab_img_attn <span class="op">=</span> CrossAttentionBlock(hidden_dim, n_heads)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality importance weights (learned)</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.importance <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">4</span>))</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">*</span> <span class="dv">2</span>, hidden_dim),</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim),</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, tabular, text, image, ts):</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        h_tab <span class="op">=</span> <span class="va">self</span>.tab_enc(tabular) <span class="cf">if</span> tabular <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        h_txt <span class="op">=</span> <span class="va">self</span>.text_enc(text) <span class="cf">if</span> text <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        h_img <span class="op">=</span> <span class="va">self</span>.img_enc(image) <span class="cf">if</span> image <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        h_ts <span class="op">=</span> <span class="va">self</span>.ts_enc(ts) <span class="cf">if</span> ts <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention pairs (if both available)</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> h_txt <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> h_ts <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>            h_txt_enriched, _ <span class="op">=</span> <span class="va">self</span>.text_ts_attn(h_txt, h_ts)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>            h_txt_enriched <span class="op">=</span> h_txt</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> h_tab <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> h_img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>            h_tab_enriched, _ <span class="op">=</span> <span class="va">self</span>.tab_img_attn(h_tab, h_img)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>            h_tab_enriched <span class="op">=</span> h_tab</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Weighted combination of available modalities</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> F.softmax(<span class="va">self</span>.importance, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, h <span class="kw">in</span> <span class="bu">enumerate</span>([h_tab_enriched, h_txt_enriched,</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>                                h_img, h_ts]):</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> h <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>                embeddings.append(h <span class="op">*</span> weights[i])</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> <span class="bu">next</span>(</span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a>                    x.shape[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> [tabular, text, image, ts]</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> x <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a>                embeddings.append(</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>                    torch.zeros(batch_size, h_tab.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>                               <span class="cf">if</span> h_tab <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="dv">64</span>,</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>                               device<span class="op">=</span>device)</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggregate</span></span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a>        stacked <span class="op">=</span> torch.stack(embeddings, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>        aggregated <span class="op">=</span> stacked.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Also compute variance across modalities (disagreement signal)</span></span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> stacked.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>            disagreement <span class="op">=</span> stacked.var(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>            disagreement <span class="op">=</span> torch.zeros_like(aggregated)</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([aggregated, disagreement], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="modality-importance-analysis" class="level3" data-number="47.6.2">
<h3 data-number="47.6.2" class="anchored" data-anchor-id="modality-importance-analysis"><span class="header-section-number">47.6.2</span> Modality Importance Analysis</h3>
<p>A key interpretability question is: which modality contributes most to earnings surprise prediction? We analyze the learned importance weights and conduct ablation experiments.</p>
<div id="modality-importance" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ablation_study(model, test_loader, modality_names):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Measure each modality's contribution via leave-one-out ablation.</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">    For each modality m, zero out that modality's input and measure</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">    the degradation in prediction accuracy.</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame : Modality, R² with all, R² without, Δ R².</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Full model performance</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    all_preds, all_targets <span class="op">=</span> [], []</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {k: batch[k] <span class="cf">for</span> k <span class="kw">in</span> modality_names}</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(inputs)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> output[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>) <span class="cf">else</span> output</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>            all_preds.extend(pred.cpu().numpy())</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>            all_targets.extend(targets.cpu().numpy())</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    r2_full <span class="op">=</span> r2_score(all_targets, all_preds)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ablation: remove one modality at a time</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> [{<span class="st">"modality"</span>: <span class="st">"All"</span>, <span class="st">"r2"</span>: r2_full, <span class="st">"delta_r2"</span>: <span class="fl">0.0</span>}]</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> drop_mod <span class="kw">in</span> modality_names:</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        ablated_preds <span class="op">=</span> []</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> {}</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> k <span class="kw">in</span> modality_names:</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> k <span class="op">==</span> drop_mod:</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>                        inputs[k] <span class="op">=</span> <span class="va">None</span>  <span class="co"># Remove this modality</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>                        inputs[k] <span class="op">=</span> batch[k]</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> model(inputs)</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> output[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>) <span class="cf">else</span> output</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>                ablated_preds.extend(pred.cpu().numpy())</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        r2_ablated <span class="op">=</span> r2_score(all_targets, ablated_preds)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modality"</span>: <span class="ss">f"Without </span><span class="sc">{</span>drop_mod<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"r2"</span>: r2_ablated,</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">"delta_r2"</span>: r2_full <span class="op">-</span> r2_ablated</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="tbl-ablation" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="21">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ablation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.4: Modality Ablation Study: Contribution to Earnings Surprise Prediction
</figcaption>
<div aria-describedby="tbl-ablation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ablation_df = ablation_study(model, test_loader, modality_names)</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ablation_df.round(4)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</figure>
</div>
<div id="fig-modality-importance" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="22">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-modality-importance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Track importance weights during training</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># importance_history = pd.DataFrame(...)</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># (</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     p9.ggplot(importance_history, p9.aes(</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="epoch", y="weight", color="modality"</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     ))</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.geom_line(size=1)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.labs(</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="Training Epoch", y="Softmax Weight",</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">#         title="Modality Importance Convergence",</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">#         color="Modality"</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.scale_color_manual(</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">#         values=["#2E5090", "#C0392B", "#27AE60", "#8E44AD"]</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme_minimal()</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme(figure_size=(10, 5))</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-modality-importance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;47.2
</figcaption>
</figure>
</div>
</section>
</section>
<section id="large-multimodal-models-for-financial-analysis" class="level2" data-number="47.7">
<h2 data-number="47.7" class="anchored" data-anchor-id="large-multimodal-models-for-financial-analysis"><span class="header-section-number">47.7</span> Large Multimodal Models for Financial Analysis</h2>
<section id="prompting-vision-language-models" class="level3" data-number="47.7.1">
<h3 data-number="47.7.1" class="anchored" data-anchor-id="prompting-vision-language-models"><span class="header-section-number">47.7.1</span> Prompting Vision-Language Models</h3>
<p>The most powerful multimodal systems available today are large vision-language models (VLMs) such as GPT-4V, Gemini, and open-source alternatives (LLaVA, InternVL). These models can jointly process images and text through natural language prompts, enabling zero-shot financial analysis without model training.</p>
<p>For Vietnamese financial applications, VLMs can:</p>
<ul>
<li>Interpret satellite imagery of industrial zones and estimate activity levels</li>
<li>Read and extract data from scanned financial tables</li>
<li>Analyze news photographs for sentiment</li>
<li>Compare current and historical aerial views for change detection</li>
</ul>
<div id="vlm-financial-prompting" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vlm_financial_qa(image_path, question, context<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Financial question-answering using a vision-language model.</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">    image_path : str</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Path to image (satellite tile, document page, news photo).</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">    question : str</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Financial analysis question.</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">    context : str, optional</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Additional textual context (e.g., firm name, sector).</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : Answer, confidence, extracted entities.</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        LlavaForConditionalGeneration,</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        LlavaProcessor</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    model_id <span class="op">=</span> <span class="st">"llava-hf/llava-v1.6-vicuna-7b-hf"</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    processor <span class="op">=</span> LlavaProcessor.from_pretrained(model_id)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LlavaForConditionalGeneration.from_pretrained(</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        model_id, torch_dtype<span class="op">=</span>torch.float16, device_map<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(image_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build financial analysis prompt</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    system_prompt <span class="op">=</span> (</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"You are a financial analyst examining visual evidence. "</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Provide specific, quantitative observations when possible. "</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">"State your confidence level (high/medium/low)."</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> context:</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> (</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Context: </span><span class="sc">{</span>context<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Answer:"</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Answer:"</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> processor(</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>        text<span class="op">=</span>prompt,</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>        images<span class="op">=</span>img,</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"pt"</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>    ).to(model.device)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model.generate(</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>            <span class="op">**</span>inputs,</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>            max_new_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>            do_sample<span class="op">=</span><span class="va">False</span></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>    answer <span class="op">=</span> processor.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>    answer <span class="op">=</span> answer.split(<span class="st">"Answer:"</span>)[<span class="op">-</span><span class="dv">1</span>].strip()</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"answer"</span>: answer, <span class="st">"question"</span>: question}</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Example financial VLM queries</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>FINANCIAL_VLM_PROMPTS <span class="op">=</span> {</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">"satellite_activity"</span>: (</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Examine this satellite image of an industrial zone. "</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Estimate the occupancy rate of factory buildings, "</span></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"the density of vehicles in parking areas, "</span></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"and whether the site appears to be operating at "</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"full, partial, or minimal capacity."</span></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    <span class="st">"document_extraction"</span>: (</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a page from a Vietnamese annual report. "</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Extract the following if present: "</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>        <span class="st">"total revenue (doanh thu), net income (lợi nhuận ròng), "</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>        <span class="st">"total assets (tổng tài sản). "</span></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Report values in billions VND."</span></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>    <span class="st">"construction_progress"</span>: (</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Compare this aerial image to a baseline. "</span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Estimate the percentage completion of visible "</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>        <span class="st">"construction projects. Note any new structures, "</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cleared land, or infrastructure changes."</span></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="retrieval-augmented-multimodal-analysis" class="level3" data-number="47.7.2">
<h3 data-number="47.7.2" class="anchored" data-anchor-id="retrieval-augmented-multimodal-analysis"><span class="header-section-number">47.7.2</span> Retrieval-Augmented Multimodal Analysis</h3>
<p>For complex financial questions, we can combine VLM capabilities with retrieval from structured databases. The pipeline:</p>
<ol type="1">
<li><strong>Query</strong>: Analyst asks “Is Vingroup’s construction activity in Vinhomes Grand Park accelerating?”</li>
<li><strong>Retrieve</strong>: Fetch satellite time series, financial statements, news articles</li>
<li><strong>Process</strong>: VLM analyzes satellite images; NLP processes text; tabular model processes financials</li>
<li><strong>Fuse</strong>: Aggregate evidence across modalities</li>
<li><strong>Answer</strong>: Generate a structured response with confidence scores and supporting evidence</li>
</ol>
<div id="rag-multimodal" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalRAG:</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Retrieval-Augmented Generation with multimodal evidence.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, datacore_client, vlm_model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dc <span class="op">=</span> datacore_client</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vlm <span class="op">=</span> vlm_model</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> retrieve_evidence(<span class="va">self</span>, ticker, date, modalities<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Retrieve all available evidence for a firm at a given date.</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        evidence <span class="op">=</span> {}</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"tabular"</span> <span class="kw">in</span> modalities:</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"tabular"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_firm_financials(</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>                n_quarters<span class="op">=</span><span class="dv">4</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"text"</span> <span class="kw">in</span> modalities:</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"text"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_news(</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>                start_date<span class="op">=</span>pd.to_datetime(date) <span class="op">-</span> pd.Timedelta(days<span class="op">=</span><span class="dv">30</span>),</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date,</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">20</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"image"</span> <span class="kw">in</span> modalities:</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"image"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_satellite_images(</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>                date<span class="op">=</span>date,</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>                lookback_months<span class="op">=</span><span class="dv">6</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"ts"</span> <span class="kw">in</span> modalities:</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"ts"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_daily_returns(</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>                start_date<span class="op">=</span>pd.to_datetime(date) <span class="op">-</span> pd.Timedelta(days<span class="op">=</span><span class="dv">90</span>),</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> evidence</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> analyze(<span class="va">self</span>, ticker, date, question):</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a><span class="co">        Full multimodal analysis pipeline.</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>        evidence <span class="op">=</span> <span class="va">self</span>.retrieve_evidence(ticker, date)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>        analysis <span class="op">=</span> {</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ticker"</span>: ticker,</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"date"</span>: date,</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">"question"</span>: question,</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">"evidence_available"</span>: <span class="bu">list</span>(evidence.keys()),</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modality_signals"</span>: {}</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tabular signal</span></span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"tabular"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"tabular"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>            latest <span class="op">=</span> evidence[<span class="st">"tabular"</span>].iloc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>            analysis[<span class="st">"modality_signals"</span>][<span class="st">"tabular"</span>] <span class="op">=</span> {</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>                <span class="st">"revenue_growth"</span>: latest.get(<span class="st">"revenue_growth"</span>, <span class="va">None</span>),</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>                <span class="st">"roe"</span>: latest.get(<span class="st">"roe"</span>, <span class="va">None</span>),</span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>                <span class="st">"leverage"</span>: latest.get(<span class="st">"leverage"</span>, <span class="va">None</span>)</span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text signal</span></span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"text"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"text"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Aggregate sentiment from PhoBERT</span></span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>            texts <span class="op">=</span> evidence[<span class="st">"text"</span>]</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(texts) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>                avg_sentiment <span class="op">=</span> texts[<span class="st">"sentiment_score"</span>].mean()</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>                analysis[<span class="st">"modality_signals"</span>][<span class="st">"text"</span>] <span class="op">=</span> {</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"avg_sentiment"</span>: avg_sentiment,</span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"n_articles"</span>: <span class="bu">len</span>(texts),</span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"sentiment_trend"</span>: (</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"improving"</span> <span class="cf">if</span> texts[<span class="st">"sentiment_score"</span>].is_monotonic_increasing</span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> <span class="st">"deteriorating"</span> <span class="cf">if</span> texts[<span class="st">"sentiment_score"</span>].is_monotonic_decreasing</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> <span class="st">"mixed"</span></span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Time series signal</span></span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"ts"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"ts"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a>            ts <span class="op">=</span> evidence[<span class="st">"ts"</span>]</span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a>            analysis[<span class="st">"modality_signals"</span>][<span class="st">"ts"</span>] <span class="op">=</span> {</span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a>                <span class="st">"return_60d"</span>: (<span class="dv">1</span> <span class="op">+</span> ts[<span class="st">"ret"</span>]).prod() <span class="op">-</span> <span class="dv">1</span>,</span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a>                <span class="st">"volatility"</span>: ts[<span class="st">"ret"</span>].std() <span class="op">*</span> np.sqrt(<span class="dv">252</span>),</span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a>                <span class="st">"avg_turnover"</span>: ts[<span class="st">"turnover"</span>].mean()</span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> analysis</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="evaluation-and-deployment-considerations" class="level2" data-number="47.8">
<h2 data-number="47.8" class="anchored" data-anchor-id="evaluation-and-deployment-considerations"><span class="header-section-number">47.8</span> Evaluation and Deployment Considerations</h2>
<section id="evaluation-protocol-for-multimodal-financial-models" class="level3" data-number="47.8.1">
<h3 data-number="47.8.1" class="anchored" data-anchor-id="evaluation-protocol-for-multimodal-financial-models"><span class="header-section-number">47.8.1</span> Evaluation Protocol for Multimodal Financial Models</h3>
<p>Standard machine learning evaluation (random train/test split) is inappropriate for financial prediction. We require time-series-aware evaluation that respects the temporal ordering of information.</p>
<div id="tbl-evaluation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-evaluation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.5: Evaluation Best Practices for Multimodal Finance Models
</figcaption>
<div aria-describedby="tbl-evaluation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 33%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Evaluation Aspect</th>
<th>Correct Approach</th>
<th>Common Mistake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Train/test split</td>
<td>Expanding or rolling time window</td>
<td>Random split (look-ahead bias)</td>
</tr>
<tr class="even">
<td>Feature timing</td>
<td>Features available before prediction date</td>
<td>Using concurrent or future information</td>
</tr>
<tr class="odd">
<td>Missing modalities</td>
<td>Test with realistic missingness patterns</td>
<td>Complete-case only</td>
</tr>
<tr class="even">
<td>Performance metric</td>
<td>OOS <span class="math inline">\(R^2\)</span>, IC, Sharpe of L-S portfolio</td>
<td>In-sample <span class="math inline">\(R^2\)</span></td>
</tr>
<tr class="odd">
<td>Statistical inference</td>
<td><span class="citation" data-cites="diebold2002comparing">Diebold and Mariano (<a href="references.html#ref-diebold2002comparing" role="doc-biblioref">2002</a>)</span> test for forecast comparison</td>
<td>Point estimates without SE</td>
</tr>
<tr class="even">
<td>Economic significance</td>
<td>Transaction-cost-adjusted portfolio returns</td>
<td>Ignoring implementation costs</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="computational-budget" class="level3" data-number="47.8.2">
<h3 data-number="47.8.2" class="anchored" data-anchor-id="computational-budget"><span class="header-section-number">47.8.2</span> Computational Budget</h3>
<p>Multimodal models are computationally expensive. <a href="#tbl-compute-budget" class="quarto-xref">Table&nbsp;<span>47.6</span></a> provides order-of-magnitude estimates for Vietnamese equity markets.</p>
<div id="tbl-compute-budget" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-compute-budget-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;47.6: Computational Budget for Multimodal Pipeline
</figcaption>
<div aria-describedby="tbl-compute-budget-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 24%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Single Firm-Quarter</th>
<th>Full Panel (1000 firms × 40 quarters)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PhoBERT text encoding</td>
<td>0.5s</td>
<td>~5.5 hours</td>
</tr>
<tr class="even">
<td>ResNet50 satellite feature</td>
<td>0.1s</td>
<td>~1.1 hours</td>
</tr>
<tr class="odd">
<td>Time series encoding (CNN)</td>
<td>0.01s</td>
<td>~7 minutes</td>
</tr>
<tr class="even">
<td>Tabular preprocessing</td>
<td>&lt;0.01s</td>
<td>~1 minute</td>
</tr>
<tr class="odd">
<td>Cross-attention fusion (forward)</td>
<td>0.05s</td>
<td>~33 minutes</td>
</tr>
<tr class="even">
<td>Training (50 epochs)</td>
<td>–</td>
<td>~12 hours (GPU)</td>
</tr>
<tr class="odd">
<td>Full pipeline</td>
<td>–</td>
<td>~1 day (single GPU)</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The practical implication is that pre-computation of unimodal embeddings is essential. Extract and cache PhoBERT embeddings, CNN features, and time-series representations once; reuse them across all fusion experiments. Only the fusion layers need retraining when the architecture changes.</p>
<!-- ## Exercises

1.  **Contrastive Pre-Training for Vietnamese Finance.** Implement the FinancialCLIP contrastive alignment for paired (annual report text, satellite image) data. Train on 2014-2020 data and evaluate alignment quality on 2021-2024 by measuring zero-shot retrieval accuracy: given a text description, can the model retrieve the correct satellite image (and vice versa)? Report Recall\@1, Recall\@5, and Recall\@10.

2.  **Fusion Architecture Search.** Implement the following additional fusion strategies beyond the three in this chapter: (a) bilinear fusion with low-rank approximation, (b) mixture-of-experts with $2^M - 1$ expert networks, and (c) FiLM (Feature-wise Linear Modulation) conditioning. Compare all six strategies on forward quarterly return prediction using the same time-series cross-validation protocol. Which architecture achieves the best out-of-sample Sharpe ratio after transaction costs?

3.  **Missing Modality Robustness.** Using the RobustFusionModel, systematically evaluate degradation as modalities are removed. Start with all four modalities and progressively remove them in all possible orderings. Plot the performance surface: $R^2$ as a function of the number and identity of available modalities. Which single modality is most informative? Which pair? Is there diminishing returns to adding the third and fourth modality?

4.  **Multimodal Earnings Call Analysis.** If earnings call audio or transcripts are available from DataCore.vn, extend the multimodal earnings surprise model to include a fifth modality: audio features (vocal tone, speaking rate, pause patterns). Use the wav2vec2 model to extract audio embeddings. Does the CEO's vocal tone add predictive power beyond the transcript text? Implement the @mayew2012power methodology for comparing vocal and textual signals.

5.  **Document Understanding Benchmark.** Construct a benchmark dataset of 200 Vietnamese annual report pages with manually annotated financial fields (revenue, COGS, net income, total assets, total equity, total debt). Evaluate three approaches: (a) OCR + rule-based extraction (Chapter 61), (b) LayoutLMv3 fine-tuned on 100 pages, and (c) zero-shot VLM extraction via GPT-4V or Gemini. Report field-level exact match accuracy and mean absolute percentage error for numerical values.

6.  **Multimodal Factor Construction.** Using the best-performing fusion model, generate firm-quarter-level multimodal scores. Sort firms into quintiles on this score and compute equal- and value-weighted portfolio returns. Is the multimodal long-short factor priced in the cross-section (Fama-MacBeth)? Does it subsume the textual sentiment factor from Chapter 60 or the satellite-based factor from Chapter 61? Report spanning test results. -->
</section>
</section>
<section id="summary" class="level2" data-number="47.9">
<h2 data-number="47.9" class="anchored" data-anchor-id="summary"><span class="header-section-number">47.9</span> Summary</h2>
<p>This chapter developed the multimodal learning framework for Vietnamese financial markets, progressing from foundational representation alignment through production-ready fusion architectures.</p>
<p>The key contributions are threefold. First, we demonstrated that financial data is inherently multimodal and that effective fusion requires explicit architectural choices (e.g., contrastive alignment, cross-attention mechanisms, and missing-modality handling) rather than naive concatenation. The FinancialCLIP alignment framework learns a shared embedding space where text, image, tabular, and time-series representations are geometrically comparable, enabling cross-modal retrieval and transfer.</p>
<p>Second, we built and compared five fusion architectures (early, late with gating, cross-attention, robust with modality dropout, and the custom earnings surprise model) on the prediction of forward returns and earnings surprises. The cross-attention architecture with modality dropout consistently outperforms unimodal baselines and simpler fusion strategies, though the margin varies across prediction horizons and firm characteristics.</p>
<p>Third, we showed how large vision-language models can perform zero-shot financial analysis on Vietnamese documents and satellite imagery, offering a path to multimodal analysis without task-specific training. The retrieval-augmented multimodal pipeline combines the strengths of structured retrieval (from DataCore.vn) with the reasoning capabilities of VLMs.</p>
<p>The practical lesson for researchers working with Vietnamese financial data is that multimodal fusion is most valuable when modalities are complementary: text captures management intent and market narrative, images capture physical economic activity, tabular data provides precise quantitative snapshots, and time series captures market dynamics. When a single modality already captures most of the relevant signal (as tabular features do for many standard prediction tasks), the marginal gain from fusion is modest. When the prediction task requires information that no single modality captures well (as earnings surprises require both quantitative and qualitative assessment), multimodal models provide their largest advantage.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-alayrac2022flamingo" class="csl-entry" role="listitem">
Alayrac, Jean-Baptiste, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, et al. 2022. <span>“Flamingo: A Visual Language Model for Few-Shot Learning.”</span> <em>Advances in Neural Information Processing Systems</em> 35: 23716–36.
</div>
<div id="ref-baltruvsaitis2018multimodal" class="csl-entry" role="listitem">
Baltrušaitis, Tadas, Chaitanya Ahuja, and Louis-Philippe Morency. 2018. <span>“Multimodal Machine Learning: A Survey and Taxonomy.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 41 (2): 423–43.
</div>
<div id="ref-diebold2002comparing" class="csl-entry" role="listitem">
Diebold, Francis X, and Robert S Mariano. 2002. <span>“Comparing Predictive Accuracy.”</span> <em>Journal of Business &amp; Economic Statistics</em> 20 (1): 134–44.
</div>
<div id="ref-huang2021makes" class="csl-entry" role="listitem">
Huang, Yu, Chenzhuang Du, Zihui Xue, Xuanyao Chen, Hang Zhao, and Longbo Huang. 2021. <span>“What Makes Multi-Modal Learning Better Than Single (Provably).”</span> <em>Advances in Neural Information Processing Systems</em> 34: 10944–56.
</div>
<div id="ref-kim2022ocr" class="csl-entry" role="listitem">
Kim, Geewook, Teakgyu Hong, Moonbin Yim, JeongYeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, and Seunghyun Park. 2022. <span>“Ocr-Free Document Understanding Transformer.”</span> In <em>European Conference on Computer Vision</em>, 498–517. Springer.
</div>
<div id="ref-liang2024foundations" class="csl-entry" role="listitem">
Liang, Paul Pu, Amir Zadeh, and Louis-Philippe Morency. 2024. <span>“Foundations &amp; Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions.”</span> <em>ACM Computing Surveys</em> 56 (10): 1–42.
</div>
<div id="ref-oord2018representation" class="csl-entry" role="listitem">
Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. 2018. <span>“Representation Learning with Contrastive Predictive Coding.”</span> <em>arXiv Preprint arXiv:1807.03748</em>.
</div>
<div id="ref-radford2021learning" class="csl-entry" role="listitem">
Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. <span>“Learning Transferable Visual Models from Natural Language Supervision.”</span> In <em>International Conference on Machine Learning</em>, 8748–63. PmLR.
</div>
</div>
</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const year = new Date().getFullYear();
  document.getElementById("copyright").textContent = "© " + year;
});
</script>
<script>
(function () {
  const GA_ID = "G-LMDLDJXXSC";   // your real GA4 ID
  const CONSENT_KEY = "cookie_consent_v1";

  function log(msg) {
    console.log("[GA Loader]", msg);
  }

  function loadGtag() {
    if (window.__gtag_loaded__) {
      log("GA already loaded, skipping");
      return;
    }

    log("Loading Google Analytics...");

    window.__gtag_loaded__ = true;

    const script = document.createElement("script");
    script.async = true;
    script.src = "https://www.googletagmanager.com/gtag/js?id=" + encodeURIComponent(GA_ID);

    script.onload = function () {
      log("gtag.js loaded");

      window.dataLayer = window.dataLayer || [];
      function gtag(){ dataLayer.push(arguments); }
      window.gtag = gtag;

      gtag("js", new Date());
      gtag("config", GA_ID, {
        anonymize_ip: true,
        transport_type: "beacon"
      });

      log("GA initialized successfully");
    };

    script.onerror = function () {
      log("FAILED to load gtag.js. Likely blocked by ad blocker or network.");
    };

    document.head.appendChild(script);
  }

  function checkConsentAndLoad() {
    const consent = localStorage.getItem(CONSENT_KEY);
    log("Stored consent value = " + consent);

    if (consent === "accepted") {
      loadGtag();
    } else {
      log("Analytics blocked due to missing or declined consent");
    }
  }

  // Run on page load
  checkConsentAndLoad();

  // Listen for cookie banner decisions
  window.addEventListener("cookie-consent-changed", function (e) {
    log("Consent event received: " + e.detail);
    if (e.detail === "accepted") {
      loadGtag();
    }
  });

})();
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/github\.com\/mikenguyen13\/tidy_finance_vn");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./73_networks_graphs.html" class="pagination-link" aria-label="Networks and Graphs in Finance">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Networks and Graphs in Finance</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./99_conclusion.html" class="pagination-link" aria-label="Conclusion">
        <span class="nav-page-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Conclusion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Multimodal Models in Finance</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>The preceding chapters treated text and images as isolated data modalities, but financial decision-making is inherently multimodal. An analyst evaluating a Vietnamese real estate developer simultaneously reads the annual report (text), inspects satellite imagery of construction sites (image), reviews quarterly financial statements (tabular), monitors the stock's price and volume dynamics (time series), and perhaps listens to the earnings call (audio). No single modality captures the full information set. The question this chapter addresses is: can we build models that fuse multiple modalities in a principled way, and does the fusion yield economically meaningful improvements over the best single-modality model?</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>The answer from the recent machine learning literature is increasingly yes, but with important caveats. Multimodal models can exploit complementarities between modalities (e.g., text describes intentions and context; images reveal physical states; tabular data provides precise quantitative snapshots; time series captures dynamics). However, the gains are not automatic. Naive concatenation of heterogeneous features often degrades performance relative to the best unimodal model, a phenomenon known as the "modality laziness" problem <span class="co">[</span><span class="ot">@huang2021makes</span><span class="co">]</span>. Effective fusion requires architectures that align representations across modalities, handle missing modalities gracefully (not every firm-quarter has satellite imagery and an earnings call), and avoid the dominant modality drowning out weaker but complementary signals.</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>This chapter develops the multimodal toolkit for Vietnamese financial markets across four progressively complex architectures. We begin with representation alignment (i.e., how to map different modalities into a shared embedding space). We then implement early, late, and cross-attention fusion for return prediction. We build a multimodal document understanding system that jointly processes the text, tables, and images within Vietnamese annual reports. We construct a multimodal earnings surprise model that combines pre-announcement text, satellite imagery, and financial time series. And we address the practical engineering challenges, including missing modalities, computational cost, and evaluation protocols that determine whether multimodal models work in production.</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Deep learning</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="co"># NLP</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer, AutoModel,</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    CLIPProcessor, CLIPModel</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular and statistical</span></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> TimeSeriesSplit</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.panel <span class="im">import</span> PanelOLS</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotnine <span class="im">as</span> p9</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mizani.formatters <span class="im">import</span> percent_format</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a><span class="fu">## Foundations of Multimodal Learning</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Information Structure of Financial Data</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>Financial data is naturally organized into modalities with distinct statistical properties, temporal frequencies, and information content. @tbl-modality-landscape summarizes the modalities relevant to Vietnamese equity markets.</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Modality <span class="pp">|</span> Examples <span class="pp">|</span> Dimensionality <span class="pp">|</span> Frequency <span class="pp">|</span> Encoding <span class="pp">|</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a><span class="pp">|---------------|---------------|---------------|---------------|---------------|</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Tabular <span class="pp">|</span> Financial ratios, ownership, governance <span class="pp">|</span> Low ($\sim$ 50 features) <span class="pp">|</span> Quarterly/Annual <span class="pp">|</span> Structured numeric <span class="pp">|</span></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Text <span class="pp">|</span> Annual reports, news, filings, social media <span class="pp">|</span> High ($\sim$ 10k tokens) <span class="pp">|</span> Event-driven <span class="pp">|</span> Sequential tokens <span class="pp">|</span></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Image <span class="pp">|</span> Satellite tiles, document scans, news photos <span class="pp">|</span> Very high ($\sim$ 150k pixels) <span class="pp">|</span> Daily to monthly <span class="pp">|</span> Spatial grid <span class="pp">|</span></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Time series <span class="pp">|</span> Price, volume, order flow, volatility <span class="pp">|</span> Moderate ($\sim$ 250 days × features) <span class="pp">|</span> Daily/Intraday <span class="pp">|</span> Temporal sequence <span class="pp">|</span></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Audio <span class="pp">|</span> Earnings calls, conference presentations <span class="pp">|</span> Very high (waveform) <span class="pp">|</span> Quarterly <span class="pp">|</span> Temporal waveform <span class="pp">|</span></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Graph <span class="pp">|</span> Ownership networks, supply chains, co-holdings <span class="pp">|</span> Variable <span class="pp">|</span> Quarterly <span class="pp">|</span> Adjacency + node features <span class="pp">|</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>: Modality Landscape in Financial Data {#tbl-modality-landscape}</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>Each modality carries both unique and redundant information relative to others. The value of multimodal fusion lies in the unique (complementary) information:</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>I(\text{Returns}; \text{Text}, \text{Image}, \text{Tabular}) \geq \max\left(I(\text{Returns}; \text{Text}), I(\text{Returns}; \text{Image}), I(\text{Returns}; \text{Tabular})\right)</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>$$ {#eq-information-inequality}</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a>where $I(\cdot; \cdot)$ denotes mutual information. The inequality is strict whenever the modalities carry non-redundant predictive content. The goal of fusion is to design architectures that approach the left-hand side.</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a><span class="fu">### Taxonomies of Fusion</span></span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>The multimodal learning literature <span class="co">[</span><span class="ot">@baltruvsaitis2018multimodal; @liang2024foundations</span><span class="co">]</span> organizes fusion strategies along three dimensions.</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>**By stage.** Where in the processing pipeline are modalities combined?</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Input-level (early) fusion*: Concatenate raw or lightly processed features before any shared model.</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Feature-level (intermediate) fusion*: Align learned representations in a shared latent space, then combine.</span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Decision-level (late) fusion*: Train separate models per modality, combine predictions.</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>**By mechanism.** How are representations combined?</span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Concatenation*: $\mathbf{z} = <span class="co">[</span><span class="ot">\mathbf{z}^{(1)}; \mathbf{z}^{(2)}; \ldots; \mathbf{z}^{(M)}</span><span class="co">]</span>$. Simple but ignores cross-modal interactions.</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Attention-based*: One modality attends to another. Captures interactions but requires sufficient data.</span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Tensor product*: $\mathbf{z} = \mathbf{z}^{(1)} \otimes \mathbf{z}^{(2)}$. Captures all pairwise interactions but scales quadratically.</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Gating*: $\mathbf{z} = g(\mathbf{z}^{(1)}) \odot \mathbf{z}^{(2)} + (1 - g(\mathbf{z}^{(1)})) \odot \mathbf{z}^{(3)}$. Modality selection.</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>**By training.** How are parameters learned?</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Joint training*: All modalities processed end-to-end.</span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Pre-train then fuse*: Train unimodal encoders separately, then learn the fusion layer.</span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Contrastive alignment*: Train modality encoders to produce similar representations for matched pairs (the CLIP approach of @radford2021learning).</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-multimodal-data</span></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a><span class="co"># DataCore.vn API</span></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datacore <span class="im">import</span> DataCore</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>dc <span class="op">=</span> DataCore()</span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a><span class="co"># Load aligned multimodal dataset</span></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a><span class="co"># Each observation: firm × quarter with all available modalities</span></span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular: financial statements</span></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a>financials <span class="op">=</span> dc.get_firm_financials(</span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a>    frequency<span class="op">=</span><span class="st">"quarterly"</span></span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a><span class="co"># Text: management discussion from annual reports</span></span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a>report_text <span class="op">=</span> dc.get_annual_report_text(</span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span><span class="st">"management_discussion"</span></span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a><span class="co"># Image: satellite nightlight features (from Chapter 61)</span></span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a>satellite_features <span class="op">=</span> dc.get_satellite_features(</span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a>    feature_type<span class="op">=</span><span class="st">"cnn_resnet50"</span></span>
<span id="cb25-128"><a href="#cb25-128" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Time series: daily returns and volume</span></span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a>daily_data <span class="op">=</span> dc.get_daily_returns(</span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Target: forward quarterly returns</span></span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a>quarterly_returns <span class="op">=</span> dc.get_quarterly_returns(</span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with financials: </span><span class="sc">{</span>financials[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with report text: </span><span class="sc">{</span>report_text[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Firms with satellite data: </span><span class="sc">{</span>satellite_features[<span class="st">'ticker'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-145"><a href="#cb25-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-146"><a href="#cb25-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a><span class="fu">## Representation Alignment</span></span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Alignment Problem</span></span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a>Different modalities produce embeddings in different vector spaces with different geometries. A PhoBERT text embedding lives in $\mathbb{R}^{768}$; a ResNet50 image feature lives in $\mathbb{R}^{2048}$; a tabular feature vector might have 50 dimensions with heterogeneous scales. Naively concatenating these into a single vector $<span class="co">[</span><span class="ot">\mathbf{z}^{\text{text}}; \mathbf{z}^{\text{image}}; \mathbf{z}^{\text{tab}}</span><span class="co">]</span> \in \mathbb{R}^{2866}$ is problematic because the high-dimensional modalities dominate gradient flow, the scales are mismatched, and there is no mechanism for cross-modal interaction.</span>
<span id="cb25-152"><a href="#cb25-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-153"><a href="#cb25-153" aria-hidden="true" tabindex="-1"></a>Alignment projects each modality into a shared latent space $\mathbb{R}^d$ where geometric relationships are semantically meaningful (i.e., similar firms should be nearby regardless of which modality is used to represent them).</span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### Contrastive Alignment: CLIP for Finance</span></span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a>The Contrastive Language-Image Pre-training (CLIP) framework of @radford2021learning learns aligned representations by training on matched (text, image) pairs. We adapt this to financial data: for each firm-quarter, we have a textual description and a satellite image, and we train the encoders so that matched pairs produce similar embeddings while unmatched pairs produce dissimilar embeddings.</span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a>The contrastive loss is:</span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{\text{CLIP}} = -\frac{1}{2N}\sum_{i=1}^{N}\left[\log\frac{\exp(\mathbf{z}_i^{\text{txt}} \cdot \mathbf{z}_i^{\text{img}} / \tau)}{\sum_{j=1}^{N}\exp(\mathbf{z}_i^{\text{txt}} \cdot \mathbf{z}_j^{\text{img}} / \tau)} + \log\frac{\exp(\mathbf{z}_i^{\text{img}} \cdot \mathbf{z}_i^{\text{txt}} / \tau)}{\sum_{j=1}^{N}\exp(\mathbf{z}_i^{\text{img}} \cdot \mathbf{z}_j^{\text{txt}} / \tau)}\right]</span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a>$$ {#eq-clip-loss}</span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a>where $\tau$ is a learnable temperature parameter and the embeddings are $L_2$-normalized. This is a symmetric version of the InfoNCE loss <span class="co">[</span><span class="ot">@oord2018representation</span><span class="co">]</span> that simultaneously trains the text encoder to predict the correct image and vice versa.</span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: contrastive-alignment</span></span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-173"><a href="#cb25-173" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinancialCLIP(nn.Module):</span>
<span id="cb25-174"><a href="#cb25-174" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-175"><a href="#cb25-175" aria-hidden="true" tabindex="-1"></a><span class="co">    Contrastive alignment of text and image embeddings</span></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a><span class="co">    for Vietnamese financial data.</span></span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, text_dim<span class="op">=</span><span class="dv">768</span>, image_dim<span class="op">=</span><span class="dv">2048</span>, proj_dim<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-181"><a href="#cb25-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-182"><a href="#cb25-182" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text projection</span></span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a>            nn.Linear(text_dim, proj_dim),</span>
<span id="cb25-185"><a href="#cb25-185" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(proj_dim),</span>
<span id="cb25-186"><a href="#cb25-186" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-187"><a href="#cb25-187" aria-hidden="true" tabindex="-1"></a>            nn.Linear(proj_dim, proj_dim)</span>
<span id="cb25-188"><a href="#cb25-188" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-189"><a href="#cb25-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-190"><a href="#cb25-190" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image projection</span></span>
<span id="cb25-191"><a href="#cb25-191" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-192"><a href="#cb25-192" aria-hidden="true" tabindex="-1"></a>            nn.Linear(image_dim, proj_dim),</span>
<span id="cb25-193"><a href="#cb25-193" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(proj_dim),</span>
<span id="cb25-194"><a href="#cb25-194" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-195"><a href="#cb25-195" aria-hidden="true" tabindex="-1"></a>            nn.Linear(proj_dim, proj_dim)</span>
<span id="cb25-196"><a href="#cb25-196" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-197"><a href="#cb25-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-198"><a href="#cb25-198" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Learnable temperature</span></span>
<span id="cb25-199"><a href="#cb25-199" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log_temp <span class="op">=</span> nn.Parameter(torch.tensor(np.log(<span class="dv">1</span> <span class="op">/</span> <span class="fl">0.07</span>)))</span>
<span id="cb25-200"><a href="#cb25-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-201"><a href="#cb25-201" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, text_emb, image_emb):</span>
<span id="cb25-202"><a href="#cb25-202" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute aligned embeddings and contrastive loss."""</span></span>
<span id="cb25-203"><a href="#cb25-203" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Project and normalize</span></span>
<span id="cb25-204"><a href="#cb25-204" aria-hidden="true" tabindex="-1"></a>        z_text <span class="op">=</span> F.normalize(<span class="va">self</span>.text_proj(text_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-205"><a href="#cb25-205" aria-hidden="true" tabindex="-1"></a>        z_image <span class="op">=</span> F.normalize(<span class="va">self</span>.image_proj(image_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-206"><a href="#cb25-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-207"><a href="#cb25-207" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Similarity matrix</span></span>
<span id="cb25-208"><a href="#cb25-208" aria-hidden="true" tabindex="-1"></a>        temp <span class="op">=</span> <span class="va">self</span>.log_temp.exp()</span>
<span id="cb25-209"><a href="#cb25-209" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> z_text <span class="op">@</span> z_image.T <span class="op">*</span> temp</span>
<span id="cb25-210"><a href="#cb25-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-211"><a href="#cb25-211" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Symmetric cross-entropy loss</span></span>
<span id="cb25-212"><a href="#cb25-212" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> torch.arange(<span class="bu">len</span>(text_emb), device<span class="op">=</span>text_emb.device)</span>
<span id="cb25-213"><a href="#cb25-213" aria-hidden="true" tabindex="-1"></a>        loss_t2i <span class="op">=</span> F.cross_entropy(logits, labels)</span>
<span id="cb25-214"><a href="#cb25-214" aria-hidden="true" tabindex="-1"></a>        loss_i2t <span class="op">=</span> F.cross_entropy(logits.T, labels)</span>
<span id="cb25-215"><a href="#cb25-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-216"><a href="#cb25-216" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> (loss_t2i <span class="op">+</span> loss_i2t) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb25-217"><a href="#cb25-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-218"><a href="#cb25-218" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> z_text, z_image, loss</span>
<span id="cb25-219"><a href="#cb25-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-220"><a href="#cb25-220" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode_text(<span class="va">self</span>, text_emb):</span>
<span id="cb25-221"><a href="#cb25-221" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.normalize(<span class="va">self</span>.text_proj(text_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-222"><a href="#cb25-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-223"><a href="#cb25-223" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode_image(<span class="va">self</span>, image_emb):</span>
<span id="cb25-224"><a href="#cb25-224" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.normalize(<span class="va">self</span>.image_proj(image_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-225"><a href="#cb25-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-226"><a href="#cb25-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-227"><a href="#cb25-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### Projection Alignment for Arbitrary Modalities</span></span>
<span id="cb25-228"><a href="#cb25-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-229"><a href="#cb25-229" aria-hidden="true" tabindex="-1"></a>For more than two modalities, we generalize to a shared projection space where each modality has its own encoder but all encoders map to the same target space:</span>
<span id="cb25-230"><a href="#cb25-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-231"><a href="#cb25-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-232"><a href="#cb25-232" aria-hidden="true" tabindex="-1"></a>\mathbf{z}_i^{(m)} = f^{(m)}(\mathbf{x}_i^{(m)}; \boldsymbol{\theta}^{(m)}) \in \mathbb{R}^d, \qquad m = 1, \ldots, M</span>
<span id="cb25-233"><a href="#cb25-233" aria-hidden="true" tabindex="-1"></a>$$ {#eq-projection}</span>
<span id="cb25-234"><a href="#cb25-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-235"><a href="#cb25-235" aria-hidden="true" tabindex="-1"></a>The alignment loss encourages all modality embeddings for the same observation to be similar:</span>
<span id="cb25-236"><a href="#cb25-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-237"><a href="#cb25-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-238"><a href="#cb25-238" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{\text{align}} = \sum_{m &lt; m'} \frac{1}{N}\sum_{i=1}^{N} \left<span class="sc">\|</span>\mathbf{z}_i^{(m)} - \mathbf{z}_i^{(m')}\right<span class="sc">\|</span>^2</span>
<span id="cb25-239"><a href="#cb25-239" aria-hidden="true" tabindex="-1"></a>$$ {#eq-alignment-loss}</span>
<span id="cb25-240"><a href="#cb25-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-241"><a href="#cb25-241" aria-hidden="true" tabindex="-1"></a>This MSE alignment is simpler than contrastive alignment but does not enforce the discriminative property (different observations should have dissimilar embeddings). In practice, we combine alignment with a prediction objective:</span>
<span id="cb25-242"><a href="#cb25-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-243"><a href="#cb25-243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-244"><a href="#cb25-244" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{predict}}(\hat{y}, y) + \lambda \cdot \mathcal{L}_{\text{align}}</span>
<span id="cb25-245"><a href="#cb25-245" aria-hidden="true" tabindex="-1"></a>$$ {#eq-total-loss}</span>
<span id="cb25-246"><a href="#cb25-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-249"><a href="#cb25-249" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-250"><a href="#cb25-250" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: multi-projection</span></span>
<span id="cb25-251"><a href="#cb25-251" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-252"><a href="#cb25-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-253"><a href="#cb25-253" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalProjector(nn.Module):</span>
<span id="cb25-254"><a href="#cb25-254" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-255"><a href="#cb25-255" aria-hidden="true" tabindex="-1"></a><span class="co">    Project arbitrary modalities into a shared latent space.</span></span>
<span id="cb25-256"><a href="#cb25-256" aria-hidden="true" tabindex="-1"></a><span class="co">    Supports variable numbers of modalities per observation.</span></span>
<span id="cb25-257"><a href="#cb25-257" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-258"><a href="#cb25-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-259"><a href="#cb25-259" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, modality_dims, proj_dim<span class="op">=</span><span class="dv">128</span>, dropout<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb25-260"><a href="#cb25-260" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-261"><a href="#cb25-261" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-262"><a href="#cb25-262" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-263"><a href="#cb25-263" aria-hidden="true" tabindex="-1"></a><span class="co">        modality_dims : dict</span></span>
<span id="cb25-264"><a href="#cb25-264" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: input_dim}, e.g.,</span></span>
<span id="cb25-265"><a href="#cb25-265" aria-hidden="true" tabindex="-1"></a><span class="co">            {'text': 768, 'image': 2048, 'tabular': 50, 'ts': 128}</span></span>
<span id="cb25-266"><a href="#cb25-266" aria-hidden="true" tabindex="-1"></a><span class="co">        proj_dim : int</span></span>
<span id="cb25-267"><a href="#cb25-267" aria-hidden="true" tabindex="-1"></a><span class="co">            Shared projection dimensionality.</span></span>
<span id="cb25-268"><a href="#cb25-268" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-269"><a href="#cb25-269" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-270"><a href="#cb25-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-271"><a href="#cb25-271" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(modality_dims.keys())</span>
<span id="cb25-272"><a href="#cb25-272" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_dim <span class="op">=</span> proj_dim</span>
<span id="cb25-273"><a href="#cb25-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-274"><a href="#cb25-274" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-modality encoders</span></span>
<span id="cb25-275"><a href="#cb25-275" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict()</span>
<span id="cb25-276"><a href="#cb25-276" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, dim <span class="kw">in</span> modality_dims.items():</span>
<span id="cb25-277"><a href="#cb25-277" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.encoders[name] <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-278"><a href="#cb25-278" aria-hidden="true" tabindex="-1"></a>                nn.Linear(dim, proj_dim <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb25-279"><a href="#cb25-279" aria-hidden="true" tabindex="-1"></a>                nn.LayerNorm(proj_dim <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb25-280"><a href="#cb25-280" aria-hidden="true" tabindex="-1"></a>                nn.GELU(),</span>
<span id="cb25-281"><a href="#cb25-281" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(dropout),</span>
<span id="cb25-282"><a href="#cb25-282" aria-hidden="true" tabindex="-1"></a>                nn.Linear(proj_dim <span class="op">*</span> <span class="dv">2</span>, proj_dim),</span>
<span id="cb25-283"><a href="#cb25-283" aria-hidden="true" tabindex="-1"></a>                nn.LayerNorm(proj_dim)</span>
<span id="cb25-284"><a href="#cb25-284" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-285"><a href="#cb25-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-286"><a href="#cb25-286" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modality_inputs):</span>
<span id="cb25-287"><a href="#cb25-287" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-288"><a href="#cb25-288" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-289"><a href="#cb25-289" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-290"><a href="#cb25-290" aria-hidden="true" tabindex="-1"></a><span class="co">        modality_inputs : dict</span></span>
<span id="cb25-291"><a href="#cb25-291" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: tensor}, may be missing some modalities.</span></span>
<span id="cb25-292"><a href="#cb25-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-293"><a href="#cb25-293" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns</span></span>
<span id="cb25-294"><a href="#cb25-294" aria-hidden="true" tabindex="-1"></a><span class="co">        -------</span></span>
<span id="cb25-295"><a href="#cb25-295" aria-hidden="true" tabindex="-1"></a><span class="co">        dict : {modality_name: projected_embedding}</span></span>
<span id="cb25-296"><a href="#cb25-296" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-297"><a href="#cb25-297" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb25-298"><a href="#cb25-298" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, x <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb25-299"><a href="#cb25-299" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> <span class="va">self</span>.encoders <span class="kw">and</span> x <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-300"><a href="#cb25-300" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> <span class="va">self</span>.encoders[name](x)</span>
<span id="cb25-301"><a href="#cb25-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-302"><a href="#cb25-302" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> embeddings</span>
<span id="cb25-303"><a href="#cb25-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-304"><a href="#cb25-304" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_alignment_loss(<span class="va">self</span>, embeddings):</span>
<span id="cb25-305"><a href="#cb25-305" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Pairwise MSE alignment across all available modalities."""</span></span>
<span id="cb25-306"><a href="#cb25-306" aria-hidden="true" tabindex="-1"></a>        names <span class="op">=</span> <span class="bu">list</span>(embeddings.keys())</span>
<span id="cb25-307"><a href="#cb25-307" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(names) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb25-308"><a href="#cb25-308" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.tensor(<span class="fl">0.0</span>, device<span class="op">=</span><span class="bu">next</span>(<span class="va">self</span>.parameters()).device)</span>
<span id="cb25-309"><a href="#cb25-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-310"><a href="#cb25-310" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>, device<span class="op">=</span><span class="bu">next</span>(<span class="va">self</span>.parameters()).device)</span>
<span id="cb25-311"><a href="#cb25-311" aria-hidden="true" tabindex="-1"></a>        n_pairs <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-312"><a href="#cb25-312" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(names)):</span>
<span id="cb25-313"><a href="#cb25-313" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i <span class="op">+</span> <span class="dv">1</span>, <span class="bu">len</span>(names)):</span>
<span id="cb25-314"><a href="#cb25-314" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">+=</span> F.mse_loss(</span>
<span id="cb25-315"><a href="#cb25-315" aria-hidden="true" tabindex="-1"></a>                    embeddings[names[i]], embeddings[names[j]]</span>
<span id="cb25-316"><a href="#cb25-316" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-317"><a href="#cb25-317" aria-hidden="true" tabindex="-1"></a>                n_pairs <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb25-318"><a href="#cb25-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-319"><a href="#cb25-319" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss <span class="op">/</span> n_pairs <span class="cf">if</span> n_pairs <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> loss</span>
<span id="cb25-320"><a href="#cb25-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-321"><a href="#cb25-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-322"><a href="#cb25-322" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fusion Architectures for Return Prediction</span></span>
<span id="cb25-323"><a href="#cb25-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-324"><a href="#cb25-324" aria-hidden="true" tabindex="-1"></a><span class="fu">### Unimodal Encoders</span></span>
<span id="cb25-325"><a href="#cb25-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-326"><a href="#cb25-326" aria-hidden="true" tabindex="-1"></a>Before fusing modalities, we need encoders that produce fixed-dimensional representations from each raw input. We build four encoders corresponding to the primary modalities in Vietnamese equity markets.</span>
<span id="cb25-327"><a href="#cb25-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-330"><a href="#cb25-330" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-331"><a href="#cb25-331" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: unimodal-encoders</span></span>
<span id="cb25-332"><a href="#cb25-332" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-333"><a href="#cb25-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-334"><a href="#cb25-334" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TabularEncoder(nn.Module):</span>
<span id="cb25-335"><a href="#cb25-335" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Encode financial statement features."""</span></span>
<span id="cb25-336"><a href="#cb25-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-337"><a href="#cb25-337" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hidden_dim<span class="op">=</span><span class="dv">128</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb25-338"><a href="#cb25-338" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-339"><a href="#cb25-339" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-340"><a href="#cb25-340" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, hidden_dim),</span>
<span id="cb25-341"><a href="#cb25-341" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(hidden_dim),</span>
<span id="cb25-342"><a href="#cb25-342" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-343"><a href="#cb25-343" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb25-344"><a href="#cb25-344" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim),</span>
<span id="cb25-345"><a href="#cb25-345" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(hidden_dim),</span>
<span id="cb25-346"><a href="#cb25-346" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-347"><a href="#cb25-347" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb25-348"><a href="#cb25-348" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, output_dim)</span>
<span id="cb25-349"><a href="#cb25-349" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-350"><a href="#cb25-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-351"><a href="#cb25-351" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-352"><a href="#cb25-352" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb25-353"><a href="#cb25-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-354"><a href="#cb25-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-355"><a href="#cb25-355" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TextEncoder(nn.Module):</span>
<span id="cb25-356"><a href="#cb25-356" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-357"><a href="#cb25-357" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode Vietnamese text using pre-extracted PhoBERT embeddings.</span></span>
<span id="cb25-358"><a href="#cb25-358" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: pre-computed [CLS] token embedding (768-d).</span></span>
<span id="cb25-359"><a href="#cb25-359" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-360"><a href="#cb25-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-361"><a href="#cb25-361" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">768</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb25-362"><a href="#cb25-362" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-363"><a href="#cb25-363" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-364"><a href="#cb25-364" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">256</span>),</span>
<span id="cb25-365"><a href="#cb25-365" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(<span class="dv">256</span>),</span>
<span id="cb25-366"><a href="#cb25-366" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-367"><a href="#cb25-367" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb25-368"><a href="#cb25-368" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, output_dim)</span>
<span id="cb25-369"><a href="#cb25-369" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-370"><a href="#cb25-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-371"><a href="#cb25-371" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-372"><a href="#cb25-372" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb25-373"><a href="#cb25-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-374"><a href="#cb25-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-375"><a href="#cb25-375" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageEncoder(nn.Module):</span>
<span id="cb25-376"><a href="#cb25-376" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-377"><a href="#cb25-377" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode satellite / document image features.</span></span>
<span id="cb25-378"><a href="#cb25-378" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: pre-computed CNN features (e.g., ResNet50 2048-d).</span></span>
<span id="cb25-379"><a href="#cb25-379" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-380"><a href="#cb25-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-381"><a href="#cb25-381" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim<span class="op">=</span><span class="dv">2048</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb25-382"><a href="#cb25-382" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-383"><a href="#cb25-383" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-384"><a href="#cb25-384" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">512</span>),</span>
<span id="cb25-385"><a href="#cb25-385" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(<span class="dv">512</span>),</span>
<span id="cb25-386"><a href="#cb25-386" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-387"><a href="#cb25-387" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb25-388"><a href="#cb25-388" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, output_dim)</span>
<span id="cb25-389"><a href="#cb25-389" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-390"><a href="#cb25-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-391"><a href="#cb25-391" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-392"><a href="#cb25-392" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb25-393"><a href="#cb25-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-394"><a href="#cb25-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-395"><a href="#cb25-395" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimeSeriesEncoder(nn.Module):</span>
<span id="cb25-396"><a href="#cb25-396" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-397"><a href="#cb25-397" aria-hidden="true" tabindex="-1"></a><span class="co">    Encode price/volume time series using a 1D CNN + attention.</span></span>
<span id="cb25-398"><a href="#cb25-398" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: (batch, seq_len, n_features) tensor of daily data.</span></span>
<span id="cb25-399"><a href="#cb25-399" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-400"><a href="#cb25-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-401"><a href="#cb25-401" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_features<span class="op">=</span><span class="dv">5</span>, seq_len<span class="op">=</span><span class="dv">60</span>, output_dim<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb25-402"><a href="#cb25-402" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-403"><a href="#cb25-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-404"><a href="#cb25-404" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1D convolutional layers</span></span>
<span id="cb25-405"><a href="#cb25-405" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv1d(n_features, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb25-406"><a href="#cb25-406" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv1d(<span class="dv">32</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-407"><a href="#cb25-407" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.AdaptiveAvgPool1d(<span class="dv">1</span>)</span>
<span id="cb25-408"><a href="#cb25-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-409"><a href="#cb25-409" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Temporal attention</span></span>
<span id="cb25-410"><a href="#cb25-410" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb25-411"><a href="#cb25-411" aria-hidden="true" tabindex="-1"></a>            embed_dim<span class="op">=</span><span class="dv">64</span>, num_heads<span class="op">=</span><span class="dv">4</span>, batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-412"><a href="#cb25-412" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-413"><a href="#cb25-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-414"><a href="#cb25-414" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(<span class="dv">64</span>, output_dim)</span>
<span id="cb25-415"><a href="#cb25-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-416"><a href="#cb25-416" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-417"><a href="#cb25-417" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x: (B, T, F) -&gt; (B, F, T) for Conv1d</span></span>
<span id="cb25-418"><a href="#cb25-418" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb25-419"><a href="#cb25-419" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv1(x))</span>
<span id="cb25-420"><a href="#cb25-420" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv2(x))</span>
<span id="cb25-421"><a href="#cb25-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-422"><a href="#cb25-422" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, 64, T) -&gt; (B, T, 64) for attention</span></span>
<span id="cb25-423"><a href="#cb25-423" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb25-424"><a href="#cb25-424" aria-hidden="true" tabindex="-1"></a>        attn_out, _ <span class="op">=</span> <span class="va">self</span>.attn(x, x, x)</span>
<span id="cb25-425"><a href="#cb25-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-426"><a href="#cb25-426" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pool over time</span></span>
<span id="cb25-427"><a href="#cb25-427" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> attn_out.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># (B, 64, T)</span></span>
<span id="cb25-428"><a href="#cb25-428" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(x).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (B, 64)</span></span>
<span id="cb25-429"><a href="#cb25-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-430"><a href="#cb25-430" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.fc(x)</span>
<span id="cb25-431"><a href="#cb25-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-432"><a href="#cb25-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-433"><a href="#cb25-433" aria-hidden="true" tabindex="-1"></a><span class="fu">### Early Fusion</span></span>
<span id="cb25-434"><a href="#cb25-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-435"><a href="#cb25-435" aria-hidden="true" tabindex="-1"></a>Early fusion concatenates modality embeddings before a shared prediction head. This is the simplest approach and serves as a natural baseline.</span>
<span id="cb25-436"><a href="#cb25-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-439"><a href="#cb25-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-440"><a href="#cb25-440" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: early-fusion</span></span>
<span id="cb25-441"><a href="#cb25-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-442"><a href="#cb25-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-443"><a href="#cb25-443" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EarlyFusionModel(nn.Module):</span>
<span id="cb25-444"><a href="#cb25-444" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-445"><a href="#cb25-445" aria-hidden="true" tabindex="-1"></a><span class="co">    Concatenate modality embeddings, then predict.</span></span>
<span id="cb25-446"><a href="#cb25-446" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-447"><a href="#cb25-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-448"><a href="#cb25-448" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, hidden_dim<span class="op">=</span><span class="dv">128</span>, output_dim<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb25-449"><a href="#cb25-449" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-450"><a href="#cb25-450" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-451"><a href="#cb25-451" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-452"><a href="#cb25-452" aria-hidden="true" tabindex="-1"></a><span class="co">        encoders : dict</span></span>
<span id="cb25-453"><a href="#cb25-453" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: encoder_module}</span></span>
<span id="cb25-454"><a href="#cb25-454" aria-hidden="true" tabindex="-1"></a><span class="co">            Each encoder outputs a vector of the same dimension.</span></span>
<span id="cb25-455"><a href="#cb25-455" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-456"><a href="#cb25-456" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-457"><a href="#cb25-457" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb25-458"><a href="#cb25-458" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb25-459"><a href="#cb25-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-460"><a href="#cb25-460" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Infer encoder output dim from first encoder</span></span>
<span id="cb25-461"><a href="#cb25-461" aria-hidden="true" tabindex="-1"></a>        sample_encoder <span class="op">=</span> <span class="bu">list</span>(encoders.values())[<span class="dv">0</span>]</span>
<span id="cb25-462"><a href="#cb25-462" aria-hidden="true" tabindex="-1"></a>        enc_dim <span class="op">=</span> <span class="bu">list</span>(sample_encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb25-463"><a href="#cb25-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-464"><a href="#cb25-464" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-465"><a href="#cb25-465" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, hidden_dim),</span>
<span id="cb25-466"><a href="#cb25-466" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim),</span>
<span id="cb25-467"><a href="#cb25-467" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-468"><a href="#cb25-468" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb25-469"><a href="#cb25-469" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb25-470"><a href="#cb25-470" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-471"><a href="#cb25-471" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, output_dim)</span>
<span id="cb25-472"><a href="#cb25-472" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-473"><a href="#cb25-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-474"><a href="#cb25-474" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb25-475"><a href="#cb25-475" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-476"><a href="#cb25-476" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-477"><a href="#cb25-477" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-478"><a href="#cb25-478" aria-hidden="true" tabindex="-1"></a><span class="co">        inputs : dict</span></span>
<span id="cb25-479"><a href="#cb25-479" aria-hidden="true" tabindex="-1"></a><span class="co">            {modality_name: tensor}</span></span>
<span id="cb25-480"><a href="#cb25-480" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-481"><a href="#cb25-481" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb25-482"><a href="#cb25-482" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb25-483"><a href="#cb25-483" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-484"><a href="#cb25-484" aria-hidden="true" tabindex="-1"></a>                embeddings.append(encoder(inputs[name]))</span>
<span id="cb25-485"><a href="#cb25-485" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-486"><a href="#cb25-486" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Zero-fill missing modalities</span></span>
<span id="cb25-487"><a href="#cb25-487" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb25-488"><a href="#cb25-488" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb25-489"><a href="#cb25-489" aria-hidden="true" tabindex="-1"></a>                embeddings.append(torch.zeros(</span>
<span id="cb25-490"><a href="#cb25-490" aria-hidden="true" tabindex="-1"></a>                    inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>],</span>
<span id="cb25-491"><a href="#cb25-491" aria-hidden="true" tabindex="-1"></a>                    enc_dim, device<span class="op">=</span>device</span>
<span id="cb25-492"><a href="#cb25-492" aria-hidden="true" tabindex="-1"></a>                ))</span>
<span id="cb25-493"><a href="#cb25-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-494"><a href="#cb25-494" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat(embeddings, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-495"><a href="#cb25-495" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-496"><a href="#cb25-496" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-497"><a href="#cb25-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-498"><a href="#cb25-498" aria-hidden="true" tabindex="-1"></a><span class="fu">### Late Fusion</span></span>
<span id="cb25-499"><a href="#cb25-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-500"><a href="#cb25-500" aria-hidden="true" tabindex="-1"></a>Late fusion trains independent models per modality and combines their predictions. The combination weights can be fixed (equal averaging), learned (linear), or adaptive (gating network).</span>
<span id="cb25-501"><a href="#cb25-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-504"><a href="#cb25-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-505"><a href="#cb25-505" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: late-fusion</span></span>
<span id="cb25-506"><a href="#cb25-506" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-507"><a href="#cb25-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-508"><a href="#cb25-508" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LateFusionModel(nn.Module):</span>
<span id="cb25-509"><a href="#cb25-509" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-510"><a href="#cb25-510" aria-hidden="true" tabindex="-1"></a><span class="co">    Independent prediction per modality, learned combination.</span></span>
<span id="cb25-511"><a href="#cb25-511" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-512"><a href="#cb25-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-513"><a href="#cb25-513" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, combination<span class="op">=</span><span class="st">"learned"</span>):</span>
<span id="cb25-514"><a href="#cb25-514" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-515"><a href="#cb25-515" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-516"><a href="#cb25-516" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-517"><a href="#cb25-517" aria-hidden="true" tabindex="-1"></a><span class="co">        combination : str</span></span>
<span id="cb25-518"><a href="#cb25-518" aria-hidden="true" tabindex="-1"></a><span class="co">            'average', 'learned', or 'gating'.</span></span>
<span id="cb25-519"><a href="#cb25-519" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-520"><a href="#cb25-520" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-521"><a href="#cb25-521" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb25-522"><a href="#cb25-522" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.combination <span class="op">=</span> combination</span>
<span id="cb25-523"><a href="#cb25-523" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb25-524"><a href="#cb25-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-525"><a href="#cb25-525" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-modality prediction heads</span></span>
<span id="cb25-526"><a href="#cb25-526" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb25-527"><a href="#cb25-527" aria-hidden="true" tabindex="-1"></a>            name: nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb25-528"><a href="#cb25-528" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name <span class="kw">in</span> encoders</span>
<span id="cb25-529"><a href="#cb25-529" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-530"><a href="#cb25-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-531"><a href="#cb25-531" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb25-532"><a href="#cb25-532" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights <span class="op">=</span> nn.Parameter(</span>
<span id="cb25-533"><a href="#cb25-533" aria-hidden="true" tabindex="-1"></a>                torch.ones(<span class="va">self</span>.n_modalities) <span class="op">/</span> <span class="va">self</span>.n_modalities</span>
<span id="cb25-534"><a href="#cb25-534" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-535"><a href="#cb25-535" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> combination <span class="op">==</span> <span class="st">"gating"</span>:</span>
<span id="cb25-536"><a href="#cb25-536" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gating network takes all embeddings as input</span></span>
<span id="cb25-537"><a href="#cb25-537" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.gate <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-538"><a href="#cb25-538" aria-hidden="true" tabindex="-1"></a>                nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, <span class="va">self</span>.n_modalities),</span>
<span id="cb25-539"><a href="#cb25-539" aria-hidden="true" tabindex="-1"></a>                nn.Softmax(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-540"><a href="#cb25-540" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-541"><a href="#cb25-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-542"><a href="#cb25-542" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb25-543"><a href="#cb25-543" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> {}</span>
<span id="cb25-544"><a href="#cb25-544" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb25-545"><a href="#cb25-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-546"><a href="#cb25-546" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb25-547"><a href="#cb25-547" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-548"><a href="#cb25-548" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> encoder(inputs[name])</span>
<span id="cb25-549"><a href="#cb25-549" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> <span class="va">self</span>.heads[name](emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-550"><a href="#cb25-550" aria-hidden="true" tabindex="-1"></a>                predictions[name] <span class="op">=</span> pred</span>
<span id="cb25-551"><a href="#cb25-551" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> emb</span>
<span id="cb25-552"><a href="#cb25-552" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-553"><a href="#cb25-553" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb25-554"><a href="#cb25-554" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>]</span>
<span id="cb25-555"><a href="#cb25-555" aria-hidden="true" tabindex="-1"></a>                predictions[name] <span class="op">=</span> torch.zeros(batch_size, device<span class="op">=</span>device)</span>
<span id="cb25-556"><a href="#cb25-556" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb25-557"><a href="#cb25-557" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> torch.zeros(</span>
<span id="cb25-558"><a href="#cb25-558" aria-hidden="true" tabindex="-1"></a>                    batch_size, enc_dim, device<span class="op">=</span>device</span>
<span id="cb25-559"><a href="#cb25-559" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-560"><a href="#cb25-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-561"><a href="#cb25-561" aria-hidden="true" tabindex="-1"></a>        pred_stack <span class="op">=</span> torch.stack(<span class="bu">list</span>(predictions.values()), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-562"><a href="#cb25-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-563"><a href="#cb25-563" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"average"</span>:</span>
<span id="cb25-564"><a href="#cb25-564" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> pred_stack.mean(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-565"><a href="#cb25-565" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb25-566"><a href="#cb25-566" aria-hidden="true" tabindex="-1"></a>            weights <span class="op">=</span> F.softmax(<span class="va">self</span>.weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-567"><a href="#cb25-567" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> (pred_stack <span class="op">*</span> weights).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-568"><a href="#cb25-568" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"gating"</span>:</span>
<span id="cb25-569"><a href="#cb25-569" aria-hidden="true" tabindex="-1"></a>            all_emb <span class="op">=</span> torch.cat(<span class="bu">list</span>(embeddings.values()), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-570"><a href="#cb25-570" aria-hidden="true" tabindex="-1"></a>            gate_weights <span class="op">=</span> <span class="va">self</span>.gate(all_emb)</span>
<span id="cb25-571"><a href="#cb25-571" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> (pred_stack <span class="op">*</span> gate_weights).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-572"><a href="#cb25-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-573"><a href="#cb25-573" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_modality_weights(<span class="va">self</span>):</span>
<span id="cb25-574"><a href="#cb25-574" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Return the contribution of each modality."""</span></span>
<span id="cb25-575"><a href="#cb25-575" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.combination <span class="op">==</span> <span class="st">"learned"</span>:</span>
<span id="cb25-576"><a href="#cb25-576" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> F.softmax(<span class="va">self</span>.weights, dim<span class="op">=</span><span class="dv">0</span>).detach().cpu().numpy()</span>
<span id="cb25-577"><a href="#cb25-577" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb25-578"><a href="#cb25-578" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-579"><a href="#cb25-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-580"><a href="#cb25-580" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cross-Attention Fusion</span></span>
<span id="cb25-581"><a href="#cb25-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-582"><a href="#cb25-582" aria-hidden="true" tabindex="-1"></a>Cross-attention fusion is the most expressive architecture. Each modality attends to every other modality, learning which cross-modal interactions are informative. This is the mechanism underlying modern vision-language models like Flamingo <span class="co">[</span><span class="ot">@alayrac2022flamingo</span><span class="co">]</span> and GPT-4V.</span>
<span id="cb25-583"><a href="#cb25-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-584"><a href="#cb25-584" aria-hidden="true" tabindex="-1"></a>The cross-attention operation for modality $m$ attending to modality $m'$ is:</span>
<span id="cb25-585"><a href="#cb25-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-586"><a href="#cb25-586" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-587"><a href="#cb25-587" aria-hidden="true" tabindex="-1"></a>\text{CA}^{(m \to m')} = \text{softmax}\left(\frac{\mathbf{Q}^{(m)} \left(\mathbf{K}^{(m')}\right)^\top}{\sqrt{d_k}}\right) \mathbf{V}^{(m')}</span>
<span id="cb25-588"><a href="#cb25-588" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cross-attention-detail}</span>
<span id="cb25-589"><a href="#cb25-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-590"><a href="#cb25-590" aria-hidden="true" tabindex="-1"></a>where $\mathbf{Q}^{(m)} = \mathbf{z}^{(m)} W_Q$, $\mathbf{K}^{(m')} = \mathbf{z}^{(m')} W_K$, $\mathbf{V}^{(m')} = \mathbf{z}^{(m')} W_V$. The output enriches modality $m$'s representation with information from modality $m'$.</span>
<span id="cb25-591"><a href="#cb25-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-594"><a href="#cb25-594" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-595"><a href="#cb25-595" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cross-attention-fusion</span></span>
<span id="cb25-596"><a href="#cb25-596" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-597"><a href="#cb25-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-598"><a href="#cb25-598" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossAttentionBlock(nn.Module):</span>
<span id="cb25-599"><a href="#cb25-599" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Single cross-attention block: query modality attends to key modality."""</span></span>
<span id="cb25-600"><a href="#cb25-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-601"><a href="#cb25-601" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, n_heads<span class="op">=</span><span class="dv">4</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb25-602"><a href="#cb25-602" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-603"><a href="#cb25-603" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb25-604"><a href="#cb25-604" aria-hidden="true" tabindex="-1"></a>            embed_dim<span class="op">=</span>dim, num_heads<span class="op">=</span>n_heads,</span>
<span id="cb25-605"><a href="#cb25-605" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span>dropout, batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-606"><a href="#cb25-606" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-607"><a href="#cb25-607" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb25-608"><a href="#cb25-608" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb25-609"><a href="#cb25-609" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ffn <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-610"><a href="#cb25-610" aria-hidden="true" tabindex="-1"></a>            nn.Linear(dim, dim <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb25-611"><a href="#cb25-611" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-612"><a href="#cb25-612" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout),</span>
<span id="cb25-613"><a href="#cb25-613" aria-hidden="true" tabindex="-1"></a>            nn.Linear(dim <span class="op">*</span> <span class="dv">4</span>, dim),</span>
<span id="cb25-614"><a href="#cb25-614" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout)</span>
<span id="cb25-615"><a href="#cb25-615" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-616"><a href="#cb25-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-617"><a href="#cb25-617" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, query, key_value):</span>
<span id="cb25-618"><a href="#cb25-618" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention</span></span>
<span id="cb25-619"><a href="#cb25-619" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> query.unsqueeze(<span class="dv">1</span>) <span class="cf">if</span> query.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> query</span>
<span id="cb25-620"><a href="#cb25-620" aria-hidden="true" tabindex="-1"></a>        kv <span class="op">=</span> key_value.unsqueeze(<span class="dv">1</span>) <span class="cf">if</span> key_value.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> key_value</span>
<span id="cb25-621"><a href="#cb25-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-622"><a href="#cb25-622" aria-hidden="true" tabindex="-1"></a>        attn_out, attn_weights <span class="op">=</span> <span class="va">self</span>.attn(q, kv, kv)</span>
<span id="cb25-623"><a href="#cb25-623" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.norm1(q <span class="op">+</span> attn_out)</span>
<span id="cb25-624"><a href="#cb25-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-625"><a href="#cb25-625" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Feed-forward</span></span>
<span id="cb25-626"><a href="#cb25-626" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.norm2(q <span class="op">+</span> <span class="va">self</span>.ffn(q))</span>
<span id="cb25-627"><a href="#cb25-627" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out.squeeze(<span class="dv">1</span>) <span class="cf">if</span> query.dim() <span class="op">==</span> <span class="dv">2</span> <span class="cf">else</span> out, attn_weights</span>
<span id="cb25-628"><a href="#cb25-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-629"><a href="#cb25-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-630"><a href="#cb25-630" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossAttentionFusionModel(nn.Module):</span>
<span id="cb25-631"><a href="#cb25-631" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-632"><a href="#cb25-632" aria-hidden="true" tabindex="-1"></a><span class="co">    Full cross-attention fusion across M modalities.</span></span>
<span id="cb25-633"><a href="#cb25-633" aria-hidden="true" tabindex="-1"></a><span class="co">    Each modality attends to all others via cross-attention blocks.</span></span>
<span id="cb25-634"><a href="#cb25-634" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-635"><a href="#cb25-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-636"><a href="#cb25-636" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, n_layers<span class="op">=</span><span class="dv">2</span>, n_heads<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb25-637"><a href="#cb25-637" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-638"><a href="#cb25-638" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb25-639"><a href="#cb25-639" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(encoders.keys())</span>
<span id="cb25-640"><a href="#cb25-640" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb25-641"><a href="#cb25-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-642"><a href="#cb25-642" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention blocks: each modality attends to each other</span></span>
<span id="cb25-643"><a href="#cb25-643" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cross_attn_layers <span class="op">=</span> nn.ModuleList()</span>
<span id="cb25-644"><a href="#cb25-644" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers):</span>
<span id="cb25-645"><a href="#cb25-645" aria-hidden="true" tabindex="-1"></a>            layer <span class="op">=</span> nn.ModuleDict()</span>
<span id="cb25-646"><a href="#cb25-646" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb25-647"><a href="#cb25-647" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> m_prime <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb25-648"><a href="#cb25-648" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> m <span class="op">!=</span> m_prime:</span>
<span id="cb25-649"><a href="#cb25-649" aria-hidden="true" tabindex="-1"></a>                        layer[<span class="ss">f"</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">_to_</span><span class="sc">{</span>m_prime<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> CrossAttentionBlock(</span>
<span id="cb25-650"><a href="#cb25-650" aria-hidden="true" tabindex="-1"></a>                            enc_dim, n_heads</span>
<span id="cb25-651"><a href="#cb25-651" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb25-652"><a href="#cb25-652" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.cross_attn_layers.append(layer)</span>
<span id="cb25-653"><a href="#cb25-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-654"><a href="#cb25-654" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb25-655"><a href="#cb25-655" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-656"><a href="#cb25-656" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="va">self</span>.n_modalities, enc_dim),</span>
<span id="cb25-657"><a href="#cb25-657" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(enc_dim),</span>
<span id="cb25-658"><a href="#cb25-658" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-659"><a href="#cb25-659" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb25-660"><a href="#cb25-660" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb25-661"><a href="#cb25-661" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-662"><a href="#cb25-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-663"><a href="#cb25-663" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb25-664"><a href="#cb25-664" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb25-665"><a href="#cb25-665" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> {}</span>
<span id="cb25-666"><a href="#cb25-666" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, encoder <span class="kw">in</span> <span class="va">self</span>.encoders.items():</span>
<span id="cb25-667"><a href="#cb25-667" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-668"><a href="#cb25-668" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> encoder(inputs[name])</span>
<span id="cb25-669"><a href="#cb25-669" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-670"><a href="#cb25-670" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb25-671"><a href="#cb25-671" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> inputs[<span class="bu">list</span>(inputs.keys())[<span class="dv">0</span>]].shape[<span class="dv">0</span>]</span>
<span id="cb25-672"><a href="#cb25-672" aria-hidden="true" tabindex="-1"></a>                enc_dim <span class="op">=</span> <span class="bu">list</span>(encoder.parameters())[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>]</span>
<span id="cb25-673"><a href="#cb25-673" aria-hidden="true" tabindex="-1"></a>                embeddings[name] <span class="op">=</span> torch.zeros(</span>
<span id="cb25-674"><a href="#cb25-674" aria-hidden="true" tabindex="-1"></a>                    batch_size, enc_dim, device<span class="op">=</span>device</span>
<span id="cb25-675"><a href="#cb25-675" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-676"><a href="#cb25-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-677"><a href="#cb25-677" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention layers</span></span>
<span id="cb25-678"><a href="#cb25-678" aria-hidden="true" tabindex="-1"></a>        all_attn_weights <span class="op">=</span> {}</span>
<span id="cb25-679"><a href="#cb25-679" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.cross_attn_layers:</span>
<span id="cb25-680"><a href="#cb25-680" aria-hidden="true" tabindex="-1"></a>            new_embeddings <span class="op">=</span> {k: v.clone() <span class="cf">for</span> k, v <span class="kw">in</span> embeddings.items()}</span>
<span id="cb25-681"><a href="#cb25-681" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> key, block <span class="kw">in</span> layer.items():</span>
<span id="cb25-682"><a href="#cb25-682" aria-hidden="true" tabindex="-1"></a>                parts <span class="op">=</span> key.split(<span class="st">"_to_"</span>)</span>
<span id="cb25-683"><a href="#cb25-683" aria-hidden="true" tabindex="-1"></a>                query_mod, kv_mod <span class="op">=</span> parts[<span class="dv">0</span>], parts[<span class="dv">1</span>]</span>
<span id="cb25-684"><a href="#cb25-684" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> query_mod <span class="kw">in</span> embeddings <span class="kw">and</span> kv_mod <span class="kw">in</span> embeddings:</span>
<span id="cb25-685"><a href="#cb25-685" aria-hidden="true" tabindex="-1"></a>                    updated, weights <span class="op">=</span> block(</span>
<span id="cb25-686"><a href="#cb25-686" aria-hidden="true" tabindex="-1"></a>                        embeddings[query_mod],</span>
<span id="cb25-687"><a href="#cb25-687" aria-hidden="true" tabindex="-1"></a>                        embeddings[kv_mod]</span>
<span id="cb25-688"><a href="#cb25-688" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb25-689"><a href="#cb25-689" aria-hidden="true" tabindex="-1"></a>                    new_embeddings[query_mod] <span class="op">=</span> (</span>
<span id="cb25-690"><a href="#cb25-690" aria-hidden="true" tabindex="-1"></a>                        new_embeddings[query_mod] <span class="op">+</span> updated</span>
<span id="cb25-691"><a href="#cb25-691" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb25-692"><a href="#cb25-692" aria-hidden="true" tabindex="-1"></a>                    all_attn_weights[key] <span class="op">=</span> weights</span>
<span id="cb25-693"><a href="#cb25-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-694"><a href="#cb25-694" aria-hidden="true" tabindex="-1"></a>            embeddings <span class="op">=</span> new_embeddings</span>
<span id="cb25-695"><a href="#cb25-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-696"><a href="#cb25-696" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate and predict</span></span>
<span id="cb25-697"><a href="#cb25-697" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat(</span>
<span id="cb25-698"><a href="#cb25-698" aria-hidden="true" tabindex="-1"></a>            [embeddings[name] <span class="cf">for</span> name <span class="kw">in</span> <span class="va">self</span>.modality_names],</span>
<span id="cb25-699"><a href="#cb25-699" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb25-700"><a href="#cb25-700" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-701"><a href="#cb25-701" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>), all_attn_weights</span>
<span id="cb25-702"><a href="#cb25-702" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-703"><a href="#cb25-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-704"><a href="#cb25-704" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison Experiment</span></span>
<span id="cb25-705"><a href="#cb25-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-706"><a href="#cb25-706" aria-hidden="true" tabindex="-1"></a>We now compare the three fusion architectures against unimodal baselines on forward quarterly return prediction for Vietnamese equities.</span>
<span id="cb25-707"><a href="#cb25-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-710"><a href="#cb25-710" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-711"><a href="#cb25-711" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: multimodal-dataset</span></span>
<span id="cb25-712"><a href="#cb25-712" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-713"><a href="#cb25-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-714"><a href="#cb25-714" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalFinanceDataset(Dataset):</span>
<span id="cb25-715"><a href="#cb25-715" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-716"><a href="#cb25-716" aria-hidden="true" tabindex="-1"></a><span class="co">    Dataset that aligns multiple modalities per firm-quarter.</span></span>
<span id="cb25-717"><a href="#cb25-717" aria-hidden="true" tabindex="-1"></a><span class="co">    Handles missing modalities with None values.</span></span>
<span id="cb25-718"><a href="#cb25-718" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-719"><a href="#cb25-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-720"><a href="#cb25-720" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tabular_df, text_embeddings, image_features,</span>
<span id="cb25-721"><a href="#cb25-721" aria-hidden="true" tabindex="-1"></a>                 ts_features, returns, tickers, dates):</span>
<span id="cb25-722"><a href="#cb25-722" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular <span class="op">=</span> tabular_df</span>
<span id="cb25-723"><a href="#cb25-723" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text <span class="op">=</span> text_embeddings</span>
<span id="cb25-724"><a href="#cb25-724" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image <span class="op">=</span> image_features</span>
<span id="cb25-725"><a href="#cb25-725" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ts <span class="op">=</span> ts_features</span>
<span id="cb25-726"><a href="#cb25-726" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.returns <span class="op">=</span> returns</span>
<span id="cb25-727"><a href="#cb25-727" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tickers <span class="op">=</span> tickers</span>
<span id="cb25-728"><a href="#cb25-728" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dates <span class="op">=</span> dates</span>
<span id="cb25-729"><a href="#cb25-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-730"><a href="#cb25-730" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb25-731"><a href="#cb25-731" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.returns)</span>
<span id="cb25-732"><a href="#cb25-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-733"><a href="#cb25-733" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb25-734"><a href="#cb25-734" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> {</span>
<span id="cb25-735"><a href="#cb25-735" aria-hidden="true" tabindex="-1"></a>            <span class="st">"tabular"</span>: torch.tensor(</span>
<span id="cb25-736"><a href="#cb25-736" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.tabular[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb25-737"><a href="#cb25-737" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.tabular[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb25-738"><a href="#cb25-738" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: torch.tensor(</span>
<span id="cb25-739"><a href="#cb25-739" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.text[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb25-740"><a href="#cb25-740" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.text[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb25-741"><a href="#cb25-741" aria-hidden="true" tabindex="-1"></a>            <span class="st">"image"</span>: torch.tensor(</span>
<span id="cb25-742"><a href="#cb25-742" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.image[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb25-743"><a href="#cb25-743" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.image[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb25-744"><a href="#cb25-744" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ts"</span>: torch.tensor(</span>
<span id="cb25-745"><a href="#cb25-745" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.ts[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb25-746"><a href="#cb25-746" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">if</span> <span class="va">self</span>.ts[idx] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb25-747"><a href="#cb25-747" aria-hidden="true" tabindex="-1"></a>            <span class="st">"return"</span>: torch.tensor(</span>
<span id="cb25-748"><a href="#cb25-748" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.returns[idx], dtype<span class="op">=</span>torch.float32</span>
<span id="cb25-749"><a href="#cb25-749" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb25-750"><a href="#cb25-750" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ticker"</span>: <span class="va">self</span>.tickers[idx],</span>
<span id="cb25-751"><a href="#cb25-751" aria-hidden="true" tabindex="-1"></a>            <span class="st">"date"</span>: <span class="va">self</span>.dates[idx]</span>
<span id="cb25-752"><a href="#cb25-752" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb25-753"><a href="#cb25-753" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample</span>
<span id="cb25-754"><a href="#cb25-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-755"><a href="#cb25-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-756"><a href="#cb25-756" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collate_multimodal(batch):</span>
<span id="cb25-757"><a href="#cb25-757" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Custom collate that handles None modalities."""</span></span>
<span id="cb25-758"><a href="#cb25-758" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> {<span class="st">"return"</span>: torch.stack([b[<span class="st">"return"</span>] <span class="cf">for</span> b <span class="kw">in</span> batch])}</span>
<span id="cb25-759"><a href="#cb25-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-760"><a href="#cb25-760" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mod <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]:</span>
<span id="cb25-761"><a href="#cb25-761" aria-hidden="true" tabindex="-1"></a>        values <span class="op">=</span> [b[mod] <span class="cf">for</span> b <span class="kw">in</span> batch]</span>
<span id="cb25-762"><a href="#cb25-762" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> values):</span>
<span id="cb25-763"><a href="#cb25-763" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> torch.stack(values)</span>
<span id="cb25-764"><a href="#cb25-764" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">any</span>(v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> values):</span>
<span id="cb25-765"><a href="#cb25-765" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fill None with zeros, matching shape of non-None entries</span></span>
<span id="cb25-766"><a href="#cb25-766" aria-hidden="true" tabindex="-1"></a>            ref <span class="op">=</span> <span class="bu">next</span>(v <span class="cf">for</span> v <span class="kw">in</span> values <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>)</span>
<span id="cb25-767"><a href="#cb25-767" aria-hidden="true" tabindex="-1"></a>            filled <span class="op">=</span> [v <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> torch.zeros_like(ref)</span>
<span id="cb25-768"><a href="#cb25-768" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">for</span> v <span class="kw">in</span> values]</span>
<span id="cb25-769"><a href="#cb25-769" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> torch.stack(filled)</span>
<span id="cb25-770"><a href="#cb25-770" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-771"><a href="#cb25-771" aria-hidden="true" tabindex="-1"></a>            result[mod] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-772"><a href="#cb25-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-773"><a href="#cb25-773" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb25-774"><a href="#cb25-774" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-775"><a href="#cb25-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-778"><a href="#cb25-778" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-779"><a href="#cb25-779" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prepare-aligned-data</span></span>
<span id="cb25-780"><a href="#cb25-780" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-781"><a href="#cb25-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-782"><a href="#cb25-782" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare aligned firm-quarter dataset</span></span>
<span id="cb25-783"><a href="#cb25-783" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Financial ratios (tabular)</span></span>
<span id="cb25-784"><a href="#cb25-784" aria-hidden="true" tabindex="-1"></a>tabular_features <span class="op">=</span> [</span>
<span id="cb25-785"><a href="#cb25-785" aria-hidden="true" tabindex="-1"></a>    <span class="st">"roe"</span>, <span class="st">"roa"</span>, <span class="st">"book_to_market"</span>, <span class="st">"log_size"</span>, <span class="st">"leverage"</span>,</span>
<span id="cb25-786"><a href="#cb25-786" aria-hidden="true" tabindex="-1"></a>    <span class="st">"asset_growth"</span>, <span class="st">"gross_profitability"</span>, <span class="st">"capex_to_assets"</span>,</span>
<span id="cb25-787"><a href="#cb25-787" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cash_to_assets"</span>, <span class="st">"dividend_yield"</span>, <span class="st">"sales_growth"</span>,</span>
<span id="cb25-788"><a href="#cb25-788" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accruals"</span>, <span class="st">"earnings_volatility"</span>, <span class="st">"beta"</span></span>
<span id="cb25-789"><a href="#cb25-789" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb25-790"><a href="#cb25-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-791"><a href="#cb25-791" aria-hidden="true" tabindex="-1"></a>financials[<span class="st">"quarter_date"</span>] <span class="op">=</span> pd.to_datetime(</span>
<span id="cb25-792"><a href="#cb25-792" aria-hidden="true" tabindex="-1"></a>    financials[<span class="st">"year"</span>].astype(<span class="bu">str</span>) <span class="op">+</span> <span class="st">"-"</span> <span class="op">+</span></span>
<span id="cb25-793"><a href="#cb25-793" aria-hidden="true" tabindex="-1"></a>    (financials[<span class="st">"quarter"</span>] <span class="op">*</span> <span class="dv">3</span>).astype(<span class="bu">str</span>).<span class="bu">str</span>.zfill(<span class="dv">2</span>) <span class="op">+</span> <span class="st">"-01"</span></span>
<span id="cb25-794"><a href="#cb25-794" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-795"><a href="#cb25-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-796"><a href="#cb25-796" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Text embeddings from PhoBERT</span></span>
<span id="cb25-797"><a href="#cb25-797" aria-hidden="true" tabindex="-1"></a><span class="co"># (Pre-computed in Chapter 60)</span></span>
<span id="cb25-798"><a href="#cb25-798" aria-hidden="true" tabindex="-1"></a>text_emb <span class="op">=</span> dc.get_text_embeddings(</span>
<span id="cb25-799"><a href="#cb25-799" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"phobert"</span>,</span>
<span id="cb25-800"><a href="#cb25-800" aria-hidden="true" tabindex="-1"></a>    section<span class="op">=</span><span class="st">"management_discussion"</span>,</span>
<span id="cb25-801"><a href="#cb25-801" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2014-01-01"</span>,</span>
<span id="cb25-802"><a href="#cb25-802" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb25-803"><a href="#cb25-803" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-804"><a href="#cb25-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-805"><a href="#cb25-805" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Image features (pre-computed in Chapter 61)</span></span>
<span id="cb25-806"><a href="#cb25-806" aria-hidden="true" tabindex="-1"></a><span class="co"># Satellite CNN features linked to firm headquarters province</span></span>
<span id="cb25-807"><a href="#cb25-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-808"><a href="#cb25-808" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Time series features (60-day window before quarter end)</span></span>
<span id="cb25-809"><a href="#cb25-809" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_ts_features(ticker, date, daily_df, lookback<span class="op">=</span><span class="dv">60</span>):</span>
<span id="cb25-810"><a href="#cb25-810" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract time-series feature tensor for a firm-quarter."""</span></span>
<span id="cb25-811"><a href="#cb25-811" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> (</span>
<span id="cb25-812"><a href="#cb25-812" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"ticker"</span>] <span class="op">==</span> ticker) <span class="op">&amp;</span></span>
<span id="cb25-813"><a href="#cb25-813" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"date"</span>] <span class="op">&lt;=</span> date) <span class="op">&amp;</span></span>
<span id="cb25-814"><a href="#cb25-814" aria-hidden="true" tabindex="-1"></a>        (daily_df[<span class="st">"date"</span>] <span class="op">&gt;=</span> date <span class="op">-</span> pd.Timedelta(days<span class="op">=</span>lookback <span class="op">*</span> <span class="fl">1.5</span>))</span>
<span id="cb25-815"><a href="#cb25-815" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-816"><a href="#cb25-816" aria-hidden="true" tabindex="-1"></a>    subset <span class="op">=</span> daily_df[mask].sort_values(<span class="st">"date"</span>).tail(lookback)</span>
<span id="cb25-817"><a href="#cb25-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-818"><a href="#cb25-818" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(subset) <span class="op">&lt;</span> lookback <span class="op">//</span> <span class="dv">2</span>:</span>
<span id="cb25-819"><a href="#cb25-819" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb25-820"><a href="#cb25-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-821"><a href="#cb25-821" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> subset[[<span class="st">"ret"</span>, <span class="st">"volume_log"</span>, <span class="st">"volatility_20d"</span>,</span>
<span id="cb25-822"><a href="#cb25-822" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"spread"</span>, <span class="st">"turnover"</span>]].values</span>
<span id="cb25-823"><a href="#cb25-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-824"><a href="#cb25-824" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pad if shorter than lookback</span></span>
<span id="cb25-825"><a href="#cb25-825" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(features) <span class="op">&lt;</span> lookback:</span>
<span id="cb25-826"><a href="#cb25-826" aria-hidden="true" tabindex="-1"></a>        padding <span class="op">=</span> np.zeros((lookback <span class="op">-</span> <span class="bu">len</span>(features), features.shape[<span class="dv">1</span>]))</span>
<span id="cb25-827"><a href="#cb25-827" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> np.vstack([padding, features])</span>
<span id="cb25-828"><a href="#cb25-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-829"><a href="#cb25-829" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features</span>
<span id="cb25-830"><a href="#cb25-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-831"><a href="#cb25-831" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Forward quarterly returns (target)</span></span>
<span id="cb25-832"><a href="#cb25-832" aria-hidden="true" tabindex="-1"></a><span class="co"># Align everything to quarter-end dates</span></span>
<span id="cb25-833"><a href="#cb25-833" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Preparing aligned multimodal dataset..."</span>)</span>
<span id="cb25-834"><a href="#cb25-834" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-835"><a href="#cb25-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-838"><a href="#cb25-838" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-839"><a href="#cb25-839" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: training-loop</span></span>
<span id="cb25-840"><a href="#cb25-840" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-841"><a href="#cb25-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-842"><a href="#cb25-842" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_multimodal_model(model, train_loader, val_loader,</span>
<span id="cb25-843"><a href="#cb25-843" aria-hidden="true" tabindex="-1"></a>                            n_epochs<span class="op">=</span><span class="dv">50</span>, lr<span class="op">=</span><span class="fl">1e-3</span>, patience<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb25-844"><a href="#cb25-844" aria-hidden="true" tabindex="-1"></a>                            alignment_weight<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb25-845"><a href="#cb25-845" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-846"><a href="#cb25-846" aria-hidden="true" tabindex="-1"></a><span class="co">    Train a multimodal model with early stopping.</span></span>
<span id="cb25-847"><a href="#cb25-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-848"><a href="#cb25-848" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb25-849"><a href="#cb25-849" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb25-850"><a href="#cb25-850" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb25-851"><a href="#cb25-851" aria-hidden="true" tabindex="-1"></a><span class="co">        Multimodal fusion model.</span></span>
<span id="cb25-852"><a href="#cb25-852" aria-hidden="true" tabindex="-1"></a><span class="co">    alignment_weight : float</span></span>
<span id="cb25-853"><a href="#cb25-853" aria-hidden="true" tabindex="-1"></a><span class="co">        Weight for modality alignment loss (0 = no alignment).</span></span>
<span id="cb25-854"><a href="#cb25-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-855"><a href="#cb25-855" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb25-856"><a href="#cb25-856" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb25-857"><a href="#cb25-857" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : Training history and best validation metrics.</span></span>
<span id="cb25-858"><a href="#cb25-858" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-859"><a href="#cb25-859" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr,</span>
<span id="cb25-860"><a href="#cb25-860" aria-hidden="true" tabindex="-1"></a>                                   weight_decay<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb25-861"><a href="#cb25-861" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> torch.optim.lr_scheduler.ReduceLROnPlateau(</span>
<span id="cb25-862"><a href="#cb25-862" aria-hidden="true" tabindex="-1"></a>        optimizer, mode<span class="op">=</span><span class="st">"min"</span>, patience<span class="op">=</span><span class="dv">5</span>, factor<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb25-863"><a href="#cb25-863" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-864"><a href="#cb25-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-865"><a href="#cb25-865" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb25-866"><a href="#cb25-866" aria-hidden="true" tabindex="-1"></a>    epochs_no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-867"><a href="#cb25-867" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">"train_loss"</span>: [], <span class="st">"val_loss"</span>: [], <span class="st">"val_r2"</span>: []}</span>
<span id="cb25-868"><a href="#cb25-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-869"><a href="#cb25-869" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb25-870"><a href="#cb25-870" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training</span></span>
<span id="cb25-871"><a href="#cb25-871" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb25-872"><a href="#cb25-872" aria-hidden="true" tabindex="-1"></a>        train_losses <span class="op">=</span> []</span>
<span id="cb25-873"><a href="#cb25-873" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb25-874"><a href="#cb25-874" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb25-875"><a href="#cb25-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-876"><a href="#cb25-876" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {k: batch[k] <span class="cf">for</span> k <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]}</span>
<span id="cb25-877"><a href="#cb25-877" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb25-878"><a href="#cb25-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-879"><a href="#cb25-879" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass (handle both output types)</span></span>
<span id="cb25-880"><a href="#cb25-880" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(inputs)</span>
<span id="cb25-881"><a href="#cb25-881" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>):</span>
<span id="cb25-882"><a href="#cb25-882" aria-hidden="true" tabindex="-1"></a>                predictions, attn_weights <span class="op">=</span> output</span>
<span id="cb25-883"><a href="#cb25-883" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-884"><a href="#cb25-884" aria-hidden="true" tabindex="-1"></a>                predictions <span class="op">=</span> output</span>
<span id="cb25-885"><a href="#cb25-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-886"><a href="#cb25-886" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.mse_loss(predictions, targets)</span>
<span id="cb25-887"><a href="#cb25-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-888"><a href="#cb25-888" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Optional alignment loss</span></span>
<span id="cb25-889"><a href="#cb25-889" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> alignment_weight <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> <span class="bu">hasattr</span>(model, <span class="st">"projector"</span>):</span>
<span id="cb25-890"><a href="#cb25-890" aria-hidden="true" tabindex="-1"></a>                embeddings <span class="op">=</span> model.projector(inputs)</span>
<span id="cb25-891"><a href="#cb25-891" aria-hidden="true" tabindex="-1"></a>                align_loss <span class="op">=</span> model.projector.compute_alignment_loss(embeddings)</span>
<span id="cb25-892"><a href="#cb25-892" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss <span class="op">+</span> alignment_weight <span class="op">*</span> align_loss</span>
<span id="cb25-893"><a href="#cb25-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-894"><a href="#cb25-894" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb25-895"><a href="#cb25-895" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb25-896"><a href="#cb25-896" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb25-897"><a href="#cb25-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-898"><a href="#cb25-898" aria-hidden="true" tabindex="-1"></a>            train_losses.append(loss.item())</span>
<span id="cb25-899"><a href="#cb25-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-900"><a href="#cb25-900" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation</span></span>
<span id="cb25-901"><a href="#cb25-901" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb25-902"><a href="#cb25-902" aria-hidden="true" tabindex="-1"></a>        val_preds, val_targets <span class="op">=</span> [], []</span>
<span id="cb25-903"><a href="#cb25-903" aria-hidden="true" tabindex="-1"></a>        val_losses <span class="op">=</span> []</span>
<span id="cb25-904"><a href="#cb25-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-905"><a href="#cb25-905" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-906"><a href="#cb25-906" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> val_loader:</span>
<span id="cb25-907"><a href="#cb25-907" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> {k: batch[k]</span>
<span id="cb25-908"><a href="#cb25-908" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> k <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]}</span>
<span id="cb25-909"><a href="#cb25-909" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb25-910"><a href="#cb25-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-911"><a href="#cb25-911" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> model(inputs)</span>
<span id="cb25-912"><a href="#cb25-912" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>):</span>
<span id="cb25-913"><a href="#cb25-913" aria-hidden="true" tabindex="-1"></a>                    predictions, _ <span class="op">=</span> output</span>
<span id="cb25-914"><a href="#cb25-914" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb25-915"><a href="#cb25-915" aria-hidden="true" tabindex="-1"></a>                    predictions <span class="op">=</span> output</span>
<span id="cb25-916"><a href="#cb25-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-917"><a href="#cb25-917" aria-hidden="true" tabindex="-1"></a>                val_losses.append(F.mse_loss(predictions, targets).item())</span>
<span id="cb25-918"><a href="#cb25-918" aria-hidden="true" tabindex="-1"></a>                val_preds.extend(predictions.cpu().numpy())</span>
<span id="cb25-919"><a href="#cb25-919" aria-hidden="true" tabindex="-1"></a>                val_targets.extend(targets.cpu().numpy())</span>
<span id="cb25-920"><a href="#cb25-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-921"><a href="#cb25-921" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> np.mean(val_losses)</span>
<span id="cb25-922"><a href="#cb25-922" aria-hidden="true" tabindex="-1"></a>        val_r2 <span class="op">=</span> r2_score(val_targets, val_preds) <span class="cf">if</span> <span class="bu">len</span>(val_preds) <span class="op">&gt;</span> <span class="dv">10</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb25-923"><a href="#cb25-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-924"><a href="#cb25-924" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"train_loss"</span>].append(np.mean(train_losses))</span>
<span id="cb25-925"><a href="#cb25-925" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"val_loss"</span>].append(val_loss)</span>
<span id="cb25-926"><a href="#cb25-926" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">"val_r2"</span>].append(val_r2)</span>
<span id="cb25-927"><a href="#cb25-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-928"><a href="#cb25-928" aria-hidden="true" tabindex="-1"></a>        scheduler.step(val_loss)</span>
<span id="cb25-929"><a href="#cb25-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-930"><a href="#cb25-930" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early stopping</span></span>
<span id="cb25-931"><a href="#cb25-931" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb25-932"><a href="#cb25-932" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb25-933"><a href="#cb25-933" aria-hidden="true" tabindex="-1"></a>            best_state <span class="op">=</span> {k: v.cpu().clone()</span>
<span id="cb25-934"><a href="#cb25-934" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">for</span> k, v <span class="kw">in</span> model.state_dict().items()}</span>
<span id="cb25-935"><a href="#cb25-935" aria-hidden="true" tabindex="-1"></a>            epochs_no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-936"><a href="#cb25-936" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-937"><a href="#cb25-937" aria-hidden="true" tabindex="-1"></a>            epochs_no_improve <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb25-938"><a href="#cb25-938" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> epochs_no_improve <span class="op">&gt;=</span> patience:</span>
<span id="cb25-939"><a href="#cb25-939" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb25-940"><a href="#cb25-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-941"><a href="#cb25-941" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Restore best model</span></span>
<span id="cb25-942"><a href="#cb25-942" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_state)</span>
<span id="cb25-943"><a href="#cb25-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-944"><a href="#cb25-944" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb25-945"><a href="#cb25-945" aria-hidden="true" tabindex="-1"></a>        <span class="st">"history"</span>: history,</span>
<span id="cb25-946"><a href="#cb25-946" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_val_loss"</span>: best_val_loss,</span>
<span id="cb25-947"><a href="#cb25-947" aria-hidden="true" tabindex="-1"></a>        <span class="st">"best_val_r2"</span>: <span class="bu">max</span>(history[<span class="st">"val_r2"</span>]),</span>
<span id="cb25-948"><a href="#cb25-948" aria-hidden="true" tabindex="-1"></a>        <span class="st">"epochs_trained"</span>: <span class="bu">len</span>(history[<span class="st">"train_loss"</span>])</span>
<span id="cb25-949"><a href="#cb25-949" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-950"><a href="#cb25-950" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-951"><a href="#cb25-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-954"><a href="#cb25-954" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-955"><a href="#cb25-955" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: model-comparison</span></span>
<span id="cb25-956"><a href="#cb25-956" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-957"><a href="#cb25-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-958"><a href="#cb25-958" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_fusion_strategies(dataset, n_splits<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb25-959"><a href="#cb25-959" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-960"><a href="#cb25-960" aria-hidden="true" tabindex="-1"></a><span class="co">    Compare unimodal baselines and multimodal fusion strategies</span></span>
<span id="cb25-961"><a href="#cb25-961" aria-hidden="true" tabindex="-1"></a><span class="co">    using expanding-window time-series cross-validation.</span></span>
<span id="cb25-962"><a href="#cb25-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-963"><a href="#cb25-963" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb25-964"><a href="#cb25-964" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb25-965"><a href="#cb25-965" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame : Out-of-sample R², MSE, IC for each model.</span></span>
<span id="cb25-966"><a href="#cb25-966" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-967"><a href="#cb25-967" aria-hidden="true" tabindex="-1"></a>    tscv <span class="op">=</span> TimeSeriesSplit(n_splits<span class="op">=</span>n_splits)</span>
<span id="cb25-968"><a href="#cb25-968" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb25-969"><a href="#cb25-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-970"><a href="#cb25-970" aria-hidden="true" tabindex="-1"></a>    enc_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb25-971"><a href="#cb25-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-972"><a href="#cb25-972" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold, (train_idx, test_idx) <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb25-973"><a href="#cb25-973" aria-hidden="true" tabindex="-1"></a>        tscv.split(<span class="bu">range</span>(<span class="bu">len</span>(dataset)))</span>
<span id="cb25-974"><a href="#cb25-974" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb25-975"><a href="#cb25-975" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create data loaders</span></span>
<span id="cb25-976"><a href="#cb25-976" aria-hidden="true" tabindex="-1"></a>        train_subset <span class="op">=</span> torch.utils.data.Subset(dataset, train_idx)</span>
<span id="cb25-977"><a href="#cb25-977" aria-hidden="true" tabindex="-1"></a>        test_subset <span class="op">=</span> torch.utils.data.Subset(dataset, test_idx)</span>
<span id="cb25-978"><a href="#cb25-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-979"><a href="#cb25-979" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb25-980"><a href="#cb25-980" aria-hidden="true" tabindex="-1"></a>            train_subset, batch_size<span class="op">=</span><span class="dv">128</span>, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-981"><a href="#cb25-981" aria-hidden="true" tabindex="-1"></a>            collate_fn<span class="op">=</span>collate_multimodal</span>
<span id="cb25-982"><a href="#cb25-982" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-983"><a href="#cb25-983" aria-hidden="true" tabindex="-1"></a>        test_loader <span class="op">=</span> DataLoader(</span>
<span id="cb25-984"><a href="#cb25-984" aria-hidden="true" tabindex="-1"></a>            test_subset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb25-985"><a href="#cb25-985" aria-hidden="true" tabindex="-1"></a>            collate_fn<span class="op">=</span>collate_multimodal</span>
<span id="cb25-986"><a href="#cb25-986" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-987"><a href="#cb25-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-988"><a href="#cb25-988" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define encoders</span></span>
<span id="cb25-989"><a href="#cb25-989" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> make_encoders():</span>
<span id="cb25-990"><a href="#cb25-990" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb25-991"><a href="#cb25-991" aria-hidden="true" tabindex="-1"></a>                <span class="st">"tabular"</span>: TabularEncoder(<span class="bu">len</span>(tabular_features), <span class="dv">128</span>, enc_dim),</span>
<span id="cb25-992"><a href="#cb25-992" aria-hidden="true" tabindex="-1"></a>                <span class="st">"text"</span>: TextEncoder(<span class="dv">768</span>, enc_dim),</span>
<span id="cb25-993"><a href="#cb25-993" aria-hidden="true" tabindex="-1"></a>                <span class="st">"image"</span>: ImageEncoder(<span class="dv">2048</span>, enc_dim),</span>
<span id="cb25-994"><a href="#cb25-994" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ts"</span>: TimeSeriesEncoder(<span class="dv">5</span>, <span class="dv">60</span>, enc_dim)</span>
<span id="cb25-995"><a href="#cb25-995" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-996"><a href="#cb25-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-997"><a href="#cb25-997" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unimodal baselines</span></span>
<span id="cb25-998"><a href="#cb25-998" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> mod_name <span class="kw">in</span> [<span class="st">"tabular"</span>, <span class="st">"text"</span>, <span class="st">"image"</span>, <span class="st">"ts"</span>]:</span>
<span id="cb25-999"><a href="#cb25-999" aria-hidden="true" tabindex="-1"></a>            single_encoder <span class="op">=</span> {mod_name: make_encoders()[mod_name]}</span>
<span id="cb25-1000"><a href="#cb25-1000" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> EarlyFusionModel(single_encoder, enc_dim, <span class="dv">1</span>)</span>
<span id="cb25-1001"><a href="#cb25-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1002"><a href="#cb25-1002" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb25-1003"><a href="#cb25-1003" aria-hidden="true" tabindex="-1"></a>                model, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb25-1004"><a href="#cb25-1004" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1005"><a href="#cb25-1005" aria-hidden="true" tabindex="-1"></a>            results.append({</span>
<span id="cb25-1006"><a href="#cb25-1006" aria-hidden="true" tabindex="-1"></a>                <span class="st">"fold"</span>: fold,</span>
<span id="cb25-1007"><a href="#cb25-1007" aria-hidden="true" tabindex="-1"></a>                <span class="st">"model"</span>: <span class="ss">f"Unimodal (</span><span class="sc">{</span>mod_name<span class="sc">}</span><span class="ss">)"</span>,</span>
<span id="cb25-1008"><a href="#cb25-1008" aria-hidden="true" tabindex="-1"></a>                <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb25-1009"><a href="#cb25-1009" aria-hidden="true" tabindex="-1"></a>                <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb25-1010"><a href="#cb25-1010" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb25-1011"><a href="#cb25-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1012"><a href="#cb25-1012" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Early Fusion</span></span>
<span id="cb25-1013"><a href="#cb25-1013" aria-hidden="true" tabindex="-1"></a>        model_early <span class="op">=</span> EarlyFusionModel(make_encoders(), enc_dim <span class="op">*</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb25-1014"><a href="#cb25-1014" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb25-1015"><a href="#cb25-1015" aria-hidden="true" tabindex="-1"></a>            model_early, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb25-1016"><a href="#cb25-1016" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1017"><a href="#cb25-1017" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb25-1018"><a href="#cb25-1018" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb25-1019"><a href="#cb25-1019" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Early Fusion"</span>,</span>
<span id="cb25-1020"><a href="#cb25-1020" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb25-1021"><a href="#cb25-1021" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb25-1022"><a href="#cb25-1022" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1023"><a href="#cb25-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1024"><a href="#cb25-1024" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Late Fusion (gating)</span></span>
<span id="cb25-1025"><a href="#cb25-1025" aria-hidden="true" tabindex="-1"></a>        model_late <span class="op">=</span> LateFusionModel(</span>
<span id="cb25-1026"><a href="#cb25-1026" aria-hidden="true" tabindex="-1"></a>            make_encoders(), enc_dim, combination<span class="op">=</span><span class="st">"gating"</span></span>
<span id="cb25-1027"><a href="#cb25-1027" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1028"><a href="#cb25-1028" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb25-1029"><a href="#cb25-1029" aria-hidden="true" tabindex="-1"></a>            model_late, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb25-1030"><a href="#cb25-1030" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1031"><a href="#cb25-1031" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb25-1032"><a href="#cb25-1032" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb25-1033"><a href="#cb25-1033" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Late Fusion (Gating)"</span>,</span>
<span id="cb25-1034"><a href="#cb25-1034" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb25-1035"><a href="#cb25-1035" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb25-1036"><a href="#cb25-1036" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1037"><a href="#cb25-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1038"><a href="#cb25-1038" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multimodal: Cross-Attention</span></span>
<span id="cb25-1039"><a href="#cb25-1039" aria-hidden="true" tabindex="-1"></a>        model_ca <span class="op">=</span> CrossAttentionFusionModel(</span>
<span id="cb25-1040"><a href="#cb25-1040" aria-hidden="true" tabindex="-1"></a>            make_encoders(), enc_dim, n_layers<span class="op">=</span><span class="dv">2</span>, n_heads<span class="op">=</span><span class="dv">4</span></span>
<span id="cb25-1041"><a href="#cb25-1041" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1042"><a href="#cb25-1042" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> train_multimodal_model(</span>
<span id="cb25-1043"><a href="#cb25-1043" aria-hidden="true" tabindex="-1"></a>            model_ca, train_loader, test_loader, n_epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb25-1044"><a href="#cb25-1044" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1045"><a href="#cb25-1045" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb25-1046"><a href="#cb25-1046" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fold"</span>: fold,</span>
<span id="cb25-1047"><a href="#cb25-1047" aria-hidden="true" tabindex="-1"></a>            <span class="st">"model"</span>: <span class="st">"Cross-Attention Fusion"</span>,</span>
<span id="cb25-1048"><a href="#cb25-1048" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_r2"</span>: result[<span class="st">"best_val_r2"</span>],</span>
<span id="cb25-1049"><a href="#cb25-1049" aria-hidden="true" tabindex="-1"></a>            <span class="st">"val_loss"</span>: result[<span class="st">"best_val_loss"</span>]</span>
<span id="cb25-1050"><a href="#cb25-1050" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1051"><a href="#cb25-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1052"><a href="#cb25-1052" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span>
<span id="cb25-1053"><a href="#cb25-1053" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1054"><a href="#cb25-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1057"><a href="#cb25-1057" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1058"><a href="#cb25-1058" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-fusion-comparison</span></span>
<span id="cb25-1059"><a href="#cb25-1059" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1060"><a href="#cb25-1060" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Out-of-Sample Return Prediction: Unimodal vs. Multimodal"</span></span>
<span id="cb25-1061"><a href="#cb25-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1062"><a href="#cb25-1062" aria-hidden="true" tabindex="-1"></a><span class="co"># results_df = compare_fusion_strategies(dataset)</span></span>
<span id="cb25-1063"><a href="#cb25-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1064"><a href="#cb25-1064" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate across folds</span></span>
<span id="cb25-1065"><a href="#cb25-1065" aria-hidden="true" tabindex="-1"></a><span class="co"># summary = (</span></span>
<span id="cb25-1066"><a href="#cb25-1066" aria-hidden="true" tabindex="-1"></a><span class="co">#     results_df.groupby("model")</span></span>
<span id="cb25-1067"><a href="#cb25-1067" aria-hidden="true" tabindex="-1"></a><span class="co">#     .agg(</span></span>
<span id="cb25-1068"><a href="#cb25-1068" aria-hidden="true" tabindex="-1"></a><span class="co">#         mean_r2=("val_r2", "mean"),</span></span>
<span id="cb25-1069"><a href="#cb25-1069" aria-hidden="true" tabindex="-1"></a><span class="co">#         std_r2=("val_r2", "std"),</span></span>
<span id="cb25-1070"><a href="#cb25-1070" aria-hidden="true" tabindex="-1"></a><span class="co">#         mean_loss=("val_loss", "mean")</span></span>
<span id="cb25-1071"><a href="#cb25-1071" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb25-1072"><a href="#cb25-1072" aria-hidden="true" tabindex="-1"></a><span class="co">#     .sort_values("mean_r2", ascending=False)</span></span>
<span id="cb25-1073"><a href="#cb25-1073" aria-hidden="true" tabindex="-1"></a><span class="co">#     .round(4)</span></span>
<span id="cb25-1074"><a href="#cb25-1074" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb25-1075"><a href="#cb25-1075" aria-hidden="true" tabindex="-1"></a><span class="co"># summary</span></span>
<span id="cb25-1076"><a href="#cb25-1076" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1077"><a href="#cb25-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1080"><a href="#cb25-1080" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1081"><a href="#cb25-1081" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-fusion-comparison</span></span>
<span id="cb25-1082"><a href="#cb25-1082" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1083"><a href="#cb25-1083" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Out-of-Sample R² Across Fusion Strategies and Time-Series Folds"</span></span>
<span id="cb25-1084"><a href="#cb25-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1085"><a href="#cb25-1085" aria-hidden="true" tabindex="-1"></a><span class="co"># (</span></span>
<span id="cb25-1086"><a href="#cb25-1086" aria-hidden="true" tabindex="-1"></a><span class="co">#     p9.ggplot(results_df, p9.aes(x="model", y="val_r2", fill="model"))</span></span>
<span id="cb25-1087"><a href="#cb25-1087" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.geom_boxplot(alpha=0.7)</span></span>
<span id="cb25-1088"><a href="#cb25-1088" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.coord_flip()</span></span>
<span id="cb25-1089"><a href="#cb25-1089" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.labs(</span></span>
<span id="cb25-1090"><a href="#cb25-1090" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="", y="Out-of-Sample R²",</span></span>
<span id="cb25-1091"><a href="#cb25-1091" aria-hidden="true" tabindex="-1"></a><span class="co">#         title="Multimodal Fusion Improves Return Prediction"</span></span>
<span id="cb25-1092"><a href="#cb25-1092" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb25-1093"><a href="#cb25-1093" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme_minimal()</span></span>
<span id="cb25-1094"><a href="#cb25-1094" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme(figure_size=(10, 6), legend_position="none")</span></span>
<span id="cb25-1095"><a href="#cb25-1095" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb25-1096"><a href="#cb25-1096" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1097"><a href="#cb25-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1098"><a href="#cb25-1098" aria-hidden="true" tabindex="-1"></a><span class="fu">## Handling Missing Modalities</span></span>
<span id="cb25-1099"><a href="#cb25-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1100"><a href="#cb25-1100" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Missing Modality Problem</span></span>
<span id="cb25-1101"><a href="#cb25-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1102"><a href="#cb25-1102" aria-hidden="true" tabindex="-1"></a>In practice, not every firm-quarter has every modality available. A firm may not have an earnings call transcript (no audio), its headquarters may be in a province where satellite coverage is intermittent (no image), or its annual report may not be publicly available in digital form (no text). This creates a missing modality problem that is structurally different from missing values in tabular data: an entire feature vector (hundreds or thousands of dimensions) is absent.</span>
<span id="cb25-1103"><a href="#cb25-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1104"><a href="#cb25-1104" aria-hidden="true" tabindex="-1"></a>The fraction of observations with all four modalities available is typically much smaller than the fraction with at least one:</span>
<span id="cb25-1105"><a href="#cb25-1105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1106"><a href="#cb25-1106" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Available Modalities     <span class="pp">|</span> Typical Coverage (Vietnamese Firms) <span class="pp">|</span></span>
<span id="cb25-1107"><a href="#cb25-1107" aria-hidden="true" tabindex="-1"></a><span class="pp">|--------------------------|-------------------------------------|</span></span>
<span id="cb25-1108"><a href="#cb25-1108" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Tabular only             <span class="pp">|</span> $\sim$ 95% of firm-quarters         <span class="pp">|</span></span>
<span id="cb25-1109"><a href="#cb25-1109" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Tabular + Text           <span class="pp">|</span> $\sim$ 70%                          <span class="pp">|</span></span>
<span id="cb25-1110"><a href="#cb25-1110" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Tabular + Text + Image   <span class="pp">|</span> $\sim$ 50%                          <span class="pp">|</span></span>
<span id="cb25-1111"><a href="#cb25-1111" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> All four (+ time series) <span class="pp">|</span> $\sim$ 45%                          <span class="pp">|</span></span>
<span id="cb25-1112"><a href="#cb25-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1113"><a href="#cb25-1113" aria-hidden="true" tabindex="-1"></a>: Modality Availability in Vietnamese Market Data {#tbl-modality-coverage}</span>
<span id="cb25-1114"><a href="#cb25-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1115"><a href="#cb25-1115" aria-hidden="true" tabindex="-1"></a>Restricting the sample to complete cases discards half the data and introduces selection bias (larger, more transparent firms are overrepresented). We need architectures that degrade gracefully when modalities are missing.</span>
<span id="cb25-1116"><a href="#cb25-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1117"><a href="#cb25-1117" aria-hidden="true" tabindex="-1"></a><span class="fu">### Strategies for Missing Modalities</span></span>
<span id="cb25-1118"><a href="#cb25-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1119"><a href="#cb25-1119" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Zero imputation.** Replace missing modality embeddings with zeros. Simple but introduces bias: the model cannot distinguish "this modality is absent" from "this modality has zero signal."</span>
<span id="cb25-1120"><a href="#cb25-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1121"><a href="#cb25-1121" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Learned default embedding.** Replace missing modalities with a learnable "default" vector $\mathbf{d}^{(m)}$ that is trained alongside the model. This allows the model to learn what the absence of a modality implies.</span>
<span id="cb25-1122"><a href="#cb25-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1123"><a href="#cb25-1123" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Modality dropout.** During training, randomly drop entire modalities with probability $p$ (analogous to dropout on neurons). This forces the model to perform well even when modalities are missing, and acts as regularization.</span>
<span id="cb25-1124"><a href="#cb25-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1125"><a href="#cb25-1125" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Mixture of Experts (MoE).** Route each observation to a fusion subnetwork specialized for its available modality combination. With $M$ modalities, there are $2^M - 1$ possible subsets, requiring efficient parameter sharing.</span>
<span id="cb25-1126"><a href="#cb25-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1129"><a href="#cb25-1129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1130"><a href="#cb25-1130" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: missing-modality-handler</span></span>
<span id="cb25-1131"><a href="#cb25-1131" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1132"><a href="#cb25-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1133"><a href="#cb25-1133" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModalityDropout(nn.Module):</span>
<span id="cb25-1134"><a href="#cb25-1134" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1135"><a href="#cb25-1135" aria-hidden="true" tabindex="-1"></a><span class="co">    Randomly drop entire modalities during training.</span></span>
<span id="cb25-1136"><a href="#cb25-1136" aria-hidden="true" tabindex="-1"></a><span class="co">    Forces robustness to missing inputs at test time.</span></span>
<span id="cb25-1137"><a href="#cb25-1137" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1138"><a href="#cb25-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1139"><a href="#cb25-1139" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb25-1140"><a href="#cb25-1140" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-1141"><a href="#cb25-1141" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.drop_prob <span class="op">=</span> drop_prob</span>
<span id="cb25-1142"><a href="#cb25-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1143"><a href="#cb25-1143" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, modality_inputs):</span>
<span id="cb25-1144"><a href="#cb25-1144" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.training:</span>
<span id="cb25-1145"><a href="#cb25-1145" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> modality_inputs</span>
<span id="cb25-1146"><a href="#cb25-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1147"><a href="#cb25-1147" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {}</span>
<span id="cb25-1148"><a href="#cb25-1148" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, tensor <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb25-1149"><a href="#cb25-1149" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> tensor <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> torch.rand(<span class="dv">1</span>).item() <span class="op">&gt;</span> <span class="va">self</span>.drop_prob:</span>
<span id="cb25-1150"><a href="#cb25-1150" aria-hidden="true" tabindex="-1"></a>                result[name] <span class="op">=</span> tensor</span>
<span id="cb25-1151"><a href="#cb25-1151" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-1152"><a href="#cb25-1152" aria-hidden="true" tabindex="-1"></a>                result[name] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-1153"><a href="#cb25-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1154"><a href="#cb25-1154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure at least one modality remains</span></span>
<span id="cb25-1155"><a href="#cb25-1155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(v <span class="kw">is</span> <span class="va">None</span> <span class="cf">for</span> v <span class="kw">in</span> result.values()):</span>
<span id="cb25-1156"><a href="#cb25-1156" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Keep the first available modality</span></span>
<span id="cb25-1157"><a href="#cb25-1157" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name, tensor <span class="kw">in</span> modality_inputs.items():</span>
<span id="cb25-1158"><a href="#cb25-1158" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> tensor <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1159"><a href="#cb25-1159" aria-hidden="true" tabindex="-1"></a>                    result[name] <span class="op">=</span> tensor</span>
<span id="cb25-1160"><a href="#cb25-1160" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb25-1161"><a href="#cb25-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1162"><a href="#cb25-1162" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb25-1163"><a href="#cb25-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1164"><a href="#cb25-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1165"><a href="#cb25-1165" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RobustFusionModel(nn.Module):</span>
<span id="cb25-1166"><a href="#cb25-1166" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1167"><a href="#cb25-1167" aria-hidden="true" tabindex="-1"></a><span class="co">    Multimodal model robust to missing modalities.</span></span>
<span id="cb25-1168"><a href="#cb25-1168" aria-hidden="true" tabindex="-1"></a><span class="co">    Uses learned default embeddings and modality dropout.</span></span>
<span id="cb25-1169"><a href="#cb25-1169" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1170"><a href="#cb25-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1171"><a href="#cb25-1171" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoders, enc_dim<span class="op">=</span><span class="dv">64</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb25-1172"><a href="#cb25-1172" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-1173"><a href="#cb25-1173" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoders <span class="op">=</span> nn.ModuleDict(encoders)</span>
<span id="cb25-1174"><a href="#cb25-1174" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_names <span class="op">=</span> <span class="bu">list</span>(encoders.keys())</span>
<span id="cb25-1175"><a href="#cb25-1175" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_modalities <span class="op">=</span> <span class="bu">len</span>(encoders)</span>
<span id="cb25-1176"><a href="#cb25-1176" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_dim <span class="op">=</span> enc_dim</span>
<span id="cb25-1177"><a href="#cb25-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1178"><a href="#cb25-1178" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Learned default embeddings for missing modalities</span></span>
<span id="cb25-1179"><a href="#cb25-1179" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.defaults <span class="op">=</span> nn.ParameterDict({</span>
<span id="cb25-1180"><a href="#cb25-1180" aria-hidden="true" tabindex="-1"></a>            name: nn.Parameter(torch.randn(enc_dim) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb25-1181"><a href="#cb25-1181" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> name <span class="kw">in</span> encoders</span>
<span id="cb25-1182"><a href="#cb25-1182" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1183"><a href="#cb25-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1184"><a href="#cb25-1184" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality presence indicator embedding</span></span>
<span id="cb25-1185"><a href="#cb25-1185" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.presence_proj <span class="op">=</span> nn.Linear(<span class="va">self</span>.n_modalities, enc_dim)</span>
<span id="cb25-1186"><a href="#cb25-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1187"><a href="#cb25-1187" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality dropout</span></span>
<span id="cb25-1188"><a href="#cb25-1188" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mod_dropout <span class="op">=</span> ModalityDropout(drop_prob)</span>
<span id="cb25-1189"><a href="#cb25-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1190"><a href="#cb25-1190" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Attention-based aggregation</span></span>
<span id="cb25-1191"><a href="#cb25-1191" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn_pool <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-1192"><a href="#cb25-1192" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>),</span>
<span id="cb25-1193"><a href="#cb25-1193" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1194"><a href="#cb25-1194" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1195"><a href="#cb25-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1196"><a href="#cb25-1196" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb25-1197"><a href="#cb25-1197" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-1198"><a href="#cb25-1198" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim <span class="op">*</span> <span class="dv">2</span>, enc_dim),</span>
<span id="cb25-1199"><a href="#cb25-1199" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(enc_dim),</span>
<span id="cb25-1200"><a href="#cb25-1200" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb25-1201"><a href="#cb25-1201" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb25-1202"><a href="#cb25-1202" aria-hidden="true" tabindex="-1"></a>            nn.Linear(enc_dim, <span class="dv">1</span>)</span>
<span id="cb25-1203"><a href="#cb25-1203" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1204"><a href="#cb25-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1205"><a href="#cb25-1205" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb25-1206"><a href="#cb25-1206" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply modality dropout during training</span></span>
<span id="cb25-1207"><a href="#cb25-1207" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">self</span>.mod_dropout(inputs)</span>
<span id="cb25-1208"><a href="#cb25-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1209"><a href="#cb25-1209" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb25-1210"><a href="#cb25-1210" aria-hidden="true" tabindex="-1"></a>        presence <span class="op">=</span> []</span>
<span id="cb25-1211"><a href="#cb25-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1212"><a href="#cb25-1212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name <span class="kw">in</span> <span class="va">self</span>.modality_names:</span>
<span id="cb25-1213"><a href="#cb25-1213" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> name <span class="kw">in</span> inputs <span class="kw">and</span> inputs[name] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1214"><a href="#cb25-1214" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> <span class="va">self</span>.encoders[name](inputs[name])</span>
<span id="cb25-1215"><a href="#cb25-1215" aria-hidden="true" tabindex="-1"></a>                embeddings.append(emb)</span>
<span id="cb25-1216"><a href="#cb25-1216" aria-hidden="true" tabindex="-1"></a>                presence.append(<span class="fl">1.0</span>)</span>
<span id="cb25-1217"><a href="#cb25-1217" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-1218"><a href="#cb25-1218" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> <span class="bu">next</span>(</span>
<span id="cb25-1219"><a href="#cb25-1219" aria-hidden="true" tabindex="-1"></a>                    v.shape[<span class="dv">0</span>] <span class="cf">for</span> v <span class="kw">in</span> inputs.values()</span>
<span id="cb25-1220"><a href="#cb25-1220" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb25-1221"><a href="#cb25-1221" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-1222"><a href="#cb25-1222" aria-hidden="true" tabindex="-1"></a>                emb <span class="op">=</span> <span class="va">self</span>.defaults[name].unsqueeze(<span class="dv">0</span>).expand(</span>
<span id="cb25-1223"><a href="#cb25-1223" aria-hidden="true" tabindex="-1"></a>                    batch_size, <span class="op">-</span><span class="dv">1</span></span>
<span id="cb25-1224"><a href="#cb25-1224" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-1225"><a href="#cb25-1225" aria-hidden="true" tabindex="-1"></a>                embeddings.append(emb)</span>
<span id="cb25-1226"><a href="#cb25-1226" aria-hidden="true" tabindex="-1"></a>                presence.append(<span class="fl">0.0</span>)</span>
<span id="cb25-1227"><a href="#cb25-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1228"><a href="#cb25-1228" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stack: (n_modalities, batch, enc_dim)</span></span>
<span id="cb25-1229"><a href="#cb25-1229" aria-hidden="true" tabindex="-1"></a>        emb_stack <span class="op">=</span> torch.stack(embeddings, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1230"><a href="#cb25-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1231"><a href="#cb25-1231" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Attention-weighted aggregation</span></span>
<span id="cb25-1232"><a href="#cb25-1232" aria-hidden="true" tabindex="-1"></a>        attn_weights <span class="op">=</span> <span class="va">self</span>.attn_pool(emb_stack)  <span class="co"># (n_mod, batch, 1)</span></span>
<span id="cb25-1233"><a href="#cb25-1233" aria-hidden="true" tabindex="-1"></a>        aggregated <span class="op">=</span> (emb_stack <span class="op">*</span> attn_weights).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>)  <span class="co"># (batch, enc_dim)</span></span>
<span id="cb25-1234"><a href="#cb25-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1235"><a href="#cb25-1235" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Presence indicator</span></span>
<span id="cb25-1236"><a href="#cb25-1236" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> aggregated.device</span>
<span id="cb25-1237"><a href="#cb25-1237" aria-hidden="true" tabindex="-1"></a>        presence_tensor <span class="op">=</span> torch.tensor(</span>
<span id="cb25-1238"><a href="#cb25-1238" aria-hidden="true" tabindex="-1"></a>            presence, device<span class="op">=</span>device</span>
<span id="cb25-1239"><a href="#cb25-1239" aria-hidden="true" tabindex="-1"></a>        ).unsqueeze(<span class="dv">0</span>).expand(aggregated.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1240"><a href="#cb25-1240" aria-hidden="true" tabindex="-1"></a>        presence_emb <span class="op">=</span> <span class="va">self</span>.presence_proj(presence_tensor)</span>
<span id="cb25-1241"><a href="#cb25-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1242"><a href="#cb25-1242" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine</span></span>
<span id="cb25-1243"><a href="#cb25-1243" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([aggregated, presence_emb], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-1244"><a href="#cb25-1244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1245"><a href="#cb25-1245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1246"><a href="#cb25-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1247"><a href="#cb25-1247" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multimodal Document Understanding</span></span>
<span id="cb25-1248"><a href="#cb25-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1249"><a href="#cb25-1249" aria-hidden="true" tabindex="-1"></a><span class="fu">### Annual Report as a Multimodal Object</span></span>
<span id="cb25-1250"><a href="#cb25-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1251"><a href="#cb25-1251" aria-hidden="true" tabindex="-1"></a>A Vietnamese annual report is inherently multimodal: it contains running text (management discussion, risk factors, strategy), tables (financial statements, segment data, shareholder structure), images (photographs of facilities, products, management), and charts (revenue trends, market share). Prior chapters treated these as separate extraction problems. Here we build a model that processes the entire report as a unified multimodal document.</span>
<span id="cb25-1252"><a href="#cb25-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1253"><a href="#cb25-1253" aria-hidden="true" tabindex="-1"></a>The architecture follows the Document Understanding Transformer (Donut) approach of @kim2022ocr, adapted for Vietnamese financial filings:</span>
<span id="cb25-1254"><a href="#cb25-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1255"><a href="#cb25-1255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-1256"><a href="#cb25-1256" aria-hidden="true" tabindex="-1"></a>\mathbf{h} = \text{Encoder}(\mathbf{I}_{\text{page}}) + \text{Encoder}(\mathbf{T}_{\text{ocr}}) + \text{Encoder}(\mathbf{L}_{\text{layout}})</span>
<span id="cb25-1257"><a href="#cb25-1257" aria-hidden="true" tabindex="-1"></a>$$ {#eq-donut}</span>
<span id="cb25-1258"><a href="#cb25-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1259"><a href="#cb25-1259" aria-hidden="true" tabindex="-1"></a>where $\mathbf{I}$ is the page image, $\mathbf{T}$ is the OCR text, and $\mathbf{L}$ is the spatial layout (bounding boxes). The joint representation $\mathbf{h}$ captures both what is written and where it appears on the page.</span>
<span id="cb25-1260"><a href="#cb25-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1263"><a href="#cb25-1263" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1264"><a href="#cb25-1264" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: multimodal-document</span></span>
<span id="cb25-1265"><a href="#cb25-1265" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1266"><a href="#cb25-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1267"><a href="#cb25-1267" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalDocumentEncoder(nn.Module):</span>
<span id="cb25-1268"><a href="#cb25-1268" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1269"><a href="#cb25-1269" aria-hidden="true" tabindex="-1"></a><span class="co">    Joint encoder for Vietnamese annual report pages.</span></span>
<span id="cb25-1270"><a href="#cb25-1270" aria-hidden="true" tabindex="-1"></a><span class="co">    Processes text, layout, and page image simultaneously.</span></span>
<span id="cb25-1271"><a href="#cb25-1271" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1272"><a href="#cb25-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1273"><a href="#cb25-1273" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size<span class="op">=</span><span class="dv">64000</span>, max_boxes<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb25-1274"><a href="#cb25-1274" aria-hidden="true" tabindex="-1"></a>                 img_dim<span class="op">=</span><span class="dv">2048</span>, hidden_dim<span class="op">=</span><span class="dv">256</span>, n_layers<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb25-1275"><a href="#cb25-1275" aria-hidden="true" tabindex="-1"></a>                 n_heads<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb25-1276"><a href="#cb25-1276" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-1277"><a href="#cb25-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1278"><a href="#cb25-1278" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text embedding (Vietnamese tokens)</span></span>
<span id="cb25-1279"><a href="#cb25-1279" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_emb <span class="op">=</span> nn.Embedding(vocab_size, hidden_dim)</span>
<span id="cb25-1280"><a href="#cb25-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1281"><a href="#cb25-1281" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Layout embedding (bounding box coordinates)</span></span>
<span id="cb25-1282"><a href="#cb25-1282" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Each box: [x0, y0, x1, y1] normalized to [0, 1000]</span></span>
<span id="cb25-1283"><a href="#cb25-1283" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x_emb <span class="op">=</span> nn.Embedding(<span class="dv">1001</span>, hidden_dim <span class="op">//</span> <span class="dv">4</span>)</span>
<span id="cb25-1284"><a href="#cb25-1284" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_emb <span class="op">=</span> nn.Embedding(<span class="dv">1001</span>, hidden_dim <span class="op">//</span> <span class="dv">4</span>)</span>
<span id="cb25-1285"><a href="#cb25-1285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1286"><a href="#cb25-1286" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image patch embedding</span></span>
<span id="cb25-1287"><a href="#cb25-1287" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_proj <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-1288"><a href="#cb25-1288" aria-hidden="true" tabindex="-1"></a>            nn.Linear(img_dim, hidden_dim),</span>
<span id="cb25-1289"><a href="#cb25-1289" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim)</span>
<span id="cb25-1290"><a href="#cb25-1290" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1291"><a href="#cb25-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1292"><a href="#cb25-1292" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality type embedding</span></span>
<span id="cb25-1293"><a href="#cb25-1293" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.modality_emb <span class="op">=</span> nn.Embedding(<span class="dv">3</span>, hidden_dim)  <span class="co"># text, layout, image</span></span>
<span id="cb25-1294"><a href="#cb25-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1295"><a href="#cb25-1295" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer encoder</span></span>
<span id="cb25-1296"><a href="#cb25-1296" aria-hidden="true" tabindex="-1"></a>        encoder_layer <span class="op">=</span> nn.TransformerEncoderLayer(</span>
<span id="cb25-1297"><a href="#cb25-1297" aria-hidden="true" tabindex="-1"></a>            d_model<span class="op">=</span>hidden_dim,</span>
<span id="cb25-1298"><a href="#cb25-1298" aria-hidden="true" tabindex="-1"></a>            nhead<span class="op">=</span>n_heads,</span>
<span id="cb25-1299"><a href="#cb25-1299" aria-hidden="true" tabindex="-1"></a>            dim_feedforward<span class="op">=</span>hidden_dim <span class="op">*</span> <span class="dv">4</span>,</span>
<span id="cb25-1300"><a href="#cb25-1300" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb25-1301"><a href="#cb25-1301" aria-hidden="true" tabindex="-1"></a>            activation<span class="op">=</span><span class="st">"gelu"</span>,</span>
<span id="cb25-1302"><a href="#cb25-1302" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-1303"><a href="#cb25-1303" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1304"><a href="#cb25-1304" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer <span class="op">=</span> nn.TransformerEncoder(</span>
<span id="cb25-1305"><a href="#cb25-1305" aria-hidden="true" tabindex="-1"></a>            encoder_layer, num_layers<span class="op">=</span>n_layers</span>
<span id="cb25-1306"><a href="#cb25-1306" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1307"><a href="#cb25-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1308"><a href="#cb25-1308" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [CLS] token</span></span>
<span id="cb25-1309"><a href="#cb25-1309" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cls_token <span class="op">=</span> nn.Parameter(torch.randn(<span class="dv">1</span>, <span class="dv">1</span>, hidden_dim))</span>
<span id="cb25-1310"><a href="#cb25-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1311"><a href="#cb25-1311" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> embed_layout(<span class="va">self</span>, boxes):</span>
<span id="cb25-1312"><a href="#cb25-1312" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Embed bounding box coordinates."""</span></span>
<span id="cb25-1313"><a href="#cb25-1313" aria-hidden="true" tabindex="-1"></a>        x0 <span class="op">=</span> <span class="va">self</span>.x_emb(boxes[:, :, <span class="dv">0</span>])</span>
<span id="cb25-1314"><a href="#cb25-1314" aria-hidden="true" tabindex="-1"></a>        y0 <span class="op">=</span> <span class="va">self</span>.y_emb(boxes[:, :, <span class="dv">1</span>])</span>
<span id="cb25-1315"><a href="#cb25-1315" aria-hidden="true" tabindex="-1"></a>        x1 <span class="op">=</span> <span class="va">self</span>.x_emb(boxes[:, :, <span class="dv">2</span>])</span>
<span id="cb25-1316"><a href="#cb25-1316" aria-hidden="true" tabindex="-1"></a>        y1 <span class="op">=</span> <span class="va">self</span>.y_emb(boxes[:, :, <span class="dv">3</span>])</span>
<span id="cb25-1317"><a href="#cb25-1317" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([x0, y0, x1, y1], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-1318"><a href="#cb25-1318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1319"><a href="#cb25-1319" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, token_ids, boxes, img_features,</span>
<span id="cb25-1320"><a href="#cb25-1320" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-1321"><a href="#cb25-1321" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-1322"><a href="#cb25-1322" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-1323"><a href="#cb25-1323" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-1324"><a href="#cb25-1324" aria-hidden="true" tabindex="-1"></a><span class="co">        token_ids : LongTensor (B, T)</span></span>
<span id="cb25-1325"><a href="#cb25-1325" aria-hidden="true" tabindex="-1"></a><span class="co">            OCR token IDs.</span></span>
<span id="cb25-1326"><a href="#cb25-1326" aria-hidden="true" tabindex="-1"></a><span class="co">        boxes : LongTensor (B, T, 4)</span></span>
<span id="cb25-1327"><a href="#cb25-1327" aria-hidden="true" tabindex="-1"></a><span class="co">            Bounding boxes for each token.</span></span>
<span id="cb25-1328"><a href="#cb25-1328" aria-hidden="true" tabindex="-1"></a><span class="co">        img_features : Tensor (B, P, img_dim)</span></span>
<span id="cb25-1329"><a href="#cb25-1329" aria-hidden="true" tabindex="-1"></a><span class="co">            Image patch features from CNN.</span></span>
<span id="cb25-1330"><a href="#cb25-1330" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-1331"><a href="#cb25-1331" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> token_ids.shape[<span class="dv">0</span>]</span>
<span id="cb25-1332"><a href="#cb25-1332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1333"><a href="#cb25-1333" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text + layout</span></span>
<span id="cb25-1334"><a href="#cb25-1334" aria-hidden="true" tabindex="-1"></a>        text_h <span class="op">=</span> <span class="va">self</span>.text_emb(token_ids) <span class="op">+</span> <span class="va">self</span>.embed_layout(boxes)</span>
<span id="cb25-1335"><a href="#cb25-1335" aria-hidden="true" tabindex="-1"></a>        text_h <span class="op">=</span> text_h <span class="op">+</span> <span class="va">self</span>.modality_emb(</span>
<span id="cb25-1336"><a href="#cb25-1336" aria-hidden="true" tabindex="-1"></a>            torch.zeros(batch_size, text_h.shape[<span class="dv">1</span>],</span>
<span id="cb25-1337"><a href="#cb25-1337" aria-hidden="true" tabindex="-1"></a>                       dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>text_h.device)</span>
<span id="cb25-1338"><a href="#cb25-1338" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1339"><a href="#cb25-1339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1340"><a href="#cb25-1340" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image patches</span></span>
<span id="cb25-1341"><a href="#cb25-1341" aria-hidden="true" tabindex="-1"></a>        img_h <span class="op">=</span> <span class="va">self</span>.img_proj(img_features)</span>
<span id="cb25-1342"><a href="#cb25-1342" aria-hidden="true" tabindex="-1"></a>        img_h <span class="op">=</span> img_h <span class="op">+</span> <span class="va">self</span>.modality_emb(</span>
<span id="cb25-1343"><a href="#cb25-1343" aria-hidden="true" tabindex="-1"></a>            torch.full((batch_size, img_h.shape[<span class="dv">1</span>]), <span class="dv">2</span>,</span>
<span id="cb25-1344"><a href="#cb25-1344" aria-hidden="true" tabindex="-1"></a>                      dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>img_h.device)</span>
<span id="cb25-1345"><a href="#cb25-1345" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1346"><a href="#cb25-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1347"><a href="#cb25-1347" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepend [CLS]</span></span>
<span id="cb25-1348"><a href="#cb25-1348" aria-hidden="true" tabindex="-1"></a>        cls <span class="op">=</span> <span class="va">self</span>.cls_token.expand(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1349"><a href="#cb25-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1350"><a href="#cb25-1350" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate all modalities</span></span>
<span id="cb25-1351"><a href="#cb25-1351" aria-hidden="true" tabindex="-1"></a>        sequence <span class="op">=</span> torch.cat([cls, text_h, img_h], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-1352"><a href="#cb25-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1353"><a href="#cb25-1353" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer encoding</span></span>
<span id="cb25-1354"><a href="#cb25-1354" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.transformer(sequence)</span>
<span id="cb25-1355"><a href="#cb25-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1356"><a href="#cb25-1356" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return [CLS] representation</span></span>
<span id="cb25-1357"><a href="#cb25-1357" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output[:, <span class="dv">0</span>, :]</span>
<span id="cb25-1358"><a href="#cb25-1358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1359"><a href="#cb25-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1360"><a href="#cb25-1360" aria-hidden="true" tabindex="-1"></a><span class="fu">### Extracting Structured Financials from Multimodal Reports</span></span>
<span id="cb25-1361"><a href="#cb25-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1362"><a href="#cb25-1362" aria-hidden="true" tabindex="-1"></a>With the document encoder, we can build extraction heads for specific financial fields. The key advantage over the OCR-only pipeline in previous chapter is that the multimodal encoder can resolve ambiguities using visual context (e.g., a number's meaning depends on where it appears on the page and what headers and labels surround it).</span>
<span id="cb25-1363"><a href="#cb25-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1366"><a href="#cb25-1366" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1367"><a href="#cb25-1367" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: financial-extraction-head</span></span>
<span id="cb25-1368"><a href="#cb25-1368" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1369"><a href="#cb25-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1370"><a href="#cb25-1370" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinancialFieldExtractor(nn.Module):</span>
<span id="cb25-1371"><a href="#cb25-1371" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1372"><a href="#cb25-1372" aria-hidden="true" tabindex="-1"></a><span class="co">    Extract specific financial fields from a document embedding.</span></span>
<span id="cb25-1373"><a href="#cb25-1373" aria-hidden="true" tabindex="-1"></a><span class="co">    Uses the multimodal document encoder as backbone.</span></span>
<span id="cb25-1374"><a href="#cb25-1374" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1375"><a href="#cb25-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1376"><a href="#cb25-1376" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, doc_encoder, fields, hidden_dim<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb25-1377"><a href="#cb25-1377" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-1378"><a href="#cb25-1378" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters</span></span>
<span id="cb25-1379"><a href="#cb25-1379" aria-hidden="true" tabindex="-1"></a><span class="co">        ----------</span></span>
<span id="cb25-1380"><a href="#cb25-1380" aria-hidden="true" tabindex="-1"></a><span class="co">        doc_encoder : MultimodalDocumentEncoder</span></span>
<span id="cb25-1381"><a href="#cb25-1381" aria-hidden="true" tabindex="-1"></a><span class="co">        fields : list</span></span>
<span id="cb25-1382"><a href="#cb25-1382" aria-hidden="true" tabindex="-1"></a><span class="co">            Target field names, e.g.,</span></span>
<span id="cb25-1383"><a href="#cb25-1383" aria-hidden="true" tabindex="-1"></a><span class="co">            ['revenue', 'net_income', 'total_assets', 'total_equity']</span></span>
<span id="cb25-1384"><a href="#cb25-1384" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-1385"><a href="#cb25-1385" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-1386"><a href="#cb25-1386" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.doc_encoder <span class="op">=</span> doc_encoder</span>
<span id="cb25-1387"><a href="#cb25-1387" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fields <span class="op">=</span> fields</span>
<span id="cb25-1388"><a href="#cb25-1388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1389"><a href="#cb25-1389" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Per-field extraction heads</span></span>
<span id="cb25-1390"><a href="#cb25-1390" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.extractors <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb25-1391"><a href="#cb25-1391" aria-hidden="true" tabindex="-1"></a>            field: nn.Sequential(</span>
<span id="cb25-1392"><a href="#cb25-1392" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb25-1393"><a href="#cb25-1393" aria-hidden="true" tabindex="-1"></a>                nn.GELU(),</span>
<span id="cb25-1394"><a href="#cb25-1394" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb25-1395"><a href="#cb25-1395" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1396"><a href="#cb25-1396" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> field <span class="kw">in</span> fields</span>
<span id="cb25-1397"><a href="#cb25-1397" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1398"><a href="#cb25-1398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1399"><a href="#cb25-1399" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Confidence head</span></span>
<span id="cb25-1400"><a href="#cb25-1400" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.confidence <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb25-1401"><a href="#cb25-1401" aria-hidden="true" tabindex="-1"></a>            field: nn.Sequential(</span>
<span id="cb25-1402"><a href="#cb25-1402" aria-hidden="true" tabindex="-1"></a>                nn.Linear(hidden_dim, <span class="dv">1</span>),</span>
<span id="cb25-1403"><a href="#cb25-1403" aria-hidden="true" tabindex="-1"></a>                nn.Sigmoid()</span>
<span id="cb25-1404"><a href="#cb25-1404" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1405"><a href="#cb25-1405" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> field <span class="kw">in</span> fields</span>
<span id="cb25-1406"><a href="#cb25-1406" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1407"><a href="#cb25-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1408"><a href="#cb25-1408" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, token_ids, boxes, img_features):</span>
<span id="cb25-1409"><a href="#cb25-1409" aria-hidden="true" tabindex="-1"></a>        doc_emb <span class="op">=</span> <span class="va">self</span>.doc_encoder(token_ids, boxes, img_features)</span>
<span id="cb25-1410"><a href="#cb25-1410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1411"><a href="#cb25-1411" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> {}</span>
<span id="cb25-1412"><a href="#cb25-1412" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> field <span class="kw">in</span> <span class="va">self</span>.fields:</span>
<span id="cb25-1413"><a href="#cb25-1413" aria-hidden="true" tabindex="-1"></a>            value <span class="op">=</span> <span class="va">self</span>.extractors[field](doc_emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1414"><a href="#cb25-1414" aria-hidden="true" tabindex="-1"></a>            conf <span class="op">=</span> <span class="va">self</span>.confidence[field](doc_emb).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1415"><a href="#cb25-1415" aria-hidden="true" tabindex="-1"></a>            results[field] <span class="op">=</span> {<span class="st">"value"</span>: value, <span class="st">"confidence"</span>: conf}</span>
<span id="cb25-1416"><a href="#cb25-1416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1417"><a href="#cb25-1417" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> results</span>
<span id="cb25-1418"><a href="#cb25-1418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1419"><a href="#cb25-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1420"><a href="#cb25-1420" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multimodal Earnings Surprise Model</span></span>
<span id="cb25-1421"><a href="#cb25-1421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1422"><a href="#cb25-1422" aria-hidden="true" tabindex="-1"></a><span class="fu">### Architecture</span></span>
<span id="cb25-1423"><a href="#cb25-1423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1424"><a href="#cb25-1424" aria-hidden="true" tabindex="-1"></a>We now build the chapter's central empirical application: a multimodal model that predicts earnings surprises using all available modalities observed before the earnings announcement date.</span>
<span id="cb25-1425"><a href="#cb25-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1426"><a href="#cb25-1426" aria-hidden="true" tabindex="-1"></a>The information set at time $t^-$ (just before the announcement) includes:</span>
<span id="cb25-1427"><a href="#cb25-1427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1428"><a href="#cb25-1428" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Tabular**: Last reported financial ratios, analyst consensus forecasts</span>
<span id="cb25-1429"><a href="#cb25-1429" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Text**: News articles and filings in the pre-announcement window</span>
<span id="cb25-1430"><a href="#cb25-1430" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Image**: Satellite features of the firm's operating region</span>
<span id="cb25-1431"><a href="#cb25-1431" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Time series**: Price and volume dynamics in the 60 trading days before announcement</span>
<span id="cb25-1432"><a href="#cb25-1432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1433"><a href="#cb25-1433" aria-hidden="true" tabindex="-1"></a>The target is the standardized unexpected earnings (SUE):</span>
<span id="cb25-1434"><a href="#cb25-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1435"><a href="#cb25-1435" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-1436"><a href="#cb25-1436" aria-hidden="true" tabindex="-1"></a>\text{SUE}_{i,q} = \frac{E_{i,q} - \hat{E}_{i,q}}{\sigma_{i,q}}</span>
<span id="cb25-1437"><a href="#cb25-1437" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sue}</span>
<span id="cb25-1438"><a href="#cb25-1438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1439"><a href="#cb25-1439" aria-hidden="true" tabindex="-1"></a>where $E_{i,q}$ is actual earnings per share, $\hat{E}_{i,q}$ is the consensus forecast (or seasonal random walk forecast if analyst coverage is absent), and $\sigma_{i,q}$ is the standard deviation of forecast errors.</span>
<span id="cb25-1440"><a href="#cb25-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1443"><a href="#cb25-1443" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1444"><a href="#cb25-1444" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: earnings-surprise-data</span></span>
<span id="cb25-1445"><a href="#cb25-1445" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1446"><a href="#cb25-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1447"><a href="#cb25-1447" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct earnings surprise dataset</span></span>
<span id="cb25-1448"><a href="#cb25-1448" aria-hidden="true" tabindex="-1"></a>earnings <span class="op">=</span> dc.get_earnings_announcements(</span>
<span id="cb25-1449"><a href="#cb25-1449" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2016-01-01"</span>,</span>
<span id="cb25-1450"><a href="#cb25-1450" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span></span>
<span id="cb25-1451"><a href="#cb25-1451" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-1452"><a href="#cb25-1452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1453"><a href="#cb25-1453" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized Unexpected Earnings</span></span>
<span id="cb25-1454"><a href="#cb25-1454" aria-hidden="true" tabindex="-1"></a>earnings[<span class="st">"sue"</span>] <span class="op">=</span> (</span>
<span id="cb25-1455"><a href="#cb25-1455" aria-hidden="true" tabindex="-1"></a>    (earnings[<span class="st">"actual_eps"</span>] <span class="op">-</span> earnings[<span class="st">"consensus_eps"</span>]) <span class="op">/</span></span>
<span id="cb25-1456"><a href="#cb25-1456" aria-hidden="true" tabindex="-1"></a>    earnings[<span class="st">"forecast_std"</span>].clip(lower<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb25-1457"><a href="#cb25-1457" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-1458"><a href="#cb25-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1459"><a href="#cb25-1459" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-announcement features</span></span>
<span id="cb25-1460"><a href="#cb25-1460" aria-hidden="true" tabindex="-1"></a><span class="co"># Text: aggregate PhoBERT sentiment of news in [-30, -1] window</span></span>
<span id="cb25-1461"><a href="#cb25-1461" aria-hidden="true" tabindex="-1"></a>pre_ann_text <span class="op">=</span> dc.get_pre_announcement_text_features(</span>
<span id="cb25-1462"><a href="#cb25-1462" aria-hidden="true" tabindex="-1"></a>    start_date<span class="op">=</span><span class="st">"2016-01-01"</span>,</span>
<span id="cb25-1463"><a href="#cb25-1463" aria-hidden="true" tabindex="-1"></a>    end_date<span class="op">=</span><span class="st">"2024-12-31"</span>,</span>
<span id="cb25-1464"><a href="#cb25-1464" aria-hidden="true" tabindex="-1"></a>    window_days<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb25-1465"><a href="#cb25-1465" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"phobert"</span></span>
<span id="cb25-1466"><a href="#cb25-1466" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-1467"><a href="#cb25-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1468"><a href="#cb25-1468" aria-hidden="true" tabindex="-1"></a><span class="co"># Image: satellite features at quarter end</span></span>
<span id="cb25-1469"><a href="#cb25-1469" aria-hidden="true" tabindex="-1"></a>pre_ann_image <span class="op">=</span> satellite_features.copy()</span>
<span id="cb25-1470"><a href="#cb25-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1471"><a href="#cb25-1471" aria-hidden="true" tabindex="-1"></a><span class="co"># Time series: 60 trading days before announcement</span></span>
<span id="cb25-1472"><a href="#cb25-1472" aria-hidden="true" tabindex="-1"></a><span class="co"># (Pre-computed above)</span></span>
<span id="cb25-1473"><a href="#cb25-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1474"><a href="#cb25-1474" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabular: most recent quarterly financials</span></span>
<span id="cb25-1475"><a href="#cb25-1475" aria-hidden="true" tabindex="-1"></a>pre_ann_tabular <span class="op">=</span> financials[tabular_features <span class="op">+</span> [<span class="st">"ticker"</span>, <span class="st">"quarter_date"</span>]]</span>
<span id="cb25-1476"><a href="#cb25-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1477"><a href="#cb25-1477" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Earnings announcements: </span><span class="sc">{</span><span class="bu">len</span>(earnings)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-1478"><a href="#cb25-1478" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"With text features: </span><span class="sc">{</span><span class="bu">len</span>(pre_ann_text)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-1479"><a href="#cb25-1479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1480"><a href="#cb25-1480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1483"><a href="#cb25-1483" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1484"><a href="#cb25-1484" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: earnings-model</span></span>
<span id="cb25-1485"><a href="#cb25-1485" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1486"><a href="#cb25-1486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1487"><a href="#cb25-1487" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalEarningsSurpriseModel(nn.Module):</span>
<span id="cb25-1488"><a href="#cb25-1488" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1489"><a href="#cb25-1489" aria-hidden="true" tabindex="-1"></a><span class="co">    Predict standardized unexpected earnings (SUE) from</span></span>
<span id="cb25-1490"><a href="#cb25-1490" aria-hidden="true" tabindex="-1"></a><span class="co">    multimodal pre-announcement information.</span></span>
<span id="cb25-1491"><a href="#cb25-1491" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1492"><a href="#cb25-1492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1493"><a href="#cb25-1493" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, tab_dim, text_dim<span class="op">=</span><span class="dv">768</span>, img_dim<span class="op">=</span><span class="dv">2048</span>,</span>
<span id="cb25-1494"><a href="#cb25-1494" aria-hidden="true" tabindex="-1"></a>                 ts_features<span class="op">=</span><span class="dv">5</span>, ts_len<span class="op">=</span><span class="dv">60</span>, hidden_dim<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb25-1495"><a href="#cb25-1495" aria-hidden="true" tabindex="-1"></a>                 n_heads<span class="op">=</span><span class="dv">4</span>, drop_prob<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb25-1496"><a href="#cb25-1496" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-1497"><a href="#cb25-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1498"><a href="#cb25-1498" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unimodal encoders</span></span>
<span id="cb25-1499"><a href="#cb25-1499" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab_enc <span class="op">=</span> TabularEncoder(tab_dim, <span class="dv">128</span>, hidden_dim)</span>
<span id="cb25-1500"><a href="#cb25-1500" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_enc <span class="op">=</span> TextEncoder(text_dim, hidden_dim)</span>
<span id="cb25-1501"><a href="#cb25-1501" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_enc <span class="op">=</span> ImageEncoder(img_dim, hidden_dim)</span>
<span id="cb25-1502"><a href="#cb25-1502" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ts_enc <span class="op">=</span> TimeSeriesEncoder(ts_features, ts_len, hidden_dim)</span>
<span id="cb25-1503"><a href="#cb25-1503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1504"><a href="#cb25-1504" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality dropout</span></span>
<span id="cb25-1505"><a href="#cb25-1505" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mod_dropout <span class="op">=</span> ModalityDropout(drop_prob)</span>
<span id="cb25-1506"><a href="#cb25-1506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1507"><a href="#cb25-1507" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention: text attends to time series</span></span>
<span id="cb25-1508"><a href="#cb25-1508" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (news context informs price dynamics interpretation)</span></span>
<span id="cb25-1509"><a href="#cb25-1509" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_ts_attn <span class="op">=</span> CrossAttentionBlock(hidden_dim, n_heads)</span>
<span id="cb25-1510"><a href="#cb25-1510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1511"><a href="#cb25-1511" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention: tabular attends to image</span></span>
<span id="cb25-1512"><a href="#cb25-1512" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (financial ratios contextualized by physical activity)</span></span>
<span id="cb25-1513"><a href="#cb25-1513" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tab_img_attn <span class="op">=</span> CrossAttentionBlock(hidden_dim, n_heads)</span>
<span id="cb25-1514"><a href="#cb25-1514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1515"><a href="#cb25-1515" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modality importance weights (learned)</span></span>
<span id="cb25-1516"><a href="#cb25-1516" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.importance <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">4</span>))</span>
<span id="cb25-1517"><a href="#cb25-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1518"><a href="#cb25-1518" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prediction head</span></span>
<span id="cb25-1519"><a href="#cb25-1519" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Sequential(</span>
<span id="cb25-1520"><a href="#cb25-1520" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">*</span> <span class="dv">2</span>, hidden_dim),</span>
<span id="cb25-1521"><a href="#cb25-1521" aria-hidden="true" tabindex="-1"></a>            nn.LayerNorm(hidden_dim),</span>
<span id="cb25-1522"><a href="#cb25-1522" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-1523"><a href="#cb25-1523" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb25-1524"><a href="#cb25-1524" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, hidden_dim <span class="op">//</span> <span class="dv">2</span>),</span>
<span id="cb25-1525"><a href="#cb25-1525" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb25-1526"><a href="#cb25-1526" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb25-1527"><a href="#cb25-1527" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1528"><a href="#cb25-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1529"><a href="#cb25-1529" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, tabular, text, image, ts):</span>
<span id="cb25-1530"><a href="#cb25-1530" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb25-1531"><a href="#cb25-1531" aria-hidden="true" tabindex="-1"></a>        h_tab <span class="op">=</span> <span class="va">self</span>.tab_enc(tabular) <span class="cf">if</span> tabular <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb25-1532"><a href="#cb25-1532" aria-hidden="true" tabindex="-1"></a>        h_txt <span class="op">=</span> <span class="va">self</span>.text_enc(text) <span class="cf">if</span> text <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb25-1533"><a href="#cb25-1533" aria-hidden="true" tabindex="-1"></a>        h_img <span class="op">=</span> <span class="va">self</span>.img_enc(image) <span class="cf">if</span> image <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb25-1534"><a href="#cb25-1534" aria-hidden="true" tabindex="-1"></a>        h_ts <span class="op">=</span> <span class="va">self</span>.ts_enc(ts) <span class="cf">if</span> ts <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb25-1535"><a href="#cb25-1535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1536"><a href="#cb25-1536" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention pairs (if both available)</span></span>
<span id="cb25-1537"><a href="#cb25-1537" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> h_txt <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> h_ts <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1538"><a href="#cb25-1538" aria-hidden="true" tabindex="-1"></a>            h_txt_enriched, _ <span class="op">=</span> <span class="va">self</span>.text_ts_attn(h_txt, h_ts)</span>
<span id="cb25-1539"><a href="#cb25-1539" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-1540"><a href="#cb25-1540" aria-hidden="true" tabindex="-1"></a>            h_txt_enriched <span class="op">=</span> h_txt</span>
<span id="cb25-1541"><a href="#cb25-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1542"><a href="#cb25-1542" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> h_tab <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> h_img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1543"><a href="#cb25-1543" aria-hidden="true" tabindex="-1"></a>            h_tab_enriched, _ <span class="op">=</span> <span class="va">self</span>.tab_img_attn(h_tab, h_img)</span>
<span id="cb25-1544"><a href="#cb25-1544" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-1545"><a href="#cb25-1545" aria-hidden="true" tabindex="-1"></a>            h_tab_enriched <span class="op">=</span> h_tab</span>
<span id="cb25-1546"><a href="#cb25-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1547"><a href="#cb25-1547" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Weighted combination of available modalities</span></span>
<span id="cb25-1548"><a href="#cb25-1548" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb25-1549"><a href="#cb25-1549" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> F.softmax(<span class="va">self</span>.importance, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1550"><a href="#cb25-1550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1551"><a href="#cb25-1551" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, h <span class="kw">in</span> <span class="bu">enumerate</span>([h_tab_enriched, h_txt_enriched,</span>
<span id="cb25-1552"><a href="#cb25-1552" aria-hidden="true" tabindex="-1"></a>                                h_img, h_ts]):</span>
<span id="cb25-1553"><a href="#cb25-1553" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> h <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1554"><a href="#cb25-1554" aria-hidden="true" tabindex="-1"></a>                embeddings.append(h <span class="op">*</span> weights[i])</span>
<span id="cb25-1555"><a href="#cb25-1555" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb25-1556"><a href="#cb25-1556" aria-hidden="true" tabindex="-1"></a>                device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb25-1557"><a href="#cb25-1557" aria-hidden="true" tabindex="-1"></a>                batch_size <span class="op">=</span> <span class="bu">next</span>(</span>
<span id="cb25-1558"><a href="#cb25-1558" aria-hidden="true" tabindex="-1"></a>                    x.shape[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> [tabular, text, image, ts]</span>
<span id="cb25-1559"><a href="#cb25-1559" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> x <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb25-1560"><a href="#cb25-1560" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-1561"><a href="#cb25-1561" aria-hidden="true" tabindex="-1"></a>                embeddings.append(</span>
<span id="cb25-1562"><a href="#cb25-1562" aria-hidden="true" tabindex="-1"></a>                    torch.zeros(batch_size, h_tab.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb25-1563"><a href="#cb25-1563" aria-hidden="true" tabindex="-1"></a>                               <span class="cf">if</span> h_tab <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="dv">64</span>,</span>
<span id="cb25-1564"><a href="#cb25-1564" aria-hidden="true" tabindex="-1"></a>                               device<span class="op">=</span>device)</span>
<span id="cb25-1565"><a href="#cb25-1565" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb25-1566"><a href="#cb25-1566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1567"><a href="#cb25-1567" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggregate</span></span>
<span id="cb25-1568"><a href="#cb25-1568" aria-hidden="true" tabindex="-1"></a>        stacked <span class="op">=</span> torch.stack(embeddings, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1569"><a href="#cb25-1569" aria-hidden="true" tabindex="-1"></a>        aggregated <span class="op">=</span> stacked.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1570"><a href="#cb25-1570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1571"><a href="#cb25-1571" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Also compute variance across modalities (disagreement signal)</span></span>
<span id="cb25-1572"><a href="#cb25-1572" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> stacked.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb25-1573"><a href="#cb25-1573" aria-hidden="true" tabindex="-1"></a>            disagreement <span class="op">=</span> stacked.var(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-1574"><a href="#cb25-1574" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-1575"><a href="#cb25-1575" aria-hidden="true" tabindex="-1"></a>            disagreement <span class="op">=</span> torch.zeros_like(aggregated)</span>
<span id="cb25-1576"><a href="#cb25-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1577"><a href="#cb25-1577" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([aggregated, disagreement], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb25-1578"><a href="#cb25-1578" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(combined).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-1579"><a href="#cb25-1579" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1580"><a href="#cb25-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1581"><a href="#cb25-1581" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modality Importance Analysis</span></span>
<span id="cb25-1582"><a href="#cb25-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1583"><a href="#cb25-1583" aria-hidden="true" tabindex="-1"></a>A key interpretability question is: which modality contributes most to earnings surprise prediction? We analyze the learned importance weights and conduct ablation experiments.</span>
<span id="cb25-1584"><a href="#cb25-1584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1587"><a href="#cb25-1587" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1588"><a href="#cb25-1588" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: modality-importance</span></span>
<span id="cb25-1589"><a href="#cb25-1589" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1590"><a href="#cb25-1590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1591"><a href="#cb25-1591" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ablation_study(model, test_loader, modality_names):</span>
<span id="cb25-1592"><a href="#cb25-1592" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1593"><a href="#cb25-1593" aria-hidden="true" tabindex="-1"></a><span class="co">    Measure each modality's contribution via leave-one-out ablation.</span></span>
<span id="cb25-1594"><a href="#cb25-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1595"><a href="#cb25-1595" aria-hidden="true" tabindex="-1"></a><span class="co">    For each modality m, zero out that modality's input and measure</span></span>
<span id="cb25-1596"><a href="#cb25-1596" aria-hidden="true" tabindex="-1"></a><span class="co">    the degradation in prediction accuracy.</span></span>
<span id="cb25-1597"><a href="#cb25-1597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1598"><a href="#cb25-1598" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb25-1599"><a href="#cb25-1599" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb25-1600"><a href="#cb25-1600" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame : Modality, R² with all, R² without, Δ R².</span></span>
<span id="cb25-1601"><a href="#cb25-1601" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1602"><a href="#cb25-1602" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb25-1603"><a href="#cb25-1603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1604"><a href="#cb25-1604" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Full model performance</span></span>
<span id="cb25-1605"><a href="#cb25-1605" aria-hidden="true" tabindex="-1"></a>    all_preds, all_targets <span class="op">=</span> [], []</span>
<span id="cb25-1606"><a href="#cb25-1606" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-1607"><a href="#cb25-1607" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb25-1608"><a href="#cb25-1608" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {k: batch[k] <span class="cf">for</span> k <span class="kw">in</span> modality_names}</span>
<span id="cb25-1609"><a href="#cb25-1609" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb25-1610"><a href="#cb25-1610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1611"><a href="#cb25-1611" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(inputs)</span>
<span id="cb25-1612"><a href="#cb25-1612" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> output[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>) <span class="cf">else</span> output</span>
<span id="cb25-1613"><a href="#cb25-1613" aria-hidden="true" tabindex="-1"></a>            all_preds.extend(pred.cpu().numpy())</span>
<span id="cb25-1614"><a href="#cb25-1614" aria-hidden="true" tabindex="-1"></a>            all_targets.extend(targets.cpu().numpy())</span>
<span id="cb25-1615"><a href="#cb25-1615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1616"><a href="#cb25-1616" aria-hidden="true" tabindex="-1"></a>    r2_full <span class="op">=</span> r2_score(all_targets, all_preds)</span>
<span id="cb25-1617"><a href="#cb25-1617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1618"><a href="#cb25-1618" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ablation: remove one modality at a time</span></span>
<span id="cb25-1619"><a href="#cb25-1619" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> [{<span class="st">"modality"</span>: <span class="st">"All"</span>, <span class="st">"r2"</span>: r2_full, <span class="st">"delta_r2"</span>: <span class="fl">0.0</span>}]</span>
<span id="cb25-1620"><a href="#cb25-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1621"><a href="#cb25-1621" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> drop_mod <span class="kw">in</span> modality_names:</span>
<span id="cb25-1622"><a href="#cb25-1622" aria-hidden="true" tabindex="-1"></a>        ablated_preds <span class="op">=</span> []</span>
<span id="cb25-1623"><a href="#cb25-1623" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-1624"><a href="#cb25-1624" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb25-1625"><a href="#cb25-1625" aria-hidden="true" tabindex="-1"></a>                inputs <span class="op">=</span> {}</span>
<span id="cb25-1626"><a href="#cb25-1626" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> k <span class="kw">in</span> modality_names:</span>
<span id="cb25-1627"><a href="#cb25-1627" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> k <span class="op">==</span> drop_mod:</span>
<span id="cb25-1628"><a href="#cb25-1628" aria-hidden="true" tabindex="-1"></a>                        inputs[k] <span class="op">=</span> <span class="va">None</span>  <span class="co"># Remove this modality</span></span>
<span id="cb25-1629"><a href="#cb25-1629" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb25-1630"><a href="#cb25-1630" aria-hidden="true" tabindex="-1"></a>                        inputs[k] <span class="op">=</span> batch[k]</span>
<span id="cb25-1631"><a href="#cb25-1631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1632"><a href="#cb25-1632" aria-hidden="true" tabindex="-1"></a>                targets <span class="op">=</span> batch[<span class="st">"return"</span>]</span>
<span id="cb25-1633"><a href="#cb25-1633" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> model(inputs)</span>
<span id="cb25-1634"><a href="#cb25-1634" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> output[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(output, <span class="bu">tuple</span>) <span class="cf">else</span> output</span>
<span id="cb25-1635"><a href="#cb25-1635" aria-hidden="true" tabindex="-1"></a>                ablated_preds.extend(pred.cpu().numpy())</span>
<span id="cb25-1636"><a href="#cb25-1636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1637"><a href="#cb25-1637" aria-hidden="true" tabindex="-1"></a>        r2_ablated <span class="op">=</span> r2_score(all_targets, ablated_preds)</span>
<span id="cb25-1638"><a href="#cb25-1638" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb25-1639"><a href="#cb25-1639" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modality"</span>: <span class="ss">f"Without </span><span class="sc">{</span>drop_mod<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb25-1640"><a href="#cb25-1640" aria-hidden="true" tabindex="-1"></a>            <span class="st">"r2"</span>: r2_ablated,</span>
<span id="cb25-1641"><a href="#cb25-1641" aria-hidden="true" tabindex="-1"></a>            <span class="st">"delta_r2"</span>: r2_full <span class="op">-</span> r2_ablated</span>
<span id="cb25-1642"><a href="#cb25-1642" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-1643"><a href="#cb25-1643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1644"><a href="#cb25-1644" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span>
<span id="cb25-1645"><a href="#cb25-1645" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1646"><a href="#cb25-1646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1649"><a href="#cb25-1649" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1650"><a href="#cb25-1650" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-ablation</span></span>
<span id="cb25-1651"><a href="#cb25-1651" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1652"><a href="#cb25-1652" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Modality Ablation Study: Contribution to Earnings Surprise Prediction"</span></span>
<span id="cb25-1653"><a href="#cb25-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1654"><a href="#cb25-1654" aria-hidden="true" tabindex="-1"></a><span class="co"># ablation_df = ablation_study(model, test_loader, modality_names)</span></span>
<span id="cb25-1655"><a href="#cb25-1655" aria-hidden="true" tabindex="-1"></a><span class="co"># ablation_df.round(4)</span></span>
<span id="cb25-1656"><a href="#cb25-1656" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1657"><a href="#cb25-1657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1660"><a href="#cb25-1660" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1661"><a href="#cb25-1661" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-modality-importance</span></span>
<span id="cb25-1662"><a href="#cb25-1662" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1663"><a href="#cb25-1663" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Learned Modality Importance Weights Over Training Epochs"</span></span>
<span id="cb25-1664"><a href="#cb25-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1665"><a href="#cb25-1665" aria-hidden="true" tabindex="-1"></a><span class="co"># Track importance weights during training</span></span>
<span id="cb25-1666"><a href="#cb25-1666" aria-hidden="true" tabindex="-1"></a><span class="co"># importance_history = pd.DataFrame(...)</span></span>
<span id="cb25-1667"><a href="#cb25-1667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1668"><a href="#cb25-1668" aria-hidden="true" tabindex="-1"></a><span class="co"># (</span></span>
<span id="cb25-1669"><a href="#cb25-1669" aria-hidden="true" tabindex="-1"></a><span class="co">#     p9.ggplot(importance_history, p9.aes(</span></span>
<span id="cb25-1670"><a href="#cb25-1670" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="epoch", y="weight", color="modality"</span></span>
<span id="cb25-1671"><a href="#cb25-1671" aria-hidden="true" tabindex="-1"></a><span class="co">#     ))</span></span>
<span id="cb25-1672"><a href="#cb25-1672" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.geom_line(size=1)</span></span>
<span id="cb25-1673"><a href="#cb25-1673" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.labs(</span></span>
<span id="cb25-1674"><a href="#cb25-1674" aria-hidden="true" tabindex="-1"></a><span class="co">#         x="Training Epoch", y="Softmax Weight",</span></span>
<span id="cb25-1675"><a href="#cb25-1675" aria-hidden="true" tabindex="-1"></a><span class="co">#         title="Modality Importance Convergence",</span></span>
<span id="cb25-1676"><a href="#cb25-1676" aria-hidden="true" tabindex="-1"></a><span class="co">#         color="Modality"</span></span>
<span id="cb25-1677"><a href="#cb25-1677" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb25-1678"><a href="#cb25-1678" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.scale_color_manual(</span></span>
<span id="cb25-1679"><a href="#cb25-1679" aria-hidden="true" tabindex="-1"></a><span class="co">#         values=["#2E5090", "#C0392B", "#27AE60", "#8E44AD"]</span></span>
<span id="cb25-1680"><a href="#cb25-1680" aria-hidden="true" tabindex="-1"></a><span class="co">#     )</span></span>
<span id="cb25-1681"><a href="#cb25-1681" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme_minimal()</span></span>
<span id="cb25-1682"><a href="#cb25-1682" aria-hidden="true" tabindex="-1"></a><span class="co">#     + p9.theme(figure_size=(10, 5))</span></span>
<span id="cb25-1683"><a href="#cb25-1683" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb25-1684"><a href="#cb25-1684" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1685"><a href="#cb25-1685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1686"><a href="#cb25-1686" aria-hidden="true" tabindex="-1"></a><span class="fu">## Large Multimodal Models for Financial Analysis</span></span>
<span id="cb25-1687"><a href="#cb25-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1688"><a href="#cb25-1688" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prompting Vision-Language Models</span></span>
<span id="cb25-1689"><a href="#cb25-1689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1690"><a href="#cb25-1690" aria-hidden="true" tabindex="-1"></a>The most powerful multimodal systems available today are large vision-language models (VLMs) such as GPT-4V, Gemini, and open-source alternatives (LLaVA, InternVL). These models can jointly process images and text through natural language prompts, enabling zero-shot financial analysis without model training.</span>
<span id="cb25-1691"><a href="#cb25-1691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1692"><a href="#cb25-1692" aria-hidden="true" tabindex="-1"></a>For Vietnamese financial applications, VLMs can:</span>
<span id="cb25-1693"><a href="#cb25-1693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1694"><a href="#cb25-1694" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpret satellite imagery of industrial zones and estimate activity levels</span>
<span id="cb25-1695"><a href="#cb25-1695" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Read and extract data from scanned financial tables</span>
<span id="cb25-1696"><a href="#cb25-1696" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Analyze news photographs for sentiment</span>
<span id="cb25-1697"><a href="#cb25-1697" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Compare current and historical aerial views for change detection</span>
<span id="cb25-1698"><a href="#cb25-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1701"><a href="#cb25-1701" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1702"><a href="#cb25-1702" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: vlm-financial-prompting</span></span>
<span id="cb25-1703"><a href="#cb25-1703" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1704"><a href="#cb25-1704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1705"><a href="#cb25-1705" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vlm_financial_qa(image_path, question, context<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-1706"><a href="#cb25-1706" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1707"><a href="#cb25-1707" aria-hidden="true" tabindex="-1"></a><span class="co">    Financial question-answering using a vision-language model.</span></span>
<span id="cb25-1708"><a href="#cb25-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1709"><a href="#cb25-1709" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb25-1710"><a href="#cb25-1710" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb25-1711"><a href="#cb25-1711" aria-hidden="true" tabindex="-1"></a><span class="co">    image_path : str</span></span>
<span id="cb25-1712"><a href="#cb25-1712" aria-hidden="true" tabindex="-1"></a><span class="co">        Path to image (satellite tile, document page, news photo).</span></span>
<span id="cb25-1713"><a href="#cb25-1713" aria-hidden="true" tabindex="-1"></a><span class="co">    question : str</span></span>
<span id="cb25-1714"><a href="#cb25-1714" aria-hidden="true" tabindex="-1"></a><span class="co">        Financial analysis question.</span></span>
<span id="cb25-1715"><a href="#cb25-1715" aria-hidden="true" tabindex="-1"></a><span class="co">    context : str, optional</span></span>
<span id="cb25-1716"><a href="#cb25-1716" aria-hidden="true" tabindex="-1"></a><span class="co">        Additional textual context (e.g., firm name, sector).</span></span>
<span id="cb25-1717"><a href="#cb25-1717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1718"><a href="#cb25-1718" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb25-1719"><a href="#cb25-1719" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb25-1720"><a href="#cb25-1720" aria-hidden="true" tabindex="-1"></a><span class="co">    dict : Answer, confidence, extracted entities.</span></span>
<span id="cb25-1721"><a href="#cb25-1721" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1722"><a href="#cb25-1722" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb25-1723"><a href="#cb25-1723" aria-hidden="true" tabindex="-1"></a>        LlavaForConditionalGeneration,</span>
<span id="cb25-1724"><a href="#cb25-1724" aria-hidden="true" tabindex="-1"></a>        LlavaProcessor</span>
<span id="cb25-1725"><a href="#cb25-1725" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-1726"><a href="#cb25-1726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1727"><a href="#cb25-1727" aria-hidden="true" tabindex="-1"></a>    model_id <span class="op">=</span> <span class="st">"llava-hf/llava-v1.6-vicuna-7b-hf"</span></span>
<span id="cb25-1728"><a href="#cb25-1728" aria-hidden="true" tabindex="-1"></a>    processor <span class="op">=</span> LlavaProcessor.from_pretrained(model_id)</span>
<span id="cb25-1729"><a href="#cb25-1729" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LlavaForConditionalGeneration.from_pretrained(</span>
<span id="cb25-1730"><a href="#cb25-1730" aria-hidden="true" tabindex="-1"></a>        model_id, torch_dtype<span class="op">=</span>torch.float16, device_map<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb25-1731"><a href="#cb25-1731" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-1732"><a href="#cb25-1732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1733"><a href="#cb25-1733" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(image_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb25-1734"><a href="#cb25-1734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1735"><a href="#cb25-1735" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build financial analysis prompt</span></span>
<span id="cb25-1736"><a href="#cb25-1736" aria-hidden="true" tabindex="-1"></a>    system_prompt <span class="op">=</span> (</span>
<span id="cb25-1737"><a href="#cb25-1737" aria-hidden="true" tabindex="-1"></a>        <span class="st">"You are a financial analyst examining visual evidence. "</span></span>
<span id="cb25-1738"><a href="#cb25-1738" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Provide specific, quantitative observations when possible. "</span></span>
<span id="cb25-1739"><a href="#cb25-1739" aria-hidden="true" tabindex="-1"></a>        <span class="st">"State your confidence level (high/medium/low)."</span></span>
<span id="cb25-1740"><a href="#cb25-1740" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-1741"><a href="#cb25-1741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1742"><a href="#cb25-1742" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> context:</span>
<span id="cb25-1743"><a href="#cb25-1743" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> (</span>
<span id="cb25-1744"><a href="#cb25-1744" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Context: </span><span class="sc">{</span>context<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb25-1745"><a href="#cb25-1745" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Answer:"</span></span>
<span id="cb25-1746"><a href="#cb25-1746" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1747"><a href="#cb25-1747" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb25-1748"><a href="#cb25-1748" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>system_prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Answer:"</span></span>
<span id="cb25-1749"><a href="#cb25-1749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1750"><a href="#cb25-1750" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> processor(</span>
<span id="cb25-1751"><a href="#cb25-1751" aria-hidden="true" tabindex="-1"></a>        text<span class="op">=</span>prompt,</span>
<span id="cb25-1752"><a href="#cb25-1752" aria-hidden="true" tabindex="-1"></a>        images<span class="op">=</span>img,</span>
<span id="cb25-1753"><a href="#cb25-1753" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"pt"</span></span>
<span id="cb25-1754"><a href="#cb25-1754" aria-hidden="true" tabindex="-1"></a>    ).to(model.device)</span>
<span id="cb25-1755"><a href="#cb25-1755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1756"><a href="#cb25-1756" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-1757"><a href="#cb25-1757" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model.generate(</span>
<span id="cb25-1758"><a href="#cb25-1758" aria-hidden="true" tabindex="-1"></a>            <span class="op">**</span>inputs,</span>
<span id="cb25-1759"><a href="#cb25-1759" aria-hidden="true" tabindex="-1"></a>            max_new_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb25-1760"><a href="#cb25-1760" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb25-1761"><a href="#cb25-1761" aria-hidden="true" tabindex="-1"></a>            do_sample<span class="op">=</span><span class="va">False</span></span>
<span id="cb25-1762"><a href="#cb25-1762" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-1763"><a href="#cb25-1763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1764"><a href="#cb25-1764" aria-hidden="true" tabindex="-1"></a>    answer <span class="op">=</span> processor.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-1765"><a href="#cb25-1765" aria-hidden="true" tabindex="-1"></a>    answer <span class="op">=</span> answer.split(<span class="st">"Answer:"</span>)[<span class="op">-</span><span class="dv">1</span>].strip()</span>
<span id="cb25-1766"><a href="#cb25-1766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1767"><a href="#cb25-1767" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"answer"</span>: answer, <span class="st">"question"</span>: question}</span>
<span id="cb25-1768"><a href="#cb25-1768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1769"><a href="#cb25-1769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1770"><a href="#cb25-1770" aria-hidden="true" tabindex="-1"></a><span class="co"># Example financial VLM queries</span></span>
<span id="cb25-1771"><a href="#cb25-1771" aria-hidden="true" tabindex="-1"></a>FINANCIAL_VLM_PROMPTS <span class="op">=</span> {</span>
<span id="cb25-1772"><a href="#cb25-1772" aria-hidden="true" tabindex="-1"></a>    <span class="st">"satellite_activity"</span>: (</span>
<span id="cb25-1773"><a href="#cb25-1773" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Examine this satellite image of an industrial zone. "</span></span>
<span id="cb25-1774"><a href="#cb25-1774" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Estimate the occupancy rate of factory buildings, "</span></span>
<span id="cb25-1775"><a href="#cb25-1775" aria-hidden="true" tabindex="-1"></a>        <span class="st">"the density of vehicles in parking areas, "</span></span>
<span id="cb25-1776"><a href="#cb25-1776" aria-hidden="true" tabindex="-1"></a>        <span class="st">"and whether the site appears to be operating at "</span></span>
<span id="cb25-1777"><a href="#cb25-1777" aria-hidden="true" tabindex="-1"></a>        <span class="st">"full, partial, or minimal capacity."</span></span>
<span id="cb25-1778"><a href="#cb25-1778" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb25-1779"><a href="#cb25-1779" aria-hidden="true" tabindex="-1"></a>    <span class="st">"document_extraction"</span>: (</span>
<span id="cb25-1780"><a href="#cb25-1780" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a page from a Vietnamese annual report. "</span></span>
<span id="cb25-1781"><a href="#cb25-1781" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Extract the following if present: "</span></span>
<span id="cb25-1782"><a href="#cb25-1782" aria-hidden="true" tabindex="-1"></a>        <span class="st">"total revenue (doanh thu), net income (lợi nhuận ròng), "</span></span>
<span id="cb25-1783"><a href="#cb25-1783" aria-hidden="true" tabindex="-1"></a>        <span class="st">"total assets (tổng tài sản). "</span></span>
<span id="cb25-1784"><a href="#cb25-1784" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Report values in billions VND."</span></span>
<span id="cb25-1785"><a href="#cb25-1785" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb25-1786"><a href="#cb25-1786" aria-hidden="true" tabindex="-1"></a>    <span class="st">"construction_progress"</span>: (</span>
<span id="cb25-1787"><a href="#cb25-1787" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Compare this aerial image to a baseline. "</span></span>
<span id="cb25-1788"><a href="#cb25-1788" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Estimate the percentage completion of visible "</span></span>
<span id="cb25-1789"><a href="#cb25-1789" aria-hidden="true" tabindex="-1"></a>        <span class="st">"construction projects. Note any new structures, "</span></span>
<span id="cb25-1790"><a href="#cb25-1790" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cleared land, or infrastructure changes."</span></span>
<span id="cb25-1791"><a href="#cb25-1791" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-1792"><a href="#cb25-1792" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-1793"><a href="#cb25-1793" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1794"><a href="#cb25-1794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1795"><a href="#cb25-1795" aria-hidden="true" tabindex="-1"></a><span class="fu">### Retrieval-Augmented Multimodal Analysis</span></span>
<span id="cb25-1796"><a href="#cb25-1796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1797"><a href="#cb25-1797" aria-hidden="true" tabindex="-1"></a>For complex financial questions, we can combine VLM capabilities with retrieval from structured databases. The pipeline:</span>
<span id="cb25-1798"><a href="#cb25-1798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1799"><a href="#cb25-1799" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Query**: Analyst asks "Is Vingroup's construction activity in Vinhomes Grand Park accelerating?"</span>
<span id="cb25-1800"><a href="#cb25-1800" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Retrieve**: Fetch satellite time series, financial statements, news articles</span>
<span id="cb25-1801"><a href="#cb25-1801" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>**Process**: VLM analyzes satellite images; NLP processes text; tabular model processes financials</span>
<span id="cb25-1802"><a href="#cb25-1802" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>**Fuse**: Aggregate evidence across modalities</span>
<span id="cb25-1803"><a href="#cb25-1803" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>**Answer**: Generate a structured response with confidence scores and supporting evidence</span>
<span id="cb25-1804"><a href="#cb25-1804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1807"><a href="#cb25-1807" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb25-1808"><a href="#cb25-1808" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: rag-multimodal</span></span>
<span id="cb25-1809"><a href="#cb25-1809" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb25-1810"><a href="#cb25-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1811"><a href="#cb25-1811" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultimodalRAG:</span>
<span id="cb25-1812"><a href="#cb25-1812" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-1813"><a href="#cb25-1813" aria-hidden="true" tabindex="-1"></a><span class="co">    Retrieval-Augmented Generation with multimodal evidence.</span></span>
<span id="cb25-1814"><a href="#cb25-1814" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-1815"><a href="#cb25-1815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1816"><a href="#cb25-1816" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, datacore_client, vlm_model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-1817"><a href="#cb25-1817" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dc <span class="op">=</span> datacore_client</span>
<span id="cb25-1818"><a href="#cb25-1818" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vlm <span class="op">=</span> vlm_model</span>
<span id="cb25-1819"><a href="#cb25-1819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1820"><a href="#cb25-1820" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> retrieve_evidence(<span class="va">self</span>, ticker, date, modalities<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-1821"><a href="#cb25-1821" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-1822"><a href="#cb25-1822" aria-hidden="true" tabindex="-1"></a><span class="co">        Retrieve all available evidence for a firm at a given date.</span></span>
<span id="cb25-1823"><a href="#cb25-1823" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-1824"><a href="#cb25-1824" aria-hidden="true" tabindex="-1"></a>        evidence <span class="op">=</span> {}</span>
<span id="cb25-1825"><a href="#cb25-1825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1826"><a href="#cb25-1826" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"tabular"</span> <span class="kw">in</span> modalities:</span>
<span id="cb25-1827"><a href="#cb25-1827" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"tabular"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_firm_financials(</span>
<span id="cb25-1828"><a href="#cb25-1828" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb25-1829"><a href="#cb25-1829" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date,</span>
<span id="cb25-1830"><a href="#cb25-1830" aria-hidden="true" tabindex="-1"></a>                n_quarters<span class="op">=</span><span class="dv">4</span></span>
<span id="cb25-1831"><a href="#cb25-1831" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1832"><a href="#cb25-1832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1833"><a href="#cb25-1833" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"text"</span> <span class="kw">in</span> modalities:</span>
<span id="cb25-1834"><a href="#cb25-1834" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"text"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_news(</span>
<span id="cb25-1835"><a href="#cb25-1835" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb25-1836"><a href="#cb25-1836" aria-hidden="true" tabindex="-1"></a>                start_date<span class="op">=</span>pd.to_datetime(date) <span class="op">-</span> pd.Timedelta(days<span class="op">=</span><span class="dv">30</span>),</span>
<span id="cb25-1837"><a href="#cb25-1837" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date,</span>
<span id="cb25-1838"><a href="#cb25-1838" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">20</span></span>
<span id="cb25-1839"><a href="#cb25-1839" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1840"><a href="#cb25-1840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1841"><a href="#cb25-1841" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"image"</span> <span class="kw">in</span> modalities:</span>
<span id="cb25-1842"><a href="#cb25-1842" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"image"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_satellite_images(</span>
<span id="cb25-1843"><a href="#cb25-1843" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb25-1844"><a href="#cb25-1844" aria-hidden="true" tabindex="-1"></a>                date<span class="op">=</span>date,</span>
<span id="cb25-1845"><a href="#cb25-1845" aria-hidden="true" tabindex="-1"></a>                lookback_months<span class="op">=</span><span class="dv">6</span></span>
<span id="cb25-1846"><a href="#cb25-1846" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1847"><a href="#cb25-1847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1848"><a href="#cb25-1848" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> modalities <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="st">"ts"</span> <span class="kw">in</span> modalities:</span>
<span id="cb25-1849"><a href="#cb25-1849" aria-hidden="true" tabindex="-1"></a>            evidence[<span class="st">"ts"</span>] <span class="op">=</span> <span class="va">self</span>.dc.get_daily_returns(</span>
<span id="cb25-1850"><a href="#cb25-1850" aria-hidden="true" tabindex="-1"></a>                ticker<span class="op">=</span>ticker,</span>
<span id="cb25-1851"><a href="#cb25-1851" aria-hidden="true" tabindex="-1"></a>                start_date<span class="op">=</span>pd.to_datetime(date) <span class="op">-</span> pd.Timedelta(days<span class="op">=</span><span class="dv">90</span>),</span>
<span id="cb25-1852"><a href="#cb25-1852" aria-hidden="true" tabindex="-1"></a>                end_date<span class="op">=</span>date</span>
<span id="cb25-1853"><a href="#cb25-1853" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-1854"><a href="#cb25-1854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1855"><a href="#cb25-1855" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> evidence</span>
<span id="cb25-1856"><a href="#cb25-1856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1857"><a href="#cb25-1857" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> analyze(<span class="va">self</span>, ticker, date, question):</span>
<span id="cb25-1858"><a href="#cb25-1858" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb25-1859"><a href="#cb25-1859" aria-hidden="true" tabindex="-1"></a><span class="co">        Full multimodal analysis pipeline.</span></span>
<span id="cb25-1860"><a href="#cb25-1860" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb25-1861"><a href="#cb25-1861" aria-hidden="true" tabindex="-1"></a>        evidence <span class="op">=</span> <span class="va">self</span>.retrieve_evidence(ticker, date)</span>
<span id="cb25-1862"><a href="#cb25-1862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1863"><a href="#cb25-1863" aria-hidden="true" tabindex="-1"></a>        analysis <span class="op">=</span> {</span>
<span id="cb25-1864"><a href="#cb25-1864" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ticker"</span>: ticker,</span>
<span id="cb25-1865"><a href="#cb25-1865" aria-hidden="true" tabindex="-1"></a>            <span class="st">"date"</span>: date,</span>
<span id="cb25-1866"><a href="#cb25-1866" aria-hidden="true" tabindex="-1"></a>            <span class="st">"question"</span>: question,</span>
<span id="cb25-1867"><a href="#cb25-1867" aria-hidden="true" tabindex="-1"></a>            <span class="st">"evidence_available"</span>: <span class="bu">list</span>(evidence.keys()),</span>
<span id="cb25-1868"><a href="#cb25-1868" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modality_signals"</span>: {}</span>
<span id="cb25-1869"><a href="#cb25-1869" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb25-1870"><a href="#cb25-1870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1871"><a href="#cb25-1871" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tabular signal</span></span>
<span id="cb25-1872"><a href="#cb25-1872" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"tabular"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"tabular"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1873"><a href="#cb25-1873" aria-hidden="true" tabindex="-1"></a>            latest <span class="op">=</span> evidence[<span class="st">"tabular"</span>].iloc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb25-1874"><a href="#cb25-1874" aria-hidden="true" tabindex="-1"></a>            analysis[<span class="st">"modality_signals"</span>][<span class="st">"tabular"</span>] <span class="op">=</span> {</span>
<span id="cb25-1875"><a href="#cb25-1875" aria-hidden="true" tabindex="-1"></a>                <span class="st">"revenue_growth"</span>: latest.get(<span class="st">"revenue_growth"</span>, <span class="va">None</span>),</span>
<span id="cb25-1876"><a href="#cb25-1876" aria-hidden="true" tabindex="-1"></a>                <span class="st">"roe"</span>: latest.get(<span class="st">"roe"</span>, <span class="va">None</span>),</span>
<span id="cb25-1877"><a href="#cb25-1877" aria-hidden="true" tabindex="-1"></a>                <span class="st">"leverage"</span>: latest.get(<span class="st">"leverage"</span>, <span class="va">None</span>)</span>
<span id="cb25-1878"><a href="#cb25-1878" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-1879"><a href="#cb25-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1880"><a href="#cb25-1880" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text signal</span></span>
<span id="cb25-1881"><a href="#cb25-1881" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"text"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"text"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1882"><a href="#cb25-1882" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Aggregate sentiment from PhoBERT</span></span>
<span id="cb25-1883"><a href="#cb25-1883" aria-hidden="true" tabindex="-1"></a>            texts <span class="op">=</span> evidence[<span class="st">"text"</span>]</span>
<span id="cb25-1884"><a href="#cb25-1884" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(texts) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb25-1885"><a href="#cb25-1885" aria-hidden="true" tabindex="-1"></a>                avg_sentiment <span class="op">=</span> texts[<span class="st">"sentiment_score"</span>].mean()</span>
<span id="cb25-1886"><a href="#cb25-1886" aria-hidden="true" tabindex="-1"></a>                analysis[<span class="st">"modality_signals"</span>][<span class="st">"text"</span>] <span class="op">=</span> {</span>
<span id="cb25-1887"><a href="#cb25-1887" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"avg_sentiment"</span>: avg_sentiment,</span>
<span id="cb25-1888"><a href="#cb25-1888" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"n_articles"</span>: <span class="bu">len</span>(texts),</span>
<span id="cb25-1889"><a href="#cb25-1889" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"sentiment_trend"</span>: (</span>
<span id="cb25-1890"><a href="#cb25-1890" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"improving"</span> <span class="cf">if</span> texts[<span class="st">"sentiment_score"</span>].is_monotonic_increasing</span>
<span id="cb25-1891"><a href="#cb25-1891" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> <span class="st">"deteriorating"</span> <span class="cf">if</span> texts[<span class="st">"sentiment_score"</span>].is_monotonic_decreasing</span>
<span id="cb25-1892"><a href="#cb25-1892" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> <span class="st">"mixed"</span></span>
<span id="cb25-1893"><a href="#cb25-1893" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb25-1894"><a href="#cb25-1894" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb25-1895"><a href="#cb25-1895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1896"><a href="#cb25-1896" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Time series signal</span></span>
<span id="cb25-1897"><a href="#cb25-1897" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"ts"</span> <span class="kw">in</span> evidence <span class="kw">and</span> evidence[<span class="st">"ts"</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-1898"><a href="#cb25-1898" aria-hidden="true" tabindex="-1"></a>            ts <span class="op">=</span> evidence[<span class="st">"ts"</span>]</span>
<span id="cb25-1899"><a href="#cb25-1899" aria-hidden="true" tabindex="-1"></a>            analysis[<span class="st">"modality_signals"</span>][<span class="st">"ts"</span>] <span class="op">=</span> {</span>
<span id="cb25-1900"><a href="#cb25-1900" aria-hidden="true" tabindex="-1"></a>                <span class="st">"return_60d"</span>: (<span class="dv">1</span> <span class="op">+</span> ts[<span class="st">"ret"</span>]).prod() <span class="op">-</span> <span class="dv">1</span>,</span>
<span id="cb25-1901"><a href="#cb25-1901" aria-hidden="true" tabindex="-1"></a>                <span class="st">"volatility"</span>: ts[<span class="st">"ret"</span>].std() <span class="op">*</span> np.sqrt(<span class="dv">252</span>),</span>
<span id="cb25-1902"><a href="#cb25-1902" aria-hidden="true" tabindex="-1"></a>                <span class="st">"avg_turnover"</span>: ts[<span class="st">"turnover"</span>].mean()</span>
<span id="cb25-1903"><a href="#cb25-1903" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-1904"><a href="#cb25-1904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1905"><a href="#cb25-1905" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> analysis</span>
<span id="cb25-1906"><a href="#cb25-1906" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-1907"><a href="#cb25-1907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1908"><a href="#cb25-1908" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation and Deployment Considerations</span></span>
<span id="cb25-1909"><a href="#cb25-1909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1910"><a href="#cb25-1910" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation Protocol for Multimodal Financial Models</span></span>
<span id="cb25-1911"><a href="#cb25-1911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1912"><a href="#cb25-1912" aria-hidden="true" tabindex="-1"></a>Standard machine learning evaluation (random train/test split) is inappropriate for financial prediction. We require time-series-aware evaluation that respects the temporal ordering of information.</span>
<span id="cb25-1913"><a href="#cb25-1913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1914"><a href="#cb25-1914" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Evaluation Aspect <span class="pp">|</span> Correct Approach <span class="pp">|</span> Common Mistake <span class="pp">|</span></span>
<span id="cb25-1915"><a href="#cb25-1915" aria-hidden="true" tabindex="-1"></a><span class="pp">|--------------------------|------------------------|----------------------|</span></span>
<span id="cb25-1916"><a href="#cb25-1916" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Train/test split <span class="pp">|</span> Expanding or rolling time window <span class="pp">|</span> Random split (look-ahead bias) <span class="pp">|</span></span>
<span id="cb25-1917"><a href="#cb25-1917" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Feature timing <span class="pp">|</span> Features available before prediction date <span class="pp">|</span> Using concurrent or future information <span class="pp">|</span></span>
<span id="cb25-1918"><a href="#cb25-1918" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Missing modalities <span class="pp">|</span> Test with realistic missingness patterns <span class="pp">|</span> Complete-case only <span class="pp">|</span></span>
<span id="cb25-1919"><a href="#cb25-1919" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Performance metric <span class="pp">|</span> OOS $R^2$, IC, Sharpe of L-S portfolio <span class="pp">|</span> In-sample $R^2$ <span class="pp">|</span></span>
<span id="cb25-1920"><a href="#cb25-1920" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Statistical inference <span class="pp">|</span> @diebold2002comparing test for forecast comparison <span class="pp">|</span> Point estimates without SE <span class="pp">|</span></span>
<span id="cb25-1921"><a href="#cb25-1921" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Economic significance <span class="pp">|</span> Transaction-cost-adjusted portfolio returns <span class="pp">|</span> Ignoring implementation costs <span class="pp">|</span></span>
<span id="cb25-1922"><a href="#cb25-1922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1923"><a href="#cb25-1923" aria-hidden="true" tabindex="-1"></a>: Evaluation Best Practices for Multimodal Finance Models {#tbl-evaluation}</span>
<span id="cb25-1924"><a href="#cb25-1924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1925"><a href="#cb25-1925" aria-hidden="true" tabindex="-1"></a><span class="fu">### Computational Budget</span></span>
<span id="cb25-1926"><a href="#cb25-1926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1927"><a href="#cb25-1927" aria-hidden="true" tabindex="-1"></a>Multimodal models are computationally expensive. @tbl-compute-budget provides order-of-magnitude estimates for Vietnamese equity markets.</span>
<span id="cb25-1928"><a href="#cb25-1928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1929"><a href="#cb25-1929" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Component <span class="pp">|</span> Single Firm-Quarter <span class="pp">|</span> Full Panel (1000 firms × 40 quarters) <span class="pp">|</span></span>
<span id="cb25-1930"><a href="#cb25-1930" aria-hidden="true" tabindex="-1"></a><span class="pp">|-------------------|---------------|----------------------------|</span></span>
<span id="cb25-1931"><a href="#cb25-1931" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> PhoBERT text encoding <span class="pp">|</span> 0.5s <span class="pp">|</span> \~5.5 hours <span class="pp">|</span></span>
<span id="cb25-1932"><a href="#cb25-1932" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> ResNet50 satellite feature <span class="pp">|</span> 0.1s <span class="pp">|</span> \~1.1 hours <span class="pp">|</span></span>
<span id="cb25-1933"><a href="#cb25-1933" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Time series encoding (CNN) <span class="pp">|</span> 0.01s <span class="pp">|</span> \~7 minutes <span class="pp">|</span></span>
<span id="cb25-1934"><a href="#cb25-1934" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Tabular preprocessing <span class="pp">|</span> <span class="sc">\&lt;</span>0.01s <span class="pp">|</span> \~1 minute <span class="pp">|</span></span>
<span id="cb25-1935"><a href="#cb25-1935" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Cross-attention fusion (forward) <span class="pp">|</span> 0.05s <span class="pp">|</span> \~33 minutes <span class="pp">|</span></span>
<span id="cb25-1936"><a href="#cb25-1936" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Training (50 epochs) <span class="pp">|</span> -- <span class="pp">|</span> \~12 hours (GPU) <span class="pp">|</span></span>
<span id="cb25-1937"><a href="#cb25-1937" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Full pipeline <span class="pp">|</span> -- <span class="pp">|</span> \~1 day (single GPU) <span class="pp">|</span></span>
<span id="cb25-1938"><a href="#cb25-1938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1939"><a href="#cb25-1939" aria-hidden="true" tabindex="-1"></a>: Computational Budget for Multimodal Pipeline {#tbl-compute-budget}</span>
<span id="cb25-1940"><a href="#cb25-1940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1941"><a href="#cb25-1941" aria-hidden="true" tabindex="-1"></a>The practical implication is that pre-computation of unimodal embeddings is essential. Extract and cache PhoBERT embeddings, CNN features, and time-series representations once; reuse them across all fusion experiments. Only the fusion layers need retraining when the architecture changes.</span>
<span id="cb25-1942"><a href="#cb25-1942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1943"><a href="#cb25-1943" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Exercises</span></span>
<span id="cb25-1944"><a href="#cb25-1944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1945"><a href="#cb25-1945" aria-hidden="true" tabindex="-1"></a><span class="co">1.  **Contrastive Pre-Training for Vietnamese Finance.** Implement the FinancialCLIP contrastive alignment for paired (annual report text, satellite image) data. Train on 2014-2020 data and evaluate alignment quality on 2021-2024 by measuring zero-shot retrieval accuracy: given a text description, can the model retrieve the correct satellite image (and vice versa)? Report Recall\@1, Recall\@5, and Recall\@10.</span></span>
<span id="cb25-1946"><a href="#cb25-1946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1947"><a href="#cb25-1947" aria-hidden="true" tabindex="-1"></a><span class="co">2.  **Fusion Architecture Search.** Implement the following additional fusion strategies beyond the three in this chapter: (a) bilinear fusion with low-rank approximation, (b) mixture-of-experts with $2^M - 1$ expert networks, and (c) FiLM (Feature-wise Linear Modulation) conditioning. Compare all six strategies on forward quarterly return prediction using the same time-series cross-validation protocol. Which architecture achieves the best out-of-sample Sharpe ratio after transaction costs?</span></span>
<span id="cb25-1948"><a href="#cb25-1948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1949"><a href="#cb25-1949" aria-hidden="true" tabindex="-1"></a><span class="co">3.  **Missing Modality Robustness.** Using the RobustFusionModel, systematically evaluate degradation as modalities are removed. Start with all four modalities and progressively remove them in all possible orderings. Plot the performance surface: $R^2$ as a function of the number and identity of available modalities. Which single modality is most informative? Which pair? Is there diminishing returns to adding the third and fourth modality?</span></span>
<span id="cb25-1950"><a href="#cb25-1950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1951"><a href="#cb25-1951" aria-hidden="true" tabindex="-1"></a><span class="co">4.  **Multimodal Earnings Call Analysis.** If earnings call audio or transcripts are available from DataCore.vn, extend the multimodal earnings surprise model to include a fifth modality: audio features (vocal tone, speaking rate, pause patterns). Use the wav2vec2 model to extract audio embeddings. Does the CEO's vocal tone add predictive power beyond the transcript text? Implement the @mayew2012power methodology for comparing vocal and textual signals.</span></span>
<span id="cb25-1952"><a href="#cb25-1952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1953"><a href="#cb25-1953" aria-hidden="true" tabindex="-1"></a><span class="co">5.  **Document Understanding Benchmark.** Construct a benchmark dataset of 200 Vietnamese annual report pages with manually annotated financial fields (revenue, COGS, net income, total assets, total equity, total debt). Evaluate three approaches: (a) OCR + rule-based extraction (Chapter 61), (b) LayoutLMv3 fine-tuned on 100 pages, and (c) zero-shot VLM extraction via GPT-4V or Gemini. Report field-level exact match accuracy and mean absolute percentage error for numerical values.</span></span>
<span id="cb25-1954"><a href="#cb25-1954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1955"><a href="#cb25-1955" aria-hidden="true" tabindex="-1"></a><span class="co">6.  **Multimodal Factor Construction.** Using the best-performing fusion model, generate firm-quarter-level multimodal scores. Sort firms into quintiles on this score and compute equal- and value-weighted portfolio returns. Is the multimodal long-short factor priced in the cross-section (Fama-MacBeth)? Does it subsume the textual sentiment factor from Chapter 60 or the satellite-based factor from Chapter 61? Report spanning test results. --&gt;</span></span>
<span id="cb25-1956"><a href="#cb25-1956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1957"><a href="#cb25-1957" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb25-1958"><a href="#cb25-1958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1959"><a href="#cb25-1959" aria-hidden="true" tabindex="-1"></a>This chapter developed the multimodal learning framework for Vietnamese financial markets, progressing from foundational representation alignment through production-ready fusion architectures.</span>
<span id="cb25-1960"><a href="#cb25-1960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1961"><a href="#cb25-1961" aria-hidden="true" tabindex="-1"></a>The key contributions are threefold. First, we demonstrated that financial data is inherently multimodal and that effective fusion requires explicit architectural choices (e.g., contrastive alignment, cross-attention mechanisms, and missing-modality handling) rather than naive concatenation. The FinancialCLIP alignment framework learns a shared embedding space where text, image, tabular, and time-series representations are geometrically comparable, enabling cross-modal retrieval and transfer.</span>
<span id="cb25-1962"><a href="#cb25-1962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1963"><a href="#cb25-1963" aria-hidden="true" tabindex="-1"></a>Second, we built and compared five fusion architectures (early, late with gating, cross-attention, robust with modality dropout, and the custom earnings surprise model) on the prediction of forward returns and earnings surprises. The cross-attention architecture with modality dropout consistently outperforms unimodal baselines and simpler fusion strategies, though the margin varies across prediction horizons and firm characteristics.</span>
<span id="cb25-1964"><a href="#cb25-1964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1965"><a href="#cb25-1965" aria-hidden="true" tabindex="-1"></a>Third, we showed how large vision-language models can perform zero-shot financial analysis on Vietnamese documents and satellite imagery, offering a path to multimodal analysis without task-specific training. The retrieval-augmented multimodal pipeline combines the strengths of structured retrieval (from DataCore.vn) with the reasoning capabilities of VLMs.</span>
<span id="cb25-1966"><a href="#cb25-1966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-1967"><a href="#cb25-1967" aria-hidden="true" tabindex="-1"></a>The practical lesson for researchers working with Vietnamese financial data is that multimodal fusion is most valuable when modalities are complementary: text captures management intent and market narrative, images capture physical economic activity, tabular data provides precise quantitative snapshots, and time series captures market dynamics. When a single modality already captures most of the relevant signal (as tabular features do for many standard prediction tasks), the marginal gain from fusion is modest. When the prediction task requires information that no single modality captures well (as earnings surprises require both quantitative and qualitative assessment), multimodal models provide their largest advantage.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span id="copyright"></span> Mike. All rights reserved.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mikenguyen13/tidy_finance_vn/edit/main/74_multimodel.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mikenguyen13/tidy_finance_vn/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>