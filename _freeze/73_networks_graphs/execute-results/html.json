{
  "hash": "fb6cd80d8062e251dd260b5aedcdcbe3",
  "result": {
    "engine": "jupyter",
    "markdown": "# Networks and Graphs in Finance\n\nFinancial markets are networks. Every stock return is shaped by connections: firms share supply chains, directors, auditors, investors, lenders, and regulators. Shocks propagate through these links (e.g., a bankruptcy ripples through supplier networks, a central bank liquidity squeeze radiates through interbank exposures, and information diffuses through board interlocks and institutional co-ownership). Yet the dominant empirical paradigm in finance treats firms as isolated observations indexed by $(i, t)$, connected only through their shared exposure to common factors. This chapter introduces tools for modeling, measuring, and exploiting the network structure that standard panel regressions ignore.\n\nThe Vietnamese financial system is particularly network-dense. State ownership creates a lattice of cross-connected enterprises: the same line ministry may oversee the borrower, the lender, and the insurer. Pyramidal business groups (such as Vingroup, Masan, and FPT) link dozens of listed and unlisted entities through chains of equity ownership. The banking system is small and concentrated, with a few state-owned commercial banks accounting for the majority of assets, generating dense interbank exposures. Board interlocks (e.g., directors who serve on multiple boards simultaneously) are pervasive and often follow ownership lines. And the equity market itself exhibits return co-movement patterns that, when represented as a correlation network, reveal sector-level and ownership-level clustering invisible in standard factor analysis.\n\nThis chapter covers the full spectrum of network methods used in financial economics, from classical graph theory through modern graph neural networks (GNNs). We organize the material in seven sections. First, graph theory fundamentals and the representation of financial data as networks. Second, ownership and control networks, which are the most distinctive network structure in Vietnamese markets. Third, board interlock and governance networks. Fourth, supply chain and trade networks. Fifth, correlation and co-movement networks for portfolio construction and systemic risk monitoring. Sixth, interbank and contagion networks. Seventh, graph neural networks and graph-based machine learning for asset pricing, credit risk, and anomaly detection.\n\n::: {#setup .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Graph libraries\nimport networkx as nx\nfrom scipy import sparse\nfrom scipy.spatial.distance import squareform\n\n# Statistical and econometric\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom linearmodels.panel import PanelOLS\n\n# Visualization\nimport plotnine as p9\nfrom mizani.formatters import percent_format, comma_format\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n# Deep learning (for GNNs later)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n```\n:::\n\n\n::: {#3bab7cb5 .cell execution_count=2}\n``` {.python .cell-code}\n# DataCore.vn API\nfrom datacore import DataCore\ndc = DataCore()\n```\n:::\n\n\n## Graph Theory Foundations for Finance\n\n### Representing Financial Data as Graphs\n\nA graph $G = (V, E)$ consists of a set of vertices (nodes) $V$ and edges (links) $E \\subseteq V \\times V$. In financial networks, nodes represent economic agents, such as firms, banks, investors, directors, and edges represent relationships including ownership stakes, lending, board seats, supply contracts, and return co-movement.\n\nFinancial graphs come in several varieties:\n\n**Directed vs. undirected.** Ownership is directed: firm $A$ owns a stake in firm $B$, but not necessarily vice versa. Board interlocks are undirected: if director $d$ sits on both firm $A$'s and firm $B$'s boards, the connection is symmetric. Supply chains are directed: $A$ supplies to $B$.\n\n**Weighted vs. unweighted.** Ownership networks are naturally weighted by the ownership percentage. Correlation networks are weighted by the pairwise correlation coefficient. Board interlocks can be weighted by the number of shared directors.\n\n**Static vs. dynamic.** Most financial networks evolve over time as ownership changes, directors rotate, and correlations shift. A temporal graph $G_t = (V_t, E_t)$ captures this evolution.\n\n**Bipartite vs. unipartite.** The raw data for many financial networks is bipartite: directors $\\times$ firms, investors $\\times$ stocks, banks $\\times$ borrowers. The one-mode projection converts this to a unipartite graph: two firms are connected if they share a director, two stocks are connected if they share an institutional investor, etc.\n\n### Key Graph Metrics\n\nFor a graph $G$ with $n = |V|$ nodes and $m = |E|$ edges, we define the following metrics, each with a specific financial interpretation.\n\n**Degree centrality.** The degree $k_i$ of node $i$ is the number of edges incident to $i$. In a directed graph, we distinguish in-degree $k_i^{\\text{in}}$ (edges pointing to $i$) and out-degree $k_i^{\\text{out}}$ (edges from $i$). Normalized degree centrality is:\n\n$$\nC_D(i) = \\frac{k_i}{n - 1}\n$$ {#eq-degree-centrality}\n\nIn an ownership network, high out-degree means a firm owns stakes in many others (conglomerate); high in-degree means many entities own stakes in the firm (dispersed ownership).\n\n**Betweenness centrality.** The fraction of shortest paths between all pairs of nodes that pass through node $i$:\n\n$$\nC_B(i) = \\sum_{s \\neq i \\neq t} \\frac{\\sigma_{st}(i)}{\\sigma_{st}}\n$$ {#eq-betweenness}\n\nwhere $\\sigma_{st}$ is the total number of shortest paths from $s$ to $t$ and $\\sigma_{st}(i)$ is the number that pass through $i$. High betweenness identifies \"bridge\" nodes (i.e., firms or banks that connect otherwise disconnected parts of the financial system). The failure of a high-betweenness bank can fragment the interbank network.\n\n**Eigenvector centrality.** A node is central if it is connected to other central nodes. The eigenvector centrality is the solution to:\n\n$$\n\\lambda \\mathbf{c} = A \\mathbf{c}\n$$ {#eq-eigenvector-centrality}\n\nwhere $A$ is the adjacency matrix and $\\lambda$ is the largest eigenvalue. Google's PageRank is a regularized variant designed for directed graphs. In financial networks, eigenvector centrality identifies systemically important institutions (i.e., those connected to other important institutions).\n\n**Clustering coefficient.** The fraction of a node's neighbors that are also neighbors of each other:\n\n$$\nC_C(i) = \\frac{2 T_i}{k_i(k_i - 1)}\n$$ {#eq-clustering}\n\nwhere $T_i$ is the number of triangles containing node $i$. High clustering indicates tightly knit groups (e.g., business groups, lending circles, co-invested portfolios).\n\n**Community structure.** Many financial networks exhibit modular structure: groups of densely connected nodes with sparse connections between groups. Community detection algorithms (Louvain, label propagation, spectral clustering) identify these modules, which in financial networks often correspond to business groups, industry sectors, or lending clusters.\n\n::: {#graph-fundamentals .cell execution_count=3}\n``` {.python .cell-code}\ndef compute_network_metrics(G):\n    \"\"\"\n    Compute standard network metrics for a graph.\n\n    Parameters\n    ----------\n    G : nx.Graph or nx.DiGraph\n        Input graph.\n\n    Returns\n    -------\n    dict : Node-level and graph-level metrics.\n    \"\"\"\n    is_directed = G.is_directed()\n\n    # Node-level metrics\n    if is_directed:\n        in_degree = dict(G.in_degree())\n        out_degree = dict(G.out_degree())\n        degree = {n: in_degree[n] + out_degree[n] for n in G.nodes()}\n    else:\n        degree = dict(G.degree())\n\n    betweenness = nx.betweenness_centrality(G, weight=\"weight\")\n    eigenvector = nx.eigenvector_centrality_numpy(\n        G, weight=\"weight\"\n    ) if len(G) > 0 else {}\n    clustering = nx.clustering(G, weight=\"weight\") if not is_directed else {}\n\n    # PageRank (works for both directed and undirected)\n    pagerank = nx.pagerank(G, weight=\"weight\")\n\n    # Graph-level metrics\n    n_nodes = G.number_of_nodes()\n    n_edges = G.number_of_edges()\n    density = nx.density(G)\n\n    # Connected components\n    if is_directed:\n        n_weak_components = nx.number_weakly_connected_components(G)\n        n_strong_components = nx.number_strongly_connected_components(G)\n    else:\n        n_components = nx.number_connected_components(G)\n\n    # Degree distribution statistics\n    degrees = list(degree.values())\n    avg_degree = np.mean(degrees) if degrees else 0\n    max_degree = max(degrees) if degrees else 0\n\n    # Assortativity\n    assortativity = nx.degree_assortativity_coefficient(G)\n\n    # Community detection (Louvain)\n    if not is_directed:\n        try:\n            communities = nx.community.louvain_communities(G)\n            modularity = nx.community.modularity(G, communities)\n            n_communities = len(communities)\n        except Exception:\n            modularity, n_communities = np.nan, 0\n    else:\n        modularity, n_communities = np.nan, 0\n\n    node_metrics = pd.DataFrame({\n        \"degree\": degree,\n        \"betweenness\": betweenness,\n        \"eigenvector\": eigenvector,\n        \"pagerank\": pagerank,\n        \"clustering\": clustering if clustering else {n: np.nan for n in G.nodes()}\n    })\n\n    graph_metrics = {\n        \"n_nodes\": n_nodes,\n        \"n_edges\": n_edges,\n        \"density\": density,\n        \"avg_degree\": avg_degree,\n        \"max_degree\": max_degree,\n        \"assortativity\": assortativity,\n        \"modularity\": modularity,\n        \"n_communities\": n_communities\n    }\n\n    return node_metrics, graph_metrics\n```\n:::\n\n\n### The Adjacency Matrix and Its Spectral Properties\n\nThe adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$ encodes the graph structure: $A_{ij} = w_{ij}$ if there is an edge from $i$ to $j$ with weight $w_{ij}$, and $A_{ij} = 0$ otherwise. For undirected graphs, $A$ is symmetric.\n\nThe graph Laplacian $L = D - A$ (where $D$ is the diagonal degree matrix) has eigenvalues $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\ldots \\leq \\lambda_n$ with important structural interpretations:\n\n-   The multiplicity of $\\lambda = 0$ equals the number of connected components.\n-   The second eigenvalue $\\lambda_2$ (the algebraic connectivity or Fiedler value) measures how well-connected the graph is. Low $\\lambda_2$ implies the graph has a bottleneck, which is a weak point where cutting a few edges would disconnect large portions.\n-   The eigenvectors of $L$ provide the spectral embedding of the graph, which is the foundation for spectral clustering and graph convolutional networks.\n\nThe normalized Laplacian $\\tilde{L} = D^{-1/2} L D^{-1/2}$ is used in GCNs because it stabilizes message passing across nodes with different degrees.\n\n::: {#spectral-analysis .cell execution_count=4}\n``` {.python .cell-code}\ndef spectral_graph_analysis(A, n_components=10):\n    \"\"\"\n    Compute spectral properties of a financial network.\n\n    Parameters\n    ----------\n    A : np.ndarray or sparse matrix\n        Adjacency matrix.\n    n_components : int\n        Number of eigenvalues/vectors to compute.\n\n    Returns\n    -------\n    dict : Eigenvalues, algebraic connectivity, spectral gap.\n    \"\"\"\n    n = A.shape[0]\n\n    if sparse.issparse(A):\n        A_dense = A.toarray()\n    else:\n        A_dense = A\n\n    # Degree matrix\n    D = np.diag(A_dense.sum(axis=1))\n\n    # Graph Laplacian\n    L = D - A_dense\n\n    # Normalized Laplacian\n    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D) + 1e-10))\n    L_norm = D_inv_sqrt @ L @ D_inv_sqrt\n\n    # Eigendecomposition (smallest eigenvalues)\n    eigenvalues, eigenvectors = np.linalg.eigh(L_norm)\n\n    # Sort by eigenvalue\n    idx = np.argsort(eigenvalues)\n    eigenvalues = eigenvalues[idx]\n    eigenvectors = eigenvectors[:, idx]\n\n    # Algebraic connectivity (Fiedler value)\n    fiedler_value = eigenvalues[1] if n > 1 else 0\n    fiedler_vector = eigenvectors[:, 1] if n > 1 else np.zeros(n)\n\n    # Spectral gap\n    spectral_gap = eigenvalues[1] - eigenvalues[0] if n > 1 else 0\n\n    return {\n        \"eigenvalues\": eigenvalues[:n_components],\n        \"fiedler_value\": fiedler_value,\n        \"fiedler_vector\": fiedler_vector,\n        \"spectral_gap\": spectral_gap,\n        \"spectral_embedding\": eigenvectors[:, 1:n_components + 1]\n    }\n```\n:::\n\n\n## Ownership and Control Networks\n\n### Vietnamese Ownership Structure\n\nOwnership networks are arguably the most economically consequential graph structure in Vietnamese markets. The Vietnamese corporate landscape is characterized by three distinctive features that generate complex ownership topologies:\n\n**State ownership pyramids.** The government holds equity in hundreds of firms through a hierarchy of holding entities: the State Capital Investment Corporation (SCIC), line ministries, provincial People's Committees, and state-owned economic groups (tập đoàn kinh tế nhà nước). These chains create multi-layered pyramids where the state's ultimate control rights may substantially exceed its cash flow rights.\n\n**Private business groups.** Vietnamese conglomerates (Vingroup, Masan, FPT, Hoà Phát, Thaco) create complex webs of cross-ownership, subsidiary relationships, and associate stakes. These structures serve multiple purposes: internal capital markets, tax optimization, regulatory arbitrage, and control enhancement.\n\n**Circular and cross-ownership.** Vietnamese regulations do not effectively prevent circular ownership (firm $A$ owns firm $B$ which owns firm $C$ which owns firm $A$), creating loops in the ownership graph that amplify control beyond direct stakes and inflate accounting equity [@bebchuk1999rent].\n\n::: {#ownership-network-data .cell execution_count=5}\n``` {.python .cell-code}\n# Load ownership data\nownership = dc.get_ownership_network(\n    date=\"2024-06-30\",\n    min_stake=1.0  # Minimum 1% ownership stake\n)\n\n# Load firm characteristics\nfirms = dc.get_firm_characteristics(\n    start_date=\"2024-01-01\",\n    end_date=\"2024-06-30\"\n).groupby(\"ticker\").last().reset_index()\n\nprint(f\"Ownership edges: {len(ownership)}\")\nprint(f\"Unique owners: {ownership['owner_id'].nunique()}\")\nprint(f\"Unique targets: {ownership['target_ticker'].nunique()}\")\n```\n:::\n\n\n::: {#build-ownership-graph .cell execution_count=6}\n``` {.python .cell-code}\n# Build directed ownership graph\nG_own = nx.DiGraph()\n\n# Add firm nodes with attributes\nfor _, row in firms.iterrows():\n    G_own.add_node(\n        row[\"ticker\"],\n        node_type=\"firm\",\n        market_cap=row.get(\"market_cap\", 0),\n        industry=row.get(\"industry\", \"Unknown\"),\n        is_soe=row.get(\"state_ownership_pct\", 0) > 50\n    )\n\n# Add ownership edges\nfor _, row in ownership.iterrows():\n    owner = row[\"owner_id\"]\n    target = row[\"target_ticker\"]\n    stake = row[\"ownership_pct\"]\n\n    # Add owner node if not present\n    if owner not in G_own:\n        G_own.add_node(\n            owner,\n            node_type=row.get(\"owner_type\", \"entity\"),\n            market_cap=0,\n            industry=\"Holding\"\n        )\n\n    G_own.add_edge(owner, target, weight=stake / 100)\n\nnode_metrics_own, graph_metrics_own = compute_network_metrics(G_own)\n\nprint(f\"\\nOwnership Network Summary:\")\nfor k, v in graph_metrics_own.items():\n    print(f\"  {k}: {v}\")\n```\n:::\n\n\n::: {#tbl-ownership-network-stats .cell tbl-cap='Ownership Network: Graph-Level Statistics' execution_count=7}\n``` {.python .cell-code}\nown_stats = pd.DataFrame([graph_metrics_own]).T\nown_stats.columns = [\"Value\"]\nown_stats = own_stats.round(4)\nown_stats\n```\n:::\n\n\n### Ultimate Ownership and Control Chains\n\nDirect ownership understates the actual control exercised through pyramidal chains. The ultimate ownership stake of entity $A$ in firm $Z$ through a chain $A \\to B \\to C \\to Z$ is the product of intermediate stakes:\n\n$$\n\\omega_{A \\to Z}^{\\text{ultimate}} = \\prod_{(i,j) \\in \\text{path}(A, Z)} w_{ij}\n$$ {#eq-ultimate-ownership}\n\nwhere $w_{ij}$ is the direct stake of $i$ in $j$. When multiple paths exist from $A$ to $Z$, the total ultimate ownership is the sum across paths. The control rights, however, are determined by the weakest link in the chain (the minimum stake along the path), reflecting the principle that control requires a majority at each level.\n\n::: {#ultimate-ownership .cell execution_count=8}\n``` {.python .cell-code}\ndef compute_ultimate_ownership(G, source, target, max_depth=10):\n    \"\"\"\n    Compute ultimate ownership of source in target through all paths.\n\n    Parameters\n    ----------\n    G : nx.DiGraph\n        Ownership graph with edge weights as ownership fractions.\n    source : str\n        Ultimate owner node.\n    target : str\n        Target firm node.\n    max_depth : int\n        Maximum chain length to consider.\n\n    Returns\n    -------\n    dict : Total ownership, control rights, number of paths.\n    \"\"\"\n    if source not in G or target not in G:\n        return {\"ownership\": 0, \"control\": 0, \"n_paths\": 0}\n\n    total_ownership = 0\n    max_control = 0\n    n_paths = 0\n\n    # Find all simple paths from source to target\n    try:\n        for path in nx.all_simple_paths(G, source, target,\n                                         cutoff=max_depth):\n            # Cash flow rights: product of stakes\n            ownership = 1.0\n            min_stake = 1.0\n            for i in range(len(path) - 1):\n                edge_data = G[path[i]][path[i + 1]]\n                stake = edge_data.get(\"weight\", 0)\n                ownership *= stake\n                min_stake = min(min_stake, stake)\n\n            total_ownership += ownership\n            max_control = max(max_control, min_stake)\n            n_paths += 1\n    except nx.NetworkXNoPath:\n        pass\n\n    return {\n        \"ownership\": total_ownership,\n        \"control\": max_control,\n        \"n_paths\": n_paths\n    }\n\n\ndef compute_control_wedge(G, firms_list, max_depth=5):\n    \"\"\"\n    Compute the wedge between control and cash flow rights\n    for the largest shareholder of each firm.\n\n    The wedge = control rights - cash flow rights.\n    Positive wedge → potential for tunneling.\n    \"\"\"\n    wedge_data = []\n\n    for firm in firms_list:\n        if firm not in G:\n            continue\n\n        # Find all direct owners\n        predecessors = list(G.predecessors(firm))\n        if not predecessors:\n            continue\n\n        # Find largest direct owner\n        stakes = {p: G[p][firm][\"weight\"] for p in predecessors}\n        largest_owner = max(stakes, key=stakes.get)\n        direct_stake = stakes[largest_owner]\n\n        # Compute ultimate ownership through all paths\n        ultimate = compute_ultimate_ownership(\n            G, largest_owner, firm, max_depth\n        )\n\n        wedge_data.append({\n            \"ticker\": firm,\n            \"largest_owner\": largest_owner,\n            \"direct_stake\": direct_stake,\n            \"ultimate_ownership\": ultimate[\"ownership\"],\n            \"control_rights\": ultimate[\"control\"],\n            \"n_ownership_paths\": ultimate[\"n_paths\"],\n            \"wedge\": ultimate[\"control\"] - ultimate[\"ownership\"]\n        })\n\n    return pd.DataFrame(wedge_data)\n\n\n# Compute for all listed firms\nlisted_firms = [n for n, d in G_own.nodes(data=True)\n                if d.get(\"node_type\") == \"firm\"]\nwedge_df = compute_control_wedge(G_own, listed_firms)\n```\n:::\n\n\n::: {#tbl-control-wedge .cell tbl-cap='Control-Cash Flow Wedge: Summary Statistics' execution_count=9}\n``` {.python .cell-code}\nwedge_summary = wedge_df[\n    [\"direct_stake\", \"ultimate_ownership\", \"control_rights\",\n     \"n_ownership_paths\", \"wedge\"]\n].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]).T.round(4)\nwedge_summary\n```\n:::\n\n\n::: {#fig-control-wedge .cell execution_count=10}\n``` {.python .cell-code}\n(\n    p9.ggplot(wedge_df, p9.aes(x=\"wedge\"))\n    + p9.geom_histogram(bins=50, fill=\"#2E5090\", alpha=0.7)\n    + p9.geom_vline(xintercept=0, linetype=\"dashed\", color=\"#C0392B\")\n    + p9.labs(\n        x=\"Control Wedge (Control Rights − Cash Flow Rights)\",\n        y=\"Count\",\n        title=\"Control-Ownership Wedge: Positive Values Indicate Tunneling Risk\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(10, 5))\n)\n```\n:::\n\n\n### Ownership Centrality and Firm Value\n\nWe test whether a firm's position in the ownership network predicts its market valuation, controlling for standard determinants:\n\n$$\nQ_{i,t} = \\beta_0 + \\beta_1 \\text{Centrality}_{i,t} + \\beta_2 \\text{Wedge}_{i,t} + \\boldsymbol{\\gamma}' \\mathbf{X}_{i,t} + \\alpha_{\\text{ind}} + \\delta_t + \\varepsilon_{i,t}\n$$ {#eq-network-valuation}\n\n::: {#ownership-valuation .cell execution_count=11}\n``` {.python .cell-code}\n# Merge network metrics with firm characteristics\nnode_metrics_own_df = node_metrics_own.reset_index().rename(\n    columns={\"index\": \"ticker\"}\n)\n\nvaluation_data = firms.merge(node_metrics_own_df, on=\"ticker\", how=\"inner\")\nvaluation_data = valuation_data.merge(\n    wedge_df[[\"ticker\", \"wedge\", \"n_ownership_paths\"]],\n    on=\"ticker\", how=\"left\"\n)\n\n# Panel regression\nval_clean = valuation_data.dropna(\n    subset=[\"tobins_q\", \"eigenvector\", \"wedge\",\n            \"log_size\", \"profitability\", \"leverage\"]\n)\n\nif len(val_clean) > 50:\n    model_network_val = sm.OLS(\n        val_clean[\"tobins_q\"],\n        sm.add_constant(val_clean[[\n            \"eigenvector\", \"betweenness\", \"wedge\",\n            \"log_size\", \"profitability\", \"leverage\"\n        ]])\n    ).fit(cov_type=\"HC1\")\n\n    print(\"Ownership Network Position and Firm Value:\")\n    for var in [\"eigenvector\", \"betweenness\", \"wedge\"]:\n        print(f\"  {var}: {model_network_val.params[var]:.4f} \"\n              f\"(t = {model_network_val.tvalues[var]:.3f})\")\n```\n:::\n\n\n### Business Group Detection\n\nBusiness groups (i.e., collections of legally independent firms linked by common ownership) are a defining feature of Vietnamese corporate structure. We detect them algorithmically using community detection on the ownership graph.\n\n::: {#business-groups .cell execution_count=12}\n``` {.python .cell-code}\ndef detect_business_groups(G, min_group_size=3, ownership_threshold=0.10):\n    \"\"\"\n    Detect business groups from ownership network.\n\n    A business group is a connected component in the undirected\n    projection of the ownership graph, filtered for economically\n    meaningful ownership stakes.\n\n    Parameters\n    ----------\n    G : nx.DiGraph\n        Directed ownership graph.\n    min_group_size : int\n        Minimum firms in a group.\n    ownership_threshold : float\n        Minimum ownership stake to count as a link.\n\n    Returns\n    -------\n    DataFrame : Group assignments with apex firm.\n    \"\"\"\n    # Filter edges by threshold\n    G_filtered = nx.DiGraph()\n    for u, v, d in G.edges(data=True):\n        if d.get(\"weight\", 0) >= ownership_threshold:\n            G_filtered.add_edge(u, v, **d)\n\n    # Convert to undirected for component detection\n    G_undirected = G_filtered.to_undirected()\n\n    # Find connected components\n    components = list(nx.connected_components(G_undirected))\n\n    # Filter by size\n    groups = [c for c in components if len(c) >= min_group_size]\n\n    # For each group, identify the apex (top of pyramid)\n    group_data = []\n    for group_id, members in enumerate(groups):\n        subgraph = G_filtered.subgraph(members)\n\n        # Apex: node with highest out-degree and lowest in-degree\n        # (controls others but is not controlled)\n        scores = {}\n        for node in members:\n            in_deg = subgraph.in_degree(node)\n            out_deg = subgraph.out_degree(node)\n            scores[node] = out_deg - in_deg\n\n        apex = max(scores, key=scores.get) if scores else list(members)[0]\n\n        for member in members:\n            node_data = G.nodes.get(member, {})\n            group_data.append({\n                \"ticker\": member,\n                \"group_id\": group_id,\n                \"group_size\": len(members),\n                \"apex\": apex,\n                \"is_apex\": member == apex,\n                \"node_type\": node_data.get(\"node_type\", \"unknown\"),\n                \"industry\": node_data.get(\"industry\", \"Unknown\"),\n                \"market_cap\": node_data.get(\"market_cap\", 0)\n            })\n\n    return pd.DataFrame(group_data)\n\n\ngroups_df = detect_business_groups(G_own)\nprint(f\"Business groups detected: {groups_df['group_id'].nunique()}\")\nprint(f\"Firms in groups: {len(groups_df[groups_df['node_type'] == 'firm'])}\")\n```\n:::\n\n\n::: {#tbl-business-groups .cell tbl-cap='Largest Vietnamese Business Groups by Ownership Network Analysis' execution_count=13}\n``` {.python .cell-code}\ntop_groups = (\n    groups_df.groupby(\"group_id\")\n    .agg(\n        apex=(\"apex\", \"first\"),\n        n_members=(\"ticker\", \"count\"),\n        n_listed=(\"node_type\", lambda x: (x == \"firm\").sum()),\n        total_mcap=(\"market_cap\", \"sum\"),\n        industries=(\"industry\", lambda x: x.nunique())\n    )\n    .sort_values(\"total_mcap\", ascending=False)\n    .head(15)\n    .reset_index()\n)\ntop_groups[\"total_mcap_bn\"] = top_groups[\"total_mcap\"] / 1e9\ntop_groups[[\"apex\", \"n_members\", \"n_listed\", \"total_mcap_bn\", \"industries\"]]\n```\n:::\n\n\n## Board Interlock Networks\n\n### Construction\n\nA board interlock exists when a director serves on the boards of two or more firms simultaneously. The board interlock network is a unipartite projection of the bipartite director$\\times$firm graph: two firms are connected if they share at least one director, weighted by the number of shared directors.\n\nBoard interlocks are an information channel. @bizjak2008does show that compensation practices diffuse through board networks. @cai2014board demonstrate that firms connected through interlocks have correlated investment policies. In Vietnamese markets, interlocks often follow ownership lines (e.g., the parent company appoints directors to subsidiary boards), creating a governance channel that reinforces the ownership channel.\n\n::: {#board-interlock-data .cell execution_count=14}\n``` {.python .cell-code}\n# Load board membership data\nboard_data = dc.get_board_memberships(\n    date=\"2024-06-30\"\n)\n\nprint(f\"Director-firm pairs: {len(board_data)}\")\nprint(f\"Unique directors: {board_data['director_id'].nunique()}\")\nprint(f\"Unique firms: {board_data['ticker'].nunique()}\")\n\n# Build bipartite graph\nB = nx.Graph()\nfor _, row in board_data.iterrows():\n    B.add_node(row[\"director_id\"], bipartite=0)\n    B.add_node(row[\"ticker\"], bipartite=1)\n    B.add_edge(\n        row[\"director_id\"], row[\"ticker\"],\n        role=row.get(\"role\", \"director\"),\n        is_independent=row.get(\"is_independent\", False)\n    )\n\n# Project to firm-firm interlock network\nfirm_nodes = [n for n, d in B.nodes(data=True) if d.get(\"bipartite\") == 1]\nG_interlock = nx.bipartite.weighted_projected_graph(B, firm_nodes)\n\n# Edge weight = number of shared directors\ninterlock_metrics, interlock_graph = compute_network_metrics(G_interlock)\n\nprint(f\"\\nBoard Interlock Network:\")\nprint(f\"  Firms: {G_interlock.number_of_nodes()}\")\nprint(f\"  Interlocking pairs: {G_interlock.number_of_edges()}\")\nprint(f\"  Density: {nx.density(G_interlock):.4f}\")\n```\n:::\n\n\n::: {#interlock-vs-ownership .cell execution_count=15}\n``` {.python .cell-code}\n# Do board interlocks follow ownership lines?\n# Compare interlock edges with ownership edges\ninterlock_edges = set(G_interlock.edges())\nownership_edges_undirected = set()\n\nfor u, v in G_own.edges():\n    if u in firm_nodes and v in firm_nodes:\n        ownership_edges_undirected.add((min(u, v), max(u, v)))\n\ninterlock_edges_normalized = {\n    (min(u, v), max(u, v)) for u, v in interlock_edges\n}\n\noverlap = interlock_edges_normalized & ownership_edges_undirected\nn_interlock = len(interlock_edges_normalized)\nn_ownership = len(ownership_edges_undirected)\nn_overlap = len(overlap)\n\nprint(f\"Interlock edges: {n_interlock}\")\nprint(f\"Ownership edges (firm-firm): {n_ownership}\")\nprint(f\"Overlap: {n_overlap}\")\nif n_interlock > 0:\n    print(f\"Fraction of interlocks with ownership link: \"\n          f\"{n_overlap / n_interlock:.3f}\")\n```\n:::\n\n\n### Interlocks and Return Co-Movement\n\nIf board interlocks serve as information channels, firms connected through interlocks should exhibit excess return co-movement beyond what is explained by shared industry or size characteristics. We test this using the methodology of @cohen2008economic:\n\n$$\n\\rho_{ij,t} = \\alpha + \\beta \\cdot \\text{Interlock}_{ij,t} + \\gamma \\cdot \\text{SameIndustry}_{ij} + \\delta \\cdot \\text{SizeProximity}_{ij,t} + \\varepsilon_{ij,t}\n$$ {#eq-interlock-comovement}\n\n::: {#interlock-comovement .cell execution_count=16}\n``` {.python .cell-code}\n# Compute pairwise return correlations for interlocked and non-interlocked pairs\nmonthly_returns = dc.get_monthly_returns(\n    start_date=\"2023-01-01\",\n    end_date=\"2024-06-30\"\n)\n\n# Pivot to wide format\nreturns_wide = monthly_returns.pivot(\n    index=\"date\", columns=\"ticker\", values=\"ret\"\n).dropna(axis=1, thresh=12)\n\n# Correlation matrix\ncorr_matrix = returns_wide.corr()\n\n# Compare correlations: interlocked vs non-interlocked\ninterlock_corrs = []\nnon_interlock_corrs = []\n\ntickers_in_both = set(corr_matrix.columns) & set(G_interlock.nodes())\n\nfor i, ticker_i in enumerate(tickers_in_both):\n    for ticker_j in list(tickers_in_both)[i + 1:]:\n        corr = corr_matrix.loc[ticker_i, ticker_j]\n        if np.isnan(corr):\n            continue\n\n        if G_interlock.has_edge(ticker_i, ticker_j):\n            interlock_corrs.append(corr)\n        else:\n            non_interlock_corrs.append(corr)\n\nif interlock_corrs and non_interlock_corrs:\n    t_stat, p_val = stats.ttest_ind(interlock_corrs, non_interlock_corrs)\n    print(f\"Interlocked pairs: n={len(interlock_corrs)}, \"\n          f\"mean corr={np.mean(interlock_corrs):.4f}\")\n    print(f\"Non-interlocked: n={len(non_interlock_corrs)}, \"\n          f\"mean corr={np.mean(non_interlock_corrs):.4f}\")\n    print(f\"Difference t-stat: {t_stat:.3f}, p-value: {p_val:.4f}\")\n```\n:::\n\n\n## Supply Chain and Trade Networks\n\n### Constructing the Supply Chain Graph\n\nSupply chain relationships (customer-supplier linkages) represent real economic connections through which shocks propagate. @acemoglu2015systemic demonstrate theoretically that in the presence of supply chain linkages, idiosyncratic shocks to individual firms can generate aggregate fluctuations rather than washing out. @cohen2008economic and @menzly2010market show that supply chain connections predict cross-sectional return differences: when a major customer's stock drops, its suppliers' stocks follow with a delay.\n\n::: {#supply-chain-data .cell execution_count=17}\n``` {.python .cell-code}\n# Load supply chain data\nsupply_chain = dc.get_supply_chain_data(\n    start_date=\"2020-01-01\",\n    end_date=\"2024-12-31\"\n)\n\n# Build directed supply chain graph\nG_supply = nx.DiGraph()\n\nfor _, row in supply_chain.iterrows():\n    G_supply.add_edge(\n        row[\"supplier_ticker\"],\n        row[\"customer_ticker\"],\n        weight=row.get(\"transaction_value\", 1),\n        pct_of_supplier_revenue=row.get(\"pct_supplier_revenue\", 0),\n        pct_of_customer_cogs=row.get(\"pct_customer_cogs\", 0),\n        year=row.get(\"year\", 2024)\n    )\n\nprint(f\"Supply chain links: {G_supply.number_of_edges()}\")\nprint(f\"Firms involved: {G_supply.number_of_nodes()}\")\n```\n:::\n\n\n### Customer Momentum\n\nThe \"customer momentum\" strategy of @cohen2008economic exploits the delayed propagation of information through supply chains. When a customer firm's stock rises, its suppliers' stocks tend to follow in subsequent months:\n\n$$\nr_{i,t+1} = \\alpha + \\beta \\cdot \\text{CustomerReturn}_{i,t} + \\gamma \\cdot r_{i,t} + \\boldsymbol{\\delta}' \\mathbf{X}_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-customer-momentum}\n\nwhere $\\text{CustomerReturn}_{i,t} = \\sum_{j \\in \\text{Customers}(i)} w_{ij} \\cdot r_{j,t}$ is the weighted average return of firm $i$'s customers.\n\n::: {#customer-momentum .cell execution_count=18}\n``` {.python .cell-code}\n# Compute customer-weighted returns for each supplier\ndef compute_customer_returns(supply_graph, monthly_returns):\n    \"\"\"\n    Compute customer-weighted returns for each supplier firm.\n    \"\"\"\n    # For each supplier, compute weighted average customer return\n    results = []\n\n    for date in monthly_returns[\"date\"].unique():\n        date_returns = monthly_returns[monthly_returns[\"date\"] == date]\n        ret_dict = dict(zip(date_returns[\"ticker\"], date_returns[\"ret\"]))\n\n        for supplier in supply_graph.nodes():\n            customers = list(supply_graph.successors(supplier))\n            if not customers:\n                continue\n\n            customer_rets = []\n            customer_weights = []\n            for cust in customers:\n                if cust in ret_dict:\n                    edge_data = supply_graph[supplier][cust]\n                    weight = edge_data.get(\"pct_of_supplier_revenue\", 1)\n                    customer_rets.append(ret_dict[cust])\n                    customer_weights.append(weight)\n\n            if customer_rets:\n                weights = np.array(customer_weights)\n                if weights.sum() > 0:\n                    weights = weights / weights.sum()\n                else:\n                    weights = np.ones(len(weights)) / len(weights)\n\n                weighted_ret = np.average(customer_rets, weights=weights)\n                results.append({\n                    \"date\": date,\n                    \"ticker\": supplier,\n                    \"customer_ret\": weighted_ret,\n                    \"n_customers\": len(customer_rets)\n                })\n\n    return pd.DataFrame(results)\n\n\ncustomer_rets = compute_customer_returns(G_supply, monthly_returns)\n\n# Merge with own returns and lag\nmomentum_data = monthly_returns.merge(\n    customer_rets, on=[\"ticker\", \"date\"], how=\"inner\"\n)\n\nmomentum_data = momentum_data.sort_values([\"ticker\", \"date\"])\nmomentum_data[\"own_ret_lag\"] = momentum_data.groupby(\"ticker\")[\"ret\"].shift(1)\nmomentum_data[\"customer_ret_lag\"] = momentum_data.groupby(\n    \"ticker\"\n)[\"customer_ret\"].shift(1)\nmomentum_data[\"ret_lead\"] = momentum_data.groupby(\"ticker\")[\"ret\"].shift(-1)\n\n# Regression\nmom_clean = momentum_data.dropna(\n    subset=[\"ret_lead\", \"customer_ret_lag\", \"own_ret_lag\"]\n)\n\nmodel_mom = sm.OLS(\n    mom_clean[\"ret_lead\"],\n    sm.add_constant(mom_clean[[\"customer_ret_lag\", \"own_ret_lag\"]])\n).fit(cov_type=\"cluster\", cov_kwds={\"groups\": mom_clean[\"ticker\"]})\n```\n:::\n\n\n::: {#tbl-customer-momentum .cell tbl-cap='Customer Momentum: Supplier Returns Predicted by Customer Returns' execution_count=19}\n``` {.python .cell-code}\nmom_results = pd.DataFrame({\n    \"Coefficient\": model_mom.params.round(4),\n    \"Std Error\": model_mom.bse.round(4),\n    \"t-stat\": model_mom.tvalues.round(3),\n    \"p-value\": model_mom.pvalues.round(4)\n})\nmom_results\n```\n:::\n\n\n### Network Propagation: Shock Diffusion Through Supply Chains\n\nThe @acemoglu2015systemic model predicts that the aggregate effect of an idiosyncratic shock depends on the network's topology. In a star network (one central hub), hub shocks generate aggregate fluctuations. In a symmetric network, shocks cancel out. We implement a simulation-based approach to measure shock propagation in the Vietnamese supply chain.\n\n::: {#shock-propagation .cell execution_count=20}\n``` {.python .cell-code}\ndef simulate_shock_propagation(G, shocked_node, shock_size=-0.10,\n                                decay=0.5, max_steps=5):\n    \"\"\"\n    Simulate the propagation of an idiosyncratic shock through\n    a supply chain network.\n\n    Parameters\n    ----------\n    G : nx.DiGraph\n        Supply chain graph (supplier → customer).\n    shocked_node : str\n        Node receiving the initial shock.\n    shock_size : float\n        Initial shock magnitude (e.g., -0.10 = -10% revenue shock).\n    decay : float\n        Fraction of shock transmitted per link (0 < decay < 1).\n    max_steps : int\n        Maximum propagation steps.\n\n    Returns\n    -------\n    dict : {node: cumulative shock received}.\n    \"\"\"\n    shocks = {shocked_node: shock_size}\n    frontier = {shocked_node}\n\n    for step in range(max_steps):\n        new_frontier = set()\n        for node in frontier:\n            # Propagate to customers (downstream)\n            for customer in G.successors(node):\n                edge_weight = G[node][customer].get(\n                    \"pct_of_customer_cogs\", 0.1\n                )\n                transmitted = shocks[node] * decay * edge_weight\n                if abs(transmitted) > 0.001:\n                    shocks[customer] = shocks.get(customer, 0) + transmitted\n                    new_frontier.add(customer)\n\n            # Propagate to suppliers (upstream)\n            for supplier in G.predecessors(node):\n                edge_weight = G[supplier][node].get(\n                    \"pct_of_supplier_revenue\", 0.1\n                )\n                transmitted = shocks[node] * decay * edge_weight\n                if abs(transmitted) > 0.001:\n                    shocks[supplier] = shocks.get(supplier, 0) + transmitted\n                    new_frontier.add(supplier)\n\n        frontier = new_frontier\n        if not frontier:\n            break\n\n    return shocks\n\n\n# Identify systemically important supply chain nodes\n# (Those whose shock has largest aggregate impact)\nsystemic_importance = {}\nlisted_in_supply = [n for n in G_supply.nodes()\n                    if n in set(firms[\"ticker\"])]\n\nfor firm in listed_in_supply[:100]:  # Sample for computational feasibility\n    shocks = simulate_shock_propagation(G_supply, firm, -0.10)\n    aggregate_impact = sum(abs(v) for k, v in shocks.items() if k != firm)\n    systemic_importance[firm] = aggregate_impact\n\nsystemic_df = pd.DataFrame(\n    list(systemic_importance.items()),\n    columns=[\"ticker\", \"systemic_impact\"]\n).sort_values(\"systemic_impact\", ascending=False)\n```\n:::\n\n\n::: {#tbl-systemic-supply-chain .cell tbl-cap='Most Systemically Important Firms in the Supply Chain Network' execution_count=21}\n``` {.python .cell-code}\ntop_systemic = systemic_df.head(20).merge(\n    firms[[\"ticker\", \"industry\", \"market_cap\"]],\n    on=\"ticker\", how=\"left\"\n)\ntop_systemic[\"market_cap_bn\"] = top_systemic[\"market_cap\"] / 1e9\ntop_systemic[[\"ticker\", \"industry\", \"market_cap_bn\", \"systemic_impact\"]].round(4)\n```\n:::\n\n\n## Correlation and Co-Movement Networks\n\n### Construction from Return Data\n\nA correlation network connects assets whose returns co-move. This is perhaps the most widely used financial network because it requires only return data---no proprietary ownership or supply chain information. The standard construction involves three steps:\n\n1.  **Compute pairwise correlations.** For $n$ assets over $T$ periods, the sample correlation matrix $\\hat{\\rho} \\in \\mathbb{R}^{n \\times n}$ has $n(n-1)/2$ unique entries.\n\n2.  **Threshold or transform.** Convert the dense correlation matrix into a sparse graph. Common approaches: hard threshold ($\\rho_{ij} > \\bar{\\rho}$), Minimum Spanning Tree (MST), or Planar Maximally Filtered Graph (PMFG).\n\n3.  **Analyze the graph.** Community detection reveals sector clustering; centrality identifies market bellwethers; temporal evolution tracks regime changes.\n\n::: {#correlation-network .cell execution_count=22}\n``` {.python .cell-code}\n# Compute correlation matrix from daily returns\ndaily_returns = dc.get_daily_returns(\n    start_date=\"2023-01-01\",\n    end_date=\"2024-06-30\"\n)\n\ndaily_wide = daily_returns.pivot(\n    index=\"date\", columns=\"ticker\", values=\"ret\"\n).dropna(axis=1, thresh=200)\n\ncorr = daily_wide.corr()\n\n# Minimum Spanning Tree (MST)\n# Convert correlation to distance: d = sqrt(2(1-ρ))\ndist = np.sqrt(2 * (1 - corr.values))\nnp.fill_diagonal(dist, 0)\n\n# Build complete graph with distances\nG_complete = nx.Graph()\ntickers = list(corr.columns)\nfor i in range(len(tickers)):\n    for j in range(i + 1, len(tickers)):\n        G_complete.add_edge(\n            tickers[i], tickers[j],\n            weight=dist[i, j],\n            correlation=corr.iloc[i, j]\n        )\n\n# MST\nG_mst = nx.minimum_spanning_tree(G_complete, weight=\"weight\")\n\n# Thresholded correlation network\nthreshold = 0.5\nG_corr = nx.Graph()\nfor i in range(len(tickers)):\n    for j in range(i + 1, len(tickers)):\n        if corr.iloc[i, j] > threshold:\n            G_corr.add_edge(\n                tickers[i], tickers[j],\n                weight=corr.iloc[i, j]\n            )\n\nprint(f\"MST: {G_mst.number_of_nodes()} nodes, \"\n      f\"{G_mst.number_of_edges()} edges\")\nprint(f\"Corr network (ρ > {threshold}): \"\n      f\"{G_corr.number_of_nodes()} nodes, \"\n      f\"{G_corr.number_of_edges()} edges\")\n```\n:::\n\n\n### The Diebold-Yilmaz Connectedness Framework\n\n@diebold2014network propose measuring financial connectedness using the variance decomposition from a vector autoregression (VAR). The fraction of the $H$-step-ahead forecast error variance of variable $i$ attributable to shocks from variable $j$ defines the pairwise directional connectedness:\n\n$$\nC_{i \\leftarrow j}(H) = \\frac{\\tilde{\\theta}_{ij}^g(H)}{\\sum_{j=1}^{n} \\tilde{\\theta}_{ij}^g(H)} \\times 100\n$$ {#eq-dy-connectedness}\n\nwhere $\\tilde{\\theta}_{ij}^g(H)$ is the generalized forecast error variance decomposition. The total connectedness index (TCI) aggregates across all pairs:\n\n$$\n\\text{TCI}(H) = \\frac{\\sum_{i \\neq j} C_{i \\leftarrow j}(H)}{\\sum_{i,j} C_{i \\leftarrow j}(H)} \\times 100\n$$ {#eq-tci}\n\nHigh TCI indicates a tightly connected system where shocks propagate widely; low TCI indicates relative isolation.\n\n::: {#diebold-yilmaz .cell execution_count=23}\n``` {.python .cell-code}\ndef diebold_yilmaz_connectedness(returns_df, var_order=2,\n                                  forecast_horizon=10):\n    \"\"\"\n    Compute the Diebold-Yilmaz (2014) connectedness table.\n\n    Parameters\n    ----------\n    returns_df : DataFrame\n        Returns with columns as assets, index as dates.\n    var_order : int\n        VAR lag order.\n    forecast_horizon : int\n        Forecast horizon for variance decomposition.\n\n    Returns\n    -------\n    dict : Connectedness matrix, TCI, TO/FROM measures.\n    \"\"\"\n    from statsmodels.tsa.api import VAR\n\n    # Fit VAR\n    model = VAR(returns_df.dropna())\n    results = model.fit(var_order)\n\n    # Generalized Forecast Error Variance Decomposition\n    fevd = results.fevd(forecast_horizon)\n\n    # Extract decomposition matrix at horizon H\n    n = returns_df.shape[1]\n    C = np.zeros((n, n))\n\n    for i in range(n):\n        decomp = fevd.decomp[i]  # H x n array\n        C[i, :] = decomp[-1, :]  # Take horizon H values\n\n    # Normalize rows to sum to 100\n    row_sums = C.sum(axis=1, keepdims=True)\n    C_norm = C / row_sums * 100\n\n    # Connectedness measures\n    # FROM: how much of i's variance comes from others\n    FROM = C_norm.sum(axis=1) - np.diag(C_norm)\n\n    # TO: how much of others' variance comes from i\n    TO = C_norm.sum(axis=0) - np.diag(C_norm)\n\n    # NET = TO - FROM\n    NET = TO - FROM\n\n    # Total Connectedness Index\n    TCI = FROM.sum() / n\n\n    names = returns_df.columns.tolist()\n\n    connectedness_df = pd.DataFrame(C_norm, index=names, columns=names)\n    connectedness_df[\"FROM_others\"] = FROM\n    connectedness_df.loc[\"TO_others\"] = list(TO) + [TCI]\n\n    return {\n        \"connectedness_matrix\": connectedness_df,\n        \"TCI\": TCI,\n        \"FROM\": pd.Series(FROM, index=names),\n        \"TO\": pd.Series(TO, index=names),\n        \"NET\": pd.Series(NET, index=names)\n    }\n\n\n# Apply to top Vietnamese stocks by liquidity\ntop_stocks = (\n    daily_returns.groupby(\"ticker\")[\"volume\"]\n    .mean()\n    .nlargest(20)\n    .index\n)\n\ntop_returns = daily_wide[\n    [c for c in top_stocks if c in daily_wide.columns]\n].dropna()\n\ndy_results = diebold_yilmaz_connectedness(top_returns)\nprint(f\"Total Connectedness Index: {dy_results['TCI']:.2f}%\")\n```\n:::\n\n\n::: {#tbl-connectedness .cell tbl-cap='Diebold-Yilmaz Net Connectedness: Net Transmitters (+) and Receivers (−)' execution_count=24}\n``` {.python .cell-code}\nnet_df = pd.DataFrame({\n    \"TO_others\": dy_results[\"TO\"].round(2),\n    \"FROM_others\": dy_results[\"FROM\"].round(2),\n    \"NET\": dy_results[\"NET\"].round(2)\n}).sort_values(\"NET\", ascending=False)\n\nnet_df\n```\n:::\n\n\n::: {#rolling-connectedness .cell execution_count=25}\n``` {.python .cell-code}\n# Rolling TCI to track systemic risk over time\ndef rolling_tci(returns_wide, window=252, step=21, var_order=1,\n                 forecast_horizon=10, min_stocks=10):\n    \"\"\"Compute rolling Total Connectedness Index.\"\"\"\n    dates = returns_wide.index\n    tci_series = []\n\n    for i in range(window, len(dates), step):\n        window_data = returns_wide.iloc[i - window:i]\n\n        # Keep stocks with sufficient data\n        valid_cols = window_data.dropna(axis=1, thresh=int(window * 0.9))\n        if valid_cols.shape[1] < min_stocks:\n            continue\n\n        # Use top stocks by variance (most informative)\n        top_cols = valid_cols.var().nlargest(min_stocks).index\n        subset = valid_cols[top_cols].dropna()\n\n        if len(subset) < window * 0.8:\n            continue\n\n        try:\n            result = diebold_yilmaz_connectedness(\n                subset, var_order, forecast_horizon\n            )\n            tci_series.append({\n                \"date\": dates[i],\n                \"TCI\": result[\"TCI\"],\n                \"n_stocks\": len(top_cols)\n            })\n        except Exception:\n            continue\n\n    return pd.DataFrame(tci_series)\n\n\n# tci_df = rolling_tci(daily_wide, window=252, step=21)\n```\n:::\n\n\n## Interbank and Financial Contagion Networks\n\n### The Interbank Market as a Network\n\nThe interbank market, where banks lend reserves to each other, is the canonical financial network. @allen2000financial demonstrate that the structure of interbank linkages determines whether a bank failure cascades into a systemic crisis or is absorbed by the network. Two extreme topologies illustrate:\n\n**Complete network (all banks linked to all).** Each bank's exposure to any single counterpart is small. A bank failure imposes small losses on many banks, which can individually absorb them. The network is resilient.\n\n**Ring network (each bank linked to one neighbor).** Each bank's exposure is concentrated in a single counterpart. A failure in one bank can topple its neighbor, triggering a chain of cascading defaults. The network is fragile.\n\nThe Vietnamese banking system, with its concentration of state-owned banks and the regulatory emphasis on interbank lending for liquidity management, lies between these extremes.\n\n::: {#interbank-network .cell execution_count=26}\n``` {.python .cell-code}\n# Load interbank exposure data\ninterbank = dc.get_interbank_exposures(\n    date=\"2024-06-30\"\n)\n\n# Build interbank network\nG_bank = nx.DiGraph()\n\nfor _, row in interbank.iterrows():\n    G_bank.add_edge(\n        row[\"lender_bank\"],\n        row[\"borrower_bank\"],\n        weight=row[\"exposure_bn_vnd\"],\n        exposure_pct_equity=row.get(\"exposure_pct_equity\", 0)\n    )\n\n# Add bank attributes\nbank_info = dc.get_bank_characteristics(date=\"2024-06-30\")\nfor _, row in bank_info.iterrows():\n    if row[\"ticker\"] in G_bank:\n        G_bank.nodes[row[\"ticker\"]].update({\n            \"total_assets\": row.get(\"total_assets\", 0),\n            \"equity\": row.get(\"equity\", 0),\n            \"is_soe\": row.get(\"is_soe\", False),\n            \"tier1_ratio\": row.get(\"tier1_ratio\", 0)\n        })\n\nbank_metrics, bank_graph_stats = compute_network_metrics(G_bank)\n```\n:::\n\n\n### Cascading Default Simulation\n\nWe implement the @eisenberg2001systemic clearing mechanism to simulate cascading defaults in the interbank network. When a bank fails, it cannot honor its interbank obligations, imposing losses on its creditors, who may in turn fail:\n\n$$\np_i^* = \\min\\left(\\bar{p}_i, \\; e_i + \\sum_{j} \\frac{L_{ji}}{\\sum_k L_{jk}} p_j^*\\right)\n$$ {#eq-eisenberg-noe}\n\nwhere $p_i^*$ is bank $i$'s actual payment, $\\bar{p}_i$ is its total obligation, $e_i$ is its external assets minus external liabilities, and $L_{ji}/\\sum_k L_{jk}$ is the fraction of bank $j$'s obligations owed to bank $i$.\n\n::: {#cascading-defaults .cell execution_count=27}\n``` {.python .cell-code}\ndef simulate_cascading_defaults(G, initial_failure, \n                                  equity_buffer=0.08,\n                                  max_rounds=20):\n    \"\"\"\n    Simulate cascading defaults in an interbank network.\n\n    Parameters\n    ----------\n    G : nx.DiGraph\n        Interbank exposure graph (lender → borrower, weight = exposure).\n    initial_failure : str\n        Bank that fails initially.\n    equity_buffer : float\n        Fraction of equity that absorbs losses before default.\n    max_rounds : int\n        Maximum cascade rounds.\n\n    Returns\n    -------\n    dict : Defaulted banks, round-by-round losses, systemic loss.\n    \"\"\"\n    defaulted = {initial_failure}\n    cascade_history = [{\"round\": 0, \"defaults\": [initial_failure],\n                        \"total_defaults\": 1}]\n\n    for round_num in range(1, max_rounds + 1):\n        new_defaults = set()\n\n        for bank in G.nodes():\n            if bank in defaulted:\n                continue\n\n            # Compute losses from defaulted counterparties\n            total_loss = 0\n            for defaulted_bank in defaulted:\n                if G.has_edge(bank, defaulted_bank):\n                    # bank lent to defaulted_bank → loss\n                    exposure = G[bank][defaulted_bank][\"weight\"]\n                    # Assume LGD = 60%\n                    loss = exposure * 0.6\n                    total_loss += loss\n\n            # Check if losses exceed equity buffer\n            bank_data = G.nodes.get(bank, {})\n            equity = bank_data.get(\"equity\", float(\"inf\"))\n\n            if total_loss > equity * equity_buffer:\n                new_defaults.add(bank)\n\n        if not new_defaults:\n            break\n\n        defaulted |= new_defaults\n        cascade_history.append({\n            \"round\": round_num,\n            \"defaults\": list(new_defaults),\n            \"total_defaults\": len(defaulted)\n        })\n\n    # Compute systemic loss\n    total_system_equity = sum(\n        G.nodes[n].get(\"equity\", 0) for n in G.nodes()\n    )\n    defaulted_equity = sum(\n        G.nodes[n].get(\"equity\", 0) for n in defaulted\n    )\n    systemic_loss_pct = (\n        defaulted_equity / total_system_equity\n        if total_system_equity > 0 else 0\n    )\n\n    return {\n        \"defaulted_banks\": list(defaulted),\n        \"n_defaults\": len(defaulted),\n        \"cascade_rounds\": len(cascade_history) - 1,\n        \"cascade_history\": cascade_history,\n        \"systemic_loss_pct\": systemic_loss_pct\n    }\n\n\n# Simulate cascade for each bank\ncascade_results = []\nfor bank in G_bank.nodes():\n    result = simulate_cascading_defaults(G_bank, bank)\n    cascade_results.append({\n        \"initial_failure\": bank,\n        \"n_cascading_defaults\": result[\"n_defaults\"],\n        \"systemic_loss_pct\": result[\"systemic_loss_pct\"],\n        \"cascade_rounds\": result[\"cascade_rounds\"]\n    })\n\ncascade_df = pd.DataFrame(cascade_results).sort_values(\n    \"systemic_loss_pct\", ascending=False\n)\n```\n:::\n\n\n::: {#tbl-systemic-banks .cell tbl-cap='Systemically Important Banks: Cascading Default Analysis' execution_count=28}\n``` {.python .cell-code}\ncascade_df.head(15).round(4)\n```\n:::\n\n\n## Graph Neural Networks for Financial Prediction\n\n### From Graphs to Predictions\n\nClassical network analysis computes hand-crafted features (centrality, clustering, community membership) and feeds them into standard regression models. Graph neural networks (GNNs) learn features directly from the graph structure and node attributes through message passing. The key insight is that a node's representation should depend not only on its own features but on the features of its neighbors, their neighbors, and so on.\n\n### Graph Convolutional Networks (GCN)\n\nThe Graph Convolutional Network of @kipf2016semi performs spectral convolution on graphs. The layer-wise propagation rule is:\n\n$$\nH^{(\\ell+1)} = \\sigma\\left(\\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} H^{(\\ell)} W^{(\\ell)}\\right)\n$$ {#eq-gcn}\n\nwhere $\\tilde{A} = A + I_n$ is the adjacency matrix with self-loops, $\\tilde{D}$ is the corresponding degree matrix, $H^{(\\ell)}$ is the node feature matrix at layer $\\ell$, $W^{(\\ell)}$ is the learnable weight matrix, and $\\sigma$ is a nonlinearity (ReLU). The normalized $\\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2}$ term averages each node's features with its neighbors' features, weighted by degree.\n\n### Graph Attention Networks (GAT)\n\nThe Graph Attention Network of @velivckovic2017graph replaces the fixed normalization in GCN with learned attention coefficients:\n\n$$\nh_i^{(\\ell+1)} = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij}^{(\\ell)} W^{(\\ell)} h_j^{(\\ell)}\\right)\n$$ {#eq-gat}\n\nwhere the attention coefficient $\\alpha_{ij}$ is computed as:\n\n$$\n\\alpha_{ij} = \\frac{\\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}^\\top [W h_i \\| W h_j]\\right)\\right)}{\\sum_{k \\in \\mathcal{N}(i)} \\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}^\\top [W h_i \\| W h_k]\\right)\\right)}\n$$ {#eq-gat-attention}\n\nThis allows the model to learn which neighbors are most informative for each node, rather than treating all neighbors equally.\n\n::: {#gnn-models .cell execution_count=29}\n``` {.python .cell-code}\nclass GCNLayer(nn.Module):\n    \"\"\"Graph Convolutional Network layer (Kipf & Welling, 2016).\"\"\"\n\n    def __init__(self, in_features, out_features, bias=True):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        if bias:\n            self.bias = nn.Parameter(torch.FloatTensor(out_features))\n        else:\n            self.bias = None\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.xavier_uniform_(self.weight)\n        if self.bias is not None:\n            nn.init.zeros_(self.bias)\n\n    def forward(self, x, adj_norm):\n        \"\"\"\n        Parameters\n        ----------\n        x : Tensor (n_nodes, in_features)\n            Node feature matrix.\n        adj_norm : Tensor (n_nodes, n_nodes)\n            Normalized adjacency matrix (D^{-1/2} A D^{-1/2}).\n        \"\"\"\n        support = x @ self.weight\n        output = adj_norm @ support\n        if self.bias is not None:\n            output = output + self.bias\n        return output\n\n\nclass GATLayer(nn.Module):\n    \"\"\"Graph Attention Network layer (Velickovic et al., 2017).\"\"\"\n\n    def __init__(self, in_features, out_features, n_heads=4,\n                 dropout=0.1, concat=True):\n        super().__init__()\n        self.n_heads = n_heads\n        self.out_features = out_features\n        self.concat = concat\n\n        self.W = nn.Parameter(\n            torch.FloatTensor(n_heads, in_features, out_features)\n        )\n        self.a = nn.Parameter(torch.FloatTensor(n_heads, 2 * out_features, 1))\n        self.dropout = nn.Dropout(dropout)\n        self.leaky_relu = nn.LeakyReLU(0.2)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.xavier_uniform_(self.W)\n        nn.init.xavier_uniform_(self.a)\n\n    def forward(self, x, adj):\n        \"\"\"\n        Parameters\n        ----------\n        x : Tensor (n_nodes, in_features)\n        adj : Tensor (n_nodes, n_nodes)\n            Binary adjacency matrix (1 if edge, 0 otherwise).\n        \"\"\"\n        n = x.size(0)\n\n        # Linear transformation for each head\n        # x: (n, in_f) -> h: (heads, n, out_f)\n        h = torch.einsum(\"ni,hio->hno\", x, self.W)\n\n        # Attention coefficients\n        # Concatenate h_i and h_j for all pairs\n        h_i = h.unsqueeze(2).expand(-1, -1, n, -1)  # (heads, n, n, out_f)\n        h_j = h.unsqueeze(1).expand(-1, n, -1, -1)  # (heads, n, n, out_f)\n        concat_h = torch.cat([h_i, h_j], dim=-1)    # (heads, n, n, 2*out_f)\n\n        e = self.leaky_relu(\n            torch.einsum(\"hnmo,hoi->hnm\", concat_h, self.a).squeeze(-1)\n        )\n\n        # Mask non-edges\n        mask = adj.unsqueeze(0).expand(self.n_heads, -1, -1)\n        e = e.masked_fill(mask == 0, float(\"-inf\"))\n\n        # Softmax attention\n        alpha = F.softmax(e, dim=-1)\n        alpha = self.dropout(alpha)\n\n        # Weighted aggregation\n        out = torch.einsum(\"hnm,hmo->hno\", alpha, h)  # (heads, n, out_f)\n\n        if self.concat:\n            out = out.permute(1, 0, 2).reshape(n, -1)  # (n, heads * out_f)\n        else:\n            out = out.mean(dim=0)  # (n, out_f)\n\n        return out, alpha\n\n\nclass FinancialGNN(nn.Module):\n    \"\"\"\n    Graph Neural Network for financial node prediction.\n    Supports GCN and GAT layers with flexible architecture.\n    \"\"\"\n\n    def __init__(self, input_dim, hidden_dim=64, output_dim=1,\n                 n_layers=2, n_heads=4, gnn_type=\"gat\",\n                 dropout=0.3):\n        super().__init__()\n\n        self.gnn_type = gnn_type\n        self.dropout = nn.Dropout(dropout)\n\n        if gnn_type == \"gcn\":\n            self.layers = nn.ModuleList()\n            self.layers.append(GCNLayer(input_dim, hidden_dim))\n            for _ in range(n_layers - 1):\n                self.layers.append(GCNLayer(hidden_dim, hidden_dim))\n\n        elif gnn_type == \"gat\":\n            self.layers = nn.ModuleList()\n            self.layers.append(\n                GATLayer(input_dim, hidden_dim // n_heads,\n                         n_heads=n_heads, concat=True)\n            )\n            for _ in range(n_layers - 2):\n                self.layers.append(\n                    GATLayer(hidden_dim, hidden_dim // n_heads,\n                             n_heads=n_heads, concat=True)\n                )\n            # Last layer: single head, no concat\n            self.layers.append(\n                GATLayer(hidden_dim, hidden_dim,\n                         n_heads=1, concat=False)\n            )\n\n        # Prediction head\n        self.head = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, output_dim)\n        )\n\n    def forward(self, x, adj):\n        \"\"\"\n        Parameters\n        ----------\n        x : Tensor (n_nodes, input_dim)\n            Node features.\n        adj : Tensor (n_nodes, n_nodes)\n            Adjacency matrix.\n        \"\"\"\n        h = x\n        attention_weights = []\n\n        for i, layer in enumerate(self.layers):\n            if self.gnn_type == \"gcn\":\n                h = layer(h, adj)\n                h = F.relu(h) if i < len(self.layers) - 1 else h\n            elif self.gnn_type == \"gat\":\n                h, alpha = layer(h, adj)\n                attention_weights.append(alpha)\n                if i < len(self.layers) - 1:\n                    h = F.elu(h)\n\n            h = self.dropout(h)\n\n        predictions = self.head(h).squeeze(-1)\n        return predictions, attention_weights\n```\n:::\n\n\n### GNN for Cross-Sectional Return Prediction\n\nWe apply the GNN to predict cross-sectional stock returns, where the graph encodes ownership connections between firms. The hypothesis is that firms connected through ownership have correlated return dynamics that the GNN can exploit.\n\n::: {#gnn-return-prediction .cell execution_count=30}\n``` {.python .cell-code}\ndef prepare_gnn_data(firms_df, ownership_graph, returns_df, date):\n    \"\"\"\n    Prepare node features and adjacency matrix for GNN prediction.\n\n    Parameters\n    ----------\n    firms_df : DataFrame\n        Firm characteristics.\n    ownership_graph : nx.DiGraph\n        Ownership network.\n    returns_df : DataFrame\n        Stock returns.\n\n    Returns\n    -------\n    tuple : (node_features, adjacency, target_returns, ticker_list)\n    \"\"\"\n    # Get stocks with both features and network presence\n    tickers = sorted(\n        set(firms_df[\"ticker\"]) &\n        set(ownership_graph.nodes()) &\n        set(returns_df[\"ticker\"])\n    )\n\n    if not tickers:\n        return None, None, None, None\n\n    # Node features\n    feature_cols = [\n        \"log_size\", \"book_to_market\", \"momentum_12m\",\n        \"profitability\", \"investment\", \"leverage\",\n        \"beta\", \"volatility\", \"turnover\"\n    ]\n\n    feat_df = firms_df[firms_df[\"ticker\"].isin(tickers)].set_index(\"ticker\")\n    feat_df = feat_df.reindex(tickers)\n\n    X = feat_df[feature_cols].fillna(0).values\n    X = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)\n\n    # Adjacency matrix\n    ticker_to_idx = {t: i for i, t in enumerate(tickers)}\n    n = len(tickers)\n    A = np.zeros((n, n))\n\n    for u, v, d in ownership_graph.edges(data=True):\n        if u in ticker_to_idx and v in ticker_to_idx:\n            weight = d.get(\"weight\", 1)\n            A[ticker_to_idx[u], ticker_to_idx[v]] = weight\n            A[ticker_to_idx[v], ticker_to_idx[u]] = weight  # Symmetrize\n\n    # Add self-loops\n    A = A + np.eye(n)\n\n    # Normalize: D^{-1/2} A D^{-1/2}\n    D = np.diag(A.sum(axis=1))\n    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D) + 1e-10))\n    A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n\n    # Target returns\n    ret_df = returns_df[\n        (returns_df[\"ticker\"].isin(tickers)) &\n        (returns_df[\"date\"] == date)\n    ].set_index(\"ticker\").reindex(tickers)\n\n    y = ret_df[\"ret\"].fillna(0).values\n\n    return (\n        torch.tensor(X, dtype=torch.float32),\n        torch.tensor(A_norm, dtype=torch.float32),\n        torch.tensor(y, dtype=torch.float32),\n        tickers\n    )\n\n\ndef train_gnn_model(model, X_train, A_train, y_train,\n                     X_val, A_val, y_val,\n                     n_epochs=100, lr=1e-3):\n    \"\"\"Train GNN model with validation-based early stopping.\"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n                                  weight_decay=1e-4)\n\n    best_val_loss = float(\"inf\")\n    patience_counter = 0\n\n    for epoch in range(n_epochs):\n        model.train()\n        optimizer.zero_grad()\n\n        pred, _ = model(X_train, A_train)\n        loss = F.mse_loss(pred, y_train)\n        loss.backward()\n        optimizer.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_pred, _ = model(X_val, A_val)\n            val_loss = F.mse_loss(val_pred, y_val).item()\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= 15:\n                break\n\n    model.load_state_dict(best_state)\n    return model, best_val_loss\n```\n:::\n\n\n### Temporal Graph Networks\n\nFinancial networks evolve over time. Ownership stakes change, directors rotate, correlations shift. Temporal GNNs extend static GNNs by incorporating the time dimension explicitly. The Temporal Graph Network (TGN) of @rossi2020temporal maintains a memory state for each node that is updated whenever an event involving the node occurs:\n\n$$\n\\mathbf{s}_i(t) = \\text{GRU}\\left(\\mathbf{s}_i(t^-), \\; \\text{msg}(i, t)\\right)\n$$ {#eq-tgn}\n\nwhere $\\mathbf{s}_i(t)$ is the memory state of node $i$ at time $t$, $\\text{msg}(i, t)$ is the message aggregated from events at time $t$, and GRU is a gated recurrent unit.\n\n::: {#temporal-gnn .cell execution_count=31}\n``` {.python .cell-code}\nclass TemporalFinancialGNN(nn.Module):\n    \"\"\"\n    Temporal GNN for dynamic financial networks.\n    Combines graph convolution with temporal memory.\n    \"\"\"\n\n    def __init__(self, node_dim, edge_dim=1, memory_dim=64,\n                 hidden_dim=64, output_dim=1, n_heads=4):\n        super().__init__()\n\n        self.memory_dim = memory_dim\n\n        # Memory update (GRU)\n        self.memory_updater = nn.GRUCell(\n            input_size=node_dim + edge_dim + memory_dim,\n            hidden_size=memory_dim\n        )\n\n        # Message function\n        self.message_fn = nn.Sequential(\n            nn.Linear(memory_dim * 2 + edge_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, memory_dim)\n        )\n\n        # Graph attention for spatial aggregation\n        self.spatial_attn = GATLayer(\n            memory_dim + node_dim, hidden_dim // n_heads,\n            n_heads=n_heads, concat=True\n        )\n\n        # Temporal attention for recent history\n        self.temporal_attn = nn.MultiheadAttention(\n            embed_dim=hidden_dim, num_heads=n_heads,\n            batch_first=True\n        )\n\n        # Prediction head\n        self.head = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, node_features, adj_sequence, memory=None):\n        \"\"\"\n        Parameters\n        ----------\n        node_features : list of Tensors\n            Node features at each time step.\n        adj_sequence : list of Tensors\n            Adjacency matrices at each time step.\n        memory : Tensor or None\n            Initial memory state (n_nodes, memory_dim).\n\n        Returns\n        -------\n        predictions : Tensor\n            Predictions for the last time step.\n        \"\"\"\n        n_nodes = node_features[0].shape[0]\n        T = len(node_features)\n\n        if memory is None:\n            memory = torch.zeros(n_nodes, self.memory_dim)\n\n        temporal_states = []\n\n        for t in range(T):\n            x_t = node_features[t]\n            adj_t = adj_sequence[t]\n\n            # Spatial aggregation via GAT\n            combined = torch.cat([x_t, memory], dim=-1)\n            spatial_out, _ = self.spatial_attn(combined, adj_t)\n\n            temporal_states.append(spatial_out.unsqueeze(1))\n\n            # Update memory with current state\n            update_input = torch.cat([\n                x_t, spatial_out[:, :1].squeeze(1) if spatial_out.dim() > 2\n                else spatial_out,\n                memory\n            ], dim=-1)[:, :self.memory_updater.input_size]\n\n        # Stack temporal states: (n_nodes, T, hidden)\n        temporal_stack = torch.cat(temporal_states, dim=1)\n\n        # Temporal attention across time steps\n        temporal_out, _ = self.temporal_attn(\n            temporal_stack, temporal_stack, temporal_stack\n        )\n\n        # Use last time step\n        last_spatial = temporal_states[-1].squeeze(1)\n        last_temporal = temporal_out[:, -1, :]\n\n        combined = torch.cat([last_spatial, last_temporal], dim=-1)\n        predictions = self.head(combined).squeeze(-1)\n\n        return predictions\n```\n:::\n\n\n### GNN for Credit Risk and Fraud Detection\n\nBeyond return prediction, GNNs are particularly powerful for credit risk assessment and fraud detection, where the network structure itself is informative. In credit risk, firms connected to defaulted counterparties face elevated risk. In fraud detection, suspicious transaction patterns propagate through networks of related entities.\n\n::: {#gnn-credit-risk .cell execution_count=32}\n``` {.python .cell-code}\nclass CreditRiskGNN(nn.Module):\n    \"\"\"\n    GNN for credit default prediction using firm and bank networks.\n    Node classification: predict default probability per firm.\n    \"\"\"\n\n    def __init__(self, firm_features_dim, bank_features_dim=0,\n                 hidden_dim=64, n_heads=4):\n        super().__init__()\n\n        input_dim = firm_features_dim + bank_features_dim\n\n        # GNN backbone\n        self.gnn = FinancialGNN(\n            input_dim=input_dim,\n            hidden_dim=hidden_dim,\n            output_dim=1,\n            n_layers=3,\n            n_heads=n_heads,\n            gnn_type=\"gat\"\n        )\n\n        # Additional head for probability output\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x, adj):\n        logits, attn = self.gnn(x, adj)\n        probs = self.sigmoid(logits)\n        return probs, attn\n```\n:::\n\n\n## When to Use Network Methods\n\n### Decision Framework\n\n| Question | Best Approach | Example |\n|----------------------|------------------------------|--------------------|\n| Does firm $A$ affect firm $B$? | Pairwise test + network controls | Supply chain momentum |\n| Which firms are most systemically important? | Centrality measures | Interbank contagion |\n| Do network-connected firms co-move? | Correlation vs. interlock overlap | Board interlock diffusion |\n| Can network structure predict returns? | GNN or network-augmented regression | GCN return prediction |\n| How does a shock propagate? | Cascade simulation | Eisenberg-Noe default model |\n| What is the optimal portfolio given network risk? | Network-regularized optimization | Correlation MST filtering |\n| How does the network change over time? | Temporal GNN or rolling analysis | DY rolling connectedness |\n\n: Decision Framework for Network Methods {#tbl-network-decision}\n\n### Data Requirements and Vietnamese Availability\n\n| Network Type | Required Data | Vietnamese Availability | Update Frequency |\n|------------------|------------------|-------------------|------------------|\n| Ownership | Shareholder registers | Good (semi-annual filings) | Semi-annual |\n| Board interlocks | Director appointments | Good (filings) | Annual |\n| Supply chain | Customer-supplier disclosures, trade data | Moderate (related-party disclosures) | Annual |\n| Correlation | Return data | Excellent (daily from exchanges) | Daily |\n| Interbank | Bilateral exposures | Limited (SBV data, banks' notes to FS) | Quarterly |\n| Co-holdings | Institutional holdings | Moderate (semi-annual disclosures) | Semi-annual |\n| Lending | Loan-level data | Limited (banking supervision data) | Quarterly |\n\n: Financial Network Data Sources in Vietnam {#tbl-network-data}\n\n<!-- ## Exercises\n\n1.  **Ownership Pyramid Depth and Tunneling.** For each listed firm, compute the depth of the longest ownership chain from the ultimate controller to the firm. Regress Tobin's $Q$ and ROA on pyramid depth, controlling for the control-cash flow wedge, firm size, industry, and listing exchange. Does deeper pyramidal ownership destroy value? Does the effect differ between state and private pyramids? Use the @claessens2002disentangling methodology.\n\n2.  **Board Network Information Diffusion.** Construct the board interlock network for 2020-2024 and identify firms that added new interlocking directors. Using a difference-in-differences design, test whether newly interlocked firms exhibit increased return co-movement relative to a matched control group. Does the effect depend on whether the shared director is classified as independent?\n\n3.  **Supply Chain Contagion During COVID-19.** Reconstruct the supply chain network as of December 2019. Identify firms with direct supply chain links to Chinese manufacturers. Using the onset of COVID-19 lockdowns in China (January 2020) as a shock, estimate the differential stock price decline for firms with high vs. low exposure to Chinese suppliers. Does the effect attenuate by network distance (direct supplier vs. supplier's supplier)?\n\n4.  **Correlation Network Regime Detection.** Compute rolling 6-month correlation networks with monthly updates for 2014-2024. Apply community detection (Louvain algorithm) at each date. Track the number of communities, modularity, and the composition of the largest community over time. Do correlation regime changes (merging of previously distinct communities) precede periods of elevated market volatility? Construct a \"network fragility\" indicator based on decreasing modularity and test its predictive power for VN-Index drawdowns.\n\n5.  **GNN vs. Linear Models for Return Prediction.** Implement a rigorous horse race between: (a) Fama-MacBeth cross-sectional regression with standard characteristics, (b) the same regression augmented with hand-crafted network features (degree, betweenness, eigenvector centrality, community membership), and (c) a GCN and GAT that take the same node features plus the adjacency matrix as input. Use expanding-window time-series cross-validation with monthly rebalancing. Report out-of-sample $R^2$, information coefficient, and the Sharpe ratio of quintile-sorted long-short portfolios. Does the GNN's ability to learn features from graph structure outperform hand-crafted network features?\n\n6.  **Dynamic Interbank Contagion Index.** Implement the rolling Diebold-Yilmaz (2014) connectedness index for the Vietnamese banking sector using quarterly data. Compute the Total Connectedness Index, directional FROM/TO measures, and net connectedness for each bank. Plot the TCI over time and identify peaks corresponding to known stress events (2011 banking consolidation, 2022 corporate bond crisis). Does a rising TCI at time $t$ predict banking sector underperformance at $t+1$?\n\n7.  **Heterogeneous Graph Neural Network.** Construct a heterogeneous financial graph with three node types (firms, banks, directors) and four edge types (ownership, lending, board membership, supply chain). Implement a Heterogeneous GAT (HAN) that uses edge-type-specific attention. Does the heterogeneous graph outperform separate homogeneous graphs for return prediction? Which edge type receives the highest attention weight?\n\n8.  **Node2Vec Financial Embeddings.** Apply the Node2Vec algorithm [@grover2016node2vec] to the ownership network with different hyperparameters ($p$, $q$) controlling the balance between BFS-like (local neighborhood) and DFS-like (structural role) exploration. Visualize the 128-dimensional embeddings using t-SNE, colored by industry. Do the embeddings capture industry structure? Use the embeddings as additional features in a return prediction model and compare with hand-crafted centrality features. -->\n\n## Summary\n\nThis chapter developed the network toolkit for Vietnamese financial markets, spanning classical graph theory, domain-specific financial network construction, and modern graph neural networks.\n\nThe central insight is that financial networks encode information invisible to standard panel regressions. Ownership networks reveal pyramidal control structures and tunneling risk that explain cross-sectional differences in firm value. Board interlocks serve as information channels through which compensation practices, investment policies, and governance norms diffuse. Supply chain networks propagate real economic shocks: the customer momentum anomaly demonstrates that market prices incorporate supply chain information with a predictable delay. Correlation networks capture co-movement structure that both reveals sector clustering and evolves across market regimes. And interbank networks determine whether individual bank failures cascade into systemic crises.\n\nVietnamese markets are particularly network-dense because of the pervasive role of state ownership, the prominence of business groups, and the concentration of the banking system. The control-cash flow wedge (i.e., the gap between control rights and cash flow rights created by pyramidal ownership) is larger and more variable than in markets with stronger minority shareholder protections. This wedge, which is computable only through network analysis of ownership chains, is both a governance risk measure and a predictor of firm value.\n\nGraph neural networks extend the toolkit from hand-crafted network features to learned representations. The GCN and GAT architectures aggregate information across network neighborhoods, and the temporal GNN captures the evolution of network structure over time. For return prediction, the empirical question is whether the GNN's ability to learn flexible functions of the graph structure outperforms the simpler approach of computing centrality measures and feeding them into standard models. The exercises provide a framework for answering this question rigorously.\n\nThe network perspective is not a replacement for standard asset pricing or corporate finance methods; it is a complement. The most productive research designs combine network structure with identification strategies from the causal inference toolkit: using network shocks as instruments, exploiting network disruptions as natural experiments, and controlling for network position when estimating treatment effects. The intersection of networks and causal inference (e.g., network interference, peer effects identification, spatial econometrics) represents the frontier of empirical finance.\n\n",
    "supporting": [
      "73_networks_graphs_files"
    ],
    "filters": [],
    "includes": {}
  }
}