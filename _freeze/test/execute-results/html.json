{
  "hash": "b435def80a5da3bdded55a6ab8e74b97",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Accessing and Managing Financial Data\nformat:\n  html:\n    toc: true\n    number-sections: true\njupyter: python3\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n## The Foundation of Empirical Finance\n\nEvery empirical finance project begins with data. Whether you're testing asset pricing models, constructing portfolios, or valuing companies, the quality and organization of your data fundamentally determines the quality of your analysis. This chapter establishes the data infrastructure that supports all subsequent chapters in this book.\n\nWorking with financial data presents unique challenges. Data comes from multiple sources in different formats. Date handling varies across systems. Missing values require careful treatment. And as datasets grow, memory constraints become binding. A systematic approach to data management (e.g., downloading, cleaning, storing, and retrieving) saves enormous time and prevents errors that can invalidate entire analyses.\n\nWe address these challenges by building a centralized SQLite database that stores all our financial data in a consistent format. This approach offers several advantages over scattered CSV files: consistent data types across sessions, efficient queries for specific subsets, easy sharing across projects and collaborators, and a single source of truth that eliminates version confusion.\n\nOur data infrastructure draws from two primary sources:\n\n1. **Public macroeconomic data** from sources like FRED (Federal Reserve Economic Data) and academic data libraries\n2. **Vietnamese market data** from DataCore, which provides stock prices, returns, and company fundamentals for firms listed on Vietnamese exchanges\n\nBy the end of this chapter, you will have a fully populated database containing stock returns, market capitalizations, company fundamentals, and risk factors. Everything needed for the portfolio analyses and asset pricing tests in subsequent chapters.\n\n::: {#432a9800 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nimport os\nfrom datetime import datetime\n\nfrom plotnine import *\nfrom mizani.formatters import comma_format, percent_format\n```\n:::\n\n\nWe define the date range for our analysis upfront, making future updates tractable:\n\n::: {#a1ba49a5 .cell execution_count=3}\n``` {.python .cell-code}\nstart_date = \"1960-01-01\"\nend_date = \"2024-12-31\"\n```\n:::\n\n\n## Setting Up the SQLite Database\n\nBefore downloading any data, we establish our storage infrastructure. We use SQLite, a lightweight, file-based database that requires no external server. SQLite is ideal for research applications: it's fast, reliable, and the database file can be easily shared or moved between computers.\n\n### Why a Database Instead of CSV Files?\n\nYou might wonder why we bother with a database when CSV files seem simpler. Consider these common problems with CSV-based workflows:\n\n1. **Type inconsistency**: Dates read as strings in one session, datetime objects in another. Numeric columns sometimes include commas or currency symbols.\n\n2. **Memory constraints**: Large datasets must be loaded entirely into memory, even when you only need a small subset.\n\n3. **Version confusion**: Multiple copies of \"cleaned\" data proliferate across projects, each slightly different.\n\n4. **Inefficient queries**: Finding all observations for a specific firm requires loading the entire dataset.\n\nA database solves all these problems. Data types are enforced on storage. Queries retrieve only the rows and columns you need. A single database file serves as the authoritative source.\n\n### Creating the Database\n\nCreating an SQLite database is remarkably simple:\n\n::: {#4c1c497b .cell execution_count=4}\n``` {.python .cell-code}\n# Create data directory if it doesn't exist\nif not os.path.exists(\"data\"):\n    os.makedirs(\"data\")\n\n# Connect to database (creates file if it doesn't exist)\ntidy_finance = sqlite3.connect(database=\"data/tidy_finance_python.sqlite\")\n\nprint(\"Database connection established\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDatabase connection established\n```\n:::\n:::\n\n\nThat's it. The database file `tidy_finance_python.sqlite` now exists in the `data` subdirectory. We'll populate it with tables throughout this chapter.\n\n## Connecting to DataCore\n\nDataCore is a leading provider of financial and economic data for the Vietnamese market. It offers comprehensive coverage of stock prices, company fundamentals, and corporate actions for firms listed on the Ho Chi Minh Stock Exchange (HOSE) and Hanoi Stock Exchange (HNX).\n\nAccess to DataCore typically requires a subscription, available through many university libraries. If you don't have access, DataCore provides demo datasets that allow you to run the code in this book with sample data.\n\n### Establishing the Connection\n\nDataCore data is accessed through a MinIO-compatible object storage interface. We establish the connection using credentials stored in environment variables:\n\n::: {#c6336558 .cell execution_count=5}\n``` {.python .cell-code}\nfrom io import BytesIO\nimport boto3\nfrom botocore.client import Config\n\n\nclass ConnectMinio:\n    \"\"\"\n    Connection handler for DataCore's MinIO-based data storage.\n    \n    Credentials should be set as environment variables:\n    - MINIO_ENDPOINT: The API endpoint URL\n    - MINIO_ACCESS_KEY: Your access key\n    - MINIO_SECRET_KEY: Your secret key\n    - MINIO_BUCKET: The bucket containing financial data\n    \"\"\"\n    \n    def __init__(self):\n        self.MINIO_ENDPOINT = os.environ.get(\"MINIO_ENDPOINT\")\n        self.MINIO_ACCESS_KEY = os.environ.get(\"MINIO_ACCESS_KEY\")\n        self.MINIO_SECRET_KEY = os.environ.get(\"MINIO_SECRET_KEY\")\n        self.REGION = os.environ.get(\"MINIO_REGION\", \"us-east-1\")\n        \n        if not all([self.MINIO_ENDPOINT, self.MINIO_ACCESS_KEY, self.MINIO_SECRET_KEY]):\n            raise ValueError(\n                \"Missing required environment variables. \"\n                \"Please set MINIO_ENDPOINT, MINIO_ACCESS_KEY, and MINIO_SECRET_KEY.\"\n            )\n        \n        self.s3 = boto3.client(\n            \"s3\",\n            endpoint_url=self.MINIO_ENDPOINT,\n            aws_access_key_id=self.MINIO_ACCESS_KEY,\n            aws_secret_access_key=self.MINIO_SECRET_KEY,\n            region_name=self.REGION,\n            config=Config(signature_version=\"s3v4\"),\n        )\n\n    def test_connection(self):\n        \"\"\"Verify connection by listing available buckets.\"\"\"\n        resp = self.s3.list_buckets()\n        print(\"Connected successfully. Available buckets:\")\n        for bucket in resp.get(\"Buckets\", []):\n            print(f\"  - {bucket['Name']}\")\n        return True\n\n\n# Establish connection\ntry:\n    conn = ConnectMinio()\n    s3 = conn.s3\n    conn.test_connection()\n    bucket_name = os.environ.get(\"MINIO_BUCKET\")\nexcept Exception as e:\n    print(f\"Could not connect to DataCore: {e}\")\n    print(\"Proceeding with existing local data if available.\")\n    s3 = None\n    bucket_name = None\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConnected successfully. Available buckets:\n  - dsteam-data\n  - rawbctc\n```\n:::\n:::\n\n\n## Downloading and Preparing Stock Price Data\n\nStock price data forms the foundation of most empirical finance research. We need daily and monthly prices to compute returns, market capitalizations, and various portfolio characteristics.\n\n### Loading Historical Prices\n\nDataCore provides historical price data including open, high, low, close prices, trading volume, and adjustment factors for corporate actions like stock splits and dividends:\n\n::: {#04e993ec .cell execution_count=6}\n``` {.python .cell-code}\nif s3 is not None and bucket_name is not None:\n    # Download price data from DataCore\n    prices_raw = pd.read_csv(\n        BytesIO(\n            s3.get_object(\n                Bucket=bucket_name,\n                Key=\"historycal_price/dataset_historical_price.csv\"\n            )[\"Body\"].read()\n        ),\n        low_memory=False\n    )\n    print(f\"Downloaded {len(prices_raw):,} price observations\")\nelse:\n    # Load from existing database if available\n    try:\n        prices_raw = pd.read_sql_query(\n            \"SELECT * FROM prices_daily_raw\",\n            con=tidy_finance\n        )\n        print(f\"Loaded {len(prices_raw):,} price observations from local database\")\n    except:\n        print(\"No price data available. Please check DataCore connection.\")\n        prices_raw = pd.DataFrame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloaded 4,307,791 price observations\n```\n:::\n:::\n\n\n### Cleaning and Standardizing Price Data\n\nRaw price data requires several transformations before it's ready for analysis:\n\n::: {#4ed1b2a4 .cell execution_count=7}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    prices = prices_raw.copy()\n    \n    # Convert date column\n    prices[\"date\"] = pd.to_datetime(prices[\"date\"])\n    \n    # Calculate adjusted close price\n    # The adjustment ratio accounts for splits, dividends, etc.\n    prices[\"adjusted_close\"] = prices[\"close_price\"] * prices[\"adj_ratio\"]\n    \n    # Standardize column names\n    prices = prices.rename(columns={\n        \"vol_total\": \"volume\",\n        \"open_price\": \"open\",\n        \"low_price\": \"low\",\n        \"high_price\": \"high\",\n        \"close_price\": \"close\"\n    })\n    \n    # Ensure proper sorting for return calculations\n    prices = prices.sort_values([\"symbol\", \"date\"]).reset_index(drop=True)\n    \n    print(f\"Processed prices for {prices['symbol'].nunique():,} securities\")\n    print(f\"Date range: {prices['date'].min().date()} to {prices['date'].max().date()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessed prices for 1,837 securities\nDate range: 2010-01-04 to 2025-05-12\n```\n:::\n:::\n\n\n### Computing Returns\n\nReturns are the primary variable of interest in asset pricing. We compute simple returns from adjusted prices:\n\n$$\nr_{i,t} = \\frac{P_{i,t} - P_{i,t-1}}{P_{i,t-1}} = \\frac{P_{i,t}}{P_{i,t-1}} - 1\n$$\n\nwhere $P_{i,t}$ is the adjusted closing price of stock $i$ on day $t$.\n\n::: {#5c0e7a2a .cell execution_count=8}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    # Compute daily returns\n    prices[\"ret\"] = (\n        prices.groupby(\"symbol\")[\"adjusted_close\"]\n        .pct_change()\n    )\n    \n    # Handle extreme values\n    # Returns below -100% are economically impossible\n    prices[\"ret\"] = prices[\"ret\"].clip(lower=-0.99)\n    \n    # Check for data quality\n    print(\"Return statistics:\")\n    print(prices[\"ret\"].describe().round(4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReturn statistics:\ncount    4.305128e+06\nmean              inf\nstd               NaN\nmin     -9.900000e-01\n25%     -4.200000e-03\n50%      0.000000e+00\n75%      3.200000e-03\nmax               inf\nName: ret, dtype: float64\n```\n:::\n:::\n\n\n### Aggregating to Monthly Frequency\n\nWhile daily data is useful for some applications, monthly data is standard for portfolio analysis and asset pricing tests. We aggregate by taking the last observation of each month:\n\n::: {#595272ee .cell execution_count=9}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    # Resample to monthly frequency\n    prices_monthly = (\n        prices\n        .sort_values([\"symbol\", \"date\"])\n        .groupby(\"symbol\")\n        .resample(\"ME\", on=\"date\")  # Month-End frequency\n        .last()\n        .drop(columns=[\"symbol\", \"date\"], errors=\"ignore\")\n        .reset_index()\n    )\n    \n    # Compute monthly returns\n    prices_monthly[\"ret\"] = (\n        prices_monthly.groupby(\"symbol\")[\"adjusted_close\"]\n        .pct_change()\n    )\n    \n    prices_monthly[\"ret\"] = prices_monthly[\"ret\"].clip(lower=-0.99)\n    \n    print(f\"Monthly observations: {len(prices_monthly):,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMonthly observations: 210,331\n```\n:::\n:::\n\n\n### Computing Market Capitalization\n\nMarket capitalization—the total market value of a company's outstanding shares—is essential for constructing value-weighted portfolios and size-based sorts:\n\n$$\n\\text{Market Cap}_{i,t} = \\text{Price}_{i,t} \\times \\text{Shares Outstanding}_{i,t}\n$$\n\nShares outstanding must be obtained from fundamental data, which we'll merge shortly.\n\n## Downloading and Preparing Company Fundamentals\n\nCompany fundamentals—accounting data from financial statements—provide the book values, earnings, and other metrics used in factor models and valuation.\n\n### Loading Fundamental Data\n\nDataCore provides annual fundamental data split across multiple files. We load and concatenate them:\n\n::: {#7e07e038 .cell execution_count=10}\n``` {.python .cell-code}\nif s3 is not None and bucket_name is not None:\n    # Define paths to fundamental data files\n    fundamental_paths = [\n        \"fundamental_annual_1767674486317/fundamental_annual_1.xlsx\",\n        \"fundamental_annual_1767674486317/fundamental_annual_2.xlsx\",\n        \"fundamental_annual_1767674486317/fundamental_annual_3.xlsx\",\n    ]\n    \n    # Load and concatenate\n    fundamental_dfs = []\n    for path in fundamental_paths:\n        try:\n            obj = s3.get_object(Bucket=bucket_name, Key=path)\n            df_tmp = pd.read_excel(BytesIO(obj[\"Body\"].read()))\n            fundamental_dfs.append(df_tmp)\n        except Exception as e:\n            print(f\"Could not load {path}: {e}\")\n    \n    if fundamental_dfs:\n        fundamentals_raw = pd.concat(fundamental_dfs, ignore_index=True)\n        print(f\"Loaded {len(fundamentals_raw):,} fundamental observations\")\n    else:\n        fundamentals_raw = pd.DataFrame()\nelse:\n    try:\n        fundamentals_raw = pd.read_sql_query(\n            \"SELECT * FROM comp_vn_raw\",\n            con=tidy_finance\n        )\n        print(f\"Loaded {len(fundamentals_raw):,} fundamental observations from local database\")\n    except:\n        print(\"No fundamental data available.\")\n        fundamentals_raw = pd.DataFrame()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoaded 22,821 fundamental observations\n```\n:::\n:::\n\n\n### Cleaning Fundamental Data\n\nFundamental data requires careful cleaning to handle duplicates, missing values, and inconsistent formats:\n\n::: {#384410e2 .cell execution_count=11}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    comp_vn = fundamentals_raw.copy()\n    \n    # Standardize identifiers\n    comp_vn[\"symbol\"] = comp_vn[\"symbol\"].astype(str).str.upper().str.strip()\n    comp_vn[\"year\"] = pd.to_numeric(comp_vn[\"year\"], errors=\"coerce\").astype(\"Int64\")\n    \n    # Drop rows missing key identifiers\n    comp_vn = comp_vn.dropna(subset=[\"symbol\", \"year\"])\n    \n    # Convert numeric columns\n    numeric_columns = [\n        \"total_asset\", \"total_equity\", \"total_liabilities\",\n        \"total_current_liabilities\", \"total_current_asset\",\n        \"is_net_revenue\", \"is_cogs\", \"is_manage_expense\",\n        \"is_interest_expense\", \"is_gross_profit\", \"is_eat\",\n        \"ca_cce\", \"ca_total_inventory\", \"ca_acc_receiv\",\n        \"cfo_depreciation\", \"capex\", \"total_cfo\",\n        \"is_ebt\", \"is_cit_expense\", \"is_net_business_profit\",\n        \"cfo_receive\", \"cfo_inventory\", \"cfo_payale\",\n        \"na_tax_deferred\", \"nl_tax_deferred\", \"e_preferred_stock\",\n        \"cl_loan\", \"cl_finlease\", \"cl_due_long_debt\",\n        \"nl_loan\", \"nl_finlease\",\n        \"is_cos_of_sales\", \"basic_eps\", \"is_shareholders_eat\"\n    ]\n    \n    for col in numeric_columns:\n        if col in comp_vn.columns:\n            comp_vn[col] = pd.to_numeric(comp_vn[col], errors=\"coerce\")\n    \n    # Handle duplicates: keep row with most non-missing values\n    comp_vn[\"_completeness\"] = comp_vn.notna().sum(axis=1)\n    comp_vn = (\n        comp_vn\n        .sort_values([\"symbol\", \"year\", \"_completeness\"])\n        .drop_duplicates(subset=[\"symbol\", \"year\"], keep=\"last\")\n        .drop(columns=[\"_completeness\"])\n        .reset_index(drop=True)\n    )\n    \n    print(f\"Cleaned fundamentals: {len(comp_vn):,} observations\")\n    print(f\"Unique firms: {comp_vn['symbol'].nunique():,}\")\n    print(f\"Year range: {comp_vn['year'].min()} to {comp_vn['year'].max()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCleaned fundamentals: 21,232 observations\nUnique firms: 1,554\nYear range: 1998 to 2023\n```\n:::\n:::\n\n\n### Creating Standardized Variables\n\nWe create standardized variable names following conventions from the academic literature, particularly the Compustat naming conventions used in US research:\n\n::: {#47fa3d60 .cell execution_count=12}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    # Fiscal year-end date\n    comp_vn[\"datadate\"] = pd.to_datetime(comp_vn[\"year\"].astype(str) + \"-12-31\")\n    \n    # Balance sheet items\n    comp_vn[\"at\"] = comp_vn[\"total_asset\"]  # Total assets\n    comp_vn[\"act\"] = comp_vn[\"total_current_asset\"]  # Current assets\n    comp_vn[\"lt\"] = comp_vn[\"total_liabilities\"]  # Total liabilities\n    comp_vn[\"lct\"] = comp_vn[\"total_current_liabilities\"]  # Current liabilities\n    comp_vn[\"seq\"] = comp_vn[\"total_equity\"]  # Stockholders' equity\n    \n    # Income statement items\n    comp_vn[\"sale\"] = comp_vn[\"is_net_revenue\"]  # Revenue\n    comp_vn[\"cogs\"] = comp_vn.get(\"is_cogs\", 0)  # Cost of goods sold\n    comp_vn[\"xsga\"] = comp_vn.get(\"is_manage_expense\", 0)  # SG&A expenses\n    comp_vn[\"xint\"] = comp_vn.get(\"is_interest_expense\", 0)  # Interest expense\n    \n    # Cash flow items\n    comp_vn[\"oancf\"] = comp_vn.get(\"total_cfo\", np.nan)  # Operating cash flow\n    comp_vn[\"capx\"] = comp_vn.get(\"capex\", np.nan)  # Capital expenditures\n    \n    # Deferred taxes (for book equity calculation)\n    comp_vn[\"txditc\"] = comp_vn.get(\"na_tax_deferred\", 0).fillna(0)\n    comp_vn[\"txdb\"] = comp_vn.get(\"nl_tax_deferred\", 0).fillna(0)\n    \n    # Preferred stock\n    comp_vn[\"pstk\"] = comp_vn.get(\"e_preferred_stock\", 0).fillna(0)\n```\n:::\n\n\n### Computing Book Equity\n\nBook equity is a critical variable for the value factor (HML) in the Fama-French model. We follow the standard definition from @Fama1992:\n\n$$\n\\text{Book Equity} = \\text{Stockholders' Equity} + \\text{Deferred Taxes} - \\text{Preferred Stock}\n$$\n\n::: {#2161c1dc .cell execution_count=13}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    # Compute book equity\n    comp_vn[\"be\"] = (\n        comp_vn[\"seq\"]\n        + comp_vn[\"txditc\"].fillna(0)\n        - comp_vn[\"pstk\"].fillna(0)\n    )\n    \n    # Set negative or zero book equity to missing\n    # This is standard practice—negative BE makes ratios meaningless\n    comp_vn[\"be\"] = comp_vn[\"be\"].apply(\n        lambda x: np.nan if pd.isna(x) or x <= 0 else x\n    )\n    \n    print(f\"Observations with valid book equity: {comp_vn['be'].notna().sum():,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nObservations with valid book equity: 20,235\n```\n:::\n:::\n\n\n### Computing Profitability and Investment\n\nThe Fama-French five-factor model requires measures of profitability and investment:\n\n::: {#af82a92a .cell execution_count=14}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    # Operating profitability (Fama-French definition)\n    # OP = (Revenue - COGS - SG&A - Interest) / Book Equity\n    comp_vn[\"op\"] = (\n        (comp_vn[\"sale\"] \n         - comp_vn[\"cogs\"].fillna(0)\n         - comp_vn[\"xsga\"].fillna(0)\n         - comp_vn[\"xint\"].fillna(0))\n        / comp_vn[\"be\"]\n    )\n    \n    # Investment (asset growth)\n    # First, create lagged assets\n    comp_vn_lag = (\n        comp_vn[[\"symbol\", \"year\", \"at\"]]\n        .assign(year=lambda x: x[\"year\"] + 1)\n        .rename(columns={\"at\": \"at_lag\"})\n    )\n    \n    comp_vn = comp_vn.merge(comp_vn_lag, on=[\"symbol\", \"year\"], how=\"left\")\n    \n    # Investment = (Assets_t / Assets_{t-1}) - 1\n    comp_vn[\"inv\"] = comp_vn[\"at\"] / comp_vn[\"at_lag\"] - 1\n    comp_vn.loc[comp_vn[\"at_lag\"] <= 0, \"inv\"] = np.nan\n```\n:::\n\n\n### Computing Total Debt\n\nFor leverage analysis, we need total interest-bearing debt. In Vietnamese financial reports, total liabilities include non-interest-bearing items like accounts payable. We compute true debt by aggregating loan and lease obligations:\n\n::: {#207f06c3 .cell execution_count=15}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    debt_columns = [\"cl_loan\", \"cl_finlease\", \"cl_due_long_debt\", \"nl_loan\", \"nl_finlease\"]\n    \n    for col in debt_columns:\n        if col not in comp_vn.columns:\n            comp_vn[col] = 0\n    \n    comp_vn[\"total_debt\"] = (\n        comp_vn[\"cl_loan\"].fillna(0)\n        + comp_vn[\"cl_finlease\"].fillna(0)\n        + comp_vn[\"cl_due_long_debt\"].fillna(0)\n        + comp_vn[\"nl_loan\"].fillna(0)\n        + comp_vn[\"nl_finlease\"].fillna(0)\n    )\n    \n    # Also compute SG&A for financial statement analysis\n    comp_vn[\"selling_general_and_administrative_expenses\"] = (\n        comp_vn.get(\"is_cos_of_sales\", 0).fillna(0)\n        + comp_vn.get(\"is_manage_expense\", 0).fillna(0)\n    )\n```\n:::\n\n\n### Filtering to Valid Observations\n\nWe keep only firm-years with the minimum required data for meaningful analysis:\n\n::: {#14bb74d1 .cell execution_count=16}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    required_columns = [\"at\", \"lt\", \"seq\", \"sale\"]\n    \n    comp_vn = comp_vn.dropna(subset=required_columns)\n    comp_vn = comp_vn[comp_vn[\"at\"] > 0]  # Assets must be positive\n    comp_vn = comp_vn[comp_vn[\"sale\"] >= 0]  # Sales cannot be negative\n    \n    # Keep only the last observation per firm-year\n    comp_vn = (\n        comp_vn\n        .sort_values(\"datadate\")\n        .groupby([\"symbol\", \"year\"])\n        .tail(1)\n        .reset_index(drop=True)\n    )\n    \n    print(f\"Final fundamental observations: {len(comp_vn):,}\")\n    print(f\"Unique firms: {comp_vn['symbol'].nunique():,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal fundamental observations: 20,091\nUnique firms: 1,502\n```\n:::\n:::\n\n\n## Merging Stock Prices with Fundamentals\n\nTo compute market-based ratios like book-to-market, we need to merge stock price data with company fundamentals. The key challenge is timing: accounting data is released with a lag, so we must be careful not to introduce look-ahead bias.\n\n### Computing Market Capitalization\n\nFirst, we need shares outstanding to compute market cap. We estimate this from earnings per share and net income:\n\n::: {#30abcaaa .cell execution_count=17}\n``` {.python .cell-code}\nif not fundamentals_raw.empty and not prices_raw.empty:\n    # Estimate shares outstanding from fundamentals\n    # Shares = Net Income / EPS\n    comp_vn[\"shrout\"] = (\n        comp_vn[\"is_shareholders_eat\"] / comp_vn[\"basic_eps\"]\n    )\n    \n    # Add year to prices for merging\n    prices_monthly[\"year\"] = prices_monthly[\"date\"].dt.year\n    \n    # Merge shares outstanding onto monthly prices\n    prices_monthly = prices_monthly.merge(\n        comp_vn[[\"symbol\", \"year\", \"shrout\"]],\n        on=[\"symbol\", \"year\"],\n        how=\"left\"\n    )\n    \n    # Compute market capitalization\n    # Market Cap = Price × Shares Outstanding\n    prices_monthly[\"mktcap\"] = prices_monthly[\"close\"] * prices_monthly[\"shrout\"]\n    \n    # Convert to millions and handle zeros\n    prices_monthly[\"mktcap\"] = (\n        prices_monthly[\"mktcap\"] / 1e6\n    ).replace(0, np.nan)\n```\n:::\n\n\n### Computing Lagged Market Capitalization\n\nFor value-weighted portfolio returns, we need market cap at the beginning of the return period (i.e., lagged market cap):\n\n::: {#8539f03e .cell execution_count=18}\n``` {.python .cell-code}\nif not fundamentals_raw.empty and not prices_raw.empty:\n    prices_monthly[\"mktcap_lag\"] = (\n        prices_monthly\n        .groupby(\"symbol\")[\"mktcap\"]\n        .shift(1)\n    )\n```\n:::\n\n\n### Computing Excess Returns\n\nExcess returns—returns above the risk-free rate—are the dependent variable in asset pricing tests. We use the Vietnam government bond yield as our risk-free rate proxy:\n\n::: {#692d8cc6 .cell execution_count=19}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    # Vietnam 10-year government bond yield (approximately 4% annualized)\n    # This is a reasonable proxy when Fama-French Vietnam data isn't available\n    annual_rf = 0.04\n    monthly_rf = annual_rf / 12\n    \n    # Create risk-free rate series\n    rf_monthly = pd.DataFrame({\n        \"date\": pd.date_range(\n            start=prices_monthly[\"date\"].min(),\n            end=prices_monthly[\"date\"].max(),\n            freq=\"ME\"\n        ),\n        \"risk_free\": monthly_rf\n    })\n    \n    # Merge and compute excess returns\n    prices_monthly = prices_monthly.merge(rf_monthly, on=\"date\", how=\"left\")\n    \n    prices_monthly[\"ret_excess\"] = prices_monthly[\"ret\"] - prices_monthly[\"risk_free\"]\n    \n    # Bound excess returns at -100%\n    prices_monthly[\"ret_excess\"] = prices_monthly[\"ret_excess\"].clip(lower=-1)\n```\n:::\n\n\n### Final Cleaning\n\nRemove observations with missing critical values:\n\n::: {#2ee1864c .cell execution_count=20}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    # Remove rows with missing returns or market cap\n    prices_monthly = prices_monthly.dropna(\n        subset=[\"ret_excess\", \"mktcap\", \"mktcap_lag\"]\n    )\n    \n    # Remove infinite values\n    prices_monthly = prices_monthly.replace([np.inf, -np.inf], np.nan)\n    prices_monthly = prices_monthly.dropna(subset=[\"ret_excess\"])\n    \n    print(f\"Final monthly price observations: {len(prices_monthly):,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal monthly price observations: 160,482\n```\n:::\n:::\n\n\n## Constructing Factor Data\n\nFor asset pricing tests, we need factor returns. While Fama-French provide factors for the US market, we must construct our own for Vietnam. This section creates a placeholder structure; the full factor construction is covered in a later chapter.\n\n### Market Factor\n\nThe market factor is the value-weighted return on all stocks minus the risk-free rate:\n\n::: {#4d6a8557 .cell execution_count=21}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    # Compute value-weighted market return\n    factors_monthly = (\n        prices_monthly\n        .groupby(\"date\")\n        .apply(\n            lambda x: pd.Series({\n                \"mkt_excess\": np.average(\n                    x[\"ret_excess\"],\n                    weights=x[\"mktcap_lag\"]\n                ) if x[\"mktcap_lag\"].sum() > 0 else np.nan\n            }),\n            include_groups=False\n        )\n        .reset_index()\n    )\n    \n    # Add risk-free rate for reference\n    factors_monthly = factors_monthly.merge(\n        rf_monthly,\n        on=\"date\",\n        how=\"left\"\n    )\n    \n    print(\"Market factor statistics:\")\n    print(factors_monthly[\"mkt_excess\"].describe().round(4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMarket factor statistics:\ncount    167.0000\nmean      -0.0130\nstd        0.0585\nmin       -0.2133\n25%       -0.0406\n50%       -0.0117\n75%        0.0193\nmax        0.1682\nName: mkt_excess, dtype: float64\n```\n:::\n:::\n\n\n## Storing Data in the Database\n\nWith all data prepared, we store it in our SQLite database for use in subsequent chapters.\n\n### Storing Company Fundamentals\n\n::: {#92002be6 .cell execution_count=22}\n``` {.python .cell-code}\nif not fundamentals_raw.empty:\n    comp_vn.to_sql(\n        name=\"comp_vn\",\n        con=tidy_finance,\n        if_exists=\"replace\",\n        index=False\n    )\n    print(f\"Stored {len(comp_vn):,} fundamental observations in 'comp_vn' table\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStored 20,091 fundamental observations in 'comp_vn' table\n```\n:::\n:::\n\n\n### Storing Monthly Prices\n\n::: {#d62b75d6 .cell execution_count=23}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    prices_monthly.to_sql(\n        name=\"prices_monthly\",\n        con=tidy_finance,\n        if_exists=\"replace\",\n        index=False\n    )\n    print(f\"Stored {len(prices_monthly):,} price observations in 'prices_monthly' table\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStored 160,482 price observations in 'prices_monthly' table\n```\n:::\n:::\n\n\n### Storing Factor Data\n\n::: {#17264206 .cell execution_count=24}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    factors_monthly.to_sql(\n        name=\"factors_ff5_monthly\",\n        con=tidy_finance,\n        if_exists=\"replace\",\n        index=False\n    )\n    print(f\"Stored {len(factors_monthly):,} factor observations in 'factors_ff5_monthly' table\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStored 167 factor observations in 'factors_ff5_monthly' table\n```\n:::\n:::\n\n\n## Accessing Data from the Database\n\nIn subsequent chapters, retrieving data is straightforward:\n\n::: {#fca8a21a .cell execution_count=25}\n``` {.python .cell-code}\n# Example: Load monthly prices\nprices_from_db = pd.read_sql_query(\n    sql=\"SELECT * FROM prices_monthly\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\nprint(f\"Retrieved {len(prices_from_db):,} observations from database\")\nprices_from_db.head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRetrieved 160,482 observations from database\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>date</th>\n      <th>#</th>\n      <th>id</th>\n      <th>adj_ratio</th>\n      <th>average_price</th>\n      <th>basic_price</th>\n      <th>buy_count</th>\n      <th>buy_vol_foreign</th>\n      <th>buy_val_foreigh</th>\n      <th>...</th>\n      <th>vol_putth</th>\n      <th>volume</th>\n      <th>year</th>\n      <th>adjusted_close</th>\n      <th>ret</th>\n      <th>shrout</th>\n      <th>mktcap</th>\n      <th>mktcap_lag</th>\n      <th>risk_free</th>\n      <th>ret_excess</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A32</td>\n      <td>2018-11-30</td>\n      <td>2186706.0</td>\n      <td>2186706.0</td>\n      <td>1.72102</td>\n      <td>32.0</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018</td>\n      <td>55.072640</td>\n      <td>0.235521</td>\n      <td>6.800000e+06</td>\n      <td>217.60</td>\n      <td>176.12</td>\n      <td>0.003333</td>\n      <td>0.232188</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A32</td>\n      <td>2018-12-31</td>\n      <td>2186726.0</td>\n      <td>2186726.0</td>\n      <td>1.72102</td>\n      <td>30.2</td>\n      <td>30.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2018</td>\n      <td>51.974804</td>\n      <td>-0.056250</td>\n      <td>6.800000e+06</td>\n      <td>205.36</td>\n      <td>217.60</td>\n      <td>0.003333</td>\n      <td>-0.059583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A32</td>\n      <td>2019-01-31</td>\n      <td>2186748.0</td>\n      <td>2186748.0</td>\n      <td>1.64034</td>\n      <td>30.5</td>\n      <td>30.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2019</td>\n      <td>50.030370</td>\n      <td>-0.037411</td>\n      <td>6.800000e+06</td>\n      <td>207.40</td>\n      <td>205.36</td>\n      <td>0.003333</td>\n      <td>-0.040744</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 37 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#c266d188 .cell execution_count=26}\n``` {.python .cell-code}\n# Example: Load specific columns with a filter\nrecent_data = pd.read_sql_query(\n    sql=\"\"\"\n    SELECT symbol, date, ret_excess, mktcap \n    FROM prices_monthly \n    WHERE date >= '2020-01-01'\n    \"\"\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\nprint(f\"Retrieved {len(recent_data):,} observations from 2020 onward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRetrieved 63,904 observations from 2020 onward\n```\n:::\n:::\n\n\n## Descriptive Statistics\n\nBefore concluding, let's examine some key characteristics of our data.\n\n### Sample Coverage Over Time\n\n@fig-100 shows the number of securities in our sample over time:\n\n::: {#cell-fig-100 .cell execution_count=27}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    securities_per_month = (\n        prices_monthly\n        .groupby(\"date\")\n        .agg(n_securities=(\"symbol\", \"nunique\"))\n        .reset_index()\n    )\n    \n    coverage_figure = (\n        ggplot(securities_per_month, aes(x=\"date\", y=\"n_securities\"))\n        + geom_line(color=\"steelblue\", size=1)\n        + labs(\n            x=\"\", y=\"Number of Securities\",\n            title=\"Monthly Number of Securities in Vietnam Stock Sample\"\n        )\n        + scale_y_continuous(labels=comma_format())\n        + theme_minimal()\n    )\n    \n    coverage_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The figure shows the monthly number of securities with valid return and market capitalization data in the Vietnamese stock market.](test_files/figure-html/fig-100-output-1.png){#fig-100 width=672 height=480 fig-alt='Title: Monthly number of securities over time. The figure shows a line chart with the count of securities by month.'}\n:::\n:::\n\n\n### Market Capitalization Distribution\n\n@fig-101 shows the evolution of total market capitalization:\n\n::: {#cell-fig-101 .cell execution_count=28}\n``` {.python .cell-code}\nif not prices_raw.empty:\n    total_mktcap = (\n        prices_monthly\n        .groupby(\"date\")\n        .agg(total_mktcap=(\"mktcap\", \"sum\"))\n        .reset_index()\n    )\n    \n    mktcap_figure = (\n        ggplot(total_mktcap, aes(x=\"date\", y=\"total_mktcap/1000\"))\n        + geom_line(color=\"darkgreen\", size=1)\n        + labs(\n            x=\"\", y=\"Total Market Cap (Billion VND)\",\n            title=\"Total Market Capitalization of Vietnamese Stocks\"\n        )\n        + scale_y_continuous(labels=comma_format())\n        + theme_minimal()\n    )\n    \n    mktcap_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The figure shows the total market capitalization of Vietnamese stocks over time.](test_files/figure-html/fig-101-output-1.png){#fig-101 width=672 height=480 fig-alt='Title: Total market capitalization over time. The figure shows a line chart of aggregate market cap.'}\n:::\n:::\n\n\n### Book Equity Coverage\n\n@fig-102 shows the share of securities with valid book equity values over time:\n\n::: {#cell-fig-102 .cell execution_count=29}\n``` {.python .cell-code}\nif not fundamentals_raw.empty and not prices_raw.empty:\n    # Merge to check book equity coverage\n    share_with_be = (\n        prices_monthly\n        .assign(year=lambda x: x[\"date\"].dt.year)\n        .sort_values(\"date\")\n        .groupby([\"symbol\", \"year\"])\n        .tail(1)\n        .merge(comp_vn[[\"symbol\", \"year\", \"be\"]], on=[\"symbol\", \"year\"], how=\"left\")\n        .groupby(\"year\")\n        .apply(\n            lambda x: pd.Series({\n                \"share_with_be\": x[\"be\"].notna().sum() / len(x)\n            }),\n            include_groups=False\n        )\n        .reset_index()\n    )\n    \n    be_coverage_figure = (\n        ggplot(share_with_be, aes(x=\"year\", y=\"share_with_be\"))\n        + geom_line(color=\"darkorange\", size=1)\n        + geom_point(color=\"darkorange\", size=2)\n        + labs(\n            x=\"Year\", y=\"Share with Book Equity\",\n            title=\"Share of Securities with Book Equity Values\"\n        )\n        + scale_y_continuous(labels=percent_format(), limits=(0, 1))\n        + theme_minimal()\n    )\n    \n    be_coverage_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The figure shows the share of securities with book equity values from financial statements.](test_files/figure-html/fig-102-output-1.png){#fig-102 width=672 height=480 fig-alt='Title: Share of securities with book equity. The figure shows a line chart of the percentage of securities with valid book equity data.'}\n:::\n:::\n\n\n## Database Maintenance\n\nOver time, database files can become bloated as deleted data leaves empty space. The `VACUUM` command rebuilds the database to reclaim this space:\n\n::: {#aa8a82de .cell execution_count=30}\n``` {.python .cell-code}\n# Optimize database file size\ntidy_finance.execute(\"VACUUM\")\nprint(\"Database optimized\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDatabase optimized\n```\n:::\n:::\n\n\n## Key Takeaways\n\nThis chapter established the data infrastructure that supports all subsequent analyses in this book. The main insights are:\n\n1. **Centralized storage beats scattered files**: An SQLite database provides consistent data types, efficient queries, and a single source of truth across all projects.\n\n2. **DataCore provides comprehensive Vietnamese market data**: Stock prices, returns, and company fundamentals are available for firms listed on HOSE and HNX through DataCore's API.\n\n3. **Data cleaning requires careful attention**: Handling duplicates, missing values, date formats, and extreme values is essential before any analysis.\n\n4. **Standardized variable names facilitate replication**: Following academic conventions (like Compustat naming) makes code more readable and research more comparable.\n\n5. **Book equity requires proper construction**: The Fama-French definition combines stockholders' equity, deferred taxes, and preferred stock with careful handling of negative values.\n\n6. **Market cap links prices to fundamentals**: Shares outstanding from fundamentals combined with market prices yields market capitalization for portfolio weighting.\n\n7. **Excess returns are the standard dependent variable**: Subtracting the risk-free rate from raw returns yields the quantity that asset pricing models aim to explain.\n\nWith our database populated, subsequent chapters can focus on analysis rather than data wrangling. Each chapter will begin by loading the relevant tables and proceed directly to portfolio construction, factor analysis, or valuation.\n\n",
    "supporting": [
      "test_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}