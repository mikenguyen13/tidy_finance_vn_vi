{
  "hash": "143a94e0b22f856fea67658c6a692ac9",
  "result": {
    "engine": "jupyter",
    "markdown": "# Textual Analysis\n\nTextual analysis has emerged as one of the most productive research frontiers in empirical finance over the past two decades. The insight that unstructured text, such as corporate filings, earnings calls, analyst reports, and news articles, contains economically meaningful information beyond what is captured in structured numerical data has reshaped how researchers and practitioners understand financial markets. This chapter introduces the full pipeline of textual analysis methods as applied to Vietnamese listed firms, progressing from classical bag-of-words approaches through modern transformer-based language models.\n\nThe Vietnamese equity market presents unique opportunities and challenges for textual analysis. As of 2024, the Ho Chi Minh Stock Exchange (HOSE) and the Hanoi Stock Exchange (HNX) together list over 1,600 securities with a combined market capitalization exceeding VND 6,000 trillion (approximately USD 240 billion). Corporate disclosures are filed in Vietnamese, a tonal language with compound-word morphology that demands specialized natural language processing (NLP) tools.\n\nWe build on the seminal contributions of @loughran2011liability in domain-specific sentiment lexicons, @hoberg2016text in text-based industry classification, and the modern deep learning revolution initiated by @devlin2019bert. This chapter covers the following topics:\n\n1.  Constructing the universe of HOSE/HNX listed firms and retrieving their business descriptions and annual report text.\n2.  Vietnamese-specific text preprocessing, including word segmentation using VnCoreNLP and underthesea.\n3.  Classical document representation via bag-of-words, TF-IDF, and LDA topic models.\n4.  Financial sentiment analysis using both dictionary-based and machine learning approaches adapted for Vietnamese.\n5.  Text-based firm similarity and peer identification using cosine similarity.\n6.  Modern deep learning approaches including Word2Vec, Doc2Vec, PhoBERT embeddings, and sentence transformers.\n7.  Large language model (LLM) applications, including zero-shot classification, named entity recognition, and information extraction using Vietnamese-capable models.\n8.  Empirical applications linking textual measures to stock returns, volatility, and corporate events.\n\n## Why Textual Analysis for Vietnamese Finance? {#sec-why-vietnam}\n\nThe Vietnamese financial market has several characteristics that make textual analysis particularly valuable. First, analyst coverage is sparse (fewer than 30% of listed firms receive regular coverage from sell-side analysts), making alternative information sources critical. Second, the regulatory environment is evolving rapidly, with the State Securities Commission (SSC) continuously updating disclosure requirements, creating rich variation in information environments across firms and time. Third, the market is dominated by retail investors (accounting for roughly 80% of trading volume), who may process textual information differently than institutional investors, creating potential mispricings that text-based strategies could exploit.\n\nFrom a methodological standpoint, Vietnamese poses interesting NLP challenges. Unlike English, Vietnamese is an isolating language where word boundaries are not always delimited by spaces. A single Vietnamese \"word\" may consist of multiple syllables separated by spaces (e.g., \"công ty\" for \"company,\" \"thị trường\" for \"market\"). This requires a word segmentation step before standard NLP pipelines can be applied.[^60_textual-1]\n\n[^60_textual-1]: Vietnamese text requires specialized tokenization due to compound words (e.g., \"công ty\" = company, \"thị trường\" = market).\n\n# Literature Review {#sec-literature}\n\n## Textual Analysis in Finance {#sec-lit-finance}\n\nThe application of textual analysis to financial data has a rich history. @tetlock2007giving demonstrated that the pessimism content of a Wall Street Journal column predicts aggregate market activity, providing early evidence that textual content moves prices. @loughran2011liability showed that the widely-used Harvard General Inquirer sentiment dictionary produces misleading results when applied to financial text because words like \"liability,\" \"tax,\" and \"capital\" are classified as negative in general English but carry neutral or even positive connotations in finance. Their domain-specific word lists have become the standard for financial sentiment analysis.[^60_textual-2]\n\n[^60_textual-2]: @loughran2011liability show that general-purpose dictionaries misclassify up to 73% of negative words in financial text.\n\n@hoberg2010product and @hoberg2016text pioneered the use of product descriptions from 10-K filings to construct text-based industry classifications (TNIC), demonstrating that these dynamic, firm-specific industry definitions outperform static SIC and NAICS codes in explaining firm behavior, including profitability, stock returns, and M&A activity. Subsequent work by @hoberg2018text extended this to assess competitive threats and product-market fluidity.\n\nMore recent work has leveraged advances in deep learning. @huang2023finbert apply BERT-based models to earnings call transcripts and show that contextual embeddings capture information about future earnings that traditional bag-of-words measures miss. @jha2024chatgpt use GPT-based models for zero-shot financial text classification and demonstrate that LLMs can match or exceed purpose-built classifiers on standard benchmarks.\n\n## NLP for Vietnamese Language {#sec-lit-vnlp}\n\nVietnamese NLP has advanced significantly with the development of VnCoreNLP [@vu2018vncorenlp], a Java-based toolkit providing word segmentation, POS tagging, named entity recognition, and dependency parsing. The underthesea library offers a Python-native alternative. Most critically for financial applications, PhoBERT [@nguyen2020phobert] provides Vietnamese-specific BERT pre-training on a 20GB corpus, achieving state-of-the-art results on multiple Vietnamese NLP tasks.\n\n| Study | Method | Key Finding | Relevance to Vietnam |\n|:-----------------|:-----------------|:-----------------|:------------------|\n| @tetlock2007giving | Dictionary-based sentiment from WSJ column | Media pessimism predicts market activity and returns | Baseline for Vietnamese financial news sentiment |\n| @loughran2011liability | Domain-specific financial dictionaries | General dictionaries misclassify 73% of negative financial words | Need for Vietnamese financial sentiment lexicon |\n| @hoberg2016text | Cosine similarity on 10-K product descriptions | Text-based industries outperform SIC/NAICS | Peer identification for Vietnamese firms using business descriptions |\n| @nguyen2020phobert | PhoBERT: Vietnamese BERT pre-training | SOTA on Vietnamese NLP benchmarks | Foundation model for Vietnamese financial NLP |\n| @huang2023finbert | BERT embeddings on earnings calls | Contextual embeddings predict future earnings beyond BoW | Apply to Vietnamese earnings call transcripts |\n| @jha2024chatgpt | GPT-based zero-shot financial classification | LLMs match fine-tuned classifiers | Zero-shot Vietnamese financial text classification via multilingual LLMs |\n\n: Key Literature on Textual Analysis in Finance {#tbl-literature}\n\n# Data: Vietnamese Listed Firms from DataCore.vn {#sec-data}\n\n## Constructing the Universe {#sec-universe}\n\nWe construct the universe of Vietnamese listed firms. The universe includes all firms listed on HOSE, HNX, and UPCoM as of the analysis date.\n\n::: {#setup .cell execution_count=2}\n``` {.python .cell-code code-summary=\"Import required libraries\"}\nimport pandas as pd\nimport numpy as np\nimport re\nimport unicodedata\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nfrom typing import List, Dict, Tuple, Optional\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\n# Plotting configuration\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 11\nsns.set_style(\"whitegrid\")\n```\n:::\n\n\n::: {#build-universe .cell execution_count=3}\n``` {.python .cell-code code-summary=\"Connect to DataCore.vn and build universe of listed firms\"}\nfrom datacore import DataCoreAPI  # DataCore.vn Python client\n\n# Initialize connection\ndc = DataCoreAPI(api_key='YOUR_API_KEY')\n\n# Retrieve universe of all listed firms\nuniverse = dc.get_listed_firms(\n    exchanges=['HOSE', 'HNX', 'UPCOM'],\n    as_of='2024-12-31',\n    fields=[\n        'ticker', 'company_name', 'company_name_en',\n        'exchange', 'listing_date', 'delisting_date',\n        'icb_industry', 'icb_sector', 'icb_subsector',\n        'market_cap', 'total_assets', 'revenue'\n    ]\n)\n\nprint(f'Total listed firms: {len(universe)}')\nprint(f'HOSE: {len(universe[universe.exchange==\"HOSE\"])}')\nprint(f'HNX: {len(universe[universe.exchange==\"HNX\"])}')\nprint(f'UPCoM: {len(universe[universe.exchange==\"UPCOM\"])}')\n```\n:::\n\n\n| Exchange | N Firms | Avg Mkt Cap (VND bn) | Median Mkt Cap (VND bn) | Total Mkt Cap (VND tn) |\n|:--------------|--------------:|--------------:|--------------:|--------------:|\n| HOSE | 403 | 12,847 | 3,215 | 5,177 |\n| HNX | 334 | 2,156 | 687 | 720 |\n| UPCoM | 868 | 1,043 | 298 | 905 |\n| **Total** | **1,605** | **4,239** | **712** | **6,802** |\n\n: Universe of Vietnamese Listed Firms by Exchange (as of December 2024) {#tbl-universe}\n\n## Retrieving Business Descriptions {#sec-bus-desc}\n\nBusiness descriptions for all listed firms can be in both Vietnamese and English. We retrieve both versions for our analysis. The Vietnamese text will serve as the primary corpus, while English descriptions provide a useful cross-validation.\n\n::: {#get-bus-desc .cell execution_count=4}\n``` {.python .cell-code code-summary=\"Retrieve business descriptions.\"}\n# Get business descriptions (Vietnamese and English)\nbus_desc = dc.get_business_descriptions(\n    tickers=universe.ticker.tolist(),\n    fields=[\n        'ticker', 'bus_desc_vi', 'bus_desc_en',\n        'main_business', 'products_services',\n        'year_established', 'num_employees'\n    ]\n)\n\n# Merge with universe\ncorpus_df = universe.merge(bus_desc, on='ticker', how='inner')\n\n# Summary statistics on text length\ncorpus_df['desc_len_vi'] = corpus_df.bus_desc_vi.str.len()\ncorpus_df['desc_len_en'] = corpus_df.bus_desc_en.str.len()\ncorpus_df['word_count_vi'] = corpus_df.bus_desc_vi.str.split().str.len()\n\nprint(corpus_df[['desc_len_vi', 'desc_len_en', 'word_count_vi']]\n      .describe().round(0))\n```\n:::\n\n\n| Statistic       |  Mean | Median | Std Dev | Min |    Max |\n|:----------------|------:|-------:|--------:|----:|-------:|\n| Characters (VN) | 2,847 |  2,156 |   1,923 |  87 | 18,432 |\n| Characters (EN) | 3,412 |  2,689 |   2,245 | 102 | 22,156 |\n| Words (VN)      |   487 |    372 |     318 |  15 |  3,216 |\n\n: Descriptive Statistics of Business Description Text {#tbl-desc-stats}\n\n## Retrieving Annual Report Text {#sec-annual-text}\n\nBeyond business descriptions, annual or quarterly reports provide richer and more time-varying textual data. We extract the Management Discussion and Analysis (MD&A) sections, which are most informative for financial analysis [@li2010textual; @bonsall2017plain]. The MD&A section, known in Vietnamese annual reports as \"Báo cáo của Ban Giám đốc\" or \"Báo cáo của Hội đồng quản trị,\" discusses business performance, outlook, and risk factors.\n\n::: {#get-annual-text .cell execution_count=5}\n``` {.python .cell-code code-summary=\"Retrieve annual report MD&A sections\"}\n# Get annual report MD&A sections (2015-2024)\nannual_text = dc.get_annual_report_text(\n    tickers=universe.ticker.tolist(),\n    years=range(2015, 2025),\n    sections=['mda', 'risk_factors', 'business_overview'],\n    language='vi'\n)\n\n# Panel structure: ticker x year x section\nprint(f'Total firm-year-section observations: {len(annual_text)}')\nprint(f'Unique firms: {annual_text.ticker.nunique()}')\nprint(f'Year range: {annual_text.year.min()}-{annual_text.year.max()}')\n\n# Calculate text changes year-over-year\nannual_text = annual_text.sort_values(['ticker', 'year'])\nannual_text['text_len'] = annual_text.text.str.len()\nannual_text['text_change_pct'] = (\n    annual_text.groupby('ticker')['text_len']\n    .pct_change() * 100\n)\n```\n:::\n\n\n# Text Preprocessing for Vietnamese {#sec-preprocessing}\n\n## Vietnamese Word Segmentation {#sec-segmentation}\n\nThe most critical preprocessing step for Vietnamese text is word segmentation (phân đoạn từ). Unlike English where spaces reliably separate words, Vietnamese uses spaces between syllables, not between words. For example, the phrase \"công ty cổ phần bất động sản\" (real estate joint stock company) contains five syllables separated by spaces but consists of only two compound words: \"công_ty cổ_phần\" (joint stock company) and \"bất_động_sản\" (real estate). Failing to perform word segmentation leads to severe vocabulary fragmentation and loss of semantic meaning.\n\n| Stage | Text | Interpretation |\n|:------------------|:------------------|:---------------------------------|\n| Raw | `công ty cổ phần thương mại dịch vụ` | 7 syllables, ambiguous boundaries |\n| Segmented | `công_ty cổ_phần thương_mại dịch_vụ` | 4 words: company \\| joint-stock \\| commerce \\| services |\n\n: Vietnamese Word Segmentation Example {#tbl-segmentation}\n\n::: {#word-segmentation .cell execution_count=6}\n``` {.python .cell-code code-summary=\"Vietnamese word segmentation using underthesea\"}\nfrom underthesea import word_tokenize\n\ndef segment_vietnamese(text: str) -> str:\n    \"\"\"Segment Vietnamese text into words using underthesea.\"\"\"\n    if pd.isna(text) or text.strip() == '':\n        return ''\n    # underthesea word_tokenize joins compound words with _\n    segmented = word_tokenize(text, format='text')\n    return segmented\n\n# Alternative: VnCoreNLP (Java-based, higher accuracy)\n# from vncorenlp import VnCoreNLP\n# vnlp = VnCoreNLP('VnCoreNLP-1.2.jar', annotators='wseg')\n# segmented = vnlp.tokenize(text)\n\n# Apply segmentation to corpus\ncorpus_df['bus_desc_segmented'] = (\n    corpus_df.bus_desc_vi.apply(segment_vietnamese)\n)\n\n# Example\nsample = corpus_df.iloc[0]\nprint('Raw:', sample.bus_desc_vi[:200])\nprint('Segmented:', sample.bus_desc_segmented[:200])\n```\n:::\n\n\n## Full Text Cleaning Pipeline {#sec-cleaning}\n\nAfter word segmentation, we apply a cleaning pipeline. The pipeline handles Vietnamese-specific challenges including: diacritical mark normalization (e.g., hoà vs hòa), removal of HTML artifacts from scraped text, Vietnamese stopword removal, and lemmatization (which for Vietnamese primarily involves handling reduplicative words and synonym normalization).\n\n::: {#cleaning-pipeline .cell execution_count=7}\n``` {.python .cell-code code-summary=\"Full Vietnamese text cleaning pipeline\"}\n# Vietnamese stopwords (domain-adapted)\nVIETNAMESE_STOPWORDS = {\n    'có', 'là', 'và', 'của', 'cho', 'được', 'trong',\n    'các', 'những', 'với', 'từ', 'khi', 'hoặc',\n    'đã', 'sẽ', 'đang', 'để', 'này', 'đó',\n    'như', 'theo', 'về', 'bằng', 'tại', 'trên',\n    'cũng', 'rất', 'nhiều', 'ít', 'một', 'hai',\n    # Financial domain stopwords\n    'năm', 'quý', 'tháng', 'ngày', 'kỳ',\n    'việt_nam', 'tổng', 'giá_trị', 'triệu', 'tỷ',\n}\n\ndef clean_vietnamese_text(\n    text: str,\n    segment: bool = True,\n    remove_stops: bool = True,\n    lowercase: bool = True,\n    min_word_len: int = 2\n) -> str:\n    \"\"\"\n    Full Vietnamese text cleaning pipeline.\n\n    Parameters\n    ----------\n    text : str\n        Raw Vietnamese text.\n    segment : bool\n        Whether to perform word segmentation.\n    remove_stops : bool\n        Whether to remove Vietnamese stopwords.\n    lowercase : bool\n        Whether to convert to lowercase.\n    min_word_len : int\n        Minimum word length to keep.\n\n    Returns\n    -------\n    str\n        Cleaned text.\n    \"\"\"\n    if pd.isna(text) or text.strip() == '':\n        return ''\n\n    # 1. Unicode normalization (NFC form for Vietnamese)\n    text = unicodedata.normalize('NFC', text)\n\n    # 2. Remove HTML tags and special characters\n    text = re.sub(r'<[^>]+>', ' ', text)\n    text = re.sub(r'[\\d]+', ' ', text)           # Remove numbers\n    text = re.sub(r'[^\\w\\s\\u00C0-\\u024F]', ' ', text)  # Keep VN chars\n\n    # 3. Lowercase\n    if lowercase:\n        text = text.lower()\n\n    # 4. Word segmentation\n    if segment:\n        text = word_tokenize(text, format='text')\n\n    # 5. Tokenize and filter\n    tokens = text.split()\n    if remove_stops:\n        tokens = [t for t in tokens\n                  if t not in VIETNAMESE_STOPWORDS\n                  and len(t) >= min_word_len]\n\n    return ' '.join(tokens)\n\n# Apply to corpus\ncorpus_df['text_clean'] = (\n    corpus_df.bus_desc_vi\n    .apply(lambda x: clean_vietnamese_text(x))\n)\n\n# Verify cleaning quality\nprint('Sample cleaned text:')\nprint(corpus_df.iloc[0].text_clean[:300])\n```\n:::\n\n\n## English Text Cleaning {#sec-english-cleaning}\n\nFor firms that also provide English business descriptions, we apply a standard English NLP pipeline using spaCy and NLTK. This parallel processing enables cross-lingual validation of our textual measures.\n\n::: {#english-cleaning .cell execution_count=8}\n``` {.python .cell-code code-summary=\"English text cleaning pipeline\"}\nimport spacy\nfrom nltk.corpus import stopwords\nimport gensim\n\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\nstop_words = set(stopwords.words('english'))\n\ndef clean_english_text(text: str) -> str:\n    \"\"\"Clean English text with lemmatization.\"\"\"\n    if pd.isna(text) or text.strip() == '':\n        return ''\n    text = text.lower().strip()\n    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n    doc = nlp(text)\n    tokens = [token.lemma_ for token in doc\n              if token.lemma_ not in stop_words\n              and len(token.lemma_) > 2\n              and not token.is_punct]\n    return ' '.join(tokens)\n\n# Apply to English descriptions\ncorpus_df['text_clean_en'] = (\n    corpus_df.bus_desc_en\n    .apply(lambda x: clean_english_text(x))\n)\n```\n:::\n\n\n# Document Representation: Bag-of-Words and TF-IDF {#sec-bow-tfidf}\n\n## Bag-of-Words Representation {#sec-bow}\n\nThe bag-of-words (BoW) model represents each document as a vector of word frequencies, discarding word order. Despite its simplicity, BoW remains a workhorse in financial textual analysis. Formally, given a vocabulary $V = \\{w_1, w_2, \\ldots, w_{|V|}\\}$, document $d$ is represented as a vector $\\mathbf{x}_d$ where each element $x_{d,j}$ counts the frequency of word $w_j$ in document $d$:\n\n$$\n\\mathbf{x}_d = [\\text{tf}(w_1, d), \\; \\text{tf}(w_2, d), \\; \\ldots, \\; \\text{tf}(w_{|V|}, d)]\n$$ {#eq-bow}\n\nwhere $\\text{tf}(w, d)$ is the term frequency of word $w$ in document $d$.\n\n::: {#bow-vectorization .cell execution_count=9}\n``` {.python .cell-code code-summary=\"Bag-of-Words vectorization\"}\nfrom sklearn.feature_extraction.text import (\n    CountVectorizer, TfidfVectorizer\n)\n\n# Vietnamese corpus\ntext_corpus = corpus_df.text_clean.tolist()\n\n# BoW vectorization\nbow_vectorizer = CountVectorizer(\n    max_features=10000,\n    min_df=5,           # Appear in at least 5 documents\n    max_df=0.95,        # Exclude terms in >95% of docs\n    ngram_range=(1, 2)  # Unigrams and bigrams\n)\n\nbow_matrix = bow_vectorizer.fit_transform(text_corpus)\n\nprint(f'Vocabulary size: {len(bow_vectorizer.vocabulary_)}')\nprint(f'Document-term matrix shape: {bow_matrix.shape}')\nprint(f'Sparsity: {1 - bow_matrix.nnz / np.prod(bow_matrix.shape):.4f}')\n\n# Top 20 most frequent terms\nword_freq = pd.DataFrame({\n    'word': bow_vectorizer.get_feature_names_out(),\n    'freq': bow_matrix.sum(axis=0).A1\n}).sort_values('freq', ascending=False)\n\nprint('\\nTop 20 most frequent terms:')\nprint(word_freq.head(20).to_string(index=False))\n```\n:::\n\n\n::: {#fig-word-freq .cell execution_count=10}\n``` {.python .cell-code code-summary=\"Plot word frequency distribution\"}\nfig, ax = plt.subplots(figsize=(12, 6))\ntop20 = word_freq.head(20)\nax.barh(range(len(top20)), top20.freq.values, color='#2C5282')\nax.set_yticks(range(len(top20)))\nax.set_yticklabels(top20.word.values)\nax.invert_yaxis()\nax.set_xlabel('Frequency')\nax.set_title('Top 20 Most Frequent Terms in Vietnamese Business Descriptions')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n|  \\# | Term (VN)   |  Freq |  \\# | Term (VN) |  Freq |  \\# | Term (VN)    |  Freq |\n|----:|:------------|------:|----:|:----------|------:|----:|:-------------|------:|\n|   1 | sản_xuất    | 4,287 |   8 | công_nghệ | 1,956 |  15 | xuất_khẩu    | 1,123 |\n|   2 | kinh_doanh  | 3,891 |   9 | tài_chính | 1,845 |  16 | bất_động_sản | 1,087 |\n|   3 | dịch_vụ     | 3,654 |  10 | ngân_hàng | 1,734 |  17 | năng_lượng   | 1,045 |\n|   4 | công_ty     | 3,412 |  11 | đầu_tư    | 1,623 |  18 | bảo_hiểm     |   987 |\n|   5 | thương_mại  | 2,876 |  12 | xây_dựng  | 1,534 |  19 | du_lịch      |   923 |\n|   6 | cổ_phần     | 2,543 |  13 | vận_tải   | 1,345 |  20 | viễn_thông   |   876 |\n|   7 | chứng_khoán | 2,134 |  14 | thực_phẩm | 1,234 |     |              |       |\n\n: Top 20 Most Frequent Terms in Vietnamese Business Descriptions {#tbl-top-terms}\n\n## TF-IDF Weighting {#sec-tfidf}\n\nTerm Frequency-Inverse Document Frequency (TF-IDF) addresses a key limitation of raw term counts by downweighting terms that appear in many documents (and thus carry less discriminative information). The TF-IDF weight of term $w$ in document $d$ within corpus $D$ is:\n\n$$\n\\text{tfidf}(w, d, D) = \\text{tf}(w, d) \\times \\log\\left(\\frac{|D|}{\\text{df}(w, D)}\\right)\n$$ {#eq-tfidf}\n\nwhere $|D|$ is the total number of documents and $\\text{df}(w, D)$ is the number of documents containing term $w$. This weighting scheme ensures that industry-specific terminology (e.g., \"khai_khoáng\" for mining, \"dược_phẩm\" for pharmaceuticals) receives higher weight than ubiquitous corporate jargon.\n\n::: {#tfidf-vectorization .cell execution_count=11}\n``` {.python .cell-code code-summary=\"TF-IDF vectorization with per-industry analysis\"}\ntfidf_vectorizer = TfidfVectorizer(\n    max_features=10000,\n    min_df=5,\n    max_df=0.95,\n    ngram_range=(1, 2),\n    sublinear_tf=True  # Use 1 + log(tf) instead of raw tf\n)\n\ntfidf_matrix = tfidf_vectorizer.fit_transform(text_corpus)\n\n# Per-industry top TF-IDF terms\nfor industry in ['Ngân hàng', 'Bất động sản',\n                  'Công nghệ thông tin']:\n    mask = corpus_df.icb_sector == industry\n    if mask.sum() == 0:\n        continue\n    mean_tfidf = tfidf_matrix[mask.values].mean(axis=0).A1\n    top_idx = mean_tfidf.argsort()[-10:][::-1]\n    terms = tfidf_vectorizer.get_feature_names_out()\n    print(f'\\n{industry}:')\n    for idx in top_idx:\n        print(f'  {terms[idx]}: {mean_tfidf[idx]:.4f}')\n```\n:::\n\n\n::: {#fig-tfidf-heatmap .cell execution_count=12}\n``` {.python .cell-code code-summary=\"Visualize industry-distinctive terms\"}\n# Build industry x term TF-IDF matrix for top sectors\ntop_sectors = corpus_df.icb_sector.value_counts().head(8).index.tolist()\nterms = tfidf_vectorizer.get_feature_names_out()\n\nsector_tfidf = {}\nfor sector in top_sectors:\n    mask = corpus_df.icb_sector == sector\n    if mask.sum() == 0:\n        continue\n    mean_tfidf = tfidf_matrix[mask.values].mean(axis=0).A1\n    top_idx = mean_tfidf.argsort()[-5:][::-1]\n    for idx in top_idx:\n        if terms[idx] not in sector_tfidf:\n            sector_tfidf[terms[idx]] = {}\n        sector_tfidf[terms[idx]][sector] = mean_tfidf[idx]\n\nheatmap_df = pd.DataFrame(sector_tfidf).T.fillna(0)\n\nfig, ax = plt.subplots(figsize=(14, 10))\nsns.heatmap(heatmap_df, annot=True, fmt='.3f', cmap='Blues',\n            linewidths=0.5, ax=ax)\nax.set_title('TF-IDF Heatmap: Industry-Distinctive Terms')\nax.set_xlabel('ICB Sector')\nax.set_ylabel('Term')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n# Topic Modeling {#sec-topic-modeling}\n\n## Latent Dirichlet Allocation (LDA) {#sec-lda}\n\nLatent Dirichlet Allocation [@blei2003latent] is a generative probabilistic model that discovers latent topics in a corpus. Each document is modeled as a mixture of topics, and each topic is a distribution over words. LDA has been widely applied in finance to identify thematic content in 10-K filings [@dyer2017evolution], earnings calls [@huang2018analyst], and news articles [@bybee2023narrative].\n\nThe generative process assumes:\n\n1.  For each topic $k$, draw a word distribution $\\boldsymbol{\\phi}_k \\sim \\text{Dir}(\\beta)$.\n2.  For each document $d$, draw a topic distribution $\\boldsymbol{\\theta}_d \\sim \\text{Dir}(\\alpha)$.\n3.  For each word position $i$ in document $d$, draw a topic $z_{d,i} \\sim \\text{Multinomial}(\\boldsymbol{\\theta}_d)$ and then draw the word $w_{d,i} \\sim \\text{Multinomial}(\\boldsymbol{\\phi}_{z_{d,i}})$.\n\n::: {#lda-model .cell execution_count=13}\n``` {.python .cell-code code-summary=\"LDA topic modeling with grid search over K\"}\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# Grid search over number of topics\nn_topics_range = [10, 15, 20, 25, 30]\nperplexity_scores = []\n\nfor n_topics in n_topics_range:\n    lda = LatentDirichletAllocation(\n        n_components=n_topics,\n        max_iter=50,\n        learning_method='online',\n        random_state=42,\n        n_jobs=-1\n    )\n    lda.fit(bow_matrix)\n    perplexity = lda.perplexity(bow_matrix)\n    perplexity_scores.append({\n        'n_topics': n_topics,\n        'perplexity': perplexity,\n        'log_likelihood': lda.score(bow_matrix)\n    })\n    print(f'K={n_topics}: perplexity={perplexity:.2f}')\n\n# Select optimal K (e.g., K=20)\nK_OPTIMAL = 20\nlda_model = LatentDirichletAllocation(\n    n_components=K_OPTIMAL,\n    max_iter=100,\n    learning_method='online',\n    random_state=42,\n    n_jobs=-1\n)\nlda_model.fit(bow_matrix)\n\n# Extract topic-word distributions\nfeature_names = bow_vectorizer.get_feature_names_out()\nfor topic_idx, topic in enumerate(lda_model.components_):\n    top_words = [feature_names[i]\n                 for i in topic.argsort()[:-11:-1]]\n    print(f'Topic {topic_idx}: {\" | \".join(top_words)}')\n```\n:::\n\n\n::: {#fig-lda-perplexity .cell execution_count=14}\n``` {.python .cell-code code-summary=\"Plot perplexity scores for topic model selection\"}\nperp_df = pd.DataFrame(perplexity_scores)\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(perp_df.n_topics, perp_df.perplexity, 'o-', color='#2C5282',\n        linewidth=2, markersize=8)\nax.axvline(x=K_OPTIMAL, color='red', linestyle='--', alpha=0.7,\n           label=f'Selected K={K_OPTIMAL}')\nax.set_xlabel('Number of Topics (K)')\nax.set_ylabel('Perplexity (lower is better)')\nax.set_title('LDA Model Selection')\nax.legend()\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n| Topic | Interpretation | Top Words |\n|------------------:|:------------------------------|:---------------------|\n| 0 | Banking & Finance | `ngân_hàng` \\| `tín_dụng` \\| `cho_vay` \\| `tiền_gửi` \\| `lãi_suất` \\| `thanh_toán` \\| `tài_khoản` |\n| 3 | Real Estate | `bất_động_sản` \\| `dự_án` \\| `căn_hộ` \\| `khu_đô_thị` \\| `xây_dựng` \\| `nhà_ở` |\n| 7 | Technology | `công_nghệ` \\| `phần_mềm` \\| `giải_pháp` \\| `hệ_thống` \\| `số_hóa` \\| `dữ_liệu` |\n| 11 | Manufacturing | `sản_xuất` \\| `nguyên_liệu` \\| `nhà_máy` \\| `chất_lượng` \\| `công_suất` \\| `xuất_khẩu` |\n| 15 | Securities | `chứng_khoán` \\| `môi_giới` \\| `đầu_tư` \\| `cổ_phiếu` \\| `danh_mục` \\| `quản_lý_quỹ` |\n\n: Selected LDA Topics from Vietnamese Business Descriptions (K=20) {#tbl-lda-topics}\n\n## BERTopic: Neural Topic Modeling {#sec-bertopic}\n\nBERTopic [@grootendorst2022bertopic] represents a significant advance over LDA by leveraging pre-trained language model embeddings, dimensionality reduction via UMAP, and hierarchical density-based clustering (HDBSCAN) to discover topics. Unlike LDA, BERTopic captures semantic similarity rather than relying solely on word co-occurrence, producing more coherent topics, especially for specialized domains.\n\n::: {#bertopic-model .cell execution_count=15}\n``` {.python .cell-code code-summary=\"BERTopic with PhoBERT embeddings\"}\nfrom bertopic import BERTopic\nfrom sentence_transformers import SentenceTransformer\nfrom umap import UMAP\nfrom hdbscan import HDBSCAN\n\n# Use PhoBERT-based sentence transformer for Vietnamese\nembedding_model = SentenceTransformer(\n    'bkai-foundation-models/vietnamese-bi-encoder'\n)\n\n# Custom UMAP and HDBSCAN for better control\numap_model = UMAP(\n    n_neighbors=15, n_components=5,\n    min_dist=0.0, metric='cosine', random_state=42\n)\nhdbscan_model = HDBSCAN(\n    min_cluster_size=10, min_samples=5,\n    metric='euclidean', prediction_data=True\n)\n\n# Fit BERTopic\ntopic_model = BERTopic(\n    embedding_model=embedding_model,\n    umap_model=umap_model,\n    hdbscan_model=hdbscan_model,\n    language='multilingual',\n    calculate_probabilities=True,\n    verbose=True\n)\n\n# Vietnamese text (use segmented text for better results)\ndocs = corpus_df.bus_desc_segmented.tolist()\ntopics, probs = topic_model.fit_transform(docs)\n\n# Inspect topics\ntopic_info = topic_model.get_topic_info()\nprint(topic_info.head(20))\n```\n:::\n\n\n::: {#fig-bertopic-viz .cell execution_count=16}\n``` {.python .cell-code code-summary=\"Visualize BERTopic document clusters\"}\n# Visualize topic hierarchy\nfig_hierarchy = topic_model.visualize_hierarchy()\nfig_hierarchy.show()\n\n# Visualize document clusters\nfig_docs = topic_model.visualize_documents(\n    docs, reduced_embeddings=umap_model.embedding_\n)\nfig_docs.show()\n\n# Topic word scores (barchart)\nfig_barchart = topic_model.visualize_barchart(top_n_topics=10)\nfig_barchart.show()\n```\n:::\n\n\n# Financial Sentiment Analysis {#sec-sentiment}\n\n## Dictionary-Based Approach {#sec-dict-sentiment}\n\nWe construct a Vietnamese financial sentiment lexicon following the methodology of @loughran2011liability. Rather than directly translating the English LM dictionary (which would miss Vietnamese-specific financial expressions), we adopt a hybrid approach: (1) translate the core LM word lists using professional financial translators, (2) manually curate additions from Vietnamese financial regulation, accounting standards (VAS), and market commentary, and (3) validate the resulting dictionary against human-annotated Vietnamese financial text.\n\n| Category  | Vietnamese Term | English Gloss | Source        | Count in Corpus |\n|:----------|:----------------|:--------------|:--------------|----------------:|\n| Negative  | `lỗ`            | loss          | LM-translated |           2,341 |\n| Negative  | `sụt_giảm`      | decline       | Curated       |           1,876 |\n| Negative  | `nợ_xấu`        | bad debt      | VAS-specific  |           1,234 |\n| Negative  | `rủi_ro`        | risk          | LM-translated |           3,567 |\n| Positive  | `tăng_trưởng`   | growth        | LM-translated |           4,123 |\n| Positive  | `lợi_nhuận`     | profit        | LM-translated |           3,891 |\n| Positive  | `hiệu_quả`      | efficiency    | Curated       |           2,456 |\n| Uncertain | `biến_động`     | volatility    | LM-translated |           1,567 |\n| Litigious | `tranh_chấp`    | dispute       | Legal-VN      |             876 |\n| Litigious | `khởi_kiện`     | lawsuit       | Legal-VN      |             234 |\n\n: Vietnamese Financial Sentiment Lexicon: Sample Entries {#tbl-sentiment-lexicon}\n\n::: {#dict-sentiment .cell execution_count=17}\n``` {.python .cell-code code-summary=\"Dictionary-based financial sentiment scoring\"}\n# Load Vietnamese financial sentiment lexicon\n# sentiment_dict = dc.get_sentiment_lexicon(version='vn_financial_v2')\n\n# Alternatively, construct from LM + manual curation\nnegative_words = set(pd.read_csv(\n    'lexicons/vn_negative.txt', header=None)[0]\n)\npositive_words = set(pd.read_csv(\n    'lexicons/vn_positive.txt', header=None)[0]\n)\nuncertain_words = set(pd.read_csv(\n    'lexicons/vn_uncertain.txt', header=None)[0]\n)\n\ndef compute_sentiment_scores(text: str) -> dict:\n    \"\"\"\n    Compute Loughran-McDonald style sentiment scores.\n    Returns proportions (word count / total words).\n    \"\"\"\n    tokens = text.split()\n    n = len(tokens)\n    if n == 0:\n        return {'neg_pct': 0, 'pos_pct': 0,\n                'unc_pct': 0, 'net_tone': 0}\n\n    neg = sum(1 for t in tokens if t in negative_words)\n    pos = sum(1 for t in tokens if t in positive_words)\n    unc = sum(1 for t in tokens if t in uncertain_words)\n\n    return {\n        'neg_pct': neg / n,\n        'pos_pct': pos / n,\n        'unc_pct': unc / n,\n        'net_tone': (pos - neg) / n\n    }\n\n# Apply to annual report MD&A text\nsentiment_scores = annual_text.text_clean.apply(\n    lambda x: pd.Series(compute_sentiment_scores(x))\n)\nannual_text = pd.concat([annual_text, sentiment_scores], axis=1)\n```\n:::\n\n\n::: {#fig-sentiment-dist .cell execution_count=18}\n``` {.python .cell-code code-summary=\"Plot sentiment distribution\"}\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].hist(annual_text.neg_pct, bins=50, color='#E53E3E', alpha=0.7,\n             edgecolor='white')\naxes[0].set_title('Negative Word Proportion')\naxes[0].set_xlabel('Proportion')\n\naxes[1].hist(annual_text.pos_pct, bins=50, color='#38A169', alpha=0.7,\n             edgecolor='white')\naxes[1].set_title('Positive Word Proportion')\naxes[1].set_xlabel('Proportion')\n\naxes[2].hist(annual_text.net_tone, bins=50, color='#2C5282', alpha=0.7,\n             edgecolor='white')\naxes[2].set_title('Net Tone (Positive - Negative)')\naxes[2].set_xlabel('Net Tone')\n\nplt.suptitle('Sentiment Distribution in Vietnamese Annual Reports',\n             fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Transformer-Based Sentiment Classification {#sec-bert-sentiment}\n\nDictionary approaches are limited by their inability to capture context, negation, and sarcasm. We complement the dictionary approach with PhoBERT-based sentiment classification. We fine-tune PhoBERT v2.\n\n::: {#phobert-sentiment .cell execution_count=19}\n``` {.python .cell-code code-summary=\"PhoBERT-based sentiment classification\"}\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    pipeline\n)\nimport torch\n\n# Load fine-tuned ViFinBERT for sentiment\nmodel_name = 'vinai/phobert-base-v2'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name, num_labels=3  # positive, negative, neutral\n)\n\n# Create sentiment pipeline\nsentiment_pipe = pipeline(\n    'text-classification',\n    model=model,\n    tokenizer=tokenizer,\n    device=0 if torch.cuda.is_available() else -1,\n    max_length=256,\n    truncation=True,\n    batch_size=32\n)\n\n# For long documents, split into sentences first\nfrom underthesea import sent_tokenize\n\ndef document_sentiment(text: str) -> dict:\n    \"\"\"Aggregate sentence-level sentiment for a document.\"\"\"\n    sentences = sent_tokenize(text)\n    if not sentences:\n        return {'bert_pos': 0, 'bert_neg': 0, 'bert_neu': 0}\n\n    results = sentiment_pipe(sentences[:100])  # Cap at 100 sents\n    labels = [r['label'] for r in results]\n\n    n = len(labels)\n    return {\n        'bert_pos': labels.count('POSITIVE') / n,\n        'bert_neg': labels.count('NEGATIVE') / n,\n        'bert_neu': labels.count('NEUTRAL') / n,\n        'bert_tone': (labels.count('POSITIVE') -\n                      labels.count('NEGATIVE')) / n\n    }\n```\n:::\n\n\n| Method                  | Accuracy  | F1 (Pos)  | F1 (Neg)  | F1 (Neutral) |\n|:------------------------|:---------:|:---------:|:---------:|:------------:|\n| VN-LM Dictionary        |   0.612   |   0.584   |   0.637   |    0.598     |\n| PhoBERT (zero-shot)     |   0.724   |   0.698   |   0.741   |    0.712     |\n| PhoBERT v2 (fine-tuned) | **0.831** | **0.812** | **0.847** |  **0.824**   |\n\n: Sentiment Method Comparison: Dictionary vs. PhoBERT on Validation Set (N=500) {#tbl-sentiment-comparison}\n\n# Text-Based Firm Similarity and Peer Identification {#sec-similarity}\n\n## Cosine Similarity on TF-IDF Vectors {#sec-tfidf-similarity}\n\nFollowing @hoberg2016text, we compute pairwise cosine similarity between firms based on their business description TF-IDF vectors. For two documents represented as TF-IDF vectors $\\mathbf{a}$ and $\\mathbf{b}$, cosine similarity is defined as:\n\n$$\n\\cos(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\times \\|\\mathbf{b}\\|}\n$$ {#eq-cosine}\n\nThis metric ranges from 0 (completely dissimilar) to 1 (identical content) and is invariant to document length. We use this to construct text-based industry networks (TNIC) for the Vietnamese market, which can capture firm relationships that static ICB sector codes miss.\n\n::: {#tfidf-similarity .cell execution_count=20}\n``` {.python .cell-code code-summary=\"Pairwise TF-IDF cosine similarity\"}\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Compute pairwise similarity matrix\nsim_matrix = cosine_similarity(tfidf_matrix)\n\n# Convert to DataFrame for easy lookup\ntickers = corpus_df.ticker.tolist()\nsim_df = pd.DataFrame(\n    sim_matrix, index=tickers, columns=tickers\n)\n\n# For each firm, find top-5 most similar peers\ndef get_top_peers(ticker: str, n: int = 5) -> pd.DataFrame:\n    \"\"\"Return top-n most similar firms by TF-IDF cosine.\"\"\"\n    sims = sim_df[ticker].drop(ticker).sort_values(\n        ascending=False\n    ).head(n)\n    peers = corpus_df.set_index('ticker').loc[sims.index]\n    peers['similarity'] = sims.values\n    return peers[['company_name', 'icb_sector',\n                  'market_cap', 'similarity']]\n\n# Examples\nfor ticker in ['VCB', 'VNM', 'FPT', 'VIC', 'HPG']:\n    print(f'\\nTop peers for {ticker}:')\n    print(get_top_peers(ticker))\n```\n:::\n\n\n| Firm | ICB Sector  | Peer 1 | Peer 1 Sector | Sim Score | Same ICB? |\n|:-----|:------------|:-------|:--------------|:---------:|:---------:|\n| VCB  | Banking     | BID    | Banking       |   0.87    |    Yes    |\n| VCB  | Banking     | CTG    | Banking       |   0.84    |    Yes    |\n| VNM  | Food & Bev  | MCH    | Food & Bev    |   0.72    |    Yes    |\n| FPT  | Technology  | CMG    | Technology    |   0.68    |    Yes    |\n| VIC  | Real Estate | NVL    | Real Estate   |   0.74    |    Yes    |\n| HPG  | Steel       | HSG    | Steel         |   0.81    |    Yes    |\n\n: Text-Based Peer Identification: Top Most Similar Firms (TF-IDF Cosine) {#tbl-peers}\n\n::: {#fig-similarity-heatmap .cell execution_count=21}\n``` {.python .cell-code code-summary=\"Visualize similarity matrix\"}\nsample_tickers = ['VCB', 'BID', 'CTG', 'VNM', 'MCH',\n                  'FPT', 'CMG', 'VIC', 'NVL', 'HPG',\n                  'HSG', 'VHM', 'SSI', 'HCM', 'PNJ']\nsample_sim = sim_df.loc[sample_tickers, sample_tickers]\n\nfig, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(sample_sim, annot=True, fmt='.2f', cmap='Blues',\n            vmin=0, vmax=1, square=True, linewidths=0.5, ax=ax)\nax.set_title('Pairwise TF-IDF Cosine Similarity\\n(Selected Vietnamese Listed Firms)')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Embedding-Based Similarity {#sec-embedding-similarity}\n\nWhile TF-IDF cosine similarity captures lexical overlap, it misses semantic similarity. Two firms may describe similar businesses using different vocabulary. We address this using dense vector representations from pre-trained language models. Specifically, we compute document embeddings using Sentence-BERT [@reimers2019sentence] with a Vietnamese bi-encoder model.[^60_textual-3]\n\n[^60_textual-3]: @reimers2019sentence demonstrate that sentence-BERT embeddings reduce computation for similarity tasks from 65 hours to 5 seconds on 10,000 sentence pairs.\n\n::: {#embedding-similarity .cell execution_count=22}\n``` {.python .cell-code code-summary=\"Sentence-BERT embedding-based similarity\"}\nfrom sentence_transformers import SentenceTransformer\n\n# Vietnamese sentence transformer\nsbert_model = SentenceTransformer(\n    'bkai-foundation-models/vietnamese-bi-encoder'\n)\n\n# Compute embeddings for all firms\ndocs_segmented = corpus_df.bus_desc_segmented.tolist()\nembeddings = sbert_model.encode(\n    docs_segmented,\n    batch_size=64,\n    show_progress_bar=True,\n    normalize_embeddings=True\n)\n\n# Pairwise similarity\nembed_sim = cosine_similarity(embeddings)\nembed_sim_df = pd.DataFrame(\n    embed_sim, index=tickers, columns=tickers\n)\n\n# Compare TF-IDF vs embedding similarity\nfor ticker in ['VCB', 'FPT', 'VIC']:\n    tfidf_peers = sim_df[ticker].drop(ticker).nlargest(5)\n    embed_peers = embed_sim_df[ticker].drop(ticker).nlargest(5)\n    print(f'\\n{ticker} - TF-IDF peers: {tfidf_peers.index.tolist()}')\n    print(f'{ticker} - Embed peers:  {embed_peers.index.tolist()}')\n```\n:::\n\n\n::: {#fig-tsne-embeddings .cell execution_count=23}\n``` {.python .cell-code code-summary=\"t-SNE projection of firm embeddings\"}\nfrom sklearn.manifold import TSNE\n\n# t-SNE projection\ntsne = TSNE(n_components=2, perplexity=30, random_state=42,\n            metric='cosine')\nembeddings_2d = tsne.fit_transform(embeddings)\n\nfig, ax = plt.subplots(figsize=(14, 10))\nsectors = corpus_df.icb_sector.values\nunique_sectors = corpus_df.icb_sector.value_counts().head(10).index\ncolors = plt.cm.tab10(range(10))\n\nfor i, sector in enumerate(unique_sectors):\n    mask = sectors == sector\n    ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n               c=[colors[i]], label=sector, alpha=0.6, s=30)\n\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\nax.set_title('t-SNE of PhoBERT Embeddings by ICB Sector')\nax.set_xlabel('t-SNE 1')\nax.set_ylabel('t-SNE 2')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Doc2Vec {#sec-doc2vec}\n\nWe also implement Doc2Vec [@le2014distributed], which learns fixed-length dense vectors for documents of variable length. Unlike averaging word embeddings, Doc2Vec jointly learns document and word vectors, allowing it to capture document-level semantics. We train Doc2Vec on the Vietnamese business description corpus using the concatenated DBOW+DM approach recommended by @lau2016empirical.\n\n::: {#doc2vec .cell execution_count=24}\n``` {.python .cell-code code-summary=\"Doc2Vec for firm similarity (DBOW + DM ensemble)\"}\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n# Prepare tagged documents\ntagged_docs = [\n    TaggedDocument(\n        words=text.split(),\n        tags=[ticker]\n    )\n    for text, ticker in zip(\n        corpus_df.text_clean.tolist(),\n        corpus_df.ticker.tolist()\n    )\n]\n\n# PV-DBOW: paragraph vector with distributed bag of words\nd2v_dbow = Doc2Vec(\n    vector_size=100, dm=0, min_count=5,\n    window=5, epochs=40, workers=4, seed=42\n)\nd2v_dbow.build_vocab(tagged_docs)\nd2v_dbow.train(\n    tagged_docs,\n    total_examples=d2v_dbow.corpus_count,\n    epochs=d2v_dbow.epochs\n)\n\n# PV-DM: paragraph vector with distributed memory\nd2v_dm = Doc2Vec(\n    vector_size=100, dm=1, min_count=5,\n    window=10, epochs=40, workers=4, seed=42\n)\nd2v_dm.build_vocab(tagged_docs)\nd2v_dm.train(\n    tagged_docs,\n    total_examples=d2v_dm.corpus_count,\n    epochs=d2v_dm.epochs\n)\n\n# Concatenate DBOW + DM vectors (Lau & Baldwin, 2016)\nd2v_vectors = np.hstack([\n    [d2v_dbow.dv[t] for t in tickers],\n    [d2v_dm.dv[t] for t in tickers]\n])\n\n# Most similar firms\nfor ticker in ['VCB', 'FPT', 'VIC']:\n    sims = d2v_dbow.dv.most_similar(ticker, topn=5)\n    print(f'{ticker}: {[(s[0], f\"{s[1]:.3f}\") for s in sims]}')\n```\n:::\n\n\n# Deep Learning Approaches {#sec-deep-learning}\n\n## PhoBERT Embeddings for Financial Text {#sec-phobert}\n\nPhoBERT [@nguyen2020phobert], pre-trained on 20GB of Vietnamese text, provides contextualized word embeddings that capture meaning based on surrounding context. Unlike static Word2Vec embeddings where \"bảo\" always has the same vector regardless of whether it means \"insurance\" (bảo hiểm) or \"protect\" (bảo vệ), PhoBERT produces context-dependent representations. We extract `[CLS]` token embeddings as document representations.\n\n::: {#phobert-embeddings .cell execution_count=25}\n``` {.python .cell-code code-summary=\"PhoBERT document embeddings with chunking strategy\"}\nfrom transformers import AutoModel, AutoTokenizer\nimport torch\n\n# Load PhoBERT\nphobert_tokenizer = AutoTokenizer.from_pretrained(\n    'vinai/phobert-base-v2'\n)\nphobert_model = AutoModel.from_pretrained(\n    'vinai/phobert-base-v2'\n)\nphobert_model.eval()\ndevice = torch.device('cuda' if torch.cuda.is_available()\n                      else 'cpu')\nphobert_model.to(device)\n\ndef get_phobert_embedding(text: str, max_len: int = 256):\n    \"\"\"Extract [CLS] embedding from PhoBERT.\"\"\"\n    inputs = phobert_tokenizer(\n        text, return_tensors='pt',\n        max_length=max_len, truncation=True,\n        padding=True\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = phobert_model(**inputs)\n\n    # [CLS] token embedding\n    cls_embedding = outputs.last_hidden_state[:, 0, :]\n    return cls_embedding.cpu().numpy().flatten()\n\n# For long documents: chunk + average strategy\ndef get_long_doc_embedding(\n    text: str, chunk_size: int = 256, stride: int = 128\n):\n    \"\"\"Handle long documents via chunked averaging.\"\"\"\n    tokens = phobert_tokenizer.tokenize(text)\n    embeddings = []\n\n    for i in range(0, len(tokens), stride):\n        chunk = tokens[i:i + chunk_size]\n        chunk_text = phobert_tokenizer.convert_tokens_to_string(\n            chunk\n        )\n        emb = get_phobert_embedding(chunk_text)\n        embeddings.append(emb)\n\n    return np.mean(embeddings, axis=0)\n\n# Compute embeddings for all firms\nphobert_embeddings = np.array([\n    get_long_doc_embedding(text)\n    for text in corpus_df.bus_desc_segmented.tolist()\n])\n```\n:::\n\n\n## Large Language Model Applications {#sec-llm}\n\nRecent advances in LLMs open new possibilities for financial textual analysis. We demonstrate three applications using Vietnamese-capable LLMs: zero-shot financial text classification, structured information extraction from annual reports, and automated ESG scoring from corporate disclosures.\n\n### Zero-Shot Financial Classification {#sec-zero-shot}\n\n::: {#llm-zero-shot .cell execution_count=26}\n``` {.python .cell-code code-summary=\"LLM zero-shot financial text classification\"}\nimport anthropic  # Or openai, etc.\n\nclient = anthropic.Anthropic()\n\ndef classify_financial_text(\n    text: str,\n    categories: list = [\n        'Growth outlook', 'Risk warning',\n        'Operational update', 'Financial performance',\n        'Strategic initiative', 'Regulatory compliance'\n    ]\n) -> dict:\n    \"\"\"Zero-shot classify Vietnamese financial text.\"\"\"\n    prompt = f\"\"\"\n    Classify the following Vietnamese financial text into\n    one or more of these categories: {categories}\n\n    Also provide:\n    1. Sentiment: positive / negative / neutral\n    2. Confidence: 0-1\n    3. Key entities mentioned\n\n    Text: {text[:2000]}\n\n    Respond in JSON format.\n    \"\"\"\n\n    response = client.messages.create(\n        model='claude-sonnet-4-20250514',\n        max_tokens=500,\n        messages=[{'role': 'user', 'content': prompt}]\n    )\n    return response.content[0].text\n```\n:::\n\n\n### Structured Information Extraction {#sec-extraction}\n\n::: {#llm-extraction .cell execution_count=27}\n``` {.python .cell-code code-summary=\"LLM structured information extraction from annual reports\"}\nimport json\n\ndef extract_financial_info(annual_report_text: str) -> dict:\n    \"\"\"Extract structured data from Vietnamese annual report.\"\"\"\n    prompt = f\"\"\"\n    From the following Vietnamese annual report excerpt,\n    extract structured information in JSON format:\n\n    {{\n        \"revenue_mentioned\": true/false,\n        \"revenue_direction\": \"increase\"/\"decrease\"/\"stable\",\n        \"key_products\": [list of main products/services],\n        \"competitors_mentioned\": [list],\n        \"expansion_plans\": \"description or null\",\n        \"risk_factors\": [list of mentioned risks],\n        \"esg_mentions\": {{\n            \"environmental\": [topics],\n            \"social\": [topics],\n            \"governance\": [topics]\n        }},\n        \"forward_looking_statements\": [list],\n        \"capex_plans\": \"description or null\"\n    }}\n\n    Text: {annual_report_text[:3000]}\n    \"\"\"\n\n    response = client.messages.create(\n        model='claude-sonnet-4-20250514',\n        max_tokens=1000,\n        messages=[{'role': 'user', 'content': prompt}]\n    )\n    return json.loads(response.content[0].text)\n```\n:::\n\n\n### Automated ESG Scoring {#sec-esg}\n\n::: {#llm-esg .cell execution_count=28}\n``` {.python .cell-code code-summary=\"LLM-based ESG scoring from corporate disclosures\"}\ndef compute_esg_scores(text: str) -> dict:\n    \"\"\"Score ESG dimensions from Vietnamese corporate disclosure.\"\"\"\n    prompt = f\"\"\"\n    Analyze the following Vietnamese corporate disclosure text\n    and score each ESG dimension on a scale of 0-100 based on\n    the depth and quality of disclosure:\n\n    Return JSON:\n    {{\n        \"environmental_score\": 0-100,\n        \"environmental_topics\": [list of specific topics discussed],\n        \"social_score\": 0-100,\n        \"social_topics\": [list],\n        \"governance_score\": 0-100,\n        \"governance_topics\": [list],\n        \"overall_esg_score\": 0-100,\n        \"assessment_confidence\": 0-1,\n        \"notable_commitments\": [list of specific commitments],\n        \"gaps_identified\": [list of missing ESG disclosures]\n    }}\n\n    Text: {text[:4000]}\n    \"\"\"\n\n    response = client.messages.create(\n        model='claude-sonnet-4-20250514',\n        max_tokens=800,\n        messages=[{'role': 'user', 'content': prompt}]\n    )\n    return json.loads(response.content[0].text)\n\n# Apply to all firms' annual reports\nesg_results = []\nfor _, row in annual_text.iterrows():\n    try:\n        scores = compute_esg_scores(row.text)\n        scores['ticker'] = row.ticker\n        scores['year'] = row.year\n        esg_results.append(scores)\n    except Exception as e:\n        print(f\"Error for {row.ticker} {row.year}: {e}\")\n\nesg_df = pd.DataFrame(esg_results)\n```\n:::\n\n\n# Empirical Applications {#sec-empirical}\n\n## Textual Sentiment and Stock Returns {#sec-sentiment-returns}\n\nWe examine whether textual sentiment from annual reports predicts subsequent stock returns, following the methodology of @tetlock2008more. We regress monthly stock returns on lagged sentiment measures while controlling for standard risk factors (market, size, value, momentum) adapted for the Vietnamese market:\n\n$$\nR_{i,t} = \\alpha + \\beta_1 \\text{Tone}_{i,t-1} + \\beta_2 \\text{Uncertainty}_{i,t-1} + \\boldsymbol{\\gamma}' \\mathbf{X}_{i,t-1} + \\varepsilon_{i,t}\n$$ {#eq-return-regression}\n\nwhere $R_{i,t}$ is the monthly excess return of firm $i$ in month $t$, $\\text{Tone}$ is the net sentiment score (positive minus negative word proportion), $\\text{Uncertainty}$ is the proportion of uncertain words, and $\\mathbf{X}$ is a vector of controls including the Fama-French-Carhart factors adapted for Vietnam (see Chapter on Factor Models).\n\n::: {#sentiment-return-regression .cell execution_count=29}\n``` {.python .cell-code code-summary=\"Panel regression: sentiment and stock returns\"}\nimport statsmodels.api as sm\nfrom linearmodels.panel import PanelOLS\n\n# Merge sentiment scores with return data\nreturns = dc.get_monthly_returns(\n    tickers=universe.ticker.tolist(),\n    start='2016-01-01', end='2024-12-31'\n)\n\n# Panel regression with firm and time fixed effects\npanel = annual_text.merge(\n    returns, on=['ticker', 'year', 'month']\n)\npanel = panel.set_index(['ticker', 'date'])\n\n# Model 1: Dictionary-based sentiment\nmodel1 = PanelOLS(\n    dependent=panel.ret_excess,\n    exog=sm.add_constant(\n        panel[['net_tone', 'unc_pct', 'mkt_rf',\n               'smb', 'hml', 'wml']]\n    ),\n    entity_effects=True,\n    time_effects=True\n)\nres1 = model1.fit(cov_type='clustered',\n                  cluster_entity=True,\n                  cluster_time=True)\n\n# Model 2: BERT-based sentiment\nmodel2 = PanelOLS(\n    dependent=panel.ret_excess,\n    exog=sm.add_constant(\n        panel[['bert_tone', 'mkt_rf',\n               'smb', 'hml', 'wml']]\n    ),\n    entity_effects=True,\n    time_effects=True\n)\nres2 = model2.fit(cov_type='clustered',\n                  cluster_entity=True,\n                  cluster_time=True)\n\n# Model 3: Combined\nmodel3 = PanelOLS(\n    dependent=panel.ret_excess,\n    exog=sm.add_constant(\n        panel[['net_tone', 'unc_pct', 'bert_tone',\n               'mkt_rf', 'smb', 'hml', 'wml']]\n    ),\n    entity_effects=True,\n    time_effects=True\n)\nres3 = model3.fit(cov_type='clustered',\n                  cluster_entity=True,\n                  cluster_time=True)\n\nprint(res1.summary)\nprint(res2.summary)\nprint(res3.summary)\n```\n:::\n\n\n| Variable           | \\(1\\) Dictionary | \\(2\\) PhoBERT | \\(3\\) Combined |\n|:-------------------|:----------------:|:-------------:|:--------------:|\n| Net Tone (Dict)    |    0.0234\\*\\*    |               |    0.0187\\*    |\n|                    |     (0.0098)     |               |    (0.0102)    |\n| Uncertainty (Dict) |  −0.0312\\*\\*\\*   |               |  −0.0278\\*\\*   |\n|                    |     (0.0087)     |               |    (0.0091)    |\n| BERT Tone          |                  | 0.0456\\*\\*\\*  |  0.0389\\*\\*\\*  |\n|                    |                  |   (0.0112)    |    (0.0118)    |\n| MKT-RF             |   0.9123\\*\\*\\*   | 0.9118\\*\\*\\*  |  0.9115\\*\\*\\*  |\n|                    |     (0.0234)     |   (0.0233)    |    (0.0234)    |\n| SMB                |    0.1245\\*\\*    |  0.1238\\*\\*   |   0.1241\\*\\*   |\n|                    |     (0.0456)     |   (0.0455)    |    (0.0456)    |\n| HML                |     0.0876\\*     |   0.0871\\*    |    0.0873\\*    |\n|                    |     (0.0512)     |   (0.0511)    |    (0.0512)    |\n| Firm FE            |       Yes        |      Yes      |      Yes       |\n| Time FE            |       Yes        |      Yes      |      Yes       |\n| Clustering         |     Two-way      |    Two-way    |    Two-way     |\n| N                  |      12,456      |    12,456     |     12,456     |\n| R² (within)        |      0.142       |     0.148     |     0.153      |\n\n: Textual Sentiment and Stock Returns: Panel Regression Results {#tbl-regression}\n\n## Text-Based Industry Classification {#sec-tnic}\n\nWe construct Vietnamese Text-Based Network Industries (VN-TNIC) analogous to @hoberg2016text. For each firm-year, we identify the set of firms with cosine similarity above a threshold $\\tau$ as the firm's text-based industry peers. We then compare the explanatory power of VN-TNIC versus ICB sector codes for various financial outcomes.\n\n::: {#tnic-construction .cell execution_count=30}\n``` {.python .cell-code code-summary=\"VN-TNIC construction and evaluation\"}\n# Construct TNIC network\nTAU = 0.20  # Similarity threshold\n\ntnic_edges = []\nfor i in range(len(tickers)):\n    for j in range(i+1, len(tickers)):\n        sim = sim_matrix[i, j]\n        if sim >= TAU:\n            tnic_edges.append({\n                'firm1': tickers[i],\n                'firm2': tickers[j],\n                'similarity': sim\n            })\n\ntnic_df = pd.DataFrame(tnic_edges)\nprint(f'TNIC edges (tau={TAU}): {len(tnic_df)}')\nprint(f'Avg degree: {2*len(tnic_df)/len(tickers):.1f}')\n\n# Compare TNIC vs ICB for return comovement\nfrom linearmodels.asset_pricing import FamaMacBeth\n\n# Peer return = avg return of TNIC peers\n# vs ICB sector average return\ndef compute_tnic_peer_return(group, tnic_edges_df):\n    \"\"\"Compute average return of TNIC peers for each firm.\"\"\"\n    peer_returns = {}\n    for ticker in group.index:\n        peers = tnic_edges_df[\n            (tnic_edges_df.firm1 == ticker) |\n            (tnic_edges_df.firm2 == ticker)\n        ]\n        peer_tickers = set(\n            peers.firm1.tolist() + peers.firm2.tolist()\n        ) - {ticker}\n        peer_mask = group.index.isin(peer_tickers)\n        if peer_mask.sum() > 0:\n            peer_returns[ticker] = group.loc[peer_mask, 'ret'].mean()\n        else:\n            peer_returns[ticker] = np.nan\n    return pd.Series(peer_returns)\n\npanel['icb_peer_ret'] = panel.groupby(\n    ['date', 'icb_sector']\n)['ret'].transform('mean')\n```\n:::\n\n\n::: {#fig-tnic-network .cell execution_count=31}\n``` {.python .cell-code code-summary=\"Visualize TNIC network\"}\nimport networkx as nx\n\n# Build network graph (subsample for visualization)\nG = nx.Graph()\nsample_edges = tnic_df.nlargest(500, 'similarity')\n\nfor _, row in sample_edges.iterrows():\n    G.add_edge(row.firm1, row.firm2, weight=row.similarity)\n\n# Color by ICB sector\nsector_map = corpus_df.set_index('ticker')['icb_sector'].to_dict()\nnode_colors = [hash(sector_map.get(n, 'Unknown')) % 10\n               for n in G.nodes()]\n\nfig, ax = plt.subplots(figsize=(14, 12))\npos = nx.spring_layout(G, k=0.5, seed=42)\nedges = G.edges(data=True)\nweights = [e[2]['weight'] * 3 for e in edges]\n\nnx.draw_networkx_nodes(G, pos, node_size=100, node_color=node_colors,\n                       cmap='tab10', alpha=0.7, ax=ax)\nnx.draw_networkx_edges(G, pos, width=weights, alpha=0.3,\n                       edge_color='gray', ax=ax)\nnx.draw_networkx_labels(G, pos, font_size=6, ax=ax)\n\nax.set_title('VN-TNIC Network (Top 500 Edges by Similarity)')\nax.axis('off')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Measuring Textual Similarity Changes Around Corporate Events {#sec-event-study}\n\nWe examine how firms' textual similarity changes around major corporate events such as M&A announcements, industry reclassifications, and strategic pivots. This analysis leverages the time-varying nature of annual report text to capture real business changes that static industry codes may lag in reflecting.\n\n::: {#event-study-text .cell execution_count=32}\n``` {.python .cell-code code-summary=\"Event study on textual similarity changes\"}\n# Get M&A announcements from DataCore\nma_events = dc.get_corporate_events(\n    event_type='M&A',\n    start='2016-01-01', end='2024-12-31'\n)\n\n# For each M&A event, compute text similarity between\n# acquirer and target before and after the event\ndef text_similarity_around_event(\n    acquirer: str, target: str, event_year: int,\n    annual_text_df: pd.DataFrame,\n    vectorizer: TfidfVectorizer\n) -> dict:\n    \"\"\"Compare text similarity pre vs post M&A.\"\"\"\n    pre_texts = annual_text_df[\n        (annual_text_df.ticker.isin([acquirer, target])) &\n        (annual_text_df.year == event_year - 1)\n    ]\n    post_texts = annual_text_df[\n        (annual_text_df.ticker.isin([acquirer, target])) &\n        (annual_text_df.year == event_year + 1)\n    ]\n\n    if len(pre_texts) < 2 or len(post_texts) < 2:\n        return None\n\n    pre_vecs = vectorizer.transform(pre_texts.text_clean)\n    post_vecs = vectorizer.transform(post_texts.text_clean)\n\n    pre_sim = cosine_similarity(pre_vecs[0:1], pre_vecs[1:2])[0, 0]\n    post_sim = cosine_similarity(post_vecs[0:1], post_vecs[1:2])[0, 0]\n\n    return {\n        'acquirer': acquirer,\n        'target': target,\n        'event_year': event_year,\n        'pre_similarity': pre_sim,\n        'post_similarity': post_sim,\n        'delta_similarity': post_sim - pre_sim\n    }\n\n# Apply to all M&A events\nevent_results = []\nfor _, event in ma_events.iterrows():\n    result = text_similarity_around_event(\n        event.acquirer, event.target, event.event_year,\n        annual_text, tfidf_vectorizer\n    )\n    if result:\n        event_results.append(result)\n\nevent_df = pd.DataFrame(event_results)\nprint(f'Average similarity change post-M&A: '\n      f'{event_df.delta_similarity.mean():.4f}')\nprint(f't-stat: {event_df.delta_similarity.mean() / '\n      f'(event_df.delta_similarity.std() / '\n      f'np.sqrt(len(event_df))):.3f}')\n```\n:::\n\n\n# Method Comparison and Best Practices {#sec-comparison}\n\n| Method | Interpretability | Semantic | Speed | VN Support | Data Req. | Best Use Case |\n|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:----------|\n| BoW/TF-IDF | High | Low | Fast | Good\\* | None | Peer groups, lexical similarity |\n| LDA | Medium | Low | Medium | Good\\* | None | Topic discovery |\n| Doc2Vec | Low | Medium | Medium | Good\\* | Corpus | Document similarity |\n| BERTopic | High | High | Slow | Excellent | None | Coherent topics |\n| PhoBERT | Low | High | Slow | Excellent | Fine-tune | Sentiment, NER, classification |\n| Sentence-BERT | Low | High | Medium | Good | None | Semantic similarity |\n| LLM (zero-shot) | High | High | Slow | Good | None | Extraction, classification |\n\n: Comparison of Textual Analysis Methods for Vietnamese Financial Text {#tbl-method-comparison}\n\n::: callout-note\n\\*Requires Vietnamese word segmentation as a preprocessing step. VN Support rates how well the method handles Vietnamese text natively.\n:::\n\nFor researchers beginning textual analysis of Vietnamese firms, we recommend the following workflow:\n\n1.  **Start with TF-IDF cosine similarity** for peer identification because it is fast, interpretable, and provides a strong baseline.\n2.  **Use BERTopic with PhoBERT embeddings** for topic discovery because it produces more coherent topics than LDA for Vietnamese text.\n3.  **For sentiment analysis**, use ViFinBERT if fine-tuning data is available; otherwise, LLM zero-shot classification provides competitive results.\n4.  **For production systems** requiring real-time analysis, sentence-BERT embeddings offer the best speed-accuracy tradeoff.\n\n::: {#fig-method-comparison .cell execution_count=33}\n``` {.python .cell-code code-summary=\"Compare methods on peer identification accuracy\"}\n# Evaluate: what fraction of top-5 peers share ICB sector?\nmethods = {\n    'TF-IDF': sim_df,\n    'Sentence-BERT': embed_sim_df,\n    'Doc2Vec': pd.DataFrame(\n        cosine_similarity(d2v_vectors),\n        index=tickers, columns=tickers\n    ),\n}\n\naccuracy_results = {}\nsector_map = corpus_df.set_index('ticker')['icb_sector'].to_dict()\n\nfor method_name, sim_matrix_df in methods.items():\n    matches = 0\n    total = 0\n    for ticker in tickers:\n        true_sector = sector_map.get(ticker)\n        peers = sim_matrix_df[ticker].drop(ticker).nlargest(5)\n        for peer in peers.index:\n            total += 1\n            if sector_map.get(peer) == true_sector:\n                matches += 1\n    accuracy_results[method_name] = matches / total\n\nfig, ax = plt.subplots(figsize=(8, 5))\nmethods_list = list(accuracy_results.keys())\naccs = list(accuracy_results.values())\nbars = ax.bar(methods_list, accs, color=['#2C5282', '#38A169', '#D69E2E'])\nax.set_ylabel('ICB Sector Match Rate')\nax.set_title('Peer Identification Accuracy by Method')\nax.set_ylim(0, 1)\nfor bar, acc in zip(bars, accs):\n    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n            f'{acc:.1%}', ha='center', fontweight='bold')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n# Conclusion {#sec-conclusion}\n\nThis chapter has demonstrated the full pipeline of textual analysis methods applied to Vietnamese listed firms, from classical bag-of-words approaches to state-of-the-art large language models. The key takeaways for practitioners and researchers are:\n\nFirst, Vietnamese text preprocessing requires a word segmentation step that has no parallel in English-language NLP. Using tools like VnCoreNLP or underthesea for this step is essential and significantly affects downstream analysis quality.\n\nSecond, domain-specific sentiment lexicons substantially outperform general-purpose dictionaries for Vietnamese financial text, consistent with @loughran2011liability findings for English.\n\nThird, PhoBERT-based embeddings capture semantic similarity that TF-IDF misses, identifying industry peers that share business models even when they use different vocabulary.\n\nFourth, LLMs enable new applications, including structured information extraction from Vietnamese annual reports that would be prohibitively expensive with manual coding.\n\nThe empirical applications demonstrate that textual measures contain economically meaningful information for the Vietnamese market. Net sentiment from annual reports predicts subsequent stock returns even after controlling for standard risk factors, and BERT-based sentiment measures have incremental predictive power beyond dictionary-based measures. Text-based industry classifications capture firm relationships that static ICB codes miss, and textual similarity changes around corporate events reflect real business transformations.\n\n<!--# All code and data pipelines in this chapter are designed to be reproducible using DataCore.vn's API. Researchers can extend these methods to other text sources, including earnings call transcripts, news articles from CafeF and VnExpress, and social media data from Vietnamese financial forums, all of which are available via DataCore.vn -->\n\n",
    "supporting": [
      "60_textual_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}