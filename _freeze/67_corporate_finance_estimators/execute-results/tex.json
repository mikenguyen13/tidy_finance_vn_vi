{
  "hash": "076be8bdb2869e06339f7e680233d360",
  "result": {
    "engine": "jupyter",
    "markdown": "# Corporate Finance Estimators and Identification\n\nCorporate finance is the study of how firms make investment, financing, and payout decisions under real-world frictions (e.g., taxes, asymmetric information, agency conflicts, transaction costs, and financial constraints). Unlike asset pricing, where the primary objects of interest are expected returns and risk premia estimated from market data, corporate finance estimators are tied to firm-level accounting and governance data, and their economic interpretation depends critically on the institutional environment in which the firm operates.\n\nThis chapter develops the core econometric toolkit for empirical corporate finance and applies it to Vietnamese listed firms. The estimators we cover (including investment-$Q$ regressions, cash flow sensitivity tests, capital structure determinants, payout smoothing models, and agency cost proxies) form the backbone of the modern corporate finance literature. Each estimator embeds specific theoretical assumptions, and each has been the subject of substantial methodological debate. We pay careful attention to identification challenges: the conditions under which a regression coefficient admits a causal or structural interpretation versus merely a descriptive association.\n\nVietnamese firms present distinctive features that interact with these estimators in economically meaningful ways. State ownership remains pervasive and creates agency problems qualitatively different from the dispersed-ownership setting of the Anglo-American literature. Concentrated family ownership, pyramidal structures, and cross-holdings generate tunneling incentives documented by @johnson2000tunneling and @claessens2002disentangling. The banking system is dominated by state-owned commercial banks whose lending decisions may reflect political rather than purely economic criteria, complicating the interpretation of financing constraint measures. And dividend policy is shaped by regulatory requirements, including minimum payout ratios for state-owned enterprises, that have no parallel in more developed markets.\n\n::: {#setup .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom linearmodels.panel import PanelOLS, PooledOLS\nimport plotnine as p9\nfrom mizani.formatters import percent_format, comma_format\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n```\n:::\n\n\n::: {#load-data .cell execution_count=2}\n``` {.python .cell-code}\n# DataCore.vn API\nfrom datacore import DataCore\ndc = DataCore()\n\n# Load annual firm-level financial data\nfirm_annual = dc.get_firm_financials(\n    start_date=\"2008-01-01\",\n    end_date=\"2024-12-31\",\n    frequency=\"annual\"\n)\n\n# Load ownership data\nownership = dc.get_ownership_data(\n    start_date=\"2008-01-01\",\n    end_date=\"2024-12-31\"\n)\n\n# Load stock returns (monthly)\nmonthly_returns = dc.get_monthly_returns(\n    start_date=\"2008-01-01\",\n    end_date=\"2024-12-31\"\n)\n\n# Load market and factor returns\nfactors = dc.get_factor_returns(\n    start_date=\"2008-01-01\",\n    end_date=\"2024-12-31\"\n)\n\nprint(f\"Firm-year observations: {len(firm_annual)}\")\nprint(f\"Unique firms: {firm_annual['ticker'].nunique()}\")\nprint(f\"Year range: {firm_annual['year'].min()}–{firm_annual['year'].max()}\")\n```\n:::\n\n\n## Investment-$Q$ Regressions\n\n### Tobin's $Q$: Intuition and Theory\n\nThe investment-$Q$ framework is the canonical structural model of corporate investment. The core insight, formalized by @hayashi1982tobin, is elegant: under perfect capital markets and constant returns to scale in the production and adjustment cost technologies, a firm's investment rate should be a sufficient statistic of a single observable (i.e., the ratio of the market value of installed capital to its replacement cost).\n\nLet $V_t$ denote the market value of the firm's assets at time $t$ and $K_t$ the replacement cost of its capital stock. Tobin's $Q$ is:\n\n$$\nQ_t = \\frac{V_t}{K_t}\n$$ {#eq-tobins-q}\n\nWhen $Q > 1$, the market values a unit of installed capital above its replacement cost, signaling that the firm should invest. When $Q < 1$, the firm should disinvest. In the frictionless @hayashi1982tobin environment, the marginal $Q$ (the shadow value of an additional unit of capital) equals the average $Q$ (the ratio of total market value to total replacement cost), and the optimal investment policy is:\n\n$$\n\\frac{I_{i,t}}{K_{i,t-1}} = \\frac{1}{\\alpha}\\left(Q_{i,t} - 1\\right)\n$$ {#eq-investment-q-theory}\n\nwhere $\\alpha$ governs the convexity of adjustment costs. The empirical counterpart is the regression:\n\n$$\n\\frac{I_{i,t}}{K_{i,t-1}} = \\beta_0 + \\beta_1 Q_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-investment-q-regression}\n\nUnder the structural interpretation, $\\beta_1 = 1/\\alpha > 0$ and $Q$ is the sole explanatory variable. Any additional variable that enters significantly implies a violation of the underlying assumptions (e.g., financial frictions, agency problems, measurement error in $Q$, or departures from constant returns to scale).\n\n### Measurement Issues\n\nThe theoretical object is marginal $Q$ (i.e., the value of the next dollar of investment) which is unobservable. The empirical proxy is average $Q$, typically constructed as:\n\n$$\nQ_{i,t}^{\\text{avg}} = \\frac{\\text{Market Value of Equity} + \\text{Book Value of Debt}}{\\text{Book Value of Total Assets}}\n$$ {#eq-average-q}\n\nThis proxy introduces several problems that are well-documented in the literature.\n\n**Problem 1: Marginal** $\\neq$ Average. The equality $q^{\\text{marginal}} = Q^{\\text{average}}$ requires constant returns to scale in both production and adjustment costs [@hayashi1982tobin]. With decreasing returns to scale (empirically relevant for most firms), average $Q$ overstates marginal $Q$ for high-$Q$ firms and understates it for low-$Q$ firms. @abel1994unified derive the wedge analytically.\n\n**Problem 2: Measurement error in numerator.** The market value of equity reflects market sentiment, bubbles, and noise-trader demand in addition to fundamentals. @bond2012real provide a comprehensive treatment. In Vietnamese markets, where retail investors dominate and price limits constrain daily adjustment, market prices may deviate persistently from fundamental value.\n\n**Problem 3: Measurement error in denominator.** Book values of assets reflect historical cost, depreciation schedules, and accounting conventions that may poorly approximate replacement cost. This is especially problematic in Vietnam, where revaluation of fixed assets is infrequent and inflation has historically been volatile, creating wedges between historical and replacement cost.\n\n**Problem 4: Errors-in-variables bias.** Because the empirical $Q$ is a noisy proxy for the true $Q$, OLS estimates of $\\beta_1$ in @eq-investment-q-regression suffer from classical attenuation bias (i.e., $hat{\\beta}_1$ is biased toward zero). @erickson2012treating develop a higher-order cumulant estimator that corrects for this bias without requiring external instruments.\n\n::: {#construct-q .cell execution_count=3}\n``` {.python .cell-code}\n# Construct Tobin's Q and investment variables\npanel = firm_annual.copy()\n\n# Tobin's Q: (Market cap + Book debt) / Total assets\npanel[\"tobins_q\"] = (\n    (panel[\"market_cap\"] + panel[\"total_debt\"]) /\n    panel[\"total_assets\"]\n)\n\n# Investment rate: Capital expenditure / Lagged total assets\npanel = panel.sort_values([\"ticker\", \"year\"])\npanel[\"lag_assets\"] = panel.groupby(\"ticker\")[\"total_assets\"].shift(1)\npanel[\"lag_ppe\"] = panel.groupby(\"ticker\")[\"ppe_net\"].shift(1)\n\npanel[\"inv_rate\"] = panel[\"capex\"] / panel[\"lag_assets\"]\npanel[\"inv_rate_ppe\"] = panel[\"capex\"] / panel[\"lag_ppe\"]\n\n# Cash flow / Assets\npanel[\"cf_assets\"] = panel[\"operating_cf\"] / panel[\"lag_assets\"]\n\n# Sales growth\npanel[\"lag_revenue\"] = panel.groupby(\"ticker\")[\"revenue\"].shift(1)\npanel[\"sales_growth\"] = (\n    (panel[\"revenue\"] - panel[\"lag_revenue\"]) / panel[\"lag_revenue\"]\n)\n\n# Winsorize at 1st and 99th percentiles\ndef winsorize(s, lower=0.01, upper=0.99):\n    return s.clip(s.quantile(lower), s.quantile(upper))\n\nfor col in [\"tobins_q\", \"inv_rate\", \"cf_assets\", \"sales_growth\"]:\n    panel[col] = winsorize(panel[col])\n\npanel_clean = panel.dropna(\n    subset=[\"tobins_q\", \"inv_rate\", \"cf_assets\"]\n).copy()\n\nprint(f\"Clean panel: {len(panel_clean)} firm-years, \"\n      f\"{panel_clean['ticker'].nunique()} firms\")\n```\n:::\n\n\n::: {#tbl-investment-summary .cell tbl-cap='Summary Statistics: Investment and Q Variables' execution_count=4}\n``` {.python .cell-code}\nsummary_vars = [\"inv_rate\", \"tobins_q\", \"cf_assets\", \"sales_growth\"]\nsummary = panel_clean[summary_vars].describe(\n    percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]\n).T.round(4)\n\nsummary.columns = [\"N\", \"Mean\", \"Std\", \"Min\", \"5%\", \"25%\",\n                    \"Median\", \"75%\", \"95%\", \"Max\"]\nsummary\n```\n:::\n\n\n::: {#baseline-q-regression .cell execution_count=5}\n``` {.python .cell-code}\n# Baseline investment-Q regression with firm and year fixed effects\npanel_clean = panel_clean.set_index([\"ticker\", \"year\"])\n\n# Model 1: Q only\nmodel1 = PanelOLS(\n    panel_clean[\"inv_rate\"],\n    panel_clean[[\"tobins_q\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\n# Model 2: Q + Cash Flow\nmodel2 = PanelOLS(\n    panel_clean[\"inv_rate\"],\n    panel_clean[[\"tobins_q\", \"cf_assets\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\n# Model 3: Q + Cash Flow + Sales Growth\nmodel3 = PanelOLS(\n    panel_clean[\"inv_rate\"],\n    panel_clean[[\"tobins_q\", \"cf_assets\", \"sales_growth\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\npanel_clean = panel_clean.reset_index()\n```\n:::\n\n\n::: {#tbl-q-regression .cell tbl-cap='Investment-Q Regressions with Firm and Year Fixed Effects' execution_count=6}\n``` {.python .cell-code}\nresults_table = pd.DataFrame({\n    \"Q Only\": {\n        \"Tobin's Q\": f\"{model1.params['tobins_q']:.4f}\",\n        \"\": f\"({model1.std_errors['tobins_q']:.4f})\",\n        \"Cash Flow/Assets\": \"\",\n        \" \": \"\",\n        \"Sales Growth\": \"\",\n        \"  \": \"\",\n        \"R² (within)\": f\"{model1.rsquared_within:.4f}\",\n        \"N\": f\"{int(model1.nobs)}\"\n    },\n    \"Q + CF\": {\n        \"Tobin's Q\": f\"{model2.params['tobins_q']:.4f}\",\n        \"\": f\"({model2.std_errors['tobins_q']:.4f})\",\n        \"Cash Flow/Assets\": f\"{model2.params['cf_assets']:.4f}\",\n        \" \": f\"({model2.std_errors['cf_assets']:.4f})\",\n        \"Sales Growth\": \"\",\n        \"  \": \"\",\n        \"R² (within)\": f\"{model2.rsquared_within:.4f}\",\n        \"N\": f\"{int(model2.nobs)}\"\n    },\n    \"Q + CF + SG\": {\n        \"Tobin's Q\": f\"{model3.params['tobins_q']:.4f}\",\n        \"\": f\"({model3.std_errors['tobins_q']:.4f})\",\n        \"Cash Flow/Assets\": f\"{model3.params['cf_assets']:.4f}\",\n        \" \": f\"({model3.std_errors['cf_assets']:.4f})\",\n        \"Sales Growth\": f\"{model3.params['sales_growth']:.4f}\",\n        \"  \": f\"({model3.std_errors['sales_growth']:.4f})\",\n        \"R² (within)\": f\"{model3.rsquared_within:.4f}\",\n        \"N\": f\"{int(model3.nobs)}\"\n    }\n})\n\nresults_table\n```\n:::\n\n\n### Interpretation Under Market Frictions\n\nThe coefficient on $Q$ in @tbl-q-regression admits multiple interpretations depending on the maintained assumptions:\n\n**Structural interpretation.** If the Hayashi conditions hold, $\\hat{\\beta}_1$ estimates the inverse of the adjustment cost parameter: $\\hat{\\beta}_1 = 1/\\hat{\\alpha}$. A larger coefficient implies lower adjustment costs. However, measurement error in $Q$ biases $\\hat{\\beta}_1$ downward, so the raw OLS estimate provides a lower bound on $1/\\alpha$.\n\n**Reduced-form interpretation.** Without the Hayashi conditions, $\\hat{\\beta}_1$ captures the association between market valuation and investment intensity. This association reflects a mixture of genuine investment opportunities (the $Q$-theory channel), market mispricing that managers exploit (the market timing channel of @baker2003does), and reverse causality (investment announcements that move market values).\n\n**The cash flow coefficient puzzle.** The significance of $\\hat{\\beta}_2$ on cash flow has been the subject of a 35-year debate. @fazzari1987financing interpret it as evidence that firms face financing constraints: controlling for investment opportunities ($Q$), cash flow should be irrelevant in a frictionless world, so its significance implies that internal funds relax binding constraints. @kaplan1997investment counter that cash flow proxies for investment opportunities not captured by the noisy $Q$ measure, making the cash flow coefficient an artifact of measurement error rather than evidence of constraints. @erickson2012treating show that correcting for measurement error in $Q$ substantially reduces (but does not eliminate) the cash flow coefficient, supporting a middle ground.\n\n### Limitations in Emerging Markets\n\nThe investment-$Q$ framework faces amplified challenges in Vietnamese markets.\n\n**Thin trading and price limits.** Market prices adjust slowly to information, so $Q$ measured at fiscal year-end may not reflect the firm's current investment opportunity set. Price limits of $\\pm 7\\%$ (HOSE) and $\\pm 10\\%$ (HNX) mechanically compress the numerator of $Q$, attenuating the investment-$Q$ relationship.\n\n**State ownership.** For state-owned enterprises (SOEs), investment decisions may be driven by policy directives rather than $Q$-theoretic optimality. Including SOEs in the regression without interactions confounds the structural relationship.\n\n**Related-party transactions.** Tunneling through related-party transactions means that measured investment may include capital expenditures that benefit controlling shareholders rather than maximizing firm value. The investment-$Q$ coefficient in tunneling firms reflects the relationship between market valuation and expropriation, not efficient capital allocation.\n\n::: {#fig-investment-q-scatter .cell execution_count=7}\n``` {.python .cell-code}\n# Create Q-decile bins for clean visualization\nplot_data = panel_clean.copy()\nplot_data[\"q_bin\"] = pd.qcut(\n    plot_data[\"tobins_q\"], q=20, duplicates=\"drop\"\n)\n\nbinned = (\n    plot_data.groupby(\"q_bin\", observed=True)\n    .agg(\n        mean_q=(\"tobins_q\", \"mean\"),\n        mean_inv=(\"inv_rate\", \"mean\"),\n        se_inv=(\"inv_rate\", lambda x: x.std() / np.sqrt(len(x)))\n    )\n    .reset_index()\n)\n\n(\n    p9.ggplot(binned, p9.aes(x=\"mean_q\", y=\"mean_inv\"))\n    + p9.geom_pointrange(\n        p9.aes(ymin=\"mean_inv - 1.96*se_inv\",\n               ymax=\"mean_inv + 1.96*se_inv\"),\n        color=\"#2E5090\", size=0.5\n    )\n    + p9.geom_smooth(method=\"lm\", color=\"#C0392B\", se=False, size=0.8)\n    + p9.labs(\n        x=\"Tobin's Q (Vingtile Mean)\",\n        y=\"Investment Rate (I/A)\",\n        title=\"Investment-Q Relationship: Binned Scatter\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(10, 6))\n)\n```\n:::\n\n\n::: {#q-regression-soe-interaction .cell execution_count=8}\n``` {.python .cell-code}\n# Merge ownership data\npanel_with_own = panel_clean.merge(\n    ownership[[\"ticker\", \"year\", \"state_ownership_pct\",\n               \"foreign_ownership_pct\", \"insider_ownership_pct\"]],\n    on=[\"ticker\", \"year\"],\n    how=\"left\"\n)\n\npanel_with_own[\"soe_dummy\"] = (\n    panel_with_own[\"state_ownership_pct\"] > 50\n).astype(int)\n\npanel_with_own[\"q_x_soe\"] = (\n    panel_with_own[\"tobins_q\"] * panel_with_own[\"soe_dummy\"]\n)\npanel_with_own[\"cf_x_soe\"] = (\n    panel_with_own[\"cf_assets\"] * panel_with_own[\"soe_dummy\"]\n)\n\n# Regression with SOE interactions\npanel_soe = panel_with_own.dropna(\n    subset=[\"inv_rate\", \"tobins_q\", \"cf_assets\", \"soe_dummy\"]\n).set_index([\"ticker\", \"year\"])\n\nmodel_soe = PanelOLS(\n    panel_soe[\"inv_rate\"],\n    panel_soe[[\"tobins_q\", \"cf_assets\", \"soe_dummy\",\n               \"q_x_soe\", \"cf_x_soe\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\npanel_soe = panel_soe.reset_index()\n```\n:::\n\n\n::: {#tbl-soe-interaction .cell tbl-cap='Investment-Q Regression with State Ownership Interactions' execution_count=9}\n``` {.python .cell-code}\nsoe_results = pd.DataFrame({\n    \"Coefficient\": model_soe.params.round(4),\n    \"Std Error\": model_soe.std_errors.round(4),\n    \"t-stat\": model_soe.tstats.round(3),\n    \"p-value\": model_soe.pvalues.round(4)\n})\n\nsoe_results\n```\n:::\n\n\nA negative coefficient on $Q \\times \\text{SOE}$ indicates that the investment-$Q$ sensitivity is attenuated for state-owned enterprises, consistent with SOE investment being driven by non-market factors. The interaction of cash flow with SOE status reveals whether state firms face tighter or looser financing constraints. This is a question with direct policy implications for SOE reform.\n\n### The Erickson-Whited Measurement Error Correction\n\n@erickson2012treating develop a GMM estimator that uses higher-order moments of the data to identify the investment-$Q$ slope in the presence of measurement error, without requiring external instruments. The key insight is that if the measurement error $\\eta$ in $Q$ is independent of the true $Q^*$ and the structural error $\\varepsilon$, then the third-order cumulants identify the signal-to-noise ratio.\n\nThe model is:\n\n$$\n\\frac{I_{i,t}}{K_{i,t-1}} = \\beta_0 + \\beta_1 Q_{i,t}^* + \\gamma X_{i,t} + \\varepsilon_{i,t}, \\qquad Q_{i,t} = Q_{i,t}^* + \\eta_{i,t}\n$$ {#eq-erickson-whited}\n\nwhere $Q_{i,t}^*$ is unobserved true $Q$ and $\\eta_{i,t}$ is measurement error. The OLS estimator $\\hat{\\beta}_1^{\\text{OLS}}$ converges to $\\beta_1 \\cdot \\lambda$ where $\\lambda = \\text{Var}(Q^*) / (\\text{Var}(Q^*) + \\text{Var}(\\eta)) < 1$ is the signal-to-noise ratio. The Erickson-Whited estimator recovers $\\beta_1$ and $\\lambda$ simultaneously.\n\n::: {#erickson-whited .cell execution_count=10}\n``` {.python .cell-code}\ndef erickson_whited_gmm(y, Q_obs, X=None, order=3):\n    \"\"\"\n    Simplified Erickson-Whited (2012) measurement error correction\n    using third-order cumulants.\n\n    Parameters\n    ----------\n    y : array\n        Dependent variable (investment rate).\n    Q_obs : array\n        Observed (mismeasured) Q.\n    X : array or None\n        Additional controls (partialled out first).\n    order : int\n        Cumulant order for identification (3 or 5).\n\n    Returns\n    -------\n    dict : Corrected beta, signal-to-noise ratio, OLS beta.\n    \"\"\"\n    if X is not None:\n        # Partial out controls via OLS\n        X_aug = sm.add_constant(X)\n        y = y - X_aug @ np.linalg.lstsq(X_aug, y, rcond=None)[0]\n        Q_obs = Q_obs - X_aug @ np.linalg.lstsq(X_aug, Q_obs, rcond=None)[0]\n\n    # Demean\n    y_dm = y - y.mean()\n    q_dm = Q_obs - Q_obs.mean()\n    n = len(y)\n\n    # Second moments\n    m_yq = np.mean(y_dm * q_dm)\n    m_qq = np.mean(q_dm**2)\n\n    # OLS beta\n    beta_ols = m_yq / m_qq\n\n    # Third-order cumulants for identification\n    k3_q = np.mean(q_dm**3)\n    k2y_q = np.mean(y_dm * q_dm**2)\n\n    if abs(k3_q) < 1e-10:\n        return {\n            \"beta_corrected\": np.nan,\n            \"lambda_snr\": np.nan,\n            \"beta_ols\": beta_ols,\n            \"note\": \"Insufficient skewness for identification\"\n        }\n\n    # Corrected beta: beta = kappa_{y,q,q} / kappa_{q,q,q}\n    beta_ew = k2y_q / k3_q\n\n    # Signal-to-noise ratio\n    # lambda = kappa_{q,q,q}^2 / (kappa_{q,q} * kappa_{q,q,q,q,q})\n    # Simplified: lambda = beta_ols / beta_ew\n    lambda_snr = beta_ols / beta_ew if abs(beta_ew) > 1e-10 else np.nan\n\n    return {\n        \"beta_corrected\": beta_ew,\n        \"lambda_snr\": lambda_snr,\n        \"beta_ols\": beta_ols,\n        \"attenuation_pct\": round((1 - lambda_snr) * 100, 1) if not np.isnan(lambda_snr) else np.nan\n    }\n\n# Apply to Vietnamese data\new_data = panel_clean.dropna(subset=[\"inv_rate\", \"tobins_q\", \"cf_assets\"])\n\new_result = erickson_whited_gmm(\n    y=ew_data[\"inv_rate\"].values,\n    Q_obs=ew_data[\"tobins_q\"].values,\n    X=ew_data[\"cf_assets\"].values.reshape(-1, 1)\n)\n\nprint(\"Erickson-Whited Measurement Error Correction:\")\nfor k, v in ew_result.items():\n    if isinstance(v, float):\n        print(f\"  {k}: {v:.4f}\")\n    else:\n        print(f\"  {k}: {v}\")\n```\n:::\n\n\n## Cash Flow Sensitivity of Investment\n\n### The Financing Constraints Hypothesis\n\nThe cash flow sensitivity of investment (CFSI) literature tests whether firms' investment decisions are constrained by the availability of internal funds. In a Modigliani-Miller world, internal and external funds are perfect substitutes, so cash flow should be irrelevant for investment after controlling for investment opportunities. The CFSI approach, pioneered by @fazzari1987financing, classifies firms as financially constrained or unconstrained using observable characteristics and tests whether constrained firms exhibit higher sensitivity of investment to cash flow.\n\nThe augmented investment regression is:\n\n$$\n\\frac{I_{i,t}}{K_{i,t-1}} = \\beta_0 + \\beta_1 Q_{i,t} + \\beta_2 \\frac{CF_{i,t}}{K_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-cfsi-base}\n\nThe CFSI hypothesis predicts $\\beta_2^{\\text{constrained}} > \\beta_2^{\\text{unconstrained}} > 0$: constrained firms rely more heavily on internal cash flow to fund investment because external finance is costly or unavailable.\n\n### The FHP-KZ Debate\n\n@fazzari1987financing (FHP) classify firms by dividend payout ratios and find that low-payout firms (presumed constrained) exhibit significantly higher cash flow sensitivity. @kaplan1997investment (KZ) challenge this interpretation on two grounds:\n\n**Critique 1:** $Q$ measurement error. If $Q$ is a noisy proxy for true investment opportunities, and cash flow is correlated with the measurement error (because both respond to demand shocks), then the cash flow coefficient captures omitted investment opportunities, not financing constraints.\n\n**Critique 2: Monotonicity failure.** KZ show that the firms FHP classify as \"most constrained\" (low-payout firms) are often rapidly growing firms that choose to retain earnings for investment, not firms that are denied external financing. Using qualitative information from annual reports, KZ reclassify firms and find that the CFSI ranking reverses: firms judged to be truly constrained by their own disclosures exhibit lower CFSI than unconstrained firms.\n\nThe resolution, as argued by @farre2016measures, is that no single proxy reliably identifies financially constrained firms. Each proxy (size, age, payout ratio, bond rating, KZ index, WW index, SA index) captures a different dimension of the financing environment, and the CFSI test is not a clean test of any single theory.\n\n### Constraint Indices\n\nWe implement the three most widely used composite constraint measures.\n\n**KZ Index** [@kaplan1997investment; @lamont2001financial]:\n\n$$\n\\text{KZ}_{i,t} = -1.002 \\cdot \\frac{CF_{i,t}}{K_{i,t-1}} + 0.283 \\cdot Q_{i,t} + 3.139 \\cdot \\frac{D_{i,t}}{A_{i,t}} - 39.368 \\cdot \\frac{\\text{Div}_{i,t}}{K_{i,t-1}} - 1.315 \\cdot \\frac{C_{i,t}}{K_{i,t-1}}\n$$ {#eq-kz-index}\n\n**WW Index** [@whited2006financial]:\n\n$$\n\\text{WW}_{i,t} = -0.091 \\cdot \\frac{CF_{i,t}}{A_{i,t}} - 0.062 \\cdot \\mathbb{1}(\\text{Div} > 0) + 0.021 \\cdot \\frac{D_{i,t}}{A_{i,t}} - 0.044 \\cdot \\ln(A_{i,t}) + 0.102 \\cdot \\text{ISG}_{i,t} - 0.035 \\cdot \\text{SG}_{i,t}\n$$ {#eq-ww-index}\n\nwhere ISG is industry sales growth and SG is firm sales growth.\n\n**SA Index** [@hadlock2010new]:\n\n$$\n\\text{SA}_{i,t} = -0.737 \\cdot \\text{Size}_{i,t} + 0.043 \\cdot \\text{Size}_{i,t}^2 - 0.040 \\cdot \\text{Age}_{i,t}\n$$ {#eq-sa-index}\n\nwhere Size $= \\ln(\\text{Total Assets})$ and Age is years since listing. @hadlock2010new argue that the SA index is preferable because it uses only exogenous firm characteristics (size and age), avoiding the endogeneity inherent in cash flow and leverage-based indices.\n\n::: {#constraint-indices .cell execution_count=11}\n``` {.python .cell-code}\n# Compute financial constraint indices\npanel_fc = panel_clean.copy()\n\n# Lagged PPE for KZ scaling\npanel_fc[\"lag_ppe\"] = panel_fc.groupby(\"ticker\")[\"ppe_net\"].shift(1)\n\n# KZ Index\npanel_fc[\"kz_index\"] = (\n    -1.002 * panel_fc[\"cf_assets\"]\n    + 0.283 * panel_fc[\"tobins_q\"]\n    + 3.139 * (panel_fc[\"total_debt\"] / panel_fc[\"total_assets\"])\n    - 39.368 * (panel_fc[\"dividends\"] / panel_fc[\"lag_assets\"])\n    - 1.315 * (panel_fc[\"cash\"] / panel_fc[\"lag_assets\"])\n)\n\n# SA Index\npanel_fc[\"log_assets\"] = np.log(panel_fc[\"total_assets\"])\npanel_fc[\"listing_age\"] = panel_fc[\"year\"] - panel_fc[\"listing_year\"]\n\npanel_fc[\"sa_index\"] = (\n    -0.737 * panel_fc[\"log_assets\"]\n    + 0.043 * panel_fc[\"log_assets\"]**2\n    - 0.040 * panel_fc[\"listing_age\"]\n)\n\n# WW Index (simplified: using firm-level variables)\npanel_fc[\"div_dummy\"] = (panel_fc[\"dividends\"] > 0).astype(int)\npanel_fc[\"leverage\"] = panel_fc[\"total_debt\"] / panel_fc[\"total_assets\"]\n\n# Industry sales growth\npanel_fc[\"isg\"] = panel_fc.groupby(\n    [\"industry\", \"year\"]\n)[\"sales_growth\"].transform(\"median\")\n\npanel_fc[\"ww_index\"] = (\n    -0.091 * panel_fc[\"cf_assets\"]\n    - 0.062 * panel_fc[\"div_dummy\"]\n    + 0.021 * panel_fc[\"leverage\"]\n    - 0.044 * panel_fc[\"log_assets\"]\n    + 0.102 * panel_fc[\"isg\"]\n    - 0.035 * panel_fc[\"sales_growth\"]\n)\n```\n:::\n\n\n::: {#tbl-constraint-summary .cell tbl-cap='Distribution of Financial Constraint Indices' execution_count=12}\n``` {.python .cell-code}\nconstraint_vars = [\"kz_index\", \"sa_index\", \"ww_index\"]\nconstraint_summary = (\n    panel_fc[constraint_vars]\n    .describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n    .T.round(4)\n)\nconstraint_summary\n```\n:::\n\n\n### Split-Sample CFSI Tests\n\nWe classify firms into constrained and unconstrained groups using each index and compare the cash flow sensitivity of investment across groups.\n\n::: {#cfsi-split-sample .cell execution_count=13}\n``` {.python .cell-code}\ndef cfsi_by_group(data, group_var, threshold=\"median\"):\n    \"\"\"\n    Estimate cash flow sensitivity of investment by constraint group.\n\n    Parameters\n    ----------\n    data : DataFrame\n        Panel data with inv_rate, tobins_q, cf_assets, group_var.\n    group_var : str\n        Variable used for classification.\n    threshold : str\n        \"median\" for sample split or \"tercile\" for top/bottom third.\n\n    Returns\n    -------\n    dict : Coefficient estimates by group.\n    \"\"\"\n    df = data.dropna(subset=[\"inv_rate\", \"tobins_q\", \"cf_assets\", group_var])\n\n    if threshold == \"median\":\n        median_val = df[group_var].median()\n        df[\"constrained\"] = (df[group_var] >= median_val).astype(int)\n    elif threshold == \"tercile\":\n        t33 = df[group_var].quantile(0.33)\n        t67 = df[group_var].quantile(0.67)\n        df = df[(df[group_var] <= t33) | (df[group_var] >= t67)]\n        df[\"constrained\"] = (df[group_var] >= t67).astype(int)\n\n    results = {}\n    for group_name, group_label in [(0, \"Unconstrained\"), (1, \"Constrained\")]:\n        subset = df[df[\"constrained\"] == group_name].copy()\n        if len(subset) < 100:\n            continue\n\n        subset = subset.set_index([\"ticker\", \"year\"])\n        model = PanelOLS(\n            subset[\"inv_rate\"],\n            subset[[\"tobins_q\", \"cf_assets\"]],\n            entity_effects=True,\n            time_effects=True,\n            check_rank=False\n        ).fit(cov_type=\"clustered\", cluster_entity=True)\n\n        results[group_label] = {\n            \"beta_Q\": model.params[\"tobins_q\"],\n            \"se_Q\": model.std_errors[\"tobins_q\"],\n            \"beta_CF\": model.params[\"cf_assets\"],\n            \"se_CF\": model.std_errors[\"cf_assets\"],\n            \"R2_within\": model.rsquared_within,\n            \"N\": int(model.nobs)\n        }\n\n    return pd.DataFrame(results).T\n\n# Run for each constraint index\ncfsi_kz = cfsi_by_group(panel_fc, \"kz_index\", \"median\")\ncfsi_sa = cfsi_by_group(panel_fc, \"sa_index\", \"median\")\ncfsi_ww = cfsi_by_group(panel_fc, \"ww_index\", \"median\")\n```\n:::\n\n\n::: {#tbl-cfsi-comparison .cell tbl-cap='Cash Flow Sensitivity by Financial Constraint Classification' execution_count=14}\n``` {.python .cell-code}\n# Combine results\ncfsi_all = pd.concat({\n    \"KZ Index\": cfsi_kz,\n    \"SA Index\": cfsi_sa,\n    \"WW Index\": cfsi_ww\n})\n\ncfsi_display = cfsi_all[[\"beta_CF\", \"se_CF\", \"beta_Q\", \"se_Q\", \"N\"]].round(4)\ncfsi_display\n```\n:::\n\n\n### Alternative Specifications\n\nThe baseline CFSI test has been augmented in several directions:\n\n**Dynamic investment models.** @bond2003financial argue that the static regression @eq-cfsi-base omits the autoregressive component of investment. The Euler equation approach, which derives directly from the firm's dynamic optimization problem, yields:\n\n$$\n\\frac{I_{i,t}}{K_{i,t-1}} = \\gamma_1 \\frac{I_{i,t-1}}{K_{i,t-2}} + \\gamma_2 \\left(\\frac{Y_{i,t}}{K_{i,t-1}}\\right) + \\gamma_3 \\frac{CF_{i,t}}{K_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-euler-investment}\n\nThis specification avoids the need for $Q$ entirely, sidestepping the measurement error problem.\n\n**External finance dependence.** @rajan1998financial propose using the industry-level technological demand for external finance as an instrument for financing constraints. Industries that technologically require more external funding should be disproportionately affected by financial development and firm-level constraints.\n\n::: {#euler-equation .cell execution_count=15}\n``` {.python .cell-code}\n# Euler equation investment model (dynamic panel)\npanel_euler = panel_fc.copy().sort_values([\"ticker\", \"year\"])\n\npanel_euler[\"lag_inv_rate\"] = panel_euler.groupby(\"ticker\")[\"inv_rate\"].shift(1)\npanel_euler[\"revenue_assets\"] = panel_euler[\"revenue\"] / panel_euler[\"lag_assets\"]\n\neuler_data = panel_euler.dropna(\n    subset=[\"inv_rate\", \"lag_inv_rate\", \"revenue_assets\", \"cf_assets\"]\n).set_index([\"ticker\", \"year\"])\n\nmodel_euler = PanelOLS(\n    euler_data[\"inv_rate\"],\n    euler_data[[\"lag_inv_rate\", \"revenue_assets\", \"cf_assets\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\neuler_data = euler_data.reset_index()\n```\n:::\n\n\n::: {#tbl-euler .cell tbl-cap='Euler Equation Investment Model' execution_count=16}\n``` {.python .cell-code}\neuler_results = pd.DataFrame({\n    \"Coefficient\": model_euler.params.round(4),\n    \"Std Error\": model_euler.std_errors.round(4),\n    \"t-stat\": model_euler.tstats.round(3),\n    \"p-value\": model_euler.pvalues.round(4)\n})\neuler_results\n```\n:::\n\n\n## Financing Choice Models\n\n### Capital Structure Determinants\n\nThe two dominant theories of capital structure (i.e., trade-off theory and pecking order theory) generate distinct predictions about the determinants of leverage. @frank2009capital provide the most comprehensive empirical synthesis, identifying six \"core\" variables that reliably predict leverage across samples and specifications.\n\nThe baseline capital structure regression is:\n\n$$\n\\text{Lev}_{i,t} = \\beta_0 + \\boldsymbol{\\beta}' \\mathbf{X}_{i,t} + \\alpha_i + \\delta_t + \\varepsilon_{i,t}\n$$ {#eq-leverage-regression}\n\nwhere $\\text{Lev}_{i,t}$ is either book leverage ($D / A$) or market leverage ($D / (D + E^{\\text{mkt}})$), and $\\mathbf{X}_{i,t}$ includes the core determinants.\n\n@tbl-cs-predictions summarizes the theoretical predictions.\n\n| Determinant | Trade-Off | Pecking Order | Measurement |\n|------------------|------------------|-------------------|------------------|\n| Profitability | \\+ (tax shield) | − (less need for external) | EBITDA / Assets |\n| Size | \\+ (lower distress costs) | \\+ (less information asymmetry) | ln(Total Assets) |\n| Tangibility | \\+ (collateral value) | \\+ (less adverse selection) | PPE / Assets |\n| Growth (MTB) | − (underinvestment) | \\+ (financing needs) | Market-to-Book |\n| Industry median leverage | \\+ (target) | ambiguous | Industry median |\n| Profitability volatility | − (distress risk) | ambiguous | Rolling σ(EBITDA/A) |\n\n: Capital Structure Predictions by Theory {#tbl-cs-predictions}\n\n::: {#capital-structure-data .cell execution_count=17}\n``` {.python .cell-code}\n# Construct capital structure variables\ncs = panel_fc.copy()\n\n# Book leverage\ncs[\"book_leverage\"] = cs[\"total_debt\"] / cs[\"total_assets\"]\n\n# Market leverage\ncs[\"market_leverage\"] = cs[\"total_debt\"] / (\n    cs[\"total_debt\"] + cs[\"market_cap\"]\n)\n\n# Profitability\ncs[\"profitability\"] = cs[\"ebitda\"] / cs[\"total_assets\"]\n\n# Tangibility\ncs[\"tangibility\"] = cs[\"ppe_net\"] / cs[\"total_assets\"]\n\n# Size\ncs[\"size\"] = np.log(cs[\"total_assets\"])\n\n# Market-to-Book\ncs[\"mtb\"] = cs[\"market_cap\"] / cs[\"book_equity\"]\n\n# Industry median leverage\ncs[\"ind_median_lev\"] = cs.groupby(\n    [\"industry\", \"year\"]\n)[\"book_leverage\"].transform(\"median\")\n\n# Rolling profitability volatility (3-year)\ncs = cs.sort_values([\"ticker\", \"year\"])\ncs[\"profit_vol\"] = (\n    cs.groupby(\"ticker\")[\"profitability\"]\n    .transform(lambda x: x.rolling(3, min_periods=2).std())\n)\n\n# Winsorize\nfor col in [\"book_leverage\", \"market_leverage\", \"profitability\",\n            \"tangibility\", \"mtb\", \"profit_vol\"]:\n    cs[col] = winsorize(cs[col])\n\ncs_clean = cs.dropna(\n    subset=[\"book_leverage\", \"profitability\", \"size\",\n            \"tangibility\", \"mtb\", \"ind_median_lev\"]\n)\n```\n:::\n\n\n::: {#leverage-regressions .cell execution_count=18}\n``` {.python .cell-code}\n# Capital structure regressions\ncs_panel = cs_clean.set_index([\"ticker\", \"year\"])\n\nregressors = [\"profitability\", \"size\", \"tangibility\",\n              \"mtb\", \"ind_median_lev\"]\n\n# Book leverage\nmodel_book = PanelOLS(\n    cs_panel[\"book_leverage\"],\n    cs_panel[regressors],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\n# Market leverage\nmodel_mkt = PanelOLS(\n    cs_panel[\"market_leverage\"],\n    cs_panel[regressors],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\ncs_panel = cs_panel.reset_index()\n```\n:::\n\n\n::: {#tbl-capital-structure .cell tbl-cap='Capital Structure Determinants: Book and Market Leverage' execution_count=19}\n``` {.python .cell-code}\ncs_table = pd.DataFrame({\n    \"Book Leverage\": [\n        f\"{model_book.params[v]:.4f} ({model_book.std_errors[v]:.4f})\"\n        for v in regressors\n    ] + [f\"{model_book.rsquared_within:.4f}\", str(int(model_book.nobs))],\n    \"Market Leverage\": [\n        f\"{model_mkt.params[v]:.4f} ({model_mkt.std_errors[v]:.4f})\"\n        for v in regressors\n    ] + [f\"{model_mkt.rsquared_within:.4f}\", str(int(model_mkt.nobs))]\n}, index=regressors + [\"R² (within)\", \"N\"])\n\ncs_table\n```\n:::\n\n\n### Pecking Order Tests\n\nThe pecking order theory [@myers1984capital] predicts that firms prefer internal finance, then debt, then equity. @shyam1999testing propose a direct test: if the pecking order holds strictly, the financing deficit (investment minus internal funds) should be financed dollar-for-dollar by debt:\n\n$$\n\\Delta D_{i,t} = \\alpha + \\beta_{\\text{PO}} \\cdot \\text{DEF}_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-pecking-order}\n\nwhere $\\text{DEF}_{i,t} = \\text{Div}_{i,t} + \\text{Capex}_{i,t} + \\Delta W_{i,t} - CF_{i,t}$ is the financing deficit and $\\Delta D_{i,t}$ is net debt issuance. A strict pecking order implies $\\hat{\\alpha} = 0$ and $\\hat{\\beta}_{\\text{PO}} = 1$. @frank2003testing show that the coefficient is typically well below 1, especially for large firms and equity issuers.\n\n::: {#pecking-order .cell execution_count=20}\n``` {.python .cell-code}\n# Construct financing deficit\npo = cs.copy().sort_values([\"ticker\", \"year\"])\npo[\"lag_debt\"] = po.groupby(\"ticker\")[\"total_debt\"].shift(1)\npo[\"net_debt_issuance\"] = po[\"total_debt\"] - po[\"lag_debt\"]\n\n# Financing deficit = Div + Capex + ΔWC - CF\npo[\"delta_wc\"] = po[\"working_capital\"] - po.groupby(\n    \"ticker\"\n)[\"working_capital\"].shift(1)\n\npo[\"fin_deficit\"] = (\n    po[\"dividends\"] + po[\"capex\"]\n    + po[\"delta_wc\"].fillna(0) - po[\"operating_cf\"]\n)\n\n# Scale by lagged assets\nfor col in [\"net_debt_issuance\", \"fin_deficit\"]:\n    po[col] = po[col] / po[\"lag_assets\"]\n\npo_clean = po.dropna(\n    subset=[\"net_debt_issuance\", \"fin_deficit\"]\n)\n\n# Winsorize\nfor col in [\"net_debt_issuance\", \"fin_deficit\"]:\n    po_clean[col] = winsorize(po_clean[col])\n\n# Pecking order regression\npo_panel = po_clean.set_index([\"ticker\", \"year\"])\n\nmodel_po = PanelOLS(\n    po_panel[\"net_debt_issuance\"],\n    po_panel[[\"fin_deficit\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\npo_panel = po_panel.reset_index()\n\nprint(f\"Pecking order coefficient: {model_po.params['fin_deficit']:.4f}\")\nprint(f\"  (se = {model_po.std_errors['fin_deficit']:.4f})\")\nprint(f\"  H0: β = 1, t = \"\n      f\"{(model_po.params['fin_deficit'] - 1) / model_po.std_errors['fin_deficit']:.3f}\")\n```\n:::\n\n\n### Market Timing Measures\n\n@baker2002market argue that capital structure is largely the cumulative outcome of market timing (i.e., firms issue equity when valuations are high and repurchase when valuations are low). Their key variable is the external-finance-weighted average market-to-book ratio:\n\n$$\n\\left(\\frac{M}{B}\\right)_{i,t}^{efwa} = \\sum_{s=\\text{IPO}}^{t-1} \\frac{e_s + d_s}{\\sum_{r=\\text{IPO}}^{t-1}(e_r + d_r)} \\cdot \\left(\\frac{M}{B}\\right)_{i,s}\n$$ {#eq-efwa-mtb}\n\nwhere $e_s$ and $d_s$ are net equity and net debt issuance in year $s$. This variable captures the historical valuations at which the firm raised capital. The market timing hypothesis predicts that higher $\\left(M/B\\right)^{efwa}$ is associated with lower current leverage (i.e., firms that historically issued equity at high valuations have persistently lower leverage).\n\n::: {#market-timing .cell execution_count=21}\n``` {.python .cell-code}\n# External-Finance-Weighted Average M/B\ndef compute_efwa_mtb(group):\n    \"\"\"Compute Baker-Wurgler EFWA M/B for one firm.\"\"\"\n    g = group.sort_values(\"year\").copy()\n\n    # Net issuance each year\n    g[\"net_equity\"] = g[\"equity_issuance\"].fillna(0)\n    g[\"net_debt\"] = g[\"net_debt_issuance\"].fillna(0)\n    g[\"total_issuance\"] = (\n        g[\"net_equity\"].abs() + g[\"net_debt\"].abs()\n    ).replace(0, np.nan)\n\n    efwa_values = []\n    for idx in range(1, len(g)):\n        past = g.iloc[:idx]\n        weights = past[\"total_issuance\"] / past[\"total_issuance\"].sum()\n        weights = weights.fillna(0)\n        efwa = (weights * past[\"mtb\"]).sum()\n        efwa_values.append(efwa)\n\n    g = g.iloc[1:].copy()\n    g[\"efwa_mtb\"] = efwa_values\n    return g[[\"ticker\", \"year\", \"efwa_mtb\"]]\n\nmt = po_clean.copy()\nmt[\"equity_issuance\"] = mt[\"market_cap\"] - mt.groupby(\n    \"ticker\"\n)[\"market_cap\"].shift(1) - mt[\"net_income\"]\n\nefwa_data = (\n    mt.groupby(\"ticker\", group_keys=False)\n    .apply(compute_efwa_mtb)\n    .reset_index(drop=True)\n)\n\n# Merge and regress\nmt_merged = cs_clean.merge(efwa_data, on=[\"ticker\", \"year\"], how=\"left\")\nmt_clean = mt_merged.dropna(\n    subset=[\"market_leverage\", \"efwa_mtb\", \"profitability\",\n            \"size\", \"tangibility\", \"mtb\"]\n)\n\nmt_panel = mt_clean.set_index([\"ticker\", \"year\"])\n\nmodel_mt = PanelOLS(\n    mt_panel[\"market_leverage\"],\n    mt_panel[[\"efwa_mtb\", \"mtb\", \"profitability\", \"size\", \"tangibility\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\nmt_panel = mt_panel.reset_index()\n```\n:::\n\n\n::: {#tbl-market-timing .cell tbl-cap='Market Timing and Capital Structure' execution_count=22}\n``` {.python .cell-code}\nmt_results = pd.DataFrame({\n    \"Coefficient\": model_mt.params.round(4),\n    \"Std Error\": model_mt.std_errors.round(4),\n    \"t-stat\": model_mt.tstats.round(3),\n    \"p-value\": model_mt.pvalues.round(4)\n})\nmt_results\n```\n:::\n\n\nA negative coefficient on $\\text{EFWA}_{M/B}$ after controlling for the current $M/B$ (which captures current investment opportunities) supports the market timing hypothesis: firms that historically raised capital at high valuations maintain persistently lower leverage.\n\n## Payout Policy Estimators\n\n### Dividend Smoothing\n\n@lintner1956distribution established the foundational model of dividend behavior: firms target a payout ratio and partially adjust dividends toward the target each year. The partial adjustment model is:\n\n$$\n\\Delta D_{i,t} = \\alpha_i + \\lambda(\\tau \\cdot E_{i,t} - D_{i,t-1}) + \\varepsilon_{i,t}\n$$ {#eq-lintner}\n\nwhere $D_{i,t}$ is the dividend per share, $E_{i,t}$ is earnings per share, $\\tau$ is the target payout ratio, and $\\lambda \\in (0, 1)$ is the speed of adjustment. Low $\\lambda$ implies strong smoothing (i.e., firms adjust dividends slowly toward the target). Rearranging:\n\n$$\nD_{i,t} = \\alpha_i + (1 - \\lambda) D_{i,t-1} + \\lambda \\tau \\cdot E_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-lintner-regression}\n\nThe coefficient on lagged dividends, $(1 - \\lambda)$, measures the degree of smoothing. Values close to 1 indicate near-complete smoothing; values close to 0 indicate no smoothing (full adjustment).\n\n::: {#lintner-model .cell execution_count=23}\n``` {.python .cell-code}\n# Construct dividend and earnings variables\ndiv = panel_fc.copy().sort_values([\"ticker\", \"year\"])\n\ndiv[\"lag_dps\"] = div.groupby(\"ticker\")[\"dividends_per_share\"].shift(1)\ndiv[\"delta_dps\"] = div[\"dividends_per_share\"] - div[\"lag_dps\"]\n\n# Only firms with positive dividends in both periods\ndiv_clean = div.dropna(\n    subset=[\"dividends_per_share\", \"lag_dps\", \"eps\"]\n).query(\"lag_dps > 0 and dividends_per_share > 0\")\n\n# Lintner regression\ndiv_panel = div_clean.set_index([\"ticker\", \"year\"])\n\nmodel_lintner = PanelOLS(\n    div_panel[\"dividends_per_share\"],\n    div_panel[[\"lag_dps\", \"eps\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\ndiv_panel = div_panel.reset_index()\n\n# Extract structural parameters\nlambda_hat = 1 - model_lintner.params[\"lag_dps\"]\ntau_hat = model_lintner.params[\"eps\"] / lambda_hat\n\nprint(f\"Lintner Model Estimates:\")\nprint(f\"  Speed of adjustment (λ): {lambda_hat:.4f}\")\nprint(f\"  Target payout ratio (τ): {tau_hat:.4f}\")\nprint(f\"  Smoothing coefficient (1-λ): {model_lintner.params['lag_dps']:.4f}\")\n```\n:::\n\n\n::: {#tbl-lintner .cell tbl-cap='Lintner Partial Adjustment Model' execution_count=24}\n``` {.python .cell-code}\nlintner_table = pd.DataFrame({\n    \"Coefficient\": model_lintner.params.round(4),\n    \"Std Error\": model_lintner.std_errors.round(4),\n    \"t-stat\": model_lintner.tstats.round(3),\n    \"p-value\": model_lintner.pvalues.round(4)\n})\nlintner_table\n```\n:::\n\n\n::: {#fig-payout-ratio .cell execution_count=25}\n``` {.python .cell-code}\npayout = panel_fc.copy()\npayout[\"payout_ratio\"] = payout[\"dividends\"] / payout[\"net_income\"]\npayout = payout[\n    (payout[\"net_income\"] > 0) &\n    (payout[\"payout_ratio\"].between(0, 2))\n]\n\npayout_ts = (\n    payout.groupby(\"year\")\n    .agg(\n        median_payout=(\"payout_ratio\", \"median\"),\n        mean_payout=(\"payout_ratio\", \"mean\"),\n        q25=(\"payout_ratio\", lambda x: x.quantile(0.25)),\n        q75=(\"payout_ratio\", lambda x: x.quantile(0.75)),\n        pct_payers=(\"payout_ratio\", lambda x: (x > 0).mean())\n    )\n    .reset_index()\n)\n\n(\n    p9.ggplot(payout_ts, p9.aes(x=\"year\"))\n    + p9.geom_ribbon(\n        p9.aes(ymin=\"q25\", ymax=\"q75\"),\n        fill=\"#2E5090\", alpha=0.2\n    )\n    + p9.geom_line(\n        p9.aes(y=\"median_payout\"),\n        color=\"#2E5090\", size=1\n    )\n    + p9.geom_line(\n        p9.aes(y=\"mean_payout\"),\n        color=\"#C0392B\", linetype=\"dashed\", size=0.7\n    )\n    + p9.labs(\n        x=\"Year\",\n        y=\"Dividend Payout Ratio\",\n        title=\"Payout Ratio: Median (Solid) and Mean (Dashed)\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(10, 5))\n)\n```\n:::\n\n\n### Smoothing Heterogeneity: SOEs vs. Private Firms\n\nDividend policy in Vietnam is shaped by regulatory mandates. The State Capital Investment Corporation (SCIC) and line ministries have historically required SOEs to distribute minimum dividend amounts, sometimes at the expense of reinvestment. This creates a fundamental asymmetry: SOE dividends are partially policy-determined rather than the outcome of the Lintner optimization.\n\n::: {#lintner-soe-split .cell execution_count=26}\n``` {.python .cell-code}\n# Merge SOE indicator\ndiv_with_soe = div_clean.merge(\n    ownership[[\"ticker\", \"year\", \"state_ownership_pct\"]],\n    on=[\"ticker\", \"year\"],\n    how=\"left\"\n)\ndiv_with_soe[\"soe\"] = (div_with_soe[\"state_ownership_pct\"] > 50).astype(int)\n\n# Estimate Lintner model separately for SOEs and private firms\nlintner_results = {}\nfor label, soe_val in [(\"Private\", 0), (\"SOE\", 1)]:\n    subset = div_with_soe[div_with_soe[\"soe\"] == soe_val].copy()\n    if len(subset) < 100:\n        continue\n\n    subset_panel = subset.set_index([\"ticker\", \"year\"])\n    model = PanelOLS(\n        subset_panel[\"dividends_per_share\"],\n        subset_panel[[\"lag_dps\", \"eps\"]],\n        entity_effects=True,\n        time_effects=True,\n        check_rank=False\n    ).fit(cov_type=\"clustered\", cluster_entity=True)\n\n    lam = 1 - model.params[\"lag_dps\"]\n    tau = model.params[\"eps\"] / lam if abs(lam) > 0.01 else np.nan\n\n    lintner_results[label] = {\n        \"Smoothing (1-λ)\": round(model.params[\"lag_dps\"], 4),\n        \"Speed of adj (λ)\": round(lam, 4),\n        \"Target payout (τ)\": round(tau, 4),\n        \"N\": int(model.nobs)\n    }\n\npd.DataFrame(lintner_results).T\n```\n:::\n\n\n### Share Repurchases\n\nShare repurchases are a relatively new phenomenon in Vietnamese markets, gradually gaining traction as regulations have evolved. Unlike dividends, repurchases are more flexible and do not create expectations of future payments. The decision to repurchase can be modeled as:\n\n$$\n\\text{Repurchase}_{i,t} = \\mathbb{1}\\left(\\beta_0 + \\beta_1 \\frac{CF_{i,t}}{A_{i,t}} + \\beta_2 Q_{i,t} + \\beta_3 \\text{Lev}_{i,t} + \\beta_4 \\frac{\\text{Cash}_{i,t}}{A_{i,t}} + \\boldsymbol{\\gamma}' \\mathbf{Z}_{i,t} + \\varepsilon_{i,t} > 0\\right)\n$$ {#eq-repurchase-probit}\n\n::: {#repurchase-model .cell execution_count=27}\n``` {.python .cell-code}\n# Identify repurchase years\nrepurchase = panel_fc.copy()\nrepurchase[\"repurchase_dummy\"] = (\n    repurchase[\"share_repurchases\"] > 0\n).astype(int)\n\nrepurchase[\"cash_assets\"] = repurchase[\"cash\"] / repurchase[\"total_assets\"]\n\n# Probit model for repurchase decision\nrep_clean = repurchase.dropna(\n    subset=[\"repurchase_dummy\", \"cf_assets\", \"tobins_q\",\n            \"book_leverage\", \"cash_assets\", \"log_assets\"]\n)\n\nprobit_model = smf.probit(\n    \"repurchase_dummy ~ cf_assets + tobins_q + book_leverage \"\n    \"+ cash_assets + log_assets + C(year)\",\n    data=rep_clean\n).fit(disp=False, cov_type=\"cluster\", cov_kwds={\"groups\": rep_clean[\"ticker\"]})\n```\n:::\n\n\n::: {#tbl-repurchase-probit .cell tbl-cap='Probit Model: Determinants of Share Repurchase Decision' execution_count=28}\n``` {.python .cell-code}\n# Extract non-year-dummy coefficients\nmain_vars = [\"cf_assets\", \"tobins_q\", \"book_leverage\",\n             \"cash_assets\", \"log_assets\"]\n\nprobit_results = pd.DataFrame({\n    \"Coefficient\": probit_model.params[main_vars].round(4),\n    \"Std Error\": probit_model.bse[main_vars].round(4),\n    \"z-stat\": probit_model.tvalues[main_vars].round(3),\n    \"p-value\": probit_model.pvalues[main_vars].round(4),\n    \"Marginal Effect\": (\n        probit_model.get_margeff().margeff[:len(main_vars)]\n    ).round(4)\n})\nprobit_results\n```\n:::\n\n\n### Agency and Signaling Interpretations\n\nPayout policy is interpreted through two competing lenses:\n\n**Agency view** [@jensen1986agency; @la2000agency]: Dividends are a mechanism for disgorging free cash flow that managers would otherwise waste on empire-building or perquisite consumption. In this view, firms with weaker governance should face greater pressure to pay dividends as a bonding device. @la2000agency distinguish the \"outcome\" model (dividends are the result of effective minority shareholder pressure) from the \"substitute\" model (firms with weak governance pay high dividends to build reputation for fair treatment).\n\n**Signaling view** [@bhattacharya1979imperfect; @miller1985dividend]: Dividends convey private information about future earnings. Because dividends are costly to fake (they require actual cash), they serve as a credible signal. The signaling interpretation predicts that dividend changes should predict future earnings changes.\n\n::: {#dividend-signaling .cell execution_count=29}\n``` {.python .cell-code}\n# Test dividend signaling: do dividend changes predict future earnings?\nsignal = panel_fc.copy().sort_values([\"ticker\", \"year\"])\n\nsignal[\"delta_div\"] = signal.groupby(\"ticker\")[\"dividends\"].diff()\nsignal[\"div_increase\"] = (signal[\"delta_div\"] > 0).astype(int)\nsignal[\"div_decrease\"] = (signal[\"delta_div\"] < 0).astype(int)\n\n# Future earnings change\nsignal[\"lead_earnings\"] = signal.groupby(\"ticker\")[\"net_income\"].shift(-1)\nsignal[\"delta_earnings_lead\"] = (\n    (signal[\"lead_earnings\"] - signal[\"net_income\"]) /\n    signal[\"total_assets\"]\n)\n\n# Current earnings change (control)\nsignal[\"lag_earnings\"] = signal.groupby(\"ticker\")[\"net_income\"].shift(1)\nsignal[\"delta_earnings_curr\"] = (\n    (signal[\"net_income\"] - signal[\"lag_earnings\"]) /\n    signal[\"total_assets\"]\n)\n\nsignal_clean = signal.dropna(\n    subset=[\"delta_earnings_lead\", \"div_increase\",\n            \"div_decrease\", \"delta_earnings_curr\"]\n)\n\n# Regression: future earnings change on dividend change indicators\nsignal_model = smf.ols(\n    \"delta_earnings_lead ~ div_increase + div_decrease \"\n    \"+ delta_earnings_curr + C(year) + C(industry)\",\n    data=signal_clean\n).fit(cov_type=\"cluster\", cov_kwds={\"groups\": signal_clean[\"ticker\"]})\n\nprint(\"Dividend Signaling Test:\")\nfor var in [\"div_increase\", \"div_decrease\", \"delta_earnings_curr\"]:\n    print(f\"  {var}: {signal_model.params[var]:.4f} \"\n          f\"(t = {signal_model.tvalues[var]:.3f})\")\n```\n:::\n\n\n## Agency Cost Proxies\n\n### Ownership Concentration and Agency Problems\n\nThe agency framework of @jensen2019theory identifies the separation of ownership and control as the fundamental source of corporate agency costs. In concentrated-ownership economies like Vietnam, the dominant agency conflict is not between dispersed shareholders and professional managers (Berle-Means agency problem) but between controlling and minority shareholders (principal-principal agency problem, @young2008corporate).\n\nThe key mechanisms through which controlling shareholders extract private benefits include: tunneling via related-party transactions [@johnson2000tunneling], diversion of corporate opportunities, excessive compensation, and dilutive equity issuances. The extent of these costs depends on the ownership structure, legal protections for minorities, and monitoring intensity.\n\n::: {#ownership-structure .cell execution_count=30}\n``` {.python .cell-code}\n# Merge ownership data comprehensively\nagency = panel_fc.merge(\n    ownership[[\"ticker\", \"year\", \"state_ownership_pct\",\n               \"foreign_ownership_pct\", \"insider_ownership_pct\",\n               \"largest_shareholder_pct\", \"top5_shareholder_pct\",\n               \"board_size\", \"independent_directors_pct\",\n               \"ceo_duality\"]],\n    on=[\"ticker\", \"year\"],\n    how=\"left\"\n)\n\n# Ownership concentration measures\n# Herfindahl of top-5 shareholdings\nagency[\"ownership_hhi\"] = agency[\"top5_shareholder_pct\"]**2\n\n# Excess control rights (proxy: difference between\n# largest shareholder and second largest)\nagency[\"control_wedge\"] = (\n    agency[\"largest_shareholder_pct\"] -\n    (agency[\"top5_shareholder_pct\"] - agency[\"largest_shareholder_pct\"]) / 4\n)\n```\n:::\n\n\n### Free Cash Flow Measures\n\n@jensen1986agency argues that the agency cost of free cash flow is the central problem in firms that generate cash in excess of positive-NPV investment opportunities. The standard measure is:\n\n$$\n\\text{FCF}_{i,t} = \\frac{\\text{Operating CF}_{i,t} - \\text{Depreciation}_{i,t} - \\text{Required Capex}_{i,t}}{\\text{Total Assets}_{i,t}}\n$$ {#eq-fcf}\n\nIn practice, \"required capex\" is unobservable, so researchers use operating cash flow minus capital expenditures as a proxy, or add the interaction of cash flow with low $Q$ (which identifies firms with cash flow but without investment opportunities):\n\n$$\n\\text{FCF Overinvestment} = \\frac{CF_{i,t}}{A_{i,t}} \\times \\mathbb{1}(Q_{i,t} < 1)\n$$ {#eq-fcf-overinvest}\n\n::: {#fcf-agency .cell execution_count=31}\n``` {.python .cell-code}\n# Free cash flow measures\nagency[\"fcf\"] = (agency[\"operating_cf\"] - agency[\"capex\"]) / agency[\"total_assets\"]\n\nagency[\"low_q\"] = (agency[\"tobins_q\"] < 1).astype(int)\nagency[\"fcf_low_q\"] = agency[\"fcf\"] * agency[\"low_q\"]\n\n# Asset utilization (inverse proxy for agency costs)\nagency[\"asset_turnover\"] = agency[\"revenue\"] / agency[\"total_assets\"]\n\n# SGA ratio (proxy for discretionary spending / empire building)\nagency[\"sga_ratio\"] = agency[\"sga_expenses\"] / agency[\"revenue\"]\n```\n:::\n\n\n### Monitoring Mechanisms and Governance Variables\n\nWe construct a governance quality composite based on observable monitoring mechanisms:\n\n::: {#governance-variables .cell execution_count=32}\n``` {.python .cell-code}\n# Governance quality indicators\nagency[\"foreign_monitor\"] = (\n    agency[\"foreign_ownership_pct\"] > 20\n).astype(int)\n\nagency[\"board_independence\"] = agency[\"independent_directors_pct\"]\n\nagency[\"no_duality\"] = (1 - agency[\"ceo_duality\"]).astype(int)\n\n# Related-party transaction intensity (if available)\n# agency[\"rpt_ratio\"] = agency[\"related_party_transactions\"] / agency[\"revenue\"]\n```\n:::\n\n\n::: {#tbl-agency-proxies .cell tbl-cap='Summary Statistics: Agency Cost Proxies and Governance Variables' execution_count=33}\n``` {.python .cell-code}\nagency_vars = [\n    \"largest_shareholder_pct\", \"state_ownership_pct\",\n    \"foreign_ownership_pct\", \"fcf\", \"fcf_low_q\",\n    \"asset_turnover\", \"board_independence\"\n]\n\nagency_summary = (\n    agency[agency_vars].dropna()\n    .describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n    .T.round(4)\n)\nagency_summary\n```\n:::\n\n\n### Agency Costs and Firm Value\n\nWe test whether agency cost proxies are associated with firm value (Tobin's $Q$) and operating performance (ROA), controlling for standard determinants:\n\n$$\nQ_{i,t} = \\beta_0 + \\beta_1 \\text{Own}_{i,t} + \\beta_2 \\text{Own}_{i,t}^2 + \\boldsymbol{\\gamma}'\\mathbf{X}_{i,t} + \\alpha_i + \\delta_t + \\varepsilon_{i,t}\n$$ {#eq-agency-valuation}\n\nThe quadratic in ownership captures the @morck1988management nonlinearity: at low levels, managerial ownership aligns incentives (positive effect on $Q$); at high levels, entrenchment dominates (negative effect).\n\n::: {#agency-valuation .cell execution_count=34}\n``` {.python .cell-code}\n# Agency cost and valuation regression\nagency[\"largest_sq\"] = agency[\"largest_shareholder_pct\"]**2\n\nval_data = agency.dropna(\n    subset=[\"tobins_q\", \"largest_shareholder_pct\", \"foreign_ownership_pct\",\n            \"fcf\", \"size\", \"profitability\", \"leverage\"]\n).copy()\n\nval_panel = val_data.set_index([\"ticker\", \"year\"])\n\nmodel_val = PanelOLS(\n    val_panel[\"tobins_q\"],\n    val_panel[[\"largest_shareholder_pct\", \"largest_sq\",\n               \"foreign_ownership_pct\", \"fcf\",\n               \"size\", \"profitability\", \"leverage\"]],\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type=\"clustered\", cluster_entity=True)\n\nval_panel = val_panel.reset_index()\n```\n:::\n\n\n::: {#tbl-agency-valuation .cell tbl-cap='Agency Proxies and Firm Value (Tobin\\'s Q)' execution_count=35}\n``` {.python .cell-code}\nval_results = pd.DataFrame({\n    \"Coefficient\": model_val.params.round(4),\n    \"Std Error\": model_val.std_errors.round(4),\n    \"t-stat\": model_val.tstats.round(3),\n    \"p-value\": model_val.pvalues.round(4)\n})\nval_results\n```\n:::\n\n\n::: {#fig-ownership-q .cell execution_count=36}\n``` {.python .cell-code}\n# Binned scatter: largest shareholder vs Q\nown_bins = val_data.copy()\nown_bins[\"own_bin\"] = pd.qcut(\n    own_bins[\"largest_shareholder_pct\"], q=20, duplicates=\"drop\"\n)\n\nown_binned = (\n    own_bins.groupby(\"own_bin\", observed=True)\n    .agg(\n        mean_own=(\"largest_shareholder_pct\", \"mean\"),\n        mean_q=(\"tobins_q\", \"mean\"),\n        se_q=(\"tobins_q\", lambda x: x.std() / np.sqrt(len(x)))\n    )\n    .reset_index()\n)\n\n(\n    p9.ggplot(own_binned, p9.aes(x=\"mean_own\", y=\"mean_q\"))\n    + p9.geom_pointrange(\n        p9.aes(ymin=\"mean_q - 1.96*se_q\",\n               ymax=\"mean_q + 1.96*se_q\"),\n        color=\"#2E5090\", size=0.5\n    )\n    + p9.geom_smooth(method=\"loess\", color=\"#C0392B\", se=False, size=0.8)\n    + p9.labs(\n        x=\"Largest Shareholder Ownership (%)\",\n        y=\"Tobin's Q\",\n        title=\"Ownership Concentration and Firm Value\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(10, 6))\n)\n```\n:::\n\n\nThe inverted-U pattern, if present, would be consistent with the Morck-Shleifer-Vishny incentive-alignment/entrenchment tradeoff. In Vietnamese markets, the pattern may differ because the dominant controlling shareholder is often the state, whose objective function includes non-value-maximizing goals (employment, regional development, strategic sector control).\n\n## Linking Corporate Decisions to Returns\n\n### Investment-Based Anomalies\n\nThe asset pricing literature has documented that corporate investment decisions predict cross-sectional return differences (i.e., the \"investment anomalies\"). The theoretical foundation is the $q$-theory of investment applied to asset pricing [@cochrane1991production; @liu2009investment]: firms invest more when the discount rate on their projects is lower. High investment therefore signals low expected returns.\n\n**The investment effect.** @titman2004capital and @cooper2008asset document that firms with high asset growth earn lower subsequent returns. The asset growth variable is:\n\n$$\n\\text{AG}_{i,t} = \\frac{A_{i,t} - A_{i,t-1}}{A_{i,t-1}}\n$$ {#eq-asset-growth}\n\n**The investment-to-assets effect.** @fama2006profitability and @hou2015digesting show that capital expenditure scaled by assets negatively predicts returns.\n\n**The profitability effect.** @novy2013other shows that gross profitability (revenue minus COGS, scaled by assets) positively predicts returns. This is consistent with $q$-theory: controlling for investment, more profitable firms must have higher discount rates (otherwise they would invest more).\n\n::: {#investment-anomalies .cell execution_count=37}\n``` {.python .cell-code}\n# Construct anomaly variables\nanomaly = panel_fc.copy().sort_values([\"ticker\", \"year\"])\n\n# Asset growth\nanomaly[\"asset_growth\"] = (\n    (anomaly[\"total_assets\"] - anomaly[\"lag_assets\"]) /\n    anomaly[\"lag_assets\"]\n)\n\n# Investment-to-assets\nanomaly[\"inv_to_assets\"] = anomaly[\"capex\"] / anomaly[\"lag_assets\"]\n\n# Gross profitability\nanomaly[\"gross_profit\"] = (\n    (anomaly[\"revenue\"] - anomaly[\"cogs\"]) / anomaly[\"total_assets\"]\n)\n\n# ROE\nanomaly[\"roe\"] = anomaly[\"net_income\"] / anomaly[\"book_equity\"]\n\n# Winsorize\nfor col in [\"asset_growth\", \"inv_to_assets\", \"gross_profit\", \"roe\"]:\n    anomaly[col] = winsorize(anomaly[col])\n```\n:::\n\n\n::: {#portfolio-sorts-investment .cell execution_count=38}\n``` {.python .cell-code}\n# Portfolio sorts: quintiles on asset growth\n# Merge with monthly returns (using June rebalancing)\nanomaly_june = anomaly.copy()\nanomaly_june[\"formation_year\"] = anomaly_june[\"year\"]\n\n# Create quintile assignments\nanomaly_june[\"ag_quintile\"] = anomaly_june.groupby(\"year\")[\n    \"asset_growth\"\n].transform(lambda x: pd.qcut(x, 5, labels=[1, 2, 3, 4, 5],\n                                duplicates=\"drop\"))\n\n# Merge with forward returns\nmonthly_with_signal = monthly_returns.copy()\nmonthly_with_signal[\"formation_year\"] = np.where(\n    monthly_with_signal[\"date\"].dt.month >= 7,\n    monthly_with_signal[\"date\"].dt.year,\n    monthly_with_signal[\"date\"].dt.year - 1\n)\n\nportfolios = monthly_with_signal.merge(\n    anomaly_june[[\"ticker\", \"formation_year\", \"ag_quintile\",\n                   \"asset_growth\", \"gross_profit\"]],\n    on=[\"ticker\", \"formation_year\"],\n    how=\"inner\"\n)\n\n# Compute equal-weighted quintile returns\nag_returns = (\n    portfolios.groupby([\"date\", \"ag_quintile\"])\n    .agg(port_ret=(\"ret\", \"mean\"))\n    .reset_index()\n)\n\n# Long-short: Q1 (low growth) - Q5 (high growth)\nag_wide = ag_returns.pivot(\n    index=\"date\", columns=\"ag_quintile\", values=\"port_ret\"\n)\nag_wide[\"L-S\"] = ag_wide[1] - ag_wide[5]\n```\n:::\n\n\n::: {#tbl-investment-anomaly .cell tbl-cap='Asset Growth Quintile Portfolio Returns' execution_count=39}\n``` {.python .cell-code}\nquintile_summary = ag_wide.describe().T[[\"mean\", \"std\"]].copy()\nquintile_summary[\"mean_ann\"] = quintile_summary[\"mean\"] * 12\nquintile_summary[\"std_ann\"] = quintile_summary[\"std\"] * np.sqrt(12)\nquintile_summary[\"sharpe\"] = (\n    quintile_summary[\"mean_ann\"] / quintile_summary[\"std_ann\"]\n)\n\n# t-statistics\nfor col in ag_wide.columns:\n    t_stat = ag_wide[col].mean() / (ag_wide[col].std() / np.sqrt(len(ag_wide)))\n    quintile_summary.loc[col, \"t_stat\"] = t_stat\n\nquintile_summary = quintile_summary[\n    [\"mean_ann\", \"std_ann\", \"sharpe\", \"t_stat\"]\n].round(4)\n\nquintile_summary.columns = [\n    \"Ann. Return\", \"Ann. Vol\", \"Sharpe Ratio\", \"t-stat\"\n]\nquintile_summary\n```\n:::\n\n\n::: {#fig-ag-cumulative .cell execution_count=40}\n``` {.python .cell-code}\ncumret = ag_wide[[\"L-S\"]].copy()\ncumret.columns = [\"Long-Short\"]\ncumret = cumret.dropna()\ncumret[\"cumulative\"] = (1 + cumret[\"Long-Short\"]).cumprod()\ncumret = cumret.reset_index()\n\n(\n    p9.ggplot(cumret, p9.aes(x=\"date\", y=\"cumulative\"))\n    + p9.geom_line(color=\"#2E5090\", size=0.8)\n    + p9.geom_hline(yintercept=1, linetype=\"dashed\", color=\"gray\")\n    + p9.labs(\n        x=\"\",\n        y=\"Cumulative Return (Growth of $1)\",\n        title=\"Investment Anomaly: Low – High Asset Growth\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(12, 5))\n)\n```\n:::\n\n\n### Financing Anomalies\n\nFirms' financing decisions also predict returns. @pontiff2008share document that net stock issuance negatively predicts returns: firms that issue equity earn lower future returns, while firms that repurchase shares earn higher returns. This is consistent with both managerial market timing and an issuance-based risk factor.\n\nThe net stock issuance variable is typically measured as:\n\n$$\n\\text{NSI}_{i,t} = \\ln\\left(\\frac{\\text{Split-Adjusted Shares}_{i,t}}{\\text{Split-Adjusted Shares}_{i,t-1}}\\right)\n$$ {#eq-nsi}\n\nPositive NSI indicates net equity issuance; negative NSI indicates net repurchases.\n\n::: {#financing-anomaly .cell execution_count=41}\n``` {.python .cell-code}\n# Net Stock Issuance\nfin_anomaly = anomaly.copy()\nfin_anomaly[\"lag_shares\"] = fin_anomaly.groupby(\n    \"ticker\"\n)[\"shares_outstanding\"].shift(1)\n\nfin_anomaly[\"nsi\"] = np.log(\n    fin_anomaly[\"shares_outstanding\"] / fin_anomaly[\"lag_shares\"]\n)\nfin_anomaly[\"nsi\"] = winsorize(fin_anomaly[\"nsi\"])\n\n# Net debt issuance (change in total debt / assets)\nfin_anomaly[\"ndi\"] = (\n    (fin_anomaly[\"total_debt\"] -\n     fin_anomaly.groupby(\"ticker\")[\"total_debt\"].shift(1)) /\n    fin_anomaly[\"lag_assets\"]\n)\nfin_anomaly[\"ndi\"] = winsorize(fin_anomaly[\"ndi\"])\n\n# Portfolio sorts on NSI\nfin_anomaly[\"nsi_quintile\"] = fin_anomaly.groupby(\"year\")[\n    \"nsi\"\n].transform(lambda x: pd.qcut(x, 5, labels=[1, 2, 3, 4, 5],\n                                duplicates=\"drop\"))\n\nport_nsi = monthly_with_signal.merge(\n    fin_anomaly[[\"ticker\", \"formation_year\", \"nsi_quintile\"]],\n    on=[\"ticker\", \"formation_year\"],\n    how=\"inner\"\n)\n\nnsi_returns = (\n    port_nsi.groupby([\"date\", \"nsi_quintile\"])\n    .agg(port_ret=(\"ret\", \"mean\"))\n    .reset_index()\n)\n\nnsi_wide = nsi_returns.pivot(\n    index=\"date\", columns=\"nsi_quintile\", values=\"port_ret\"\n)\nnsi_wide[\"L-S\"] = nsi_wide[1] - nsi_wide[5]\n```\n:::\n\n\n::: {#tbl-nsi-anomaly .cell tbl-cap='Net Stock Issuance Quintile Portfolio Returns' execution_count=42}\n``` {.python .cell-code}\nnsi_summary = nsi_wide.describe().T[[\"mean\", \"std\"]].copy()\nnsi_summary[\"mean_ann\"] = nsi_summary[\"mean\"] * 12\nnsi_summary[\"sharpe\"] = (\n    nsi_summary[\"mean_ann\"] /\n    (nsi_summary[\"std\"] * np.sqrt(12))\n)\n\nfor col in nsi_wide.columns:\n    t_stat = nsi_wide[col].mean() / (\n        nsi_wide[col].std() / np.sqrt(len(nsi_wide))\n    )\n    nsi_summary.loc[col, \"t_stat\"] = t_stat\n\nnsi_summary = nsi_summary[[\"mean_ann\", \"sharpe\", \"t_stat\"]].round(4)\nnsi_summary.columns = [\"Ann. Return\", \"Sharpe\", \"t-stat\"]\nnsi_summary\n```\n:::\n\n\n### Valuation Implications: Fama-French Factor Regressions\n\nWe evaluate whether the investment and financing anomalies represent compensation for systematic risk by regressing the long-short portfolios on standard factor models:\n\n$$\nR_{p,t} - R_{f,t} = \\alpha + \\beta_{\\text{MKT}} \\text{MKT}_t + \\beta_{\\text{SMB}} \\text{SMB}_t + \\beta_{\\text{HML}} \\text{HML}_t + \\varepsilon_t\n$$ {#eq-factor-regression}\n\nSignificant positive $\\alpha$ after controlling for known risk factors would indicate that the anomaly is not explained by size and value exposures.\n\n::: {#factor-regressions .cell execution_count=43}\n``` {.python .cell-code}\n# Merge long-short returns with factor data\nfactor_data = factors.set_index(\"date\")\n\n# Asset growth anomaly alpha\nag_ls = ag_wide[[\"L-S\"]].dropna().rename(columns={\"L-S\": \"excess_ret\"})\nag_merged = ag_ls.join(factor_data[[\"mkt_rf\", \"smb\", \"hml\"]], how=\"inner\")\n\nmodel_ag_ff3 = sm.OLS(\n    ag_merged[\"excess_ret\"],\n    sm.add_constant(ag_merged[[\"mkt_rf\", \"smb\", \"hml\"]])\n).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 6})\n\n# NSI anomaly alpha\nnsi_ls = nsi_wide[[\"L-S\"]].dropna().rename(columns={\"L-S\": \"excess_ret\"})\nnsi_merged = nsi_ls.join(factor_data[[\"mkt_rf\", \"smb\", \"hml\"]], how=\"inner\")\n\nmodel_nsi_ff3 = sm.OLS(\n    nsi_merged[\"excess_ret\"],\n    sm.add_constant(nsi_merged[[\"mkt_rf\", \"smb\", \"hml\"]])\n).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 6})\n```\n:::\n\n\n::: {#tbl-factor-alphas .cell tbl-cap='Fama-French Three-Factor Alphas for Corporate Decision Anomalies' execution_count=44}\n``` {.python .cell-code}\nalpha_table = pd.DataFrame({\n    \"Asset Growth L-S\": {\n        \"Alpha (monthly)\": f\"{model_ag_ff3.params['const']:.4f}\",\n        \"  t-stat\": f\"{model_ag_ff3.tvalues['const']:.3f}\",\n        \"MKT\": f\"{model_ag_ff3.params['mkt_rf']:.4f}\",\n        \"SMB\": f\"{model_ag_ff3.params['smb']:.4f}\",\n        \"HML\": f\"{model_ag_ff3.params['hml']:.4f}\",\n        \"R²\": f\"{model_ag_ff3.rsquared:.4f}\"\n    },\n    \"Net Issuance L-S\": {\n        \"Alpha (monthly)\": f\"{model_nsi_ff3.params['const']:.4f}\",\n        \"  t-stat\": f\"{model_nsi_ff3.tvalues['const']:.3f}\",\n        \"MKT\": f\"{model_nsi_ff3.params['mkt_rf']:.4f}\",\n        \"SMB\": f\"{model_nsi_ff3.params['smb']:.4f}\",\n        \"HML\": f\"{model_nsi_ff3.params['hml']:.4f}\",\n        \"R²\": f\"{model_nsi_ff3.rsquared:.4f}\"\n    }\n})\nalpha_table\n```\n:::\n\n\n::: {#fig-anomaly-comparison .cell execution_count=45}\n``` {.python .cell-code}\n# Combine asset growth and NSI long-short for comparison\ncombined = pd.DataFrame({\n    \"Asset Growth\": ag_wide[\"L-S\"],\n    \"Net Issuance\": nsi_wide[\"L-S\"]\n}).dropna()\n\ncombined_cum = (1 + combined).cumprod().reset_index()\ncombined_long = combined_cum.melt(\n    id_vars=\"date\",\n    var_name=\"Anomaly\",\n    value_name=\"Cumulative Return\"\n)\n\n(\n    p9.ggplot(combined_long, p9.aes(\n        x=\"date\", y=\"Cumulative Return\", color=\"Anomaly\"\n    ))\n    + p9.geom_line(size=0.8)\n    + p9.geom_hline(yintercept=1, linetype=\"dashed\", color=\"gray\")\n    + p9.scale_color_manual(values=[\"#2E5090\", \"#C0392B\"])\n    + p9.labs(\n        x=\"\",\n        y=\"Cumulative Return (Growth of $1)\",\n        title=\"Investment vs. Financing Anomalies: Long-Short Portfolios\"\n    )\n    + p9.theme_minimal()\n    + p9.theme(figure_size=(12, 5), legend_position=\"top\")\n)\n```\n:::\n\n\n<!-- ## Exercises\n\n1.  **Measurement Error Quantification.** Implement the full @erickson2012treating fifth-order cumulant estimator (using both third and fifth moments) for the investment-$Q$ regression. Compare the corrected $\\beta_1$ with the OLS estimate. What fraction of the OLS attenuation is attributable to measurement error in $Q$? Does the correction change the significance of the cash flow coefficient?\n\n2.  **Financial Constraints and Investment Efficiency.** Construct the @hadlock2010new SA index for all Vietnamese firms. Sort firms into SA quintiles and estimate separate investment-$Q$ regressions for each quintile. Plot the $Q$ coefficient across quintiles. Is the investment-$Q$ sensitivity monotonically increasing in the SA index (as the constraint hypothesis predicts), or does the Kaplan-Zingales monotonicity failure replicate?\n\n3.  **Speed of Leverage Adjustment.** Estimate the target adjustment model: $\\text{Lev}_{i,t} - \\text{Lev}_{i,t-1} = \\lambda(\\text{Lev}_{i,t}^* - \\text{Lev}_{i,t-1}) + \\varepsilon_{i,t}$, where $\\text{Lev}^*$ is the target leverage predicted by the Frank-Goyal determinants. Estimate $\\lambda$ for the full sample and separately for SOEs versus private firms. Does state ownership accelerate or retard adjustment to target leverage? Use a system GMM estimator to address the Nickell bias from the lagged dependent variable in short panels.\n\n4.  **Tunneling and Related-Party Transactions.** If DataCore.vn provides related-party transaction (RPT) data, estimate the effect of RPT intensity on firm value (Tobin's $Q$) and operating performance (ROA), controlling for ownership concentration, governance variables, and firm fundamentals. Use the @jiang2010tunneling methodology to distinguish potentially expropriative RPTs from benign ones. Does the RPT-value relationship depend on the identity of the controlling shareholder (state vs. family vs. foreign)?\n\n5.  **Dividend Tax Clientele.** Vietnam implemented a 5% dividend tax in 2014. Using a difference-in-differences design around this regulatory change, test whether the tax altered payout composition (dividends vs. share repurchases vs. retained earnings). Control for firm characteristics and use a matched sample of high- vs. low-dividend firms to estimate the treatment effect on total payout and payout mix.\n\n6.  **Investment Factor Construction.** Construct a Vietnamese investment factor (CMA, \"Conservative Minus Aggressive\") following the @FamaFrench2015 methodology. Sort firms into 2×3 portfolios on size and asset growth, compute value-weighted returns, and form the long-short factor. Test whether the factor is priced in the cross-section using Fama-MacBeth regressions and whether it subsumes the asset growth anomaly documented in this chapter. Compare the factor's performance with the profitability factor (RMW). -->\n\n## Summary\n\nThis chapter implemented the core econometric toolkit of empirical corporate finance for Vietnamese listed firms. The estimators span four interconnected domains: investment decisions (investment-$Q$ regressions and their measurement-error-corrected variants), financing decisions (capital structure determinants, pecking order tests, and market timing measures), payout policy (Lintner smoothing, repurchase models, and dividend signaling tests), and agency costs (ownership-value relationships, free cash flow measures, and governance variables).\n\nSeveral findings deserve emphasis. The investment-$Q$ relationship in Vietnam is attenuated relative to developed-market benchmarks, reflecting both the severity of measurement error in $Q$ (thin trading, price limits, volatile inflation) and the prevalence of non-market-driven investment by SOEs. Cash flow remains a significant predictor of investment across constraint classifications, though the FHP-KZ debate about interpretation applies with full force. Capital structure is strongly predicted by profitability (negatively, consistent with the pecking order) and tangibility (positively, consistent with trade-off theory). Dividend smoothing is pronounced, but the smoothing parameter differs systematically between SOEs and private firms, reflecting the distinct institutional forces governing each group's payout policy.\n\nThe chapter also linked corporate decisions to asset returns through portfolio sorts on asset growth and net stock issuance. Whether these anomalies survive risk adjustment and persist out of sample in Vietnamese markets is an important open question for future research.\n\n",
    "supporting": [
      "67_corporate_finance_estimators_files/figure-pdf"
    ],
    "filters": []
  }
}