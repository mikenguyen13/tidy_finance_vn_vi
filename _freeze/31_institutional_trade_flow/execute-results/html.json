{
  "hash": "2cc1c52df2c5b49eb119ee61386b67de",
  "result": {
    "engine": "jupyter",
    "markdown": "# Institutional Trades, Flows, and Turnover Ratios\n\n\n\nInstitutional investors play a pivotal role in price discovery, corporate governance, and market liquidity. Understanding *how* institutions trade and *how much* they trade provides insights into both asset pricing dynamics and the real effects of institutional monitoring. The seminal work of @grinblatt1995momentum on mutual fund momentum trading, @wermers2000mutual on fund performance decomposition, and @yan2008liquidity on the relationship between turnover and future returns all rely on accurately measured institutional trades, flows, and turnover.\n\nIn the United States, this research is enabled by the mandatory quarterly 13F filing system administered by the Securities and Exchange Commission (SEC). Every institutional investment manager with at least \\$100 million in qualifying assets must disclose their equity holdings within 45 days of each calendar quarter end. The Thomson-Reuters (now Refinitiv) 13F database, accessible through WRDS, provides the canonical data infrastructure for this literature.\n\nVietnam's equity market presents a fundamentally different institutional landscape. This chapter adapts the core methodology for the Vietnamese context, addressing five critical differences:\n\n1.  **Disclosure regime.** Vietnam has no 13F-equivalent mandatory quarterly filing. Ownership disclosure is a patchwork of event-driven reports (threshold crossings at 5%, 10%, etc.), annual/semi-annual reports with shareholder registers, and daily foreign ownership tracking by exchanges.\n\n2.  **Corporate actions.** Vietnamese firms issue stock dividends and bonus shares at extremely high rates compared to US firms. A firm might issue 20-30% bonus shares in a single year, fundamentally altering the share count. Share adjustment is therefore critical and nontrivial.\n\n3.  **Foreign ownership limits (FOLs).** Binding foreign ownership ceiling, typically 49% for most sectors, 30% for banking, and 0% for certain restricted sectors, create a unique institutional constraint. When a stock approaches its FOL, foreign buying becomes mechanically restricted, distorting standard trade inference.\n\n4.  **State ownership.** The Vietnamese government retains significant ownership in many listed firms through the State Capital Investment Corporation (SCIC) and other state entities. This creates a distinct ownership category not present in the US 13F data.\n\n5.  **Market microstructure.** Daily price limits ($\\pm 7\\%$ on HOSE, $\\pm 10\\%$ on HNX, $\\pm 15\\%$ on UPCOM), T+2 settlement, and the absence of short-selling all affect how institutional trades translate into market outcomes.\n\n## Measuring Institutional Ownership and Trading\n\nThe measurement of institutional ownership and trading activity has been a central concern in empirical finance since @gompers2003corporate documented the rise of institutional investors. The approach relies on comparing holdings snapshots across consecutive reporting periods to infer trades. If manager $j$ holds $h_{j,i,t}$ shares of stock $i$ at time $t$, then the inferred trade is:\n\n$$\n\\Delta h_{j,i,t} = h_{j,i,t} - h_{j,i,t-1}\n$$ {#eq-trade-simple}\n\nwhere $\\Delta h_{j,i,t} > 0$ indicates a buy and $\\Delta h_{j,i,t} < 0$ indicates a sale. This simple differencing approach requires that holdings are observed at regular intervals (e.g., quarterly), share counts are adjusted for corporate actions between reporting dates, and entry and exit from the dataset are handled appropriately.\n\n@chen2000value introduced the concept of ownership *breadth* (i.e., the number of institutions holding a stock) and showed that changes in breadth predict future returns. @sias2004institutional decomposed institutional demand into a herding component and an information component. @yan2008liquidity linked fund turnover to information-based trading and documented that high-turnover funds outperform, challenging the view that turnover reflects noise trading.\n\n## Trade Classification\n\n@tbl-trade-types shows four categories of trades:\n\n| Code | Type             | Description                            |\n|:-----|:-----------------|:---------------------------------------|\n| $+1$ | Initiating Buy   | Manager enters a new position          |\n| $+2$ | Incremental Buy  | Manager increases an existing position |\n| $-1$ | Terminating Sale | Manager completely exits a position    |\n| $-2$ | Regular Sale     | Manager reduces an existing position   |\n\n: Trade Classification Taxonomy {#tbl-trade-types}\n\nThis classification is informative because initiating buys and terminating sales represent discrete portfolio decisions with different information content from marginal position adjustments [@alexander2007does].\n\n## Turnover Measures\n\nThree standard turnover definitions have been used in the literature:\n\n**Carhart (1997) Turnover.** The minimum of aggregate buys and sales, normalized by average assets:\n\n$$\n\\text{Turnover}^{C}_{j,t} = \\frac{\\min\\left(\\sum_i B_{j,i,t},\\, \\sum_i S_{j,i,t}\\right)}\n{\\frac{1}{2}\\left(A_{j,t} + A_{j,t-1}\\right)}\n$$ {#eq-turnover-carhart}\n\nwhere $B_{j,i,t}$ and $S_{j,i,t}$ are the dollar values of buys and sales of stock $i$ by manager $j$ in quarter $t$, and $A_{j,t}$ is total portfolio assets [@Carhart1997].\n\n**Flow-Adjusted Turnover.** Adds back the absolute value of net flows to account for flow-driven trading:\n\n$$\n\\text{Turnover}^{F}_{j,t} = \\frac{\\min\\left(\\sum_i B_{j,i,t},\\, \\sum_i S_{j,i,t}\\right) + |\\text{NetFlow}_{j,t}|}\n{A_{j,t-1}}\n$$ {#eq-turnover-flow}\n\n**Symmetric Turnover.** Uses the sum of buys and sales minus the absolute net flow:\n\n$$\n\\text{Turnover}^{S}_{j,t} = \\frac{\\sum_i B_{j,i,t} + \\sum_i S_{j,i,t} - |\\text{NetFlow}_{j,t}|}\n{A_{j,t-1}}\n$$ {#eq-turnover-symmetric}\n\nThe relationship between these measures depends on the correlation between discretionary trading and flow-induced trading [@pastor2003liquidity].\n\n## Institutional Ownership in Emerging Markets\n\nThe emerging markets literature has documented several stylized facts about institutional ownership that differ from developed market findings. @aggarwal2011does documented that foreign institutional ownership improves corporate governance in emerging markets. For Vietnam specifically, @phung2016ownership examined the relationship between ownership structure and firm performance, while @vo2015foreign studied the impact of foreign ownership on stock market liquidity.\n\n## Net Flows and Performance Attribution\n\nNet flows measure the dollar amount of new money entering or leaving a fund:\n\n$$\n\\text{NetFlow}_{j,t} = A_{j,t} - A_{j,t-1}(1 + R_{j,t}^p)\n$$ {#eq-netflow}\n\nwhere $R_{j,t}^p$ is the portfolio return. This decomposition, due to @sirri1998costly, separates changes in fund assets into investment returns and investor capital allocation decisions. @coval2007asset showed that flow-driven trades create price pressure, with fire sales by funds experiencing redemptions generating significant negative abnormal returns.\n\n# Data Infrastructure {#sec-data}\n\n@tbl-datacore-datasets summarizes the datasets used in this chapter.\n\n| Dataset | Content | Frequency | Key Variables |\n|:-----------------|:-----------------|:-----------------|:------------------|\n| Stock Prices | Daily/monthly OHLCV | Daily | `ticker`, `date`, `close`, `adjusted_close`, `volume`, `shares_outstanding` |\n| Ownership Structure | Shareholder composition | Quarterly/Annual | `ticker`, `date`, `shareholder_name`, `shares_held`, `pct`, `type` |\n| Major Shareholders | Holders $\\geq$ 5% | Event-driven | `ticker`, `date`, `shareholder_name`, `shares`, `is_foreign`, `is_state` |\n| Corporate Actions | Splits, dividends, bonus | Event | `ticker`, `ex_date`, `action_type`, `ratio` |\n| Company Profile | Sector, exchange, FOL | Static/Annual | `ticker`, `exchange`, `industry`, `listing_date`, `fol_limit` |\n| Foreign Ownership | Daily foreign tracking | Daily | `ticker`, `date`, `foreign_shares`, `foreign_pct`, `fol_limit` |\n| Fund Holdings | Fund portfolio snapshots | Semi-annual | `fund_name`, `report_date`, `ticker`, `shares_held`, `market_value` |\n\n: DataCore.vn Datasets Used in This Chapter {#tbl-datacore-datasets}\n\n## Data Reader Class {#sec-reader}\n\nWe begin by defining a unified data reader that handles file loading, date parsing, and basic validation:\n\n::: {#datacore-reader .cell execution_count=2}\n``` {.python .cell-code code-summary=\"DataCoreReader: Unified Data Access Layer\"}\n@dataclass\nclass DataCoreReader:\n    \"\"\"\n    Unified reader for DataCore.vn datasets stored locally.\n    \n    Supports Parquet (recommended) and CSV formats. Implements\n    lazy loading with caching to minimize memory footprint.\n    \n    Parameters\n    ----------\n    data_dir : str or Path\n        Directory containing DataCore.vn data files.\n    file_format : str\n        File format: 'parquet' or 'csv'.\n    \n    Examples\n    --------\n    >>> dc = DataCoreReader('/data/datacore', file_format='parquet')\n    >>> prices = dc.prices\n    >>> ownership = dc.ownership\n    \"\"\"\n    data_dir: Path\n    file_format: str = 'parquet'\n    _cache: Dict[str, pd.DataFrame] = field(\n        default_factory=dict, repr=False\n    )\n    \n    FILE_MAP: Dict[str, str] = field(default_factory=lambda: {\n        'prices': 'stock_prices',\n        'ownership': 'ownership_structure',\n        'major_shareholders': 'major_shareholders',\n        'corporate_actions': 'corporate_actions',\n        'company_profile': 'company_profile',\n        'financials': 'financial_statements',\n        'foreign_ownership': 'foreign_ownership',\n        'fund_holdings': 'fund_holdings',\n    }, repr=False)\n    \n    def __post_init__(self):\n        self.data_dir = Path(self.data_dir)\n        if not self.data_dir.exists():\n            raise FileNotFoundError(\n                f\"Data directory not found: {self.data_dir}\"\n            )\n    \n    def _read(self, key: str) -> pd.DataFrame:\n        \"\"\"Read and cache a dataset with automatic date parsing.\"\"\"\n        if key in self._cache:\n            return self._cache[key]\n        \n        fname = self.FILE_MAP.get(key, key)\n        filepath = self.data_dir / f\"{fname}.{self.file_format}\"\n        \n        if not filepath.exists():\n            raise FileNotFoundError(\n                f\"Dataset not found: {filepath}\\n\"\n                f\"Available: \"\n                f\"{list(self.data_dir.glob(f'*.{self.file_format}'))}\"\n            )\n        \n        if self.file_format == 'parquet':\n            df = pd.read_parquet(filepath)\n        else:\n            df = pd.read_csv(filepath, parse_dates=True)\n        \n        # Auto-detect and parse date columns\n        date_cols = [\n            'date', 'ex_date', 'record_date', 'period',\n            'report_date', 'listing_date'\n        ]\n        for col in df.columns:\n            if col.lower() in date_cols or 'date' in col.lower():\n                try:\n                    df[col] = pd.to_datetime(df[col])\n                except (ValueError, TypeError):\n                    pass\n        \n        self._cache[key] = df\n        print(f\"  Loaded {key}: {len(df):,} rows x {len(df.columns)} cols\")\n        return df\n    \n    @property\n    def prices(self) -> pd.DataFrame:\n        return self._read('prices')\n    \n    @property\n    def ownership(self) -> pd.DataFrame:\n        return self._read('ownership')\n    \n    @property\n    def major_shareholders(self) -> pd.DataFrame:\n        return self._read('major_shareholders')\n    \n    @property\n    def corporate_actions(self) -> pd.DataFrame:\n        return self._read('corporate_actions')\n    \n    @property\n    def company_profile(self) -> pd.DataFrame:\n        return self._read('company_profile')\n    \n    @property\n    def foreign_ownership(self) -> pd.DataFrame:\n        return self._read('foreign_ownership')\n    \n    @property\n    def fund_holdings(self) -> pd.DataFrame:\n        return self._read('fund_holdings')\n    \n    def clear_cache(self):\n        n = len(self._cache)\n        self._cache.clear()\n        print(f\"  Cleared {n} cached datasets\")\n\n# Initialize:\n# dc = DataCoreReader('/path/to/datacore_data', file_format='parquet')\n```\n:::\n\n\n# Stock Price and Return Processing {#sec-crsp}\n\nThe first step processes stock data to obtain adjusted prices, shares outstanding, and quarterly returns.\n\n## Price Data Extraction and Adjustment {#sec-price-adj}\n\nVietnamese stock data requires careful adjustment for frequent corporate actions. Unlike the US where CRSP provides a cumulative adjustment factor (`cfacpr`, `cfacshr`), in Vietnam we must construct adjustment factors from the corporate actions history.\n\n::: callout-note\n## Vietnamese Corporate Actions\n\nVietnamese firms commonly execute the following corporate actions, each requiring share count and/or price adjustment:\n\n-   **Stock dividend** (*co tuc bang co phieu*): e.g., 20% stock dividend means 100 shares become 120 shares\n-   **Bonus shares** (*co phieu thuong*): free shares distributed from retained earnings\n-   **Rights issue** (*phat hanh quyen mua*): right to buy new shares at a discount\n-   **Stock split/reverse split** (*chia/gop co phieu*): rare but occasionally used\n:::\n\n::: {#corporate-action-adjustment .cell execution_count=3}\n``` {.python .cell-code code-summary=\"Corporate Action Adjustment Factor Construction\"}\ndef build_adjustment_factors(\n    corporate_actions: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"\n    Construct cumulative share adjustment factors from corporate actions.\n    \n    This is the Vietnamese equivalent of CRSP's cfacshr factor. For each\n    ticker, we compute a cumulative product of adjustment ratios from\n    corporate actions, working forward in time.\n    \n    The adjustment factor at date t converts historical share counts to\n    be comparable with current (post-action) share counts:\n    \n        shares_adjusted_t = shares_raw_t * cfacshr_t\n    \n    Parameters\n    ----------\n    corporate_actions : pd.DataFrame\n        Corporate actions with columns: ticker, ex_date, action_type,\n        ratio. The ratio field represents:\n        - Stock dividend 20%: ratio = 1.20\n        - 2:1 stock split: ratio = 2.00\n        - Bonus shares 10%: ratio = 1.10\n    \n    Returns\n    -------\n    pd.DataFrame\n        Adjustment factors: ticker, ex_date, cfacshr (cumulative).\n    \"\"\"\n    share_actions = corporate_actions[\n        corporate_actions['action_type'].isin([\n            'stock_dividend', 'bonus_shares', 'stock_split',\n            'reverse_split', 'rights_issue'\n        ])\n    ].copy()\n    \n    if share_actions.empty:\n        return pd.DataFrame(columns=['ticker', 'ex_date', 'cfacshr'])\n    \n    share_actions = share_actions.sort_values(['ticker', 'ex_date'])\n    \n    share_actions['cfacshr'] = (\n        share_actions\n        .groupby('ticker')['ratio']\n        .cumprod()\n    )\n    \n    return share_actions[['ticker', 'ex_date', 'cfacshr']].reset_index(\n        drop=True\n    )\n\n\ndef get_cfacshr_at_date(\n    ticker: str,\n    date: pd.Timestamp,\n    adj_factors: pd.DataFrame,\n) -> float:\n    \"\"\"\n    Look up the cumulative share adjustment factor for a given\n    ticker and date. Returns 1.0 if no corporate actions occurred.\n    \"\"\"\n    mask = (\n        (adj_factors['ticker'] == ticker) &\n        (adj_factors['ex_date'] <= date)\n    )\n    subset = adj_factors.loc[mask]\n    \n    if subset.empty:\n        return 1.0\n    return subset.iloc[-1]['cfacshr']\n\n\ndef adjust_shares_between_dates(\n    shares: float,\n    ticker: str,\n    date_from: pd.Timestamp,\n    date_to: pd.Timestamp,\n    adj_factors: pd.DataFrame,\n) -> float:\n    \"\"\"\n    Adjust a share count observed at date_from to be comparable\n    with shares observed at date_to, accounting for all intervening\n    corporate actions.\n    \n    Example\n    -------\n    >>> # Investor held 1000 shares on 2023-01-01\n    >>> # A 20% stock dividend occurred on 2023-03-15\n    >>> adjust_shares_between_dates(\n    ...     1000, 'VNM',\n    ...     pd.Timestamp('2023-01-01'),\n    ...     pd.Timestamp('2023-06-30'), adj_factors\n    ... )\n    1200.0\n    \"\"\"\n    factor_from = get_cfacshr_at_date(ticker, date_from, adj_factors)\n    factor_to = get_cfacshr_at_date(ticker, date_to, adj_factors)\n    relative_factor = factor_to / factor_from\n    return shares * relative_factor\n```\n:::\n\n\n## Monthly and Quarterly Price Processing {#sec-price-processing}\n\n::: {#price-processing .cell execution_count=4}\n``` {.python .cell-code code-summary=\"Step 1: Price Data Processing\"}\ndef process_prices(\n    prices: pd.DataFrame,\n    adj_factors: pd.DataFrame,\n    begdate: str = '2010-01-01',\n    enddate: str = '2024-12-31',\n) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Process raw DataCore.vn price data into analysis-ready format.\n    \n    Block logic:\n    1. Filter to date range\n    2. Compute adjusted prices and shares outstanding\n    3. Compute quarterly compounded returns\n    4. Create forward quarterly returns (shifted one quarter)\n    \n    Parameters\n    ----------\n    prices : pd.DataFrame\n        Raw price data with: ticker, date, close, adjusted_close,\n        volume, shares_outstanding.\n    adj_factors : pd.DataFrame\n        Corporate action adjustment factors.\n    begdate, enddate : str\n        Sample period boundaries.\n    \n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        (price_quarterly, qret): quarter-end observations with\n        adjusted price, total shares, and forward quarterly return.\n    \"\"\"\n    price = prices[\n        (prices['date'] >= begdate) & (prices['date'] <= enddate)\n    ].copy()\n    \n    # Month-end and quarter-end dates\n    price['mdate'] = price['date'] + pd.offsets.MonthEnd(0)\n    price['qdate'] = price['date'] + pd.offsets.QuarterEnd(0)\n    \n    # Adjusted price\n    if 'adjusted_close' in price.columns:\n        price['p'] = price['adjusted_close']\n    else:\n        price['p'] = price['close']\n    \n    # Total shares outstanding\n    price['tso'] = price['shares_outstanding']\n    \n    # Market capitalization (millions VND)\n    price['mcap'] = price['p'] * price['tso'] / 1e6\n    \n    # Filter out zero shares\n    price = price[price['tso'] > 0].copy()\n    \n    # Compute daily returns if not present\n    if 'ret' not in price.columns:\n        price = price.sort_values(['ticker', 'date'])\n        price['ret'] = price.groupby('ticker')['p'].pct_change()\n    \n    price['ret'] = price['ret'].fillna(0)\n    price['logret'] = np.log(1 + price['ret'])\n    \n    # ---- Quarterly compounded returns ----\n    qret = (\n        price\n        .groupby(['ticker', 'qdate'])['logret']\n        .sum()\n        .reset_index()\n    )\n    qret['qret'] = np.exp(qret['logret']) - 1\n    \n    # Shift qdate back one quarter: make qret a *forward* return\n    qret['qdate'] = qret['qdate'] + pd.offsets.QuarterEnd(-1)\n    qret = qret.drop(columns=['logret'])\n    \n    # ---- Quarter-end observations ----\n    price_q = price[price['qdate'] == price['mdate']].copy()\n    price_q = price_q[['qdate', 'ticker', 'p', 'tso', 'mcap']].copy()\n    \n    # Merge forward quarterly return\n    price_q = price_q.merge(qret, on=['ticker', 'qdate'], how='left')\n    \n    # Build cfacshr lookup at each quarter-end\n    price_q['cfacshr'] = price_q.apply(\n        lambda row: get_cfacshr_at_date(\n            row['ticker'], row['qdate'], adj_factors\n        ),\n        axis=1\n    )\n    \n    return price_q, qret\n```\n:::\n\n\n::: callout-tip\n## Performance Optimization\n\nThe `get_cfacshr_at_date` function uses a row-wise lookup which can be slow for large datasets. For production use with millions of rows, vectorize using `pd.merge_asof()`:\n\n``` python\nprice_q = pd.merge_asof(\n    price_q.sort_values('qdate'),\n    adj_factors.sort_values('ex_date'),\n    by='ticker',\n    left_on='qdate',\n    right_on='ex_date',\n    direction='backward'\n).fillna({'cfacshr': 1.0})\n```\n:::\n\nThe output is a quarterly panel of stock-level observations (\\@tbl-institutional-price-vars)\n\n| Variable  | Description                          |\n|:----------|:-------------------------------------|\n| `ticker`  | Stock ticker (e.g., VNM, VCB, FPT)   |\n| `qdate`   | Quarter-end date                     |\n| `p`       | Adjusted closing price (VND)         |\n| `tso`     | Total shares outstanding             |\n| `mcap`    | Market capitalization (millions VND) |\n| `qret`    | Forward quarterly compounded return  |\n| `cfacshr` | Cumulative share adjustment factor   |\n\n: Quarter-End Price Panel Variables {#tbl-institutional-price-vars}\n\n# Ownership Data Processing {#sec-ownership}\n\n## Ownership Taxonomy {#sec-taxonomy}\n\nWe define a classification system for Vietnamese shareholders that maps to the categories available in DataCore.vn:\n\n::: {#ownership-taxonomy .cell execution_count=5}\n``` {.python .cell-code code-summary=\"Vietnamese Ownership Type Classification\"}\nclass OwnershipType:\n    \"\"\"\n    Vietnamese ownership type classification.\n    \n    Vietnam's ownership structure is fundamentally different from the US:\n    \n    - **State** (Nha nuoc): SCIC, ministries, state-owned parents\n    - **Foreign Institutional** (To chuc nuoc ngoai): foreign funds,\n      ETFs, pension funds, insurance, sovereign wealth funds\n    - **Domestic Institutional** (To chuc trong nuoc): Vietnamese\n      securities companies, fund managers, banks, insurance\n    - **Individual** (Ca nhan): retail investors (domestic + foreign)\n    - **Treasury** (Co phieu quy): company repurchases\n    \"\"\"\n    \n    STATE = 'State'\n    FOREIGN_INST = 'Foreign Institutional'\n    DOMESTIC_INST = 'Domestic Institutional'\n    INDIVIDUAL = 'Individual'\n    TREASURY = 'Treasury'\n    \n    INSTITUTIONAL = [FOREIGN_INST, DOMESTIC_INST]\n    ALL_INSTITUTIONAL = [STATE, FOREIGN_INST, DOMESTIC_INST]\n    ALL_TYPES = [STATE, FOREIGN_INST, DOMESTIC_INST, INDIVIDUAL, TREASURY]\n    \n    STATE_KEYWORDS = [\n        'scic', 'state capital', 'bo', 'ubnd', 'tong cong ty',\n        'nha nuoc', 'state', 'government', \"people's committee\",\n        'ministry', 'vietnam national', 'vnpt', 'evn', 'pvn',\n    ]\n    \n    FOREIGN_KEYWORDS = [\n        'fund', 'investment', 'capital', 'asset management',\n        'securities', 'gic', 'templeton', 'dragon capital',\n        'vinacapital', 'mekong capital', 'kb securities',\n        'mirae asset', 'samsung', 'jp morgan', 'goldman',\n        'blackrock', 'vanguard', 'aberdeen', 'hsbc',\n    ]\n    \n    @classmethod\n    def classify(cls, row: pd.Series) -> str:\n        \"\"\"Classify based on explicit flags, then keyword fallback.\"\"\"\n        if pd.notna(row.get('is_state')) and row['is_state']:\n            return cls.STATE\n        if pd.notna(row.get('is_foreign')) and row['is_foreign']:\n            if pd.notna(row.get('is_institution')) and row['is_institution']:\n                return cls.FOREIGN_INST\n            return cls.INDIVIDUAL\n        if pd.notna(row.get('is_institution')) and row['is_institution']:\n            return cls.DOMESTIC_INST\n        \n        name = str(row.get('shareholder_name', '')).lower()\n        if any(kw in name for kw in cls.STATE_KEYWORDS):\n            return cls.STATE\n        if any(kw in name for kw in cls.FOREIGN_KEYWORDS):\n            return cls.FOREIGN_INST\n        \n        return cls.INDIVIDUAL\n```\n:::\n\n\n## Building the Holdings Panel {#sec-holdings-panel}\n\nWe construct the holdings panel (i.e., the Vietnamese equivalent of merging the 13F Type 1 and Type 3 datasets). The key steps are:\n\n1.  Identify the first available vintage for each shareholder-stock-report date combination.\n2.  Compute reporting gaps to flag first and last reports.\n3.  Classify shareholders.\n4.  Adjust shares for corporate actions.\n\n::: {#holdings-panel .cell execution_count=6}\n``` {.python .cell-code code-summary=\"Steps 2--4: Holdings Panel Construction\"}\ndef build_holdings_panel(\n    ownership: pd.DataFrame,\n    adj_factors: pd.DataFrame,\n    price_q: pd.DataFrame,\n    company_profile: pd.DataFrame,\n    begdate: str = '2010-01-01',\n    enddate: str = '2024-12-31',\n) -> pd.DataFrame:\n    \"\"\"\n    Construct the institutional holdings panel from DataCore.vn\n    ownership data.\n    \"\"\"\n    own = ownership.copy()\n    \n    # Align to quarter-end\n    own['rdate'] = own['date'] + pd.offsets.QuarterEnd(0)\n    own['fdate'] = own['date']\n    \n    own = own[\n        (own['rdate'] >= begdate) & (own['rdate'] <= enddate)\n    ].copy()\n    \n    # Keep earliest vintage per shareholder-ticker-rdate\n    own = own.sort_values(\n        ['shareholder_name', 'ticker', 'rdate', 'fdate']\n    )\n    fst_vint = (\n        own\n        .groupby(['shareholder_name', 'ticker', 'rdate'])\n        .first()\n        .reset_index()\n    )\n    \n    # ---- Reporting gaps for first/last flags ----\n    fst_vint = fst_vint.sort_values(\n        ['shareholder_name', 'ticker', 'rdate']\n    )\n    \n    grp = fst_vint.groupby(['shareholder_name', 'ticker'])\n    fst_vint['lag_rdate'] = grp['rdate'].shift(1)\n    \n    fst_vint['qtr_gap'] = fst_vint.apply(\n        lambda r: (\n            (r['rdate'].to_period('Q')\n             - r['lag_rdate'].to_period('Q')).n\n            if pd.notna(r['lag_rdate']) else np.nan\n        ),\n        axis=1\n    )\n    \n    fst_vint['first_report'] = (\n        fst_vint['qtr_gap'].isna() | (fst_vint['qtr_gap'] >= 2)\n    )\n    \n    # Last report flag (forward gap)\n    fst_vint = fst_vint.sort_values(\n        ['shareholder_name', 'ticker', 'rdate'],\n        ascending=[True, True, False]\n    )\n    fst_vint['lead_rdate'] = grp['rdate'].shift(1)\n    \n    fst_vint['lead_gap'] = fst_vint.apply(\n        lambda r: (\n            (r['lead_rdate'].to_period('Q')\n             - r['rdate'].to_period('Q')).n\n            if pd.notna(r['lead_rdate']) else np.nan\n        ),\n        axis=1\n    )\n    \n    fst_vint['last_report'] = (\n        fst_vint['lead_gap'].isna() | (fst_vint['lead_gap'] >= 2)\n    )\n    \n    fst_vint = fst_vint.drop(\n        columns=['lag_rdate', 'qtr_gap', 'lead_rdate', 'lead_gap'],\n        errors='ignore'\n    )\n    \n    # ---- Classify shareholders ----\n    fst_vint['owner_type'] = fst_vint.apply(\n        OwnershipType.classify, axis=1\n    )\n    \n    # ---- Adjust shares for corporate actions ----\n    fst_vint = fst_vint.merge(\n        price_q[['ticker', 'qdate', 'cfacshr']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    \n    fst_vint['shares_adj'] = (\n        fst_vint['shares_held'] * fst_vint['cfacshr']\n    )\n    fst_vint = fst_vint[fst_vint['shares_adj'] > 0].copy()\n    \n    fst_vint = fst_vint.drop_duplicates(\n        subset=['shareholder_name', 'ticker', 'rdate']\n    )\n    \n    # Merge company profile\n    if company_profile is not None:\n        fst_vint = fst_vint.merge(\n            company_profile[['ticker', 'exchange', 'fol_limit']]\n            .drop_duplicates(),\n            on='ticker',\n            how='left'\n        )\n    \n    cols = [\n        'shareholder_name', 'ticker', 'rdate', 'fdate',\n        'shares_held', 'shares_adj', 'owner_type',\n        'first_report', 'last_report'\n    ]\n    if 'exchange' in fst_vint.columns:\n        cols.extend(['exchange', 'fol_limit'])\n    \n    holdings = fst_vint[cols].copy()\n    \n    print(f\"Holdings panel: {len(holdings):,} observations\")\n    print(f\"  Shareholders: {holdings['shareholder_name'].nunique():,}\")\n    print(f\"  Stocks: {holdings['ticker'].nunique():,}\")\n    print(f\"  Quarters: {holdings['rdate'].nunique()}\")\n    \n    return holdings\n```\n:::\n\n\n# Institutional Ownership Metrics {#sec-io-metrics}\n\nBefore computing trades, we establish the standard institutional ownership metrics that serve as both outputs and inputs to the trading analysis.\n\n## Institutional Ownership Ratio {#sec-io-ratio}\n\nThe institutional ownership ratio (IO) for stock $i$ at time $t$ is:\n\n$$\nIO_{i,t} = \\frac{\\sum_{j \\in \\mathcal{J}} h_{j,i,t}}{TSO_{i,t}}\n$$ {#eq-io-ratio}\n\nwhere $\\mathcal{J}$ is the set of institutional investors and $TSO_{i,t}$ is total shares outstanding. In Vietnam, we compute separate ratios for each ownership type:\n\n$$\nIO_{i,t}^{\\text{type}} = \\frac{\\sum_{j \\in \\mathcal{J}^{\\text{type}}} h_{j,i,t}}{TSO_{i,t}},\n\\quad \\text{type} \\in \\{\\text{State}, \\text{Foreign}, \\text{Domestic}, \\text{Individual}\\}\n$$ {#eq-io-by-type}\n\n::: {#io-ratio-computation .cell execution_count=7}\n``` {.python .cell-code code-summary=\"Institutional Ownership Ratio Computation\"}\ndef compute_io_ratios(\n    holdings: pd.DataFrame,\n    price_q: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Compute IO ratios by type for each stock-quarter.\"\"\"\n    agg = (\n        holdings\n        .groupby(['ticker', 'rdate', 'owner_type'])['shares_adj']\n        .sum()\n        .reset_index()\n    )\n    \n    io_wide = agg.pivot_table(\n        index=['ticker', 'rdate'],\n        columns='owner_type',\n        values='shares_adj',\n        fill_value=0\n    ).reset_index()\n    \n    io_wide.columns = [\n        c if c in ['ticker', 'rdate']\n        else f'shares_{c.lower().replace(\" \", \"_\")}'\n        for c in io_wide.columns\n    ]\n    \n    io_wide = io_wide.merge(\n        price_q[['ticker', 'qdate', 'tso']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    \n    share_cols = [c for c in io_wide.columns if c.startswith('shares_')]\n    for col in share_cols:\n        ratio_name = col.replace('shares_', 'io_')\n        io_wide[ratio_name] = io_wide[col] / io_wide['tso']\n    \n    inst_cols = [\n        c for c in io_wide.columns\n        if c.startswith('shares_')\n        and 'individual' not in c\n        and 'treasury' not in c\n    ]\n    io_wide['io_total_inst'] = (\n        io_wide[inst_cols].sum(axis=1) / io_wide['tso']\n    )\n    \n    return io_wide\n```\n:::\n\n\n## Ownership Concentration: Herfindahl-Hirschman Index {#sec-hhi}\n\nThe HHI measures ownership concentration:\n\n$$\nHHI_{i,t} = \\sum_{j=1}^{N_{i,t}} \\left(\\frac{h_{j,i,t}}{\\sum_{k=1}^{N_{i,t}} h_{k,i,t}}\\right)^2\n$$ {#eq-hhi}\n\nwhere $N_{i,t}$ is the number of shareholders. HHI ranges from $1/N_{i,t}$ (equal) to 1 (single shareholder). In Vietnam, ownership tends to be highly concentrated due to large state and founding-family blocks.\n\n::: {#hhi-computation .cell execution_count=8}\n``` {.python .cell-code code-summary=\"Ownership Concentration (HHI)\"}\ndef compute_hhi(holdings: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Compute HHI for each stock-quarter, overall and institutional.\"\"\"\n    def _hhi(shares: pd.Series) -> float:\n        total = shares.sum()\n        if total <= 0:\n            return np.nan\n        weights = shares / total\n        return (weights ** 2).sum()\n    \n    hhi_overall = (\n        holdings.groupby(['ticker', 'rdate'])['shares_adj']\n        .apply(_hhi).reset_index()\n        .rename(columns={'shares_adj': 'hhi_overall'})\n    )\n    \n    inst = holdings[\n        holdings['owner_type'].isin(OwnershipType.ALL_INSTITUTIONAL)\n    ]\n    hhi_inst = (\n        inst.groupby(['ticker', 'rdate'])['shares_adj']\n        .apply(_hhi).reset_index()\n        .rename(columns={'shares_adj': 'hhi_institutional'})\n    )\n    \n    return hhi_overall.merge(hhi_inst, on=['ticker', 'rdate'], how='left')\n```\n:::\n\n\n## Ownership Breadth {#sec-breadth}\n\nFollowing @chen2000value, ownership breadth is the number of institutional holders:\n\n$$\n\\text{Breadth}_{i,t} = \\#\\{j : h_{j,i,t} > 0, \\, j \\in \\mathcal{J}\\}\n$$ {#eq-breadth}\n\nThe *change* in breadth predicts future returns:\n\n$$\n\\Delta\\text{Breadth}_{i,t} = \\text{Breadth}_{i,t} - \\text{Breadth}_{i,t-1}\n$$ {#eq-breadth-change}\n\n::: {#breadth-computation .cell execution_count=9}\n``` {.python .cell-code code-summary=\"Ownership Breadth and Breadth Changes\"}\ndef compute_breadth(holdings: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Compute ownership breadth and changes by type.\"\"\"\n    breadth = (\n        holdings[\n            holdings['owner_type'].isin(OwnershipType.ALL_INSTITUTIONAL)\n        ]\n        .groupby(['ticker', 'rdate', 'owner_type'])['shareholder_name']\n        .nunique()\n        .reset_index()\n        .rename(columns={'shareholder_name': 'n_holders'})\n    )\n    \n    breadth_wide = breadth.pivot_table(\n        index=['ticker', 'rdate'],\n        columns='owner_type',\n        values='n_holders',\n        fill_value=0\n    ).reset_index()\n    \n    breadth_wide.columns = [\n        c if c in ['ticker', 'rdate']\n        else f'n_{c.lower().replace(\" \", \"_\")}'\n        for c in breadth_wide.columns\n    ]\n    \n    n_cols = [c for c in breadth_wide.columns if c.startswith('n_')]\n    breadth_wide['n_total_inst'] = breadth_wide[n_cols].sum(axis=1)\n    \n    breadth_wide = breadth_wide.sort_values(['ticker', 'rdate'])\n    for col in n_cols + ['n_total_inst']:\n        breadth_wide[f'd_{col}'] = (\n            breadth_wide.groupby('ticker')[col].diff()\n        )\n    \n    return breadth_wide\n```\n:::\n\n\n($\\text{BS} = -1$) is generated for the prior position, dated to the quarter after the last report.\n\nFor intermediate gaps (reports at $t-2$ and $t$ but not $t-1$), we split into:\n\n-   A terminating sale at $t-1$ of $-h_{j,i,t-2}^{\\text{adj}}$;\n-   An initiating buy at $t$ of $h_{j,i,t}$.\n\n## Implementation {#sec-trade-impl}\n\n::: {#trade-computation .cell execution_count=10}\n``` {.python .cell-code code-summary=\"Step 5: Institutional Trade Computation\"}\ndef compute_trades(\n    holdings: pd.DataFrame,\n    adj_factors: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"\n    Compute institutional trades from holdings panel.\n    \n    Uses vectorized conditional logic (NOT apply()) for performance.\n    \n    Algorithm:\n    1. Sort holdings by shareholder, ticker, quarter\n    2. Compute lagged holdings and reporting gaps\n    3. Apply modified trade logic based on first_report, gap\n    4. Handle terminating sales and intermediate gaps\n    5. Append all trade records\n    \"\"\"\n    t1 = holdings.sort_values(\n        ['shareholder_name', 'ticker', 'rdate']\n    ).copy()\n    \n    # Previous holding quarter and shares\n    grp = t1.groupby(['shareholder_name', 'ticker'])\n    t1['phrdate'] = grp['rdate'].shift(1)\n    t1['pshares_adj'] = grp['shares_adj'].shift(1)\n    \n    # Raw trade\n    t1['trade'] = t1['shares_adj'] - t1['pshares_adj']\n    \n    # Quarter gap\n    t1['qtrgap'] = t1.apply(\n        lambda r: (\n            (r['rdate'].to_period('Q')\n             - r['phrdate'].to_period('Q')).n\n            if pd.notna(r['phrdate']) else np.nan\n        ),\n        axis=1\n    )\n    \n    # Boundary detection keys\n    t1['l_key'] = (\n        t1['shareholder_name'] + '_' + t1['ticker']\n    ).shift(1)\n    t1['n_key'] = (\n        t1['shareholder_name'] + '_' + t1['ticker']\n    ).shift(-1)\n    t1['curr_key'] = t1['shareholder_name'] + '_' + t1['ticker']\n    \n    # ---- Vectorized trade classification ----\n    is_new = (t1['curr_key'] != t1['l_key'])\n    not_first = ~t1['first_report']\n    consec = (t1['qtrgap'] == 1)\n    gap = (t1['qtrgap'] != 1) & t1['qtrgap'].notna()\n    \n    cond1   = is_new\n    cond1_1 = is_new & not_first\n    cond2_1 = (~is_new) & not_first & consec\n    cond2_2 = (~is_new) & not_first & gap\n    \n    # Modified trade amounts\n    t1['modtrade'] = t1['trade']\n    t1.loc[cond1, 'modtrade'] = np.nan\n    t1.loc[cond1_1, 'modtrade'] = t1.loc[cond1_1, 'shares_adj']\n    t1.loc[cond2_1, 'modtrade'] = t1.loc[cond2_1, 'trade']\n    t1.loc[cond2_2, 'modtrade'] = t1.loc[cond2_2, 'shares_adj']\n    \n    # Buy/sale classification\n    t1['buysale'] = np.nan\n    t1.loc[cond1_1, 'buysale'] = 1\n    t1.loc[cond2_1, 'buysale'] = (\n        2 * np.sign(t1.loc[cond2_1, 'trade'])\n    )\n    t1.loc[cond2_2, 'buysale'] = 1.5  # placeholder for split\n    \n    # ---- Handle intermediate gaps (buysale == 1.5) ----\n    t2 = t1[t1['buysale'] == 1.5].copy()\n    t2['rdate'] = t2['phrdate'] + pd.offsets.QuarterEnd(1)\n    t2['buysale'] = -1\n    t2['modtrade'] = -t2['pshares_adj']\n    \n    t1.loc[t1['buysale'] == 1.5, 'buysale'] = 1\n    \n    # ---- Terminating sales ----\n    is_last_combo = (t1['curr_key'] != t1['n_key'])\n    not_last_rpt = ~t1['last_report']\n    \n    t3 = t1[is_last_combo & not_last_rpt].copy()\n    t3['rdate'] = t3['rdate'] + pd.offsets.QuarterEnd(1)\n    t3['modtrade'] = -t3['shares_adj']\n    t3['buysale'] = -1\n    \n    # ---- Combine ----\n    trades = pd.concat([t1, t2, t3], ignore_index=True)\n    trades = trades[\n        (trades['modtrade'] != 0) &\n        trades['modtrade'].notna() &\n        trades['buysale'].notna()\n    ].copy()\n    \n    trades = trades[[\n        'rdate', 'shareholder_name', 'ticker', 'modtrade',\n        'buysale', 'owner_type', 'first_report', 'last_report'\n    ]].rename(columns={'modtrade': 'trade'})\n    \n    print(f\"\\nTrade computation complete:\")\n    print(f\"  Total records: {len(trades):,}\")\n    print(f\"  Initiating buys:  {(trades['buysale'] == 1).sum():,}\")\n    print(f\"  Incremental buys: {(trades['buysale'] == 2).sum():,}\")\n    print(f\"  Terminating sales:{(trades['buysale'] == -1).sum():,}\")\n    print(f\"  Regular sales:    {(trades['buysale'] == -2).sum():,}\")\n    \n    return trades\n```\n:::\n\n\n### Trade Visualization {#sec-trade-viz}\n\n::: {#fig-trade-distribution .cell execution_count=11}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_trade_distribution(trades: pd.DataFrame):\n    \"\"\"Plot time series of trade types by quarter.\"\"\"\n    bs_labels = {\n        1: 'Initiating Buy', 2: 'Incremental Buy',\n        -1: 'Terminating Sale', -2: 'Regular Sale'\n    }\n    trades = trades.copy()\n    trades['trade_type'] = trades['buysale'].map(bs_labels)\n    \n    counts = (\n        trades\n        .groupby([pd.Grouper(key='rdate', freq='QE'), 'trade_type'])\n        .size()\n        .unstack(fill_value=0)\n    )\n    \n    fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n    \n    buy_cols = [c for c in counts.columns if 'Buy' in c]\n    counts[buy_cols].plot(\n        kind='bar', stacked=True, ax=axes[0],\n        color=['#1f77b4', '#aec7e8'], width=0.8\n    )\n    axes[0].set_title('Panel A: Institutional Purchases', fontweight='bold')\n    axes[0].set_ylabel('Number of Trades')\n    \n    sale_cols = [c for c in counts.columns if 'Sale' in c]\n    counts[sale_cols].plot(\n        kind='bar', stacked=True, ax=axes[1],\n        color=['#d62728', '#ff9896'], width=0.8\n    )\n    axes[1].set_title('Panel B: Institutional Sales', fontweight='bold')\n    axes[1].set_ylabel('Number of Trades')\n    \n    for ax in axes:\n        ax.tick_params(axis='x', rotation=45)\n        for i, label in enumerate(ax.get_xticklabels()):\n            if i % 4 != 0:\n                label.set_visible(False)\n    \n    plt.tight_layout()\n    plt.show()\n\n# plot_trade_distribution(trades)\n```\n:::\n\n\n::: {#fig-net-trading-by-type .cell execution_count=12}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_net_trading_by_type(trades: pd.DataFrame, price_q: pd.DataFrame):\n    \"\"\"Plot net trading volume by owner type over time.\"\"\"\n    _t = trades.merge(\n        price_q[['ticker', 'qdate', 'p']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    _t['trade_vnd'] = _t['trade'] * _t['p'] / 1e9\n    \n    net = (\n        _t\n        .groupby([pd.Grouper(key='rdate', freq='QE'), 'owner_type'])\n        ['trade_vnd'].sum()\n        .unstack(fill_value=0)\n    )\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    for col in net.columns:\n        ax.plot(net.index, net[col], label=col,\n                color=OWNER_COLORS.get(col, '#333'), linewidth=1.5)\n    ax.axhline(y=0, color='black', linewidth=0.5)\n    ax.set_title('Net Institutional Trading by Ownership Type',\n                 fontweight='bold')\n    ax.set_ylabel('Net Trading (Billions VND)')\n    ax.legend(loc='best')\n    plt.tight_layout()\n    plt.show()\n\n# plot_net_trading_by_type(trades, price_q)\n```\n:::\n\n\n# Portfolio Assets, Flows, and Returns {#sec-assets-flows}\n\nThis section computes total portfolio assets, aggregates buys and sales, and portfolio-level returns for each institutional investor.\n\n## Total Assets and Portfolio Returns {#sec-assets}\n\nFor each manager $j$ and quarter $t$, portfolio assets are:\n\n$$\nA_{j,t} = \\sum_{i=1}^{N_{j,t}} h_{j,i,t} \\cdot P_{i,t}\n$$ {#eq-assets}\n\nThe portfolio return assuming buy-and-hold is:\n\n$$\nR_{j,t}^{p} = \\frac{\\sum_{i=1}^{N_{j,t}} h_{j,i,t} \\cdot P_{i,t} \\cdot r_{i,t+1}}\n{\\sum_{i=1}^{N_{j,t}} h_{j,i,t} \\cdot P_{i,t}}\n$$ {#eq-portfolio-return}\n\n::: {#assets-computation .cell execution_count=13}\n``` {.python .cell-code code-summary=\"Step 6a: Portfolio Assets and Returns\"}\ndef compute_assets_and_returns(\n    holdings: pd.DataFrame,\n    price_q: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Compute total portfolio assets and buy-and-hold returns.\"\"\"\n    _assets = holdings[\n        ['shareholder_name', 'ticker', 'rdate', 'shares_adj']\n    ].merge(\n        price_q[['ticker', 'qdate', 'p', 'qret']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    \n    _assets['hold_per_stock'] = _assets['shares_adj'] * _assets['p'] / 1e6\n    _assets['next_value'] = (\n        _assets['shares_adj'] * _assets['p'] * _assets['qret']\n    )\n    _assets['curr_value'] = _assets['shares_adj'] * _assets['p']\n    \n    assets = (\n        _assets\n        .groupby(['shareholder_name', 'rdate'])\n        .agg(\n            assets=('hold_per_stock', 'sum'),\n            total_next=('next_value', 'sum'),\n            total_curr=('curr_value', 'sum'),\n        )\n        .reset_index()\n    )\n    \n    assets['pret'] = assets['total_next'] / assets['total_curr']\n    assets = assets.drop(columns=['total_next', 'total_curr'])\n    return assets\n```\n:::\n\n\n## Aggregate Buys and Sales {#sec-aggregate-buysales}\n\nTotal buys and sales for manager $j$ in quarter $t$:\n\n$$\nB_{j,t} = \\sum_{i : \\Delta h > 0} \\Delta h_{j,i,t} \\cdot P_{i,t}, \\qquad\nS_{j,t} = \\sum_{i : \\Delta h < 0} |\\Delta h_{j,i,t}| \\cdot P_{i,t}\n$$ {#eq-total-buys-sales}\n\nThe trade gain is:\n\n$$\nG_{j,t} = \\sum_{i=1}^{N_{j,t}} \\Delta h_{j,i,t} \\cdot P_{i,t} \\cdot r_{i,t+1}\n$$ {#eq-trade-gain}\n\n::: {#buys-sales-computation .cell execution_count=14}\n``` {.python .cell-code code-summary=\"Step 6b: Aggregate Buys, Sales, and Trade Gains\"}\ndef compute_buys_sales(\n    trades: pd.DataFrame,\n    price_q: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Compute aggregate buys, sales, trade gains per manager-quarter.\"\"\"\n    _flows = trades.merge(\n        price_q[['ticker', 'qdate', 'p', 'qret']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    \n    _flows['tbuys'] = (\n        _flows['trade'] * (_flows['trade'] > 0).astype(float)\n        * _flows['p'] / 1e6\n    )\n    _flows['tsales'] = (\n        (-1) * _flows['trade'] * (_flows['trade'] < 0).astype(float)\n        * _flows['p'] / 1e6\n    )\n    _flows['tgain'] = (\n        _flows['trade'] * _flows['p'] * _flows['qret'] / 1e6\n    )\n    \n    flows = (\n        _flows\n        .groupby(['shareholder_name', 'rdate'])\n        .agg(\n            tbuys=('tbuys', 'sum'),\n            tsales=('tsales', 'sum'),\n            tgain=('tgain', 'sum'),\n        )\n        .reset_index()\n    )\n    return flows\n```\n:::\n\n\n# Net Flows and Turnover Ratios {#sec-turnover}\n\n## Net Flows {#sec-netflows}\n\nNet flows separate capital allocation decisions from investment returns:\n\n$$\n\\text{NetFlow}_{j,t} = A_{j,t} - A_{j,t-1}(1 + R_{j,t}^p)\n$$ {#eq-netflow-def}\n\n::: callout-warning\n## Interpreting Net Flows in Vietnam\n\nFor state entities or corporate cross-holders, \"net flows\" do not necessarily reflect investment decisions. State ownership changes often result from government policy (equitization, divestment programs). Interpretation should account for institutional context.\n:::\n\n## Three Turnover Measures {#sec-turnover-measures}\n\n::: {#turnover-computation .cell execution_count=15}\n``` {.python .cell-code code-summary=\"Step 7: Net Flows and Turnover Ratios\"}\ndef compute_aggregates(\n    holdings: pd.DataFrame,\n    assets: pd.DataFrame,\n    flows: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"\n    Compute net flows and three turnover measures.\n    \n    1. Carhart (1997): min(buys, sales) / avg(assets)\n    2. Flow-adjusted: [min(buys, sales) + |net flows|] / lag assets\n    3. Symmetric: [buys + sales - |net flows|] / lag assets\n    \"\"\"\n    report_flags = (\n        holdings\n        .groupby(['shareholder_name', 'rdate'])\n        .agg(first_report=('first_report', 'any'),\n             last_report=('last_report', 'any'))\n        .reset_index()\n    )\n    \n    agg = report_flags.merge(\n        assets, on=['shareholder_name', 'rdate'], how='inner'\n    )\n    agg = agg.merge(\n        flows, on=['shareholder_name', 'rdate'], how='left'\n    )\n    \n    agg = agg.sort_values(['shareholder_name', 'rdate'])\n    \n    agg['assets_comp'] = agg['assets'] * (1 + agg['pret'].fillna(0))\n    \n    grp = agg.groupby('shareholder_name')\n    agg['lassets_comp'] = grp['assets_comp'].shift(1)\n    agg['lassets'] = grp['assets'].shift(1)\n    \n    # Trade gain return\n    agg['tgainret'] = agg['tgain'] / (agg['tbuys'] + agg['tsales'])\n    \n    # Net flows\n    agg['netflows'] = agg['assets'] - agg['lassets_comp']\n    \n    # Turnover 1: Carhart (1997)\n    agg['turnover1'] = (\n        agg[['tbuys', 'tsales']].min(axis=1) /\n        agg[['assets', 'lassets']].mean(axis=1)\n    )\n    \n    # Turnover 2: Flow-adjusted\n    agg['turnover2'] = (\n        (agg[['tbuys', 'tsales']].min(axis=1)\n         + agg['netflows'].abs().fillna(0))\n        / agg['lassets']\n    )\n    \n    # Turnover 3: Symmetric\n    agg['turnover3'] = (\n        (agg['tbuys'].fillna(0) + agg['tsales'].fillna(0)\n         - agg['netflows'].abs().fillna(0))\n        / agg['lassets']\n    )\n    \n    # Missing for first report\n    first_mask = agg['first_report']\n    for col in ['netflows', 'tgainret',\n                'turnover1', 'turnover2', 'turnover3']:\n        agg.loc[first_mask, col] = np.nan\n    \n    agg = agg.drop(columns=['assets_comp', 'lassets_comp', 'lassets'])\n    \n    print(f\"\\nAggregates: {len(agg):,} manager-quarters\")\n    print(f\"  Turnover1 mean: {agg['turnover1'].mean():.4f}\")\n    print(f\"  Turnover2 mean: {agg['turnover2'].mean():.4f}\")\n    print(f\"  Turnover3 mean: {agg['turnover3'].mean():.4f}\")\n    \n    return agg\n```\n:::\n\n\n### Turnover Summary Statistics {#sec-turnover-stats}\n\n::: {#tbl-turnover-summary .cell tbl-cap='Summary statistics for three turnover measures across institutional investor types in Vietnam. Turnover 1 follows @Carhart1997, Turnover 2 adds back absolute net flows, and Turnover 3 uses the symmetric definition.' execution_count=16}\n``` {.python .cell-code code-fold=\"true\"}\ndef turnover_summary_table(\n    aggregates: pd.DataFrame,\n    holdings: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Publication-quality turnover summary statistics table.\"\"\"\n    owner_map = (\n        holdings.groupby('shareholder_name')['owner_type']\n        .first().reset_index()\n    )\n    agg = aggregates.merge(owner_map, on='shareholder_name', how='left')\n    \n    turnover_cols = ['turnover1', 'turnover2', 'turnover3']\n    results = []\n    \n    for otype in ['All'] + OwnershipType.ALL_TYPES:\n        subset = agg if otype == 'All' else agg[agg['owner_type'] == otype]\n        row = {'Owner Type': otype, 'N': len(subset)}\n        for col in turnover_cols:\n            s = subset[col].dropna()\n            row[f'{col}_mean'] = s.mean()\n            row[f'{col}_median'] = s.median()\n            row[f'{col}_std'] = s.std()\n        results.append(row)\n    \n    return pd.DataFrame(results).round(4)\n\n# turnover_summary_table(aggregates, holdings)\n```\n:::\n\n\n::: {#fig-turnover-timeseries .cell execution_count=17}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_turnover_timeseries(\n    aggregates: pd.DataFrame, holdings: pd.DataFrame\n):\n    \"\"\"Plot turnover time series by ownership type.\"\"\"\n    owner_map = (\n        holdings.groupby('shareholder_name')['owner_type']\n        .first().reset_index()\n    )\n    agg = aggregates.merge(owner_map, on='shareholder_name', how='left')\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    for otype in OwnershipType.ALL_INSTITUTIONAL:\n        subset = agg[agg['owner_type'] == otype]\n        qtr_mean = (\n            subset\n            .groupby(pd.Grouper(key='rdate', freq='QE'))['turnover1']\n            .mean()\n        )\n        ax.plot(qtr_mean.index, qtr_mean.values, label=otype,\n                color=OWNER_COLORS.get(otype, '#333'), linewidth=1.5)\n    \n    ax.set_title('Quarterly Average Turnover (Carhart)',\n                 fontweight='bold')\n    ax.set_ylabel('Turnover Ratio')\n    ax.legend(loc='best')\n    ax.yaxis.set_major_formatter(mticker.PercentFormatter(1.0))\n    plt.tight_layout()\n    plt.show()\n\n# plot_turnover_timeseries(aggregates, holdings)\n```\n:::\n\n\n# Foreign Ownership Analytics {#sec-foreign}\n\nVietnam's foreign ownership limits create unique analytical dimensions absent from developed market studies.\n\n## FOL Utilization {#sec-fol-util}\n\n$$\n\\text{FOL\\_Util}_{i,t} = \\frac{FO_{i,t}}{FOL_i}\n$$ {#eq-fol-util}\n\nStocks with $\\text{FOL\\_Util}_{i,t} \\to 1$ face mechanical foreign buying restrictions.\n\n::: {#fol-analytics .cell execution_count=18}\n``` {.python .cell-code code-summary=\"Foreign Ownership Limit Analytics\"}\ndef compute_fol_analytics(\n    foreign_ownership: pd.DataFrame,\n    company_profile: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Compute FOL utilization and related metrics.\"\"\"\n    fo = foreign_ownership.copy()\n    fo = fo.merge(\n        company_profile[['ticker', 'fol_limit']].drop_duplicates(),\n        on='ticker', how='left'\n    )\n    \n    fo['fol_utilization'] = fo['foreign_pct'] / fo['fol_limit']\n    fo['foreign_room'] = fo['fol_limit'] - fo['foreign_pct']\n    fo['fol_binding'] = (fo['fol_utilization'] >= 0.98)\n    fo['fol_category'] = pd.cut(\n        fo['fol_utilization'],\n        bins=[0, 0.25, 0.50, 0.75, 0.95, 1.0, float('inf')],\n        labels=['<25%', '25-50%', '50-75%', '75-95%',\n                '95-100%', '>100%']\n    )\n    return fo\n```\n:::\n\n\n## Room Premium Regression {#sec-room-premium}\n\nWhen foreign ownership approaches the FOL, remaining \"room\" becomes scarce. We model:\n\n$$\nr_{i,t+1} = \\alpha + \\beta_1 \\cdot \\text{FOL\\_Util}_{i,t} +\n\\beta_2 \\cdot \\text{FOL\\_Util}_{i,t}^2 + \\gamma \\cdot X_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-room-premium}\n\nThe quadratic term captures nonlinear acceleration of the premium as ownership approaches the limit.\n\n::: {#room-premium-regression .cell execution_count=19}\n``` {.python .cell-code code-summary=\"FOL Room Premium Regression\"}\ndef estimate_room_premium(\n    fol_analytics: pd.DataFrame,\n    price_q: pd.DataFrame,\n) -> dict:\n    \"\"\"Estimate foreign ownership room premium via panel regression.\"\"\"\n    fol_q = (\n        fol_analytics\n        .assign(qdate=lambda x: x['date'] + pd.offsets.QuarterEnd(0))\n        .groupby(['ticker', 'qdate'])\n        .agg(fol_utilization=('fol_utilization', 'last'),\n             foreign_room=('foreign_room', 'last'))\n        .reset_index()\n    )\n    \n    panel = fol_q.merge(\n        price_q[['ticker', 'qdate', 'mcap', 'qret']],\n        on=['ticker', 'qdate'], how='inner'\n    )\n    \n    panel['log_mcap'] = np.log(panel['mcap'] + 1)\n    panel['fol_util_sq'] = panel['fol_utilization'] ** 2\n    panel = panel.dropna(subset=['qret', 'fol_utilization', 'log_mcap'])\n    \n    X = panel[['fol_utilization', 'fol_util_sq', 'log_mcap']]\n    X = sm.add_constant(X)\n    y = panel['qret']\n    \n    model = sm.OLS(y, X).fit(\n        cov_type='cluster', cov_kwds={'groups': panel['ticker']}\n    )\n    return {'model': model, 'n_obs': len(panel)}\n\n# results = estimate_room_premium(fol_analytics, price_q)\n```\n:::\n\n\n::: {#fig-fol-distribution .cell execution_count=20}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_fol_utilization(fol_analytics: pd.DataFrame):\n    \"\"\"Plot FOL utilization distribution.\"\"\"\n    latest = (\n        fol_analytics.sort_values(['ticker', 'date'])\n        .groupby('ticker').last().reset_index()\n    )\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    axes[0].hist(latest['fol_utilization'].dropna(), bins=50,\n                 color='#1f77b4', alpha=0.7, edgecolor='white')\n    axes[0].axvline(x=0.95, color='red', linestyle='--',\n                     label='95% threshold')\n    axes[0].set_title('Panel A: FOL Utilization Distribution',\n                       fontweight='bold')\n    axes[0].set_xlabel('FOL Utilization Ratio')\n    axes[0].set_ylabel('Number of Stocks')\n    axes[0].legend()\n    \n    for exch in ['HOSE', 'HNX', 'UPCOM']:\n        sub = latest[latest.get('exchange') == exch]\n        if len(sub) > 0:\n            axes[1].hist(sub['fol_utilization'].dropna(), bins=30,\n                        alpha=0.5, label=exch,\n                        color=EXCHANGE_COLORS.get(exch, '#333'))\n    axes[1].set_title('Panel B: By Exchange', fontweight='bold')\n    axes[1].set_xlabel('FOL Utilization Ratio')\n    axes[1].legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# plot_fol_utilization(fol_analytics)\n```\n:::\n\n\n# Complete Pipeline {#sec-pipeline}\n\nWe integrate all steps into a single end-to-end function:\n\n::: {#complete-pipeline .cell execution_count=21}\n``` {.python .cell-code code-summary=\"Complete End-to-End Pipeline\"}\ndef run_complete_pipeline(\n    dc: 'DataCoreReader',\n    begdate: str = '2010-01-01',\n    enddate: str = '2024-12-31',\n) -> Dict[str, pd.DataFrame]:\n    \"\"\"\n    Execute the complete institutional ownership analytics pipeline.\n    \n    Steps:\n    1. Build corporate action adjustment factors\n    2. Process stock prices\n    3. Construct holdings panel (Steps 2-4)\n    4. Compute IO metrics\n    5. Compute institutional trades (Step 5)\n    6. Compute portfolio assets and returns (Step 6a)\n    7. Compute aggregate buys, sales, trade gains (Step 6b)\n    8. Compute net flows and turnover (Step 7)\n    9. Compute foreign ownership analytics\n    \n    Returns dict of all output DataFrames.\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"INSTITUTIONAL TRADES, FLOWS, AND TURNOVER PIPELINE\")\n    print(f\"Sample: {begdate} to {enddate}\")\n    print(\"=\" * 60)\n    \n    print(\"\\n[1/9] Building adjustment factors...\")\n    adj_factors = build_adjustment_factors(dc.corporate_actions)\n    \n    print(\"\\n[2/9] Processing stock prices...\")\n    price_q, qret = process_prices(\n        dc.prices, adj_factors, begdate, enddate\n    )\n    \n    print(\"\\n[3/9] Building holdings panel...\")\n    holdings = build_holdings_panel(\n        dc.ownership, adj_factors, price_q,\n        dc.company_profile, begdate, enddate\n    )\n    \n    print(\"\\n[4/9] Computing ownership metrics...\")\n    io_ratios = compute_io_ratios(holdings, price_q)\n    hhi = compute_hhi(holdings)\n    breadth = compute_breadth(holdings)\n    \n    print(\"\\n[5/9] Computing institutional trades...\")\n    trades = compute_trades(holdings, adj_factors)\n    \n    print(\"\\n[6/9] Computing portfolio assets...\")\n    assets = compute_assets_and_returns(holdings, price_q)\n    \n    print(\"\\n[7/9] Computing aggregate buys and sales...\")\n    flows = compute_buys_sales(trades, price_q)\n    \n    print(\"\\n[8/9] Computing net flows and turnover...\")\n    aggregates = compute_aggregates(holdings, assets, flows)\n    \n    print(\"\\n[9/9] Computing foreign ownership analytics...\")\n    fol_analytics = compute_fol_analytics(\n        dc.foreign_ownership, dc.company_profile\n    )\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"PIPELINE COMPLETE\")\n    print(\"=\" * 60)\n    \n    return {\n        'price_q': price_q, 'holdings': holdings,\n        'io_ratios': io_ratios, 'hhi': hhi,\n        'breadth': breadth, 'trades': trades,\n        'assets': assets, 'flows': flows,\n        'aggregates': aggregates, 'fol_analytics': fol_analytics,\n    }\n\n# dc = DataCoreReader('/path/to/datacore_data', file_format='parquet')\n# results = run_complete_pipeline(dc, '2010-01-01', '2024-12-31')\n```\n:::\n\n\n# Advanced Extensions {#sec-extensions}\n\n## Herding Measures {#sec-herding}\n\nFollowing @sias2004institutional, the Lakonishok-Shleifer-Vishny herding measure is:\n\n$$\nHM_{i,t} = \\left|\\frac{B_{i,t}}{B_{i,t} + S_{i,t}} - p_t\\right|\n- E\\left[\\left|\\frac{B_{i,t}}{B_{i,t} + S_{i,t}} - p_t\\right|\\right]\n$$ {#eq-herding}\n\nwhere $B_{i,t}$ is the number of managers buying stock $i$ in quarter $t$, $S_{i,t}$ the number selling, and $p_t$ the expected buyer proportion under independent trading.\n\n::: {#herding-measure .cell execution_count=22}\n``` {.python .cell-code code-summary=\"LSV Herding Measure\"}\ndef compute_lsv_herding(\n    trades: pd.DataFrame,\n    min_traders: int = 5,\n) -> pd.DataFrame:\n    \"\"\"Compute LSV herding measure for each stock-quarter.\"\"\"\n    tc = (\n        trades.groupby(['ticker', 'rdate'])\n        .apply(lambda g: pd.Series({\n            'n_buyers': (g['trade'] > 0).sum(),\n            'n_sellers': (g['trade'] < 0).sum(),\n            'n_traders': len(g),\n        }))\n        .reset_index()\n    )\n    \n    tc = tc[tc['n_traders'] >= min_traders].copy()\n    tc['buy_prop'] = tc['n_buyers'] / tc['n_traders']\n    tc['p_t'] = tc.groupby('rdate')['buy_prop'].transform('mean')\n    tc['raw_hm'] = (tc['buy_prop'] - tc['p_t']).abs()\n    \n    def expected_abs_deviation(row):\n        n = int(row['n_traders'])\n        p = row['p_t']\n        if n == 0 or p == 0 or p == 1:\n            return 0\n        from scipy.stats import binom\n        k = np.arange(0, n + 1)\n        probs = binom.pmf(k, n, p)\n        return np.sum(np.abs(k / n - p) * probs)\n    \n    tc['expected_hm'] = tc.apply(expected_abs_deviation, axis=1)\n    tc['herding'] = tc['raw_hm'] - tc['expected_hm']\n    \n    tc['buy_herding'] = np.where(\n        tc['buy_prop'] > tc['p_t'], tc['herding'], np.nan\n    )\n    tc['sell_herding'] = np.where(\n        tc['buy_prop'] < tc['p_t'], tc['herding'], np.nan\n    )\n    \n    return tc[['ticker', 'rdate', 'n_buyers', 'n_sellers',\n               'n_traders', 'herding', 'buy_herding', 'sell_herding']]\n```\n:::\n\n\n## Demand Persistence {#sec-persistence}\n\n@sias2004institutional showed institutional demand is persistent:\n\n$$\n\\rho_t = \\text{Corr}\\left(\\Delta IO_{i,t},\\, \\Delta IO_{i,t-1}\\right)\n$$ {#eq-persistence}\n\n::: {#demand-persistence .cell execution_count=23}\n``` {.python .cell-code code-summary=\"Institutional Demand Persistence\"}\ndef compute_demand_persistence(io_ratios: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Rolling cross-sectional correlation of IO changes.\"\"\"\n    io = io_ratios[['ticker', 'rdate', 'io_total_inst']].copy()\n    io = io.sort_values(['ticker', 'rdate'])\n    io['dio'] = io.groupby('ticker')['io_total_inst'].diff()\n    io['lag_dio'] = io.groupby('ticker')['dio'].shift(1)\n    \n    persistence = (\n        io.dropna(subset=['dio', 'lag_dio'])\n        .groupby('rdate')\n        .apply(lambda g: g['dio'].corr(g['lag_dio']))\n        .reset_index()\n        .rename(columns={0: 'persistence'})\n    )\n    persistence = persistence.sort_values('rdate')\n    persistence['persistence_ma'] = (\n        persistence['persistence'].rolling(window=20, min_periods=4).mean()\n    )\n    return persistence\n```\n:::\n\n\n::: {#fig-persistence .cell execution_count=24}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_demand_persistence(persistence: pd.DataFrame):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    ax.bar(persistence['rdate'], persistence['persistence'],\n           width=80, alpha=0.3, color='#1f77b4', label='Quarterly')\n    ax.plot(persistence['rdate'], persistence['persistence_ma'],\n            color='#d62728', linewidth=2, label='Rolling Average')\n    ax.axhline(y=0, color='black', linewidth=0.5)\n    ax.set_title('Persistence of Institutional Demand', fontweight='bold')\n    ax.set_ylabel('Cross-Sectional Correlation')\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n```\n:::\n\n\n## Information Content of Trades {#sec-info-content}\n\nFollowing @alexander2007does, the InfoTrade ratio measures the proportion of dollar trading from entry/exit decisions vs. position adjustments:\n\n$$\n\\text{InfoTrade}_{i,t} = \\frac{\n\\sum_{j: BS \\in \\{+1,-1\\}} |\\Delta h_{j,i,t}| \\cdot P_{i,t}\n}{\n\\sum_j |\\Delta h_{j,i,t}| \\cdot P_{i,t}\n}\n$$ {#eq-info-trade}\n\n::: {#info-trade-ratio .cell execution_count=25}\n``` {.python .cell-code code-summary=\"Information Content of Trades\"}\ndef compute_info_trade_ratio(\n    trades: pd.DataFrame, price_q: pd.DataFrame\n) -> pd.DataFrame:\n    \"\"\"Compute info trade ratio for each stock-quarter.\"\"\"\n    _t = trades.merge(\n        price_q[['ticker', 'qdate', 'p']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    _t['dollar_trade'] = _t['trade'].abs() * _t['p'] / 1e6\n    _t['is_discrete'] = _t['buysale'].isin([1, -1])\n    \n    info = _t.groupby(['ticker', 'rdate']).apply(\n        lambda g: pd.Series({\n            'discrete_vol': g.loc[g['is_discrete'], 'dollar_trade'].sum(),\n            'total_vol': g['dollar_trade'].sum(),\n        })\n    ).reset_index()\n    \n    info['info_trade_ratio'] = (\n        info['discrete_vol'] / info['total_vol']\n    ).clip(0, 1)\n    return info\n```\n:::\n\n\n# Empirical Applications {#sec-applications}\n\n## Application 1: Institutional Ownership Changes and Future Returns {#sec-app-returns}\n\nWe test whether changes in institutional ownership predict future stock returns [@chen2000value] via Fama-MacBeth regressions:\n\n$$\nr_{i,t+1} = \\alpha_t + \\beta_{1,t} \\cdot \\Delta IO_{i,t} + \\beta_{2,t} \\cdot\n\\Delta\\text{Breadth}_{i,t} + \\gamma_t \\cdot X_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-fama-macbeth}\n\n::: {#fama-macbeth .cell execution_count=26}\n``` {.python .cell-code code-summary=\"Fama-MacBeth: IO Changes and Future Returns\"}\ndef fama_macbeth_io_returns(\n    io_ratios: pd.DataFrame,\n    breadth: pd.DataFrame,\n    price_q: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Run Fama-MacBeth regressions of future returns on IO changes.\"\"\"\n    panel = io_ratios[['ticker', 'rdate', 'io_total_inst']].merge(\n        breadth[['ticker', 'rdate', 'n_total_inst', 'd_n_total_inst']],\n        on=['ticker', 'rdate'], how='inner'\n    ).merge(\n        price_q[['ticker', 'qdate', 'mcap', 'qret']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    \n    panel = panel.sort_values(['ticker', 'rdate'])\n    panel['dio'] = panel.groupby('ticker')['io_total_inst'].diff()\n    panel['log_mcap'] = np.log(panel['mcap'] + 1)\n    panel['mom'] = panel.groupby('ticker')['qret'].shift(1)\n    \n    reg_vars = ['qret', 'dio', 'd_n_total_inst', 'log_mcap', 'mom']\n    panel = panel.dropna(subset=reg_vars)\n    \n    quarters = sorted(panel['rdate'].unique())\n    results = []\n    \n    for q in quarters:\n        qdata = panel[panel['rdate'] == q]\n        if len(qdata) < 30:\n            continue\n        X = sm.add_constant(\n            qdata[['dio', 'd_n_total_inst', 'log_mcap', 'mom']]\n        )\n        try:\n            model = sm.OLS(qdata['qret'], X).fit()\n            coefs = model.params.to_dict()\n            coefs['rdate'] = q\n            coefs['n_obs'] = len(qdata)\n            results.append(coefs)\n        except Exception:\n            continue\n    \n    fm = pd.DataFrame(results)\n    \n    # Time-series averages with Newey-West t-statistics\n    print(\"\\nFama-MacBeth Results:\")\n    print(\"=\" * 50)\n    for var in ['const', 'dio', 'd_n_total_inst', 'log_mcap', 'mom']:\n        coefs = fm[var].dropna()\n        mean_c = coefs.mean()\n        nw_se = sm.OLS(\n            coefs - mean_c, np.ones(len(coefs))\n        ).fit(cov_type='HAC', cov_kwds={'maxlags': 4}).bse[0]\n        t = mean_c / nw_se if nw_se > 0 else np.nan\n        print(f\"  {var:20s}: coef={mean_c:8.4f}, t={t:6.2f}\")\n    \n    return fm\n```\n:::\n\n\n## Application 2: Turnover and Performance {#sec-app-turnover}\n\n@yan2008liquidity documented a positive turnover-performance relationship. We test in Vietnam:\n\n$$\n\\alpha_{j,t} = a + b \\cdot \\text{Turnover}_{j,t-1} + c \\cdot\n\\log(A_{j,t-1}) + d \\cdot \\text{Flow}_{j,t} + \\varepsilon_{j,t}\n$$ {#eq-turnover-perf}\n\n::: {#turnover-performance .cell execution_count=27}\n``` {.python .cell-code code-summary=\"Turnover-Performance Relationship\"}\ndef turnover_performance_regression(\n    aggregates: pd.DataFrame,\n) -> dict:\n    \"\"\"Test turnover-performance relationship.\"\"\"\n    agg = aggregates.sort_values(['shareholder_name', 'rdate']).copy()\n    agg['lag_turnover1'] = (\n        agg.groupby('shareholder_name')['turnover1'].shift(1)\n    )\n    agg['log_assets'] = np.log(agg['assets'] + 1)\n    agg['flow_ratio'] = agg['netflows'] / agg['assets'].shift(1)\n    \n    panel = agg.dropna(\n        subset=['pret', 'lag_turnover1', 'log_assets', 'flow_ratio']\n    )\n    \n    for col in ['pret', 'lag_turnover1', 'flow_ratio']:\n        lo, hi = panel[col].quantile([0.01, 0.99])\n        panel[col] = panel[col].clip(lo, hi)\n    \n    X = sm.add_constant(\n        panel[['lag_turnover1', 'log_assets', 'flow_ratio']]\n    )\n    model = sm.OLS(panel['pret'], X).fit(\n        cov_type='cluster',\n        cov_kwds={'groups': panel['shareholder_name']}\n    )\n    return {'model': model, 'n': len(panel)}\n```\n:::\n\n\n## Application 3: Foreign vs. Domestic Trading {#sec-app-foreign-domestic}\n\n::: {#foreign-domestic-comparison .cell execution_count=28}\n``` {.python .cell-code code-summary=\"Foreign vs. Domestic Trading Comparison\"}\ndef compare_foreign_domestic(\n    trades: pd.DataFrame, price_q: pd.DataFrame,\n) -> pd.DataFrame:\n    \"\"\"Compare trading patterns between foreign and domestic institutions.\"\"\"\n    _t = trades.merge(\n        price_q[['ticker', 'qdate', 'p']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    _t['dollar_trade'] = _t['trade'] * _t['p'] / 1e6\n    _t['is_buy'] = _t['trade'] > 0\n    \n    return (\n        _t[_t['owner_type'].isin(OwnershipType.INSTITUTIONAL)]\n        .groupby('owner_type')\n        .agg(\n            n_trades=('trade', 'count'),\n            n_buys=('is_buy', 'sum'),\n            avg_dollar=('dollar_trade', lambda x: x.abs().mean()),\n            net_buying=('dollar_trade', 'sum'),\n            pct_initiating=('buysale', lambda x: (x.abs() == 1).mean()),\n        )\n        .reset_index()\n    )\n```\n:::\n\n\n::: {#fig-cumulative-net-buying .cell execution_count=29}\n``` {.python .cell-code code-fold=\"true\"}\ndef plot_cumulative_net_buying(\n    trades: pd.DataFrame, price_q: pd.DataFrame\n):\n    _t = trades.merge(\n        price_q[['ticker', 'qdate', 'p']],\n        left_on=['ticker', 'rdate'],\n        right_on=['ticker', 'qdate'],\n        how='inner'\n    )\n    _t['trade_vnd'] = _t['trade'] * _t['p'] / 1e9\n    \n    inst = _t[_t['owner_type'].isin(OwnershipType.INSTITUTIONAL)]\n    net = (\n        inst.groupby(\n            [pd.Grouper(key='rdate', freq='QE'), 'owner_type']\n        )['trade_vnd'].sum().unstack(fill_value=0)\n    )\n    cum = net.cumsum()\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    for col in cum.columns:\n        ax.plot(cum.index, cum[col], label=col,\n                color=OWNER_COLORS.get(col, '#333'), linewidth=2)\n    ax.axhline(y=0, color='black', linewidth=0.5)\n    ax.set_title('Cumulative Net Institutional Buying', fontweight='bold')\n    ax.set_ylabel('Billions VND')\n    ax.legend(loc='best')\n    plt.tight_layout()\n    plt.show()\n```\n:::\n\n\n# Data Quality and Robustness {#sec-robustness}\n\n## Common Pitfalls {#sec-pitfalls}\n\n### Corporate Action Misadjustment\n\n::: callout-caution\n## Example: Phantom Trade from Unadjusted Stock Dividend\n\nVinamilk (VNM) issues a 20% stock dividend with ex-date March 15, 2023.\n\n-   Q4 2022: Fund X holds 1,000,000 shares of VNM\n-   Q1 2023: Fund X holds 1,200,000 shares of VNM\n\n**Without adjustment:** Inferred buy of +200,000 shares (BS = +2) **With adjustment:** Prior holdings become 1,200,000 adjusted shares, trade = 0\n\nThis phantom trade inflates measured turnover and creates spurious buying signals.\n:::\n\n### Disclosure Timing Mismatches\n\nVietnamese ownership disclosure dates may not align with calendar quarter ends. Our pipeline addresses this by aligning all disclosures to the nearest quarter-end.\n\n### Name Changes and Entity Mergers\n\nVietnamese institutions frequently rename. Without a stable identifier, the same entity may appear as two different shareholders, creating phantom entries/exits. We recommend maintaining a master entity mapping table.\n\n## Validation Checks {#sec-validation}\n\n::: {#validation .cell execution_count=30}\n``` {.python .cell-code code-summary=\"Data Quality Validation Suite\"}\ndef validate_pipeline_outputs(\n    results: Dict[str, pd.DataFrame],\n) -> pd.DataFrame:\n    \"\"\"Run comprehensive validation on pipeline outputs.\"\"\"\n    checks = []\n    h = results['holdings']\n    t = results['trades']\n    a = results['aggregates']\n    \n    checks.append({\n        'Check': 'No negative adjusted shares',\n        'Result': 'PASS' if (h['shares_adj'] < 0).sum() == 0 else 'FAIL',\n        'Detail': f'{(h[\"shares_adj\"] < 0).sum()} negative obs'\n    })\n    \n    checks.append({\n        'Check': 'No duplicate holdings',\n        'Result': 'PASS' if h.duplicated(\n            subset=['shareholder_name', 'ticker', 'rdate']\n        ).sum() == 0 else 'FAIL',\n    })\n    \n    checks.append({\n        'Check': 'Valid buysale codes only',\n        'Result': 'PASS' if t['buysale'].isin([1, 2, -1, -2]).all()\n        else 'FAIL',\n    })\n    \n    checks.append({\n        'Check': 'No zero trades',\n        'Result': 'PASS' if (t['trade'] == 0).sum() == 0 else 'FAIL',\n    })\n    \n    t1 = a['turnover1'].dropna()\n    checks.append({\n        'Check': 'Turnover1 in [0, 10]',\n        'Result': 'PASS' if ((t1 < 0) | (t1 > 10)).sum() == 0\n        else 'WARNING',\n        'Detail': f'{((t1<0)|(t1>10)).sum()} extreme values'\n    })\n    \n    first_rpt = a[a['first_report']]\n    checks.append({\n        'Check': 'First report -> missing netflows',\n        'Result': 'PASS' if first_rpt['netflows'].isna().all()\n        else 'FAIL',\n    })\n    \n    return pd.DataFrame(checks)\n\n# validate_pipeline_outputs(results)\n```\n:::\n\n\n# Summary {#sec-summary}\n\nThis chapter developed a framework for computing institutional trades, flows, and turnover ratios in the Vietnamese equity market. The key contributions include:\n\n1.  **Corporate action adjustment** for Vietnam's frequent stock dividends and bonus shares, preventing phantom trades that contaminate standard differencing.\n\n2.  **Four-way ownership taxonomy** (state, foreign institutional, domestic institutional, individual) capturing Vietnam's unique ownership landscape.\n\n3.  **FOL utilization analytics** for studying foreign ownership constraints absent from developed markets.\n\n4.  **Irregular disclosure handling** with correct gap splitting into terminating sales and initiating buys.\n\n5.  **Advanced extensions** including herding, demand persistence, and information content decomposition.\n\nThe pipeline produces several output datasets (@tbl-institutional-outputs)\n\n| Output | Grain | Key Variables | Use Cases |\n|:-----------------|:-----------------|:------------------|:-----------------|\n| `holdings` | Shareholder x Ticker x Quarter | `shares_adj`, `owner_type` | Cross-sectional ownership |\n| `io_ratios` | Ticker x Quarter | `io_state`, `io_foreign`, etc. | Governance, liquidity |\n| `trades` | Shareholder x Ticker x Quarter | `trade`, `buysale` | Informed trading, herding |\n| `aggregates` | Shareholder x Quarter | `assets`, `turnover`, `netflows` | Fund performance, flows |\n| `fol_analytics` | Ticker x Date | `fol_utilization`, `foreign_room` | FOL premium, foreign investment |\n\n: Summary of Pipeline Output Datasets {#tbl-institutional-outputs}\n\n<!-- # Exercises {#sec-exercises}\n\n1.  **Corporate Action Sensitivity.** Download corporate action data for VNM from DataCore.vn and compute the cumulative share adjustment factor from 2010 to 2024. How many phantom trades would be generated without adjustment? Plot the factor.\n\n2.  **FOL Binding and Returns.** Construct a long-short portfolio: long FOL-binding stocks ($\\text{FOL\\_Util} > 0.95$), short non-binding ($< 0.50$). What is the average quarterly return spread? Is it statistically significant?\n\n3.  **Herding Asymmetry.** Compute LSV herding separately for large-cap (HOSE top 50) and small-cap stocks. Is herding stronger in small caps? Compare buy vs. sell herding.\n\n4.  **State Divestment Events.** Identify quarters where SCIC conducted major divestments. What happens to breadth and foreign ownership post-divestment?\n\n5.  **Turnover Quintile Portfolios.** Sort investors by lagged Carhart turnover into quintiles. Compare returns: is the turnover-performance relation positive (information) or negative (costs) in Vietnam?\n\n6.  **Replication Exercise.** Replicate @chen2000value: do breadth changes predict future returns in the Vietnamese market? -->\n\n",
    "supporting": [
      "31_institutional_trade_flow_files"
    ],
    "filters": [],
    "includes": {}
  }
}