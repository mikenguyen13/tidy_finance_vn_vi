{
  "hash": "98ae4abe26428c9d9c72192dd0ce7946",
  "result": {
    "engine": "jupyter",
    "markdown": "# Dữ liệu Datacore\n\nChương này giới thiệu [Datacore](https://datacore.vn/), nền tảng dữ liệu của Việt Nam dành cho nghiên cứu học thuật, doanh nghiệp và chính phủ. Datacore cung cấp các bộ dữ liệu tài chính và kinh tế toàn diện, bao gồm dữ liệu giao dịch lịch sử, các yếu tố cơ bản của công ty và các chỉ số kinh tế vĩ mô thiết yếu cho nghiên cứu tài chính có thể tái tạo. Chúng ta sử dụng Datacore làm nguồn dữ liệu chính xuyên suốt cuốn sách này.\n\n## Các tùy chọn truy cập dữ liệu\n\nĐộc giả có thể truy cập dữ liệu được sử dụng trong cuốn sách này thông qua một số kênh sau:\n\n1. **Gói đăng ký dành cho tổ chức**: Nhiều trường đại học và viện nghiên cứu đăng ký sử dụng Datacore. Hãy liên hệ với thư viện hoặc văn phòng nghiên cứu của bạn để nhận thông tin đăng nhập. Nếu tổ chức của bạn chưa có gói đăng ký, hãy cân nhắc yêu cầu một gói thông qua quy trình mua sắm của thư viện — Datacore cung cấp giá ưu đãi cho mục đích học thuật.\n\n2. **Bộ dữ liệu demo**: Datacore cung cấp [bộ dữ liệu demo](https://datacore.vn/demo/dataset-groups) cho phép bạn chạy các ví dụ mã trong sách này với dữ liệu mẫu.\n\n## Tổng quan chương\n\nChương này được tổ chức như sau. Trước tiên, chúng ta thiết lập kết nối với cơ sở hạ tầng lưu trữ đám mây của Datacore. Sau đó, chúng ta tải xuống và chuẩn bị dữ liệu cơ bản của công ty, bao gồm các khoản mục bảng cân đối kế toán, các biến số báo cáo kết quả kinh doanh và các chỉ số phái sinh cần thiết cho nghiên cứu định giá tài sản. Tiếp theo, chúng ta truy xuất và xử lý dữ liệu giá cổ phiếu, tính toán lợi nhuận, vốn hóa thị trường và lợi nhuận vượt trội. Cuối cùng, chúng ta kết hợp các tập dữ liệu này và cung cấp số liệu thống kê mô tả đặc trưng cho thị trường chứng khoán Việt Nam.\n\n## Thiết lập môi trường\n\nChúng ta bắt đầu bằng cách tải các gói Python được sử dụng xuyên suốt chương này. Các gói cốt lõi bao gồm `pandas` để thao tác dữ liệu, `numpy` cho các phép toán số học và `sqlite3` để quản lý cơ sở dữ liệu cục bộ. Chúng ta cũng nhập các thư viện trực quan hóa để tạo ra các hình ảnh chất lượng cao phục vụ cho việc xuất bản.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nfrom datetime import datetime\nfrom io import BytesIO\n\nfrom plotnine import *\nfrom mizani.formatters import comma_format, percent_format\n```\n:::\n\n\nChúng ta thiết lập kết nối đến cơ sở dữ liệu SQLite cục bộ, đóng vai trò là kho lưu trữ trung tâm cho tất cả dữ liệu đã được xử lý. Cơ sở dữ liệu này đã được giới thiệu trong chương trước và sẽ lưu trữ các tập dữ liệu đã được làm sạch để sử dụng trong các phân tích tiếp theo.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntidy_finance = sqlite3.connect(database=\"data/tidy_finance_python.sqlite\")\n```\n:::\n\n\nChúng ta xác định phạm vi ngày tháng cho việc thu thập dữ liệu. Thị trường chứng khoán Việt Nam bắt đầu hoạt động vào tháng 7 năm 2000 với sự thành lập của Sở Giao dịch Chứng khoán Thành phố Hồ Chí Minh (HOSE), vì vậy giai đoạn mẫu của chúng ta bắt đầu từ năm 2000 và kéo dài đến hết năm 2024.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nstart_date = \"2000-01-01\"\nend_date = \"2024-12-31\"\n```\n:::\n\n\n## Kết nối với Datacore\n\nDatacore cung cấp dữ liệu thông qua hệ thống lưu trữ đối tượng dựa trên đám mây được xây dựng trên MinIO, một cơ sở hạ tầng lưu trữ tương thích với S3. Kiến trúc này cho phép truy cập hiệu quả, lập trình được vào các tập dữ liệu lớn mà không bị hạn chế bởi các kết nối cơ sở dữ liệu truyền thống. Để truy cập dữ liệu, bạn cần thông tin xác thực do Datacore cung cấp khi đăng ký: URL điểm cuối, khóa truy cập và khóa bí mật.\n\nLớp sau đây thiết lập kết nối với hệ thống lưu trữ của Datacore. Thông tin đăng nhập được lưu trữ dưới dạng biến môi trường để đảm bảo an toàn, tuân theo các thực tiễn tốt nhất về quản lý thông tin đăng nhập trong môi trường điện toán nghiên cứu.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport os\nimport boto3\nfrom botocore.client import Config\n\nclass DatacoreConnection:\n    \"\"\"\n    Connection handler for Datacore's MinIO-based storage system.\n    \n    This class manages authentication and provides methods for\n    accessing financial datasets stored in Datacore's cloud infrastructure.\n    \n    Attributes\n    ----------\n    s3 : boto3.client\n        S3-compatible client for interacting with Datacore storage\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize connection using environment variables.\"\"\"\n        self.MINIO_ENDPOINT = os.environ[\"MINIO_ENDPOINT\"]\n        self.MINIO_ACCESS_KEY = os.environ[\"MINIO_ACCESS_KEY\"]\n        self.MINIO_SECRET_KEY = os.environ[\"MINIO_SECRET_KEY\"]\n        self.REGION = os.getenv(\"MINIO_REGION\", \"us-east-1\")\n        \n        self.s3 = boto3.client(\n            \"s3\",\n            endpoint_url=self.MINIO_ENDPOINT,\n            aws_access_key_id=self.MINIO_ACCESS_KEY,\n            aws_secret_access_key=self.MINIO_SECRET_KEY,\n            region_name=self.REGION,\n            config=Config(signature_version=\"s3v4\"),\n        )\n    \n    def test_connection(self):\n        \"\"\"Verify connection by listing available buckets.\"\"\"\n        response = self.s3.list_buckets()\n        print(\"Connected successfully. Available buckets:\")\n        for bucket in response.get(\"Buckets\", []):\n            print(f\"  - {bucket['Name']}\")\n    \n    def list_objects(self, bucket_name, prefix=\"\"):\n        \"\"\"List objects in a bucket with optional prefix filter.\"\"\"\n        response = self.s3.list_objects_v2(\n            Bucket=bucket_name, \n            Prefix=prefix\n        )\n        return [obj[\"Key\"] for obj in response.get(\"Contents\", [])]\n    \n    def read_excel(self, bucket_name, key):\n        \"\"\"Read an Excel file from Datacore storage.\"\"\"\n        obj = self.s3.get_object(Bucket=bucket_name, Key=key)\n        return pd.read_excel(BytesIO(obj[\"Body\"].read()))\n    \n    def read_csv(self, bucket_name, key, **kwargs):\n        \"\"\"Read a CSV file from Datacore storage.\"\"\"\n        obj = self.s3.get_object(Bucket=bucket_name, Key=key)\n        return pd.read_csv(BytesIO(obj[\"Body\"].read()), **kwargs)\n```\n:::\n\n\nSau khi định nghĩa lớp kết nối, chúng ta có thể thiết lập kết nối và xác minh quyền truy cập vào các kho dữ liệu của Datacore.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Initialize connection\nconn = DatacoreConnection()\nconn.test_connection()\n\n# Get bucket name from environment\nbucket_name = os.environ[\"MINIO_BUCKET\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConnected successfully. Available buckets:\n  - dsteam-data\n  - rawbctc\n```\n:::\n:::\n\n\n## Dữ liệu cơ bản của công ty\n\nDữ liệu kế toán của các công ty là yếu tố thiết yếu cho việc phân tích danh mục đầu tư, xây dựng yếu tố và nghiên cứu định giá. Datacore cung cấp dữ liệu cơ bản toàn diện cho các công ty niêm yết của Việt Nam, bao gồm báo cáo tài chính hàng năm và hàng quý được lập theo Chuẩn mực Kế toán Việt Nam (VAS).\n\n### Hiểu về Báo cáo Tài chính Việt Nam\n\nTrước khi xử lý dữ liệu, điều quan trọng là phải hiểu cấu trúc của báo cáo tài chính Việt Nam. Các công ty Việt Nam tuân theo Chuẩn mực kế toán Việt Nam (VAS), có nhiều điểm tương đồng với Chuẩn mực báo cáo tài chính quốc tế (IFRS) nhưng cũng có những khác biệt đáng chú ý:\n\n1. **Năm tài chính**: Hầu hết các công ty Việt Nam sử dụng năm tài chính theo lịch dương, kết thúc vào ngày 31 tháng 12, mặc dù một số công ty (đặc biệt là trong lĩnh vực bán lẻ và nông nghiệp) sử dụng năm tài chính kết thúc vào ngày khác.\n\n2. **Tần suất báo cáo**: Các công ty niêm yết phải công bố báo cáo tài chính hàng quý trong vòng 20 ngày kể từ ngày kết thúc quý và báo cáo kiểm toán hàng năm trong vòng 90 ngày kể từ ngày kết thúc năm tài chính.\n\n3. **Các định dạng đặc thù theo ngành**: Các công ty trong lĩnh vực ngân hàng, bảo hiểm và chứng khoán tuân theo các định dạng báo cáo chuyên biệt, khác với định dạng tiêu chuẩn của ngành.\n\n4. **Tiền tệ**: Tất cả các số liệu được báo cáo bằng Đồng Việt Nam (VND). Do giá trị danh nghĩa lớn (hàng triệu đến hàng nghìn tỷ VND), chúng ta thường quy đổi các số liệu thành hàng triệu hoặc hàng tỷ để dễ đọc hơn.\n\n### Tải xuống dữ liệu cơ bản\n\nDatacore tổ chức dữ liệu cơ bản trong các tệp Excel được phân vùng theo khoảng thời gian để truy cập hiệu quả. Chúng ta tải xuống và ghép nối các tệp này để tạo ra một tập dữ liệu toàn diện bao gồm toàn bộ giai đoạn mẫu của chúng ta.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Define paths to fundamentals data files\nfundamentals_paths = [\n    \"fundamental_annual_1767674486317/fundamental_annual_1.xlsx\",\n    \"fundamental_annual_1767674486317/fundamental_annual_2.xlsx\",\n    \"fundamental_annual_1767674486317/fundamental_annual_3.xlsx\",\n]\n\n# Download and combine all files\nfundamentals_list = []\nfor path in fundamentals_paths:\n    df_temp = conn.read_excel(bucket_name, path)\n    fundamentals_list.append(df_temp)\n    print(f\"Downloaded: {path} ({len(df_temp):,} rows)\")\n\ndf_fundamentals_raw = pd.concat(fundamentals_list, ignore_index=True)\nprint(f\"\\nTotal observations: {len(df_fundamentals_raw):,}\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/mikenguyen/project/tidyfinance/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloaded: fundamental_annual_1767674486317/fundamental_annual_1.xlsx (10,000 rows)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/mikenguyen/project/tidyfinance/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloaded: fundamental_annual_1767674486317/fundamental_annual_2.xlsx (10,000 rows)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/mikenguyen/project/tidyfinance/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloaded: fundamental_annual_1767674486317/fundamental_annual_3.xlsx (2,821 rows)\n\nTotal observations: 22,821\n```\n:::\n:::\n\n\n### Nguyên tắc cơ bản về vệ sinh và tiêu chuẩn hóa\n\nDữ liệu cơ bản thô cần trải qua nhiều bước làm sạch để đảm bảo tính nhất quán và khả năng sử dụng. Chúng ta chuẩn hóa tên biến, xử lý các giá trị thiếu và tạo ra các biến dẫn xuất thường được sử dụng trong nghiên cứu định giá tài sản.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef clean_fundamentals(df):\n    \"\"\"\n    Clean and standardize company fundamentals data.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Raw fundamentals data from Datacore\n    \n    Returns\n    -------\n    pd.DataFrame\n        Cleaned fundamentals with standardized column names\n    \"\"\"\n    df = df.copy()\n    \n    # Standardize identifiers\n    df[\"symbol\"] = df[\"symbol\"].astype(str).str.upper().str.strip()\n    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n    \n    # Drop rows with missing identifiers\n    df = df.dropna(subset=[\"symbol\", \"year\"])\n    \n    # Define columns that should be numeric\n    numeric_columns = [\n        \"total_asset\", \"total_equity\", \"total_liabilities\",\n        \"total_current_asset\", \"total_current_liabilities\",\n        \"is_net_revenue\", \"is_cogs\", \"is_manage_expense\",\n        \"is_interest_expense\", \"is_eat\", \"is_net_business_profit\",\n        \"na_tax_deferred\", \"nl_tax_deferred\", \"e_preferred_stock\",\n        \"capex\", \"total_cfo\", \"ca_cce\", \"ca_total_inventory\",\n        \"ca_acc_receiv\", \"cfo_interest_expense\", \"basic_eps\",\n        \"is_shareholders_eat\", \"cl_loan\", \"cl_finlease\",\n        \"cl_due_long_debt\", \"nl_loan\", \"nl_finlease\",\n        \"is_cos_of_sales\", \"e_equity\"\n    ]\n    \n    for col in numeric_columns:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n    \n    # Handle duplicates: keep row with most non-missing values\n    df[\"_completeness\"] = df.notna().sum(axis=1)\n    df = (df\n        .sort_values([\"symbol\", \"year\", \"_completeness\"])\n        .drop_duplicates(subset=[\"symbol\", \"year\"], keep=\"last\")\n        .drop(columns=\"_completeness\")\n        .reset_index(drop=True)\n    )\n    \n    return df\n\ndf_fundamentals = clean_fundamentals(df_fundamentals_raw)\nprint(f\"After cleaning: {len(df_fundamentals):,} firm-year observations\")\nprint(f\"Unique firms: {df_fundamentals['symbol'].nunique():,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAfter cleaning: 21,232 firm-year observations\nUnique firms: 1,554\n```\n:::\n:::\n\n\n### Tạo các biến chuẩn hóa\n\nĐể tạo điều kiện so sánh với các nghiên cứu quốc tế và đảm bảo tính tương thích với các phương pháp định giá tài sản tiêu chuẩn, chúng ta tạo ra các biến số theo các quy ước đã được thiết lập trong tài liệu học thuật. Chúng ta đối chiếu các khoản mục báo cáo tài chính của Việt Nam với các giá trị tương đương trong Compustat khi có thể.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef create_standard_variables(df):\n    \"\"\"\n    Create standardized financial variables for asset pricing research.\n    \n    This function maps Vietnamese financial statement items to standard\n    variable names used in the academic finance literature, following\n    conventions from Fama and French (1992, 1993, 2015).\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Cleaned fundamentals data\n    \n    Returns\n    -------\n    pd.DataFrame\n        Fundamentals with standardized variables added\n    \"\"\"\n    df = df.copy()\n    \n    # Fiscal date (assume December year-end)\n    df[\"datadate\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-12-31\")\n    \n    # === Balance Sheet Items ===\n    df[\"at\"] = df[\"total_asset\"]                    # Total assets\n    df[\"lt\"] = df[\"total_liabilities\"]              # Total liabilities\n    df[\"seq\"] = df[\"total_equity\"]                  # Stockholders' equity\n    df[\"act\"] = df[\"total_current_asset\"]           # Current assets\n    df[\"lct\"] = df[\"total_current_liabilities\"]     # Current liabilities\n    \n    # Common equity (fallback to total equity if not available)\n    df[\"ceq\"] = df.get(\"e_equity\", df[\"seq\"])\n    \n    # === Deferred Taxes ===\n    df[\"txditc\"] = df.get(\"na_tax_deferred\", 0).fillna(0)  # Deferred tax assets\n    df[\"txdb\"] = df.get(\"nl_tax_deferred\", 0).fillna(0)    # Deferred tax liab.\n    df[\"itcb\"] = 0  # Investment tax credit (rare in Vietnam)\n    \n    # === Preferred Stock ===\n    pref = df.get(\"e_preferred_stock\", 0)\n    if isinstance(pref, pd.Series):\n        pref = pref.fillna(0)\n    df[\"pstk\"] = pref\n    df[\"pstkrv\"] = pref  # Redemption value\n    df[\"pstkl\"] = pref   # Liquidating value\n    \n    # === Income Statement Items ===\n    df[\"sale\"] = df[\"is_net_revenue\"]                        # Net sales/revenue\n    df[\"cogs\"] = df.get(\"is_cogs\", 0).fillna(0)              # Cost of goods sold\n    df[\"xsga\"] = df.get(\"is_manage_expense\", 0).fillna(0)    # SG&A expenses\n    df[\"xint\"] = df.get(\"is_interest_expense\", 0).fillna(0)  # Interest expense\n    df[\"ni\"] = df.get(\"is_eat\", np.nan)                      # Net income\n    df[\"oibdp\"] = df.get(\"is_net_business_profit\", np.nan)   # Operating income\n    \n    # === Cash Flow Items ===\n    df[\"oancf\"] = df.get(\"total_cfo\", np.nan)  # Operating cash flow\n    df[\"capx\"] = df.get(\"capex\", np.nan)       # Capital expenditures\n    \n    return df\n\ndf_fundamentals = create_standard_variables(df_fundamentals)\n```\n:::\n\n\n### Tính toán giá trị sổ sách và lợi nhuận\n\nGiá trị sổ sách là một biến số quan trọng đối với các chiến lược đầu tư giá trị và việc xây dựng danh mục đầu tư theo yếu tố HML (Cao Trừ Thấp). Chúng ta tuân theo định nghĩa từ thư viện dữ liệu của Kenneth French, có tính đến thuế hoãn lại và cổ phiếu ưu đãi.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef compute_book_equity(df):\n    \"\"\"\n    Compute book equity following Fama-French conventions.\n    \n    Book equity = Stockholders' equity \n                  + Deferred taxes and investment tax credit\n                  - Preferred stock\n    \n    Negative or zero book equity is set to missing, as book-to-market\n    ratios are undefined for such firms.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Fundamentals with standardized variables\n    \n    Returns\n    -------\n    pd.DataFrame\n        Fundamentals with book equity (be) added\n    \"\"\"\n    df = df.copy()\n    \n    # Primary measure: stockholders' equity\n    # Fallback 1: common equity + preferred stock\n    # Fallback 2: total assets - total liabilities\n    seq_measure = (df[\"seq\"]\n        .combine_first(df[\"ceq\"] + df[\"pstk\"])\n        .combine_first(df[\"at\"] - df[\"lt\"])\n    )\n    \n    # Add deferred taxes\n    deferred_taxes = (df[\"txditc\"]\n        .combine_first(df[\"txdb\"] + df[\"itcb\"])\n        .fillna(0)\n    )\n    \n    # Subtract preferred stock (use redemption value as primary)\n    preferred = (df[\"pstkrv\"]\n        .combine_first(df[\"pstkl\"])\n        .combine_first(df[\"pstk\"])\n        .fillna(0)\n    )\n    \n    # Book equity calculation\n    df[\"be\"] = seq_measure + deferred_taxes - preferred\n    \n    # Set non-positive book equity to missing\n    df[\"be\"] = df[\"be\"].where(df[\"be\"] > 0, np.nan)\n    \n    return df\n\ndf_fundamentals = compute_book_equity(df_fundamentals)\n\n# Summary statistics for book equity\nprint(\"Book Equity Summary Statistics (in million VND):\")\nprint(df_fundamentals[\"be\"].describe().round(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBook Equity Summary Statistics (in million VND):\ncount    2.023500e+04\nmean     1.031884e+12\nstd      4.705269e+12\nmin      4.404402e+07\n25%      7.267610e+10\n50%      1.803885e+11\n75%      5.304653e+11\nmax      1.836314e+14\nName: be, dtype: float64\n```\n:::\n:::\n\n\nLợi nhuận hoạt động, được giới thiệu bởi @fama2015five, đo lường lợi nhuận của một công ty so với vốn chủ sở hữu trên sổ sách. Các công ty có lợi nhuận hoạt động cao hơn thường có tỷ suất sinh lời kỳ vọng cao hơn.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef compute_profitability(df):\n    \"\"\"\n    Compute operating profitability following Fama-French (2015).\n    \n    Operating profitability = (Revenue - COGS - SG&A - Interest) / Book Equity\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Fundamentals with book equity computed\n    \n    Returns\n    -------\n    pd.DataFrame\n        Fundamentals with operating profitability (op) added\n    \"\"\"\n    df = df.copy()\n    \n    # Operating profit before taxes\n    operating_profit = (\n        df[\"sale\"] \n        - df[\"cogs\"].fillna(0) \n        - df[\"xsga\"].fillna(0) \n        - df[\"xint\"].fillna(0)\n    )\n    \n    # Scale by book equity\n    df[\"op\"] = operating_profit / df[\"be\"]\n    \n    # Winsorize extreme values (outside 1st and 99th percentiles)\n    lower = df[\"op\"].quantile(0.01)\n    upper = df[\"op\"].quantile(0.99)\n    df[\"op\"] = df[\"op\"].clip(lower=lower, upper=upper)\n    \n    return df\n\ndf_fundamentals = compute_profitability(df_fundamentals)\n```\n:::\n\n\n### Tính toán Đầu tư\n\nĐầu tư, được đo lường bằng sự tăng trưởng tài sản, nắm bắt hành vi đầu tư của các công ty. @fama2015five ghi nhận rằng các công ty có tốc độ tăng trưởng tài sản cao (đầu tư tháo vát) thường có tỷ suất sinh lời trong tương lai thấp hơn.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndef compute_investment(df):\n    \"\"\"\n    Compute investment (asset growth) following Fama-French (2015).\n    \n    Investment = (Total Assets_t / Total Assets_{t-1}) - 1\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Fundamentals data\n    \n    Returns\n    -------\n    pd.DataFrame\n        Fundamentals with investment (inv) added\n    \"\"\"\n    df = df.copy()\n    \n    # Create lagged assets\n    df_lag = (df[[\"symbol\", \"year\", \"at\"]]\n        .assign(year=lambda x: x[\"year\"] + 1)\n        .rename(columns={\"at\": \"at_lag\"})\n    )\n    \n    # Merge lagged values\n    df = df.merge(df_lag, on=[\"symbol\", \"year\"], how=\"left\")\n    \n    # Compute investment (asset growth)\n    df[\"inv\"] = df[\"at\"] / df[\"at_lag\"] - 1\n    \n    # Set to missing if lagged assets non-positive\n    df[\"inv\"] = df[\"inv\"].where(df[\"at_lag\"] > 0, np.nan)\n    \n    return df\n\ndf_fundamentals = compute_investment(df_fundamentals)\n```\n:::\n\n\n### Tính toán tổng nợ\n\nTrong báo cáo tài chính của Việt Nam, tổng nợ phải trả bao gồm các khoản mục không sinh lãi như khoản phải trả cho nhà cung cấp và thuế phải trả. Để phân tích đòn bẩy, chúng ta tính tổng nợ có lãi bằng cách cộng gộp các khoản vay và nghĩa vụ thuê.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef compute_total_debt(df):\n    \"\"\"\n    Compute total interest-bearing debt.\n    \n    Total Debt = Short-term loans + Finance leases (current)\n                 + Current portion of long-term debt\n                 + Long-term loans + Finance leases (non-current)\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Fundamentals data\n    \n    Returns\n    -------\n    pd.DataFrame\n        Fundamentals with total_debt added\n    \"\"\"\n    df = df.copy()\n    \n    df[\"total_debt\"] = (\n        df.get(\"cl_loan\", 0).fillna(0) +           # Short-term bank loans\n        df.get(\"cl_finlease\", 0).fillna(0) +       # Current finance leases\n        df.get(\"cl_due_long_debt\", 0).fillna(0) +  # Current portion LT debt\n        df.get(\"nl_loan\", 0).fillna(0) +           # Long-term bank loans\n        df.get(\"nl_finlease\", 0).fillna(0)         # Non-current finance leases\n    )\n    \n    return df\n\ndf_fundamentals = compute_total_debt(df_fundamentals)\n```\n:::\n\n\n### Áp dụng bộ lọc\n\nChúng ta áp dụng các bộ lọc tiêu chuẩn để đảm bảo chất lượng dữ liệu: yêu cầu tài sản dương, doanh số bán hàng không âm và sự hiện diện của các biến cốt lõi cần thiết để xây dựng danh mục đầu tư.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Keep only observations with required variables\nrequired_vars = [\"at\", \"lt\", \"seq\", \"sale\"]\ncomp_vn = df_fundamentals.dropna(subset=required_vars)\n\n# Apply quality filters\ncomp_vn = comp_vn.query(\"at > 0\")      # Positive assets\ncomp_vn = comp_vn.query(\"sale >= 0\")   # Non-negative sales\n\n# Keep last observation per firm-year (in case of restatements)\ncomp_vn = (comp_vn\n    .sort_values(\"datadate\")\n    .groupby([\"symbol\", \"year\"])\n    .tail(1)\n    .reset_index(drop=True)\n)\n\n# Diagnostic summary\nprint(f\"Final sample: {len(comp_vn):,} firm-year observations\")\nprint(f\"Unique firms: {comp_vn['symbol'].nunique():,}\")\nprint(f\"Sample period: {comp_vn['year'].min()} - {comp_vn['year'].max()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal sample: 20,091 firm-year observations\nUnique firms: 1,502\nSample period: 1998 - 2023\n```\n:::\n:::\n\n\n### Lưu trữ dữ liệu\n\nChúng ta lưu trữ dữ liệu cơ bản đã chuẩn bị trong cơ sở dữ liệu SQLite cục bộ để sử dụng trong các chương tiếp theo.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ncomp_vn.to_sql(\n    name=\"comp_vn\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\n\nprint(\"Company fundamentals saved to database.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompany fundamentals saved to database.\n```\n:::\n:::\n\n\n## Dữ liệu giá cổ phiếu\n\nDữ liệu giá cổ phiếu là nền tảng của các phân tích dựa trên lợi nhuận trong tài chính thực nghiệm. Datacore cung cấp dữ liệu giá lịch sử toàn diện cho tất cả các chứng khoán được giao dịch trên HOSE, HNX và UPCoM, bao gồm cả giá điều chỉnh có tính đến các hành động của công ty.\n\n### Tải xuống dữ liệu giá\n\nChúng ta tải xuống dữ liệu giá lịch sử từ hệ thống lưu trữ của Datacore. Dữ liệu bao gồm các quan sát hàng ngày với giá mở cửa, giá cao nhất, giá thấp nhất, giá đóng cửa, khối lượng giao dịch và các yếu tố điều chỉnh.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Download historical price data\nprices_raw = conn.read_csv(\n    bucket_name,\n    \"historycal_price/dataset_historical_price.csv\",\n    low_memory=False\n)\n\nprint(f\"Downloaded {len(prices_raw):,} daily price observations\")\nprint(f\"Date range: {prices_raw['date'].min()} to {prices_raw['date'].max()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloaded 4,307,791 daily price observations\nDate range: 2010-01-04 to 2025-05-12\n```\n:::\n:::\n\n\n### Xử lý dữ liệu giá\n\nChúng ta làm sạch dữ liệu giá và tính toán giá điều chỉnh có tính đến việc chia tách cổ phiếu, cổ tức bằng cổ phiếu và các hành động khác của công ty.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ndef process_price_data(df):\n    \"\"\"\n    Process raw price data from Datacore.\n    \"\"\"\n    df = df.copy()\n    \n    # Parse dates\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    \n    # Standardize column names\n    df = df.rename(columns={\n        \"open_price\": \"open\",\n        \"high_price\": \"high\",\n        \"low_price\": \"low\",\n        \"close_price\": \"close\",\n        \"vol_total\": \"volume\"\n    })\n    \n    # Compute adjusted close price\n    df[\"adjusted_close\"] = df[\"close\"] * df[\"adj_ratio\"]\n    \n    # Standardize symbol\n    df[\"symbol\"] = df[\"symbol\"].astype(str).str.upper().str.strip()\n    \n    # Sort for return calculation\n    df = df.sort_values([\"symbol\", \"date\"])\n    \n    # Add year and month\n    df[\"year\"] = df[\"date\"].dt.year\n    df[\"month\"] = df[\"date\"].dt.month\n    \n    return df\n\nprices = process_price_data(prices_raw)\n```\n:::\n\n\n### Tính toán Số lượng Cổ phiếu Hoạt động và Giá trị Thị trường\n\nGiá trị thị trường được tính bằng sản phẩm của giá và số lượng cổ phiếu hoạt động. Vì Datacore cung cấp lợi nhuận trên mỗi cổ phiếu và lợi nhuận sau thuế, chúng ta có thể suy ra số lượng cổ phiếu hoạt động từ các biến số này.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ndef compute_shares_outstanding(fundamentals_df):\n    \"\"\"\n    Compute shares outstanding from fundamentals.\n    \"\"\"\n    shares = fundamentals_df.copy()\n    shares[\"shrout\"] = shares[\"is_shareholders_eat\"] / shares[\"basic_eps\"]\n    shares = shares[[\"symbol\", \"year\", \"shrout\"]].dropna()\n    \n    return shares\n\nshares_outstanding = compute_shares_outstanding(df_fundamentals)\n```\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndef add_market_cap(df, shares_df):\n    \"\"\"\n    Add market capitalization to price data.\n    \"\"\"\n    df = df.merge(shares_df, on=[\"symbol\", \"year\"], how=\"left\")\n    \n    # Compute market cap (in million VND)\n    df[\"mktcap\"] = (df[\"close\"] * df[\"shrout\"]) / 1_000_000\n    \n    # Set zero or negative market cap to missing\n    df[\"mktcap\"] = df[\"mktcap\"].where(df[\"mktcap\"] > 0, np.nan)\n    \n    return df\n\nprices = add_market_cap(prices, shares_outstanding)\n```\n:::\n\n\n### Tính Lợi Nhuận và Lợi Nhuận Kỳ Lượng\nChúng ta tính toán lợi nhuận sử dụng giá đóng cửa điều chỉnh để đảm bảo lợi nhuận phản ánh chính xác lợi nhuận tổng của cổ đông bao gồm cả cổ tức và các hành động của công ty.\n\n#### Tạo Bộ Dữ Liệu Hàng Ngày\n\n1. Phiên bản tuần tự\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ndef create_daily_dataset(df, annual_rf=0.04):\n    \"\"\"\n    Create daily price dataset with returns and excess returns.\n    \"\"\"\n    df = df.copy()\n    \n    # Sort by symbol and date (critical for correct return calculation)\n    df = df.sort_values([\"symbol\", \"date\"]).reset_index(drop=True)\n    \n    # Remove duplicate dates within each symbol (keep last observation)\n    df = df.drop_duplicates(subset=[\"symbol\", \"date\"], keep=\"last\")\n    \n    # Compute daily returns\n    df[\"ret\"] = df.groupby(\"symbol\")[\"adjusted_close\"].pct_change()\n    \n    # Cap extreme negative returns\n    df[\"ret\"] = df[\"ret\"].clip(lower=-0.99)\n    \n    # Daily risk-free rate (assuming 252 trading days)\n    df[\"risk_free\"] = annual_rf / 252\n    \n    # Excess returns\n    df[\"ret_excess\"] = df[\"ret\"] - df[\"risk_free\"]\n    df[\"ret_excess\"] = df[\"ret_excess\"].clip(lower=-1.0)\n    \n    # Lagged market cap\n    df[\"mktcap_lag\"] = df.groupby(\"symbol\")[\"mktcap\"].shift(1)\n    \n    return df\n\nprices_daily = create_daily_dataset(prices)\n```\n:::\n\n\n2. Phiên bản song song\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nfrom joblib import Parallel, delayed\nimport os\n\ndef process_daily_symbol(symbol_df, annual_rf=0.04):\n    \"\"\"\n    Process a single symbol's daily data.\n    \"\"\"\n    df = symbol_df.copy()\n    \n    # Sort by date (critical for correct return calculation)\n    df = df.sort_values(\"date\").reset_index(drop=True)\n    \n    # Remove duplicate dates (keep last observation if duplicates exist)\n    df = df.drop_duplicates(subset=[\"date\"], keep=\"last\")\n    \n    # Compute daily returns\n    df[\"ret\"] = df[\"adjusted_close\"].pct_change()\n\n    # Replace infinite values with NaN\n    df[\"ret\"] = df[\"ret\"].replace([np.inf, -np.inf], np.nan)\n    \n    # Cap extreme negative returns\n    df[\"ret\"] = df[\"ret\"].clip(lower=-0.99)\n    \n    # Daily risk-free rate\n    df[\"risk_free\"] = annual_rf / 252\n    \n    # Excess returns\n    df[\"ret_excess\"] = df[\"ret\"] - df[\"risk_free\"]\n    df[\"ret_excess\"] = df[\"ret_excess\"].clip(lower=-1.0)\n    \n    # Lagged market cap\n    df[\"mktcap_lag\"] = df[\"mktcap\"].shift(1)\n    \n    return df\n\ndef create_daily_dataset_parallel(df, annual_rf=0.04):\n    \"\"\"\n    Create daily price dataset using parallel processing.\n    \"\"\"\n    # Ensure data is sorted before splitting\n    df = df.sort_values([\"symbol\", \"date\"])\n    \n    # Split by symbol\n    symbol_groups = [group for _, group in df.groupby(\"symbol\")]\n    \n    n_jobs = max(1, os.cpu_count() - 1)\n    print(f\"Processing {len(symbol_groups):,} symbols using {n_jobs} cores...\")\n    \n    results = Parallel(n_jobs=n_jobs, verbose=1)(\n        delayed(process_daily_symbol)(group, annual_rf) \n        for group in symbol_groups\n    )\n    \n    return pd.concat(results, ignore_index=True)\n\nprices_daily = create_daily_dataset_parallel(prices)\n\n# Quick validation\nprint(\"\\nValidation checks:\")\nprint(f\"Any duplicate (symbol, date): {prices_daily.duplicated(subset=['symbol', 'date']).sum()}\")\nprint(f\"Sample of non-zero returns:\")\nprint(prices_daily[prices_daily[\"ret\"] != 0][[\"symbol\", \"date\", \"adjusted_close\", \"ret\"]].head(10))\n\n\nprices_daily.query(\"symbol == 'FPT'\")[[\"symbol\", \"date\", \"adjusted_close\", \"ret\"]].head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing 1,837 symbols using 87 cores...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n[Parallel(n_jobs=87)]: Using backend LokyBackend with 87 concurrent workers.\n[Parallel(n_jobs=87)]: Done  26 tasks      | elapsed:    8.1s\n[Parallel(n_jobs=87)]: Done 276 tasks      | elapsed:   10.6s\n[Parallel(n_jobs=87)]: Done 626 tasks      | elapsed:   11.7s\n[Parallel(n_jobs=87)]: Done 1076 tasks      | elapsed:   13.6s\n[Parallel(n_jobs=87)]: Done 1626 tasks      | elapsed:   15.9s\n[Parallel(n_jobs=87)]: Done 1837 out of 1837 | elapsed:   16.6s finished\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nValidation checks:\nAny duplicate (symbol, date): 0\nSample of non-zero returns:\n   symbol       date  adjusted_close       ret\n0     A32 2018-10-23       44.574418       NaN\n27    A32 2018-11-29       55.072640  0.235521\n30    A32 2018-12-04       48.188560 -0.125000\n43    A32 2018-12-21       51.974804  0.078571\n49    A32 2019-01-02       55.072640  0.059603\n53    A32 2019-01-08       50.030370 -0.091557\n74    A32 2019-02-13       44.289180 -0.114754\n75    A32 2019-02-14       41.008500 -0.074074\n78    A32 2019-02-19       36.087480 -0.120000\n91    A32 2019-03-08       41.336568  0.145455\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>date</th>\n      <th>adjusted_close</th>\n      <th>ret</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1146076</th>\n      <td>FPT</td>\n      <td>2010-01-04</td>\n      <td>1170.9885</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1146077</th>\n      <td>FPT</td>\n      <td>2010-01-05</td>\n      <td>1170.9885</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1146078</th>\n      <td>FPT</td>\n      <td>2010-01-06</td>\n      <td>1149.6978</td>\n      <td>-0.018182</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# Select columns\ndaily_columns = [\n    \"symbol\", \"date\", \"year\", \"month\",\n    \"open\", \"high\", \"low\", \"close\", \"volume\",\n    \"adjusted_close\", \"shrout\", \"mktcap\", \"mktcap_lag\",\n    \"ret\", \"risk_free\", \"ret_excess\"\n]\nprices_daily = prices_daily[daily_columns]\n\n# Remove observations with missing essential variables\nprices_daily = prices_daily.dropna(subset=[\"ret_excess\", \"mktcap\", \"mktcap_lag\"])\n\nprint(\"Daily Return Summary Statistics:\")\nprint(prices_daily[\"ret\"].describe().round(4))\nprint(f\"\\nFinal daily sample: {len(prices_daily):,} observations\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDaily Return Summary Statistics:\ncount    3.462157e+06\nmean     3.000000e-04\nstd      4.480000e-02\nmin     -9.900000e-01\n25%     -4.900000e-03\n50%      0.000000e+00\n75%      4.000000e-03\nmax      3.250000e+01\nName: ret, dtype: float64\n\nFinal daily sample: 3,462,157 observations\n```\n:::\n:::\n\n\n#### Tạo Dữ liệu Tháng\n\nĐối với lợi nhuận hàng tháng, chúng ta tính toán lợi nhuận trực tiếp từ giá điều chỉnh cuối tháng thay vì lãi kép lợi nhuận hàng ngày. Điều này tránh được sai sót do lãi kép từ các ngày thiếu và là phương pháp tiêu chuẩn trong tài chính thực nghiệm.\n\n1. Phiên bản tuần tự\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ndef create_monthly_dataset(df, annual_rf=0.04):\n    \"\"\"\n    Create monthly price dataset with returns computed from \n    month-end to month-end adjusted prices.\n    \"\"\"\n    df = df.copy()\n    \n    # Sort by symbol and date (critical for correct return calculation)\n    df = df.sort_values([\"symbol\", \"date\"]).reset_index(drop=True)\n    \n    # Remove duplicate dates within each symbol (keep last observation)\n    df = df.drop_duplicates(subset=[\"symbol\", \"date\"], keep=\"last\")\n    \n    # Get month-end observations\n    monthly = (df\n        .groupby(\"symbol\")\n        .resample(\"ME\", on=\"date\")\n        .agg({\n            \"open\": \"first\",           # First day open\n            \"high\": \"max\",             # Monthly high\n            \"low\": \"min\",              # Monthly low\n            \"close\": \"last\",           # Last day close\n            \"volume\": \"sum\",           # Total monthly volume\n            \"adjusted_close\": \"last\",  # Month-end adjusted price\n            \"shrout\": \"last\",          # Month-end shares outstanding\n            \"mktcap\": \"last\",          # Month-end market cap\n            \"year\": \"last\",\n            \"month\": \"last\"\n        })\n        .reset_index()\n    )\n    \n    # Remove duplicate (symbol, date) after resampling (safety check)\n    monthly = monthly.drop_duplicates(subset=[\"symbol\", \"date\"], keep=\"last\")\n    \n    # Sort again after resampling\n    monthly = monthly.sort_values([\"symbol\", \"date\"]).reset_index(drop=True)\n    \n    # Compute monthly returns from month-end to month-end adjusted prices\n    monthly[\"ret\"] = monthly.groupby(\"symbol\")[\"adjusted_close\"].pct_change()\n    \n    # Cap extreme returns\n    monthly[\"ret\"] = monthly[\"ret\"].clip(lower=-0.99)\n    \n    # Monthly risk-free rate\n    monthly[\"risk_free\"] = annual_rf / 12\n    \n    # Excess returns\n    monthly[\"ret_excess\"] = monthly[\"ret\"] - monthly[\"risk_free\"]\n    monthly[\"ret_excess\"] = monthly[\"ret_excess\"].clip(lower=-1.0)\n    \n    # Lagged market cap for portfolio weighting\n    monthly[\"mktcap_lag\"] = monthly.groupby(\"symbol\")[\"mktcap\"].shift(1)\n    \n    return monthly\n\nprices_monthly = create_monthly_dataset(prices)\n```\n:::\n\n\n2. Phiên bản song song\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nfrom joblib import Parallel, delayed\nimport os\n\ndef process_monthly_symbol(symbol_df, annual_rf=0.04):\n    \"\"\"\n    Process a single symbol's data to monthly frequency.\n    \"\"\"\n    df = symbol_df.copy()\n    \n    # Sort by date (critical for correct return calculation)\n    df = df.sort_values(\"date\").reset_index(drop=True)\n    \n    # Remove duplicate dates (keep last observation if duplicates exist)\n    df = df.drop_duplicates(subset=[\"date\"], keep=\"last\")\n    \n    # Set date as index for resampling\n    df = df.set_index(\"date\")\n    \n    # Resample to monthly\n    monthly = df.resample(\"ME\").agg({\n        \"symbol\": \"last\",\n        \"open\": \"first\",\n        \"high\": \"max\",\n        \"low\": \"min\",\n        \"close\": \"last\",\n        \"volume\": \"sum\",\n        \"adjusted_close\": \"last\",\n        \"shrout\": \"last\",\n        \"mktcap\": \"last\",\n        \"year\": \"last\",\n        \"month\": \"last\"\n    }).reset_index()\n    \n    # Remove rows where symbol is NaN (months with no trading)\n    monthly = monthly.dropna(subset=[\"symbol\"])\n    \n    # Sort by date\n    monthly = monthly.sort_values(\"date\").reset_index(drop=True)\n    \n    # Compute monthly returns\n    monthly[\"ret\"] = monthly[\"adjusted_close\"].pct_change()\n    \n    # Replace infinite values with NaN\n    monthly[\"ret\"] = monthly[\"ret\"].replace([np.inf, -np.inf], np.nan)\n    \n    # Cap extreme returns\n    monthly[\"ret\"] = monthly[\"ret\"].clip(lower=-0.99)\n    \n    # Monthly risk-free rate\n    monthly[\"risk_free\"] = annual_rf / 12\n    \n    # Excess returns\n    monthly[\"ret_excess\"] = monthly[\"ret\"] - monthly[\"risk_free\"]\n    monthly[\"ret_excess\"] = monthly[\"ret_excess\"].clip(lower=-1.0)\n    \n    # Lagged market cap\n    monthly[\"mktcap_lag\"] = monthly[\"mktcap\"].shift(1)\n    \n    return monthly\n\ndef create_monthly_dataset_parallel(df, annual_rf=0.04):\n    \"\"\"\n    Create monthly price dataset using parallel processing.\n    \"\"\"\n    # Ensure data is sorted before splitting\n    df = df.sort_values([\"symbol\", \"date\"])\n    \n    # Split by symbol\n    symbol_groups = [group for _, group in df.groupby(\"symbol\")]\n    \n    n_jobs = max(1, os.cpu_count() - 1)\n    print(f\"Processing {len(symbol_groups):,} symbols using {n_jobs} cores...\")\n    \n    results = Parallel(n_jobs=n_jobs, verbose=1)(\n        delayed(process_monthly_symbol)(group, annual_rf) \n        for group in symbol_groups\n    )\n    \n    return pd.concat(results, ignore_index=True)\n\nprices_monthly = create_monthly_dataset_parallel(prices)\n\n# Validation checks\nprint(\"\\nValidation checks:\")\nprint(f\"Any duplicate (symbol, date): {prices_monthly.duplicated(subset=['symbol', 'date']).sum()}\")\nprint(f\"\\nSample of non-zero returns:\")\nprint(prices_monthly[prices_monthly[\"ret\"] != 0][[\"symbol\", \"date\", \"adjusted_close\", \"ret\"]].head(10))\n\nprices_monthly.query(\"symbol == 'FPT'\")[[\"symbol\", \"date\", \"adjusted_close\", \"ret\"]].head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing 1,837 symbols using 87 cores...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n[Parallel(n_jobs=87)]: Using backend LokyBackend with 87 concurrent workers.\n[Parallel(n_jobs=87)]: Done  26 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=87)]: Done 378 tasks      | elapsed:    1.7s\n[Parallel(n_jobs=87)]: Done 1078 tasks      | elapsed:    4.5s\n[Parallel(n_jobs=87)]: Done 1664 out of 1837 | elapsed:    6.9s remaining:    0.7s\n[Parallel(n_jobs=87)]: Done 1837 out of 1837 | elapsed:    7.7s finished\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nValidation checks:\nAny duplicate (symbol, date): 0\n\nSample of non-zero returns:\n   symbol       date  adjusted_close       ret\n0     A32 2018-10-31       44.574418       NaN\n1     A32 2018-11-30       55.072640  0.235521\n2     A32 2018-12-31       51.974804 -0.056250\n3     A32 2019-01-31       50.030370 -0.037411\n4     A32 2019-02-28       36.087480 -0.278689\n5     A32 2019-03-31       41.828670  0.159091\n7     A32 2019-05-31       43.304976  0.035294\n8     A32 2019-06-30       35.929125 -0.170323\n9     A32 2019-07-31       37.525975  0.044444\n10    A32 2019-08-31       38.324400  0.021277\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>date</th>\n      <th>adjusted_close</th>\n      <th>ret</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55963</th>\n      <td>FPT</td>\n      <td>2010-01-31</td>\n      <td>1092.9226</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55964</th>\n      <td>FPT</td>\n      <td>2010-02-28</td>\n      <td>1107.1164</td>\n      <td>0.012987</td>\n    </tr>\n    <tr>\n      <th>55965</th>\n      <td>FPT</td>\n      <td>2010-03-31</td>\n      <td>1185.1823</td>\n      <td>0.070513</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# Select columns (same structure as daily)\nmonthly_columns = [\n    \"symbol\", \"date\", \"year\", \"month\",\n    \"open\", \"high\", \"low\", \"close\", \"volume\",\n    \"adjusted_close\", \"shrout\", \"mktcap\", \"mktcap_lag\",\n    \"ret\", \"risk_free\", \"ret_excess\"\n]\nprices_monthly = prices_monthly[monthly_columns]\n\n# Remove observations with missing essential variables\nprices_monthly = prices_monthly.dropna(subset=[\"ret_excess\", \"mktcap\", \"mktcap_lag\"])\n\nprint(\"Monthly Return Summary Statistics:\")\nprint(prices_monthly[\"ret\"].describe().round(4))\nprint(f\"\\nFinal monthly sample: {len(prices_monthly):,} observations\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMonthly Return Summary Statistics:\ncount    165499.0000\nmean          0.0042\nstd           0.1862\nmin          -0.9900\n25%          -0.0703\n50%           0.0000\n75%           0.0553\nmax          12.7500\nName: ret, dtype: float64\n\nFinal monthly sample: 165,499 observations\n```\n:::\n:::\n\n\n### Lưu trữ dữ liệu giá\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nprices_daily.to_sql(\n    name=\"prices_daily\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\nprint(\"Daily price data saved to database.\")\n\nprices_monthly.to_sql(\n    name=\"prices_monthly\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\nprint(\"Monthly price data saved to database.\")\n```\n:::\n\n\n## Thống kê mô tả\n\nTrước khi tiến hành phân tích giá tài sản, chúng ta xem xét các đặc điểm của mẫu để hiểu sự phát triển và thành phần của thị trường chứng khoán Việt Nam.\n\n### Sự phát triển của thị trường theo thời gian\n\nTrước tiên, chúng ta kiểm tra số lượng chứng khoán niêm yết đã tăng lên như thế nào theo thời gian.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nsecurities_over_time = (prices_monthly\n    .groupby(\"date\")\n    .agg(\n        n_securities=(\"symbol\", \"nunique\"),\n        total_mktcap=(\"mktcap\", \"sum\")\n    )\n    .reset_index()\n)\n```\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nsecurities_figure = (\n    ggplot(securities_over_time, aes(x=\"date\", y=\"n_securities\"))\n    + geom_line(color=\"steelblue\", size=1)\n    + labs(\n        x=\"\",\n        y=\"Number of Securities\",\n        title=\"Growth of Vietnamese Stock Market\"\n    )\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + scale_y_continuous(labels=comma_format())\n    + theme_minimal()\n)\nsecurities_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The figure shows the monthly number of securities in the Vietnamese stock market sample.](02_datacore_data_files/figure-pdf/fig-securities-over-time-output-1.pdf){#fig-securities-over-time fig-alt='Line chart showing the growth in number of listed securities over time.' fig-pos='H'}\n:::\n:::\n\n\n### Sự phát triển của Tổng vốn hóa thị trường\n\nTổng vốn hóa thị trường phản ánh quy mô và sự phát triển chung của thị trường chứng khoán Việt Nam.\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nmktcap_figure = (\n    ggplot(securities_over_time, aes(x=\"date\", y=\"total_mktcap / 1000\"))\n    + geom_line(color=\"darkgreen\", size=1)\n    + labs(\n        x=\"\",\n        y=\"Market Cap (Trillion VND)\",\n        title=\"Total Market Capitalization of Vietnamese Equities\"\n    )\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + scale_y_continuous(labels=comma_format())\n    + theme_minimal()\n)\nmktcap_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![The figure shows the total market capitalization of Vietnamese listed companies over time.](02_datacore_data_files/figure-pdf/fig-market-cap-over-time-output-1.pdf){#fig-market-cap-over-time fig-alt='Line chart showing total market capitalization growth.' fig-pos='H'}\n:::\n:::\n\n\n### Phân phối lợi nhuận\n\nViệc hiểu rõ sự phân bố lợi nhuận hàng tháng giúp xác định các vấn đề tiềm ẩn về chất lượng dữ liệu và đánh giá rủi ro thị trường.\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nreturn_distribution = (\n    ggplot(prices_monthly, aes(x=\"ret_excess\"))\n    + geom_histogram(\n        binwidth=0.02, \n        fill=\"steelblue\", \n        color=\"white\",\n        alpha=0.7\n    )\n    + labs(\n        x=\"Monthly Excess Return\",\n        y=\"Frequency\",\n        title=\"Distribution of Monthly Excess Returns\"\n    )\n    + scale_x_continuous(limits=(-0.5, 0.5))\n    + theme_minimal()\n)\nreturn_distribution.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/mikenguyen/project/tidyfinance/.venv/lib/python3.13/site-packages/plotnine/layer.py:293: PlotnineWarning: stat_bin : Removed 3264 rows containing non-finite values.\n/home/mikenguyen/project/tidyfinance/.venv/lib/python3.13/site-packages/plotnine/layer.py:374: PlotnineWarning: geom_histogram : Removed 2 rows containing missing values.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Distribution of monthly excess returns for Vietnamese stocks.](02_datacore_data_files/figure-pdf/fig-return-distribution-output-2.pdf){#fig-return-distribution fig-alt='Histogram showing the distribution of monthly excess returns.' fig-pos='H'}\n:::\n:::\n\n\n### Phạm vi Giá Trị Sổ Sách của Vốn Chủ Sở Hữu\n\nVốn chủ sở hữu sổ sách là điều cần thiết để xây dựng danh mục đầu tư giá trị. Chúng ta kiểm tra phần nào trong mẫu của chúng ta có dữ liệu vốn chủ sở hữu sổ sách theo thời gian.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\n# Merge prices with fundamentals\ncoverage_data = (prices_monthly\n    .assign(year=lambda x: x[\"date\"].dt.year)\n    .groupby([\"symbol\", \"year\"])\n    .tail(1)\n    .merge(comp_vn[[\"symbol\", \"year\", \"be\"]], \n           on=[\"symbol\", \"year\"], \n           how=\"left\")\n)\n\n# Compute coverage by year\nbe_coverage = (coverage_data\n    .groupby(\"year\")\n    .apply(lambda x: pd.Series({\n        \"share_with_be\": x[\"be\"].notna().mean()\n    }))\n    .reset_index()\n)\n\ncoverage_figure = (\n    ggplot(be_coverage, aes(x=\"year\", y=\"share_with_be\"))\n    + geom_line(color=\"darkorange\", size=1)\n    + geom_point(color=\"darkorange\", size=2)\n    + labs(\n        x=\"Year\",\n        y=\"Share with Book Equity\",\n        title=\"Coverage of Book Equity Data\"\n    )\n    + scale_y_continuous(labels=percent_format(), limits=(0, 1))\n    + theme_minimal()\n)\ncoverage_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Share of securities with available book equity data by year.](02_datacore_data_files/figure-pdf/fig-book-equity-coverage-output-1.pdf){#fig-book-equity-coverage fig-alt='Line chart showing the coverage of book equity data over time.' fig-pos='H'}\n:::\n:::\n\n\n## Hợp nhất cổ phiếu và dữ liệu cơ bản\n\nBước cuối cùng liên kết dữ liệu giá với dữ liệu cơ bản bằng cách sử dụng biểu tượng chứng khoán làm mã định danh chung. Bộ dữ liệu hợp nhất này tạo cơ sở để xây dựng danh mục đầu tư được sắp xếp theo đặc điểm của công ty.\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n# Example: Create merged dataset for end-of-June each year\nmerged_data = (prices_monthly\n    .query(\"month == 6\")\n    .merge(\n        comp_vn[[\"symbol\", \"year\", \"be\", \"op\", \"inv\", \"at\"]],\n        on=[\"symbol\", \"year\"],\n        how=\"left\",\n        suffixes=(\"\", \"_fundamental\")\n    )\n)\n\n# Convert BE from VND to BILLION VND\nmerged_data[\"be\"] = merged_data[\"be\"] / 1e9\n\n# Compute book-to-market ratio\nmerged_data[\"bm\"] = merged_data[\"be\"] / merged_data[\"mktcap\"]\n\nmerged_data.loc[\n    (merged_data[\"bm\"] <= 0) |\n    (merged_data[\"bm\"] > 20),\n    \"bm\"\n] = pd.NA\n\n\nmerged_data[\"bm\"].describe(percentiles=[.01, .1, .5, .9, .99])\n\nprint(f\"Merged observations: {len(merged_data):,}\")\nprint(f\"With book-to-market: {merged_data['bm'].notna().sum():,}\")\nmerged_data.head(3)\nmerged_data.describe()\nmerged_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMerged observations: 13,756\nWith book-to-market: 12,859\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=28}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>adjusted_close</th>\n      <th>...</th>\n      <th>mktcap</th>\n      <th>mktcap_lag</th>\n      <th>ret</th>\n      <th>risk_free</th>\n      <th>ret_excess</th>\n      <th>be</th>\n      <th>op</th>\n      <th>inv</th>\n      <th>at</th>\n      <th>bm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A32</td>\n      <td>2019-06-30</td>\n      <td>2019.0</td>\n      <td>6.0</td>\n      <td>26.4</td>\n      <td>26.4</td>\n      <td>21.0</td>\n      <td>22.5</td>\n      <td>3700</td>\n      <td>35.929125</td>\n      <td>...</td>\n      <td>153.000</td>\n      <td>179.52</td>\n      <td>-0.170323</td>\n      <td>0.003333</td>\n      <td>-0.173657</td>\n      <td>223.612748</td>\n      <td>0.232362</td>\n      <td>-0.072329</td>\n      <td>4.349303e+11</td>\n      <td>1.461521</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A32</td>\n      <td>2020-06-30</td>\n      <td>2020.0</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>26.3</td>\n      <td>24.5</td>\n      <td>26.3</td>\n      <td>7500</td>\n      <td>38.811173</td>\n      <td>...</td>\n      <td>178.840</td>\n      <td>187.00</td>\n      <td>-0.067977</td>\n      <td>0.003333</td>\n      <td>-0.071311</td>\n      <td>242.216943</td>\n      <td>0.195565</td>\n      <td>0.122698</td>\n      <td>4.882955e+11</td>\n      <td>1.354378</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A32</td>\n      <td>2021-06-30</td>\n      <td>2021.0</td>\n      <td>6.0</td>\n      <td>30.2</td>\n      <td>37.0</td>\n      <td>29.5</td>\n      <td>32.0</td>\n      <td>78400</td>\n      <td>45.363520</td>\n      <td>...</td>\n      <td>217.600</td>\n      <td>214.20</td>\n      <td>0.015873</td>\n      <td>0.003333</td>\n      <td>0.012540</td>\n      <td>238.385190</td>\n      <td>0.157723</td>\n      <td>0.081581</td>\n      <td>5.281309e+11</td>\n      <td>1.095520</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A32</td>\n      <td>2022-06-30</td>\n      <td>2022.0</td>\n      <td>6.0</td>\n      <td>30.9</td>\n      <td>35.5</td>\n      <td>25.0</td>\n      <td>35.3</td>\n      <td>15200</td>\n      <td>47.503210</td>\n      <td>...</td>\n      <td>240.040</td>\n      <td>210.12</td>\n      <td>0.142395</td>\n      <td>0.003333</td>\n      <td>0.139061</td>\n      <td>215.399735</td>\n      <td>0.172085</td>\n      <td>0.036584</td>\n      <td>5.474523e+11</td>\n      <td>0.897349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A32</td>\n      <td>2023-06-30</td>\n      <td>2023.0</td>\n      <td>6.0</td>\n      <td>30.1</td>\n      <td>33.5</td>\n      <td>29.2</td>\n      <td>29.4</td>\n      <td>2400</td>\n      <td>35.064204</td>\n      <td>...</td>\n      <td>199.920</td>\n      <td>204.68</td>\n      <td>-0.023256</td>\n      <td>0.003333</td>\n      <td>-0.026589</td>\n      <td>222.024135</td>\n      <td>0.174658</td>\n      <td>-0.076752</td>\n      <td>5.054342e+11</td>\n      <td>1.110565</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13751</th>\n      <td>YTC</td>\n      <td>2019-06-30</td>\n      <td>2019.0</td>\n      <td>6.0</td>\n      <td>70.0</td>\n      <td>79.9</td>\n      <td>70.0</td>\n      <td>79.9</td>\n      <td>38900</td>\n      <td>171.451817</td>\n      <td>...</td>\n      <td>246.092</td>\n      <td>215.60</td>\n      <td>0.141429</td>\n      <td>0.003333</td>\n      <td>0.138095</td>\n      <td>59.901389</td>\n      <td>0.738190</td>\n      <td>-0.021758</td>\n      <td>7.521980e+11</td>\n      <td>0.243411</td>\n    </tr>\n    <tr>\n      <th>13752</th>\n      <td>YTC</td>\n      <td>2020-06-30</td>\n      <td>2020.0</td>\n      <td>6.0</td>\n      <td>88.5</td>\n      <td>88.5</td>\n      <td>77.0</td>\n      <td>87.0</td>\n      <td>150640</td>\n      <td>180.966960</td>\n      <td>...</td>\n      <td>267.960</td>\n      <td>272.58</td>\n      <td>-0.016949</td>\n      <td>0.003333</td>\n      <td>-0.020282</td>\n      <td>13.459082</td>\n      <td>-0.458548</td>\n      <td>0.323501</td>\n      <td>9.955348e+11</td>\n      <td>0.050228</td>\n    </tr>\n    <tr>\n      <th>13753</th>\n      <td>YTC</td>\n      <td>2021-06-30</td>\n      <td>2021.0</td>\n      <td>6.0</td>\n      <td>76.0</td>\n      <td>115.5</td>\n      <td>61.0</td>\n      <td>61.0</td>\n      <td>34100</td>\n      <td>126.884880</td>\n      <td>...</td>\n      <td>187.880</td>\n      <td>234.08</td>\n      <td>-0.197368</td>\n      <td>0.003333</td>\n      <td>-0.200702</td>\n      <td>21.746595</td>\n      <td>0.539521</td>\n      <td>-0.215694</td>\n      <td>7.808035e+11</td>\n      <td>0.115747</td>\n    </tr>\n    <tr>\n      <th>13754</th>\n      <td>YTC</td>\n      <td>2022-06-30</td>\n      <td>2022.0</td>\n      <td>6.0</td>\n      <td>68.0</td>\n      <td>68.0</td>\n      <td>65.0</td>\n      <td>65.5</td>\n      <td>200</td>\n      <td>136.245240</td>\n      <td>...</td>\n      <td>201.740</td>\n      <td>209.44</td>\n      <td>-0.036765</td>\n      <td>0.003333</td>\n      <td>-0.040098</td>\n      <td>32.403055</td>\n      <td>0.483088</td>\n      <td>0.182911</td>\n      <td>9.236206e+11</td>\n      <td>0.160618</td>\n    </tr>\n    <tr>\n      <th>13755</th>\n      <td>YTC</td>\n      <td>2023-06-30</td>\n      <td>2023.0</td>\n      <td>6.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>49545</td>\n      <td>122.724720</td>\n      <td>...</td>\n      <td>181.720</td>\n      <td>181.72</td>\n      <td>0.000000</td>\n      <td>0.003333</td>\n      <td>-0.003333</td>\n      <td>38.976624</td>\n      <td>0.450157</td>\n      <td>0.017930</td>\n      <td>9.401815e+11</td>\n      <td>0.214487</td>\n    </tr>\n  </tbody>\n</table>\n<p>13756 rows × 21 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nfrom plotnine import *\nimport numpy as np\n\nbm_plot_data = (\n    merged_data[[\"bm\"]]\n      .dropna()\n      .assign(bm_plot=lambda x: x[\"bm\"].clip(upper=10))\n)\n\n(\n    ggplot(bm_plot_data, aes(x=\"bm_plot\")) +\n    geom_histogram(bins=80) +\n    labs(\n        title=\"Distribution of Book to Market Ratios\",\n        x=\"Book to Market (capped at 10 for plotting)\",\n        y=\"Number of firms\"\n    ) +\n    theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n![](02_datacore_data_files/figure-pdf/cell-33-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nsize_plot_data = (\n    merged_data[[\"mktcap_lag\"]]\n      .dropna()\n      .assign(log_size=lambda x: np.log(x[\"mktcap_lag\"]))\n)\n\n(\n    ggplot(size_plot_data, aes(x=\"log_size\")) +\n    geom_histogram(bins=80) +\n    labs(\n        title=\"Distribution of Log Market Capitalization\",\n        x=\"Log Market Cap\",\n        y=\"Number of firms\"\n    ) +\n    theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n![](02_datacore_data_files/figure-pdf/cell-34-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nscatter_data = (\n    merged_data[[\"be\", \"mktcap_lag\"]]\n      .dropna()\n      .assign(\n          log_be=lambda x: np.log(x[\"be\"]),\n          log_me=lambda x: np.log(x[\"mktcap_lag\"])\n      )\n)\n\n(\n    ggplot(scatter_data, aes(x=\"log_me\", y=\"log_be\")) +\n    geom_point(alpha=0.2) +\n    labs(\n        title=\"Log Book Equity vs Log Market Equity\",\n        x=\"Log Market Cap\",\n        y=\"Log Book Equity\"\n    ) +\n    theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n![](02_datacore_data_files/figure-pdf/cell-35-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Những điểm chính cần ghi nhớ\n\n1. **Datacore cung cấp quyền truy cập thống nhất** vào dữ liệu tài chính Việt Nam thông qua cơ sở hạ tầng điện toán đám mây hiện đại, loại bỏ nhu cầu tổng hợp dữ liệu từ nhiều nguồn phân tán.\n\n2. **Các yếu tố cơ bản của công ty** từ Datacore bao gồm bảng cân đối kế toán, báo cáo kết quả kinh doanh và dữ liệu lưu chuyển tiền tệ toàn diện được lập theo Chuẩn mực Kế toán Việt Nam, mà chúng ta đối chiếu với các biến số chuẩn được sử dụng trong nghiên cứu quốc tế.\n\n3. **Cách tính giá trị sổ sách** tuân theo phương pháp Fama-French, có tính đến thuế hoãn lại và cổ phiếu ưu đãi để đảm bảo tính tương đồng với các nghiên cứu tại Hoa Kỳ.\n\n4. **Dữ liệu giá cổ phiếu** bao gồm các yếu tố điều chỉnh cho các hoạt động của công ty, cho phép tính toán lợi nhuận chính xác trong thời gian dài.\n\n5. **Tần suất hàng tháng** là tiêu chuẩn trong nghiên cứu định giá tài sản, giúp giảm nhiễu trong khi vẫn duy trì đủ số liệu quan sát để suy luận thống kê.\n\n6. **Phương pháp ước tính lãi suất phi rủi ro** sử dụng lợi suất trái phiếu chính phủ Việt Nam làm thước đo thay thế, do không có chuỗi lãi suất ngắn hạn tiêu chuẩn tương đương với tín phiếu kho bạc Mỹ.\n\n7. **Kiểm định chất lượng dữ liệu** thông qua thống kê mô tả và trực quan hóa giúp xác định các vấn đề tiềm ẩn trước khi tiến hành phân tích chính thức.\n\n8. **Xử lý theo lô** cho phép xử lý hiệu quả các tập dữ liệu lớn hàng ngày mà nếu không sẽ vượt quá giới hạn bộ nhớ.\n\n",
    "supporting": [
      "02_datacore_data_files/figure-pdf"
    ],
    "filters": []
  }
}