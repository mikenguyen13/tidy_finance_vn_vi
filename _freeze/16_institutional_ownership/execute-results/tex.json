{
  "hash": "b91abccc8f867b66d5747e23390d297f",
  "result": {
    "engine": "jupyter",
    "markdown": "# Institutional Ownership Analytics in Vietnam\n\n\n\n## Institutional Ownership in Vietnam: A Distinct Landscape\n\nVietnam's equity market presents a fundamentally different institutional ownership landscape from the mature markets of the US, Europe, or Japan. Since the Ho Chi Minh City Securities Trading Center (now HOSE) opened on July 28, 2000 with just two listed stocks, the market has grown to over 1,700 listed companies across three exchanges (HOSE, HNX, and UPCOM) with a combined market capitalization exceeding 200 billion USD. Yet the ownership structure remains distinctive in several critical ways:\n\n-   **Retail dominance.** Individual investors account for approximately 85% of trading value on Vietnamese exchanges, far exceeding the institutional share. This contrasts sharply with the US, where institutional investors dominate both ownership and trading [@bao2024institutional]. The implications for market efficiency, price discovery, and volatility are profound.\n\n-   **State ownership legacy.** Vietnam's equitization (privatization) program, initiated under Đổi Mới reforms in 1986, means that the state remains a significant or controlling shareholder in many listed companies. As of 2022, SOEs (firms with state ownership \\> 50%) account for approximately 30% of total market capitalization despite representing less than 10% of listed firms [@huang2023factors]. State ownership introduces unique agency problems, governance dynamics, and liquidity constraints.\n\n-   **Foreign Ownership Limits (FOLs).** Vietnam imposes sector-specific caps on aggregate foreign ownership, typically 49% for most sectors, 30% for banking, and varying limits for aviation, media, and telecommunications. When a stock reaches its FOL, foreign investors can only buy from other foreign sellers, creating a segmented market with distinct pricing dynamics and a well-documented \"FOL premium\" [@vo2015foreign].\n\n-   **Disclosure regime.** Unlike the US quarterly 13F filing system, Vietnam's ownership disclosure is event-driven and periodic. Major shareholders (≥5%) must disclose within 7 business days of crossing thresholds. Annual reports contain detailed shareholder registers. Semi-annual fund reports provide portfolio snapshots. This creates a patchwork of disclosure frequencies that require careful handling.\n\n## Data Infrastructure: DataCore.vn {#sec-datacore}\n\n**DataCore.vn** is a comprehensive Vietnamese financial data platform that provides academic-grade datasets for the Vietnamese market. Throughout this chapter, we assume all data is sourced exclusively from DataCore.vn, which provides:\n\n| DataCore.vn Dataset | Content | Key Variables |\n|:------------------------|:------------------|:---------------------------|\n| **Stock Prices** | Daily/monthly OHLCV for HOSE, HNX, UPCOM | `ticker`, `date`, `close`, `adjusted_close`, `volume`, `shares_outstanding` |\n| **Ownership Structure** | Shareholder composition snapshots | `ticker`, `date`, `shareholder_name`, `shares_held`, `ownership_pct`, `shareholder_type` |\n| **Major Shareholders** | Detailed ≥5% holders | `ticker`, `date`, `shareholder_name`, `shares_held`, `is_foreign`, `is_state`, `is_institution` |\n| **Corporate Actions** | Dividends, stock splits, bonus shares, rights issues | `ticker`, `ex_date`, `action_type`, `ratio`, `record_date` |\n| **Company Profile** | Sector, exchange, listing date, charter capital | `ticker`, `exchange`, `industry_code`, `listing_date`, `fol_limit` |\n| **Financial Statements** | Quarterly/annual financials | `ticker`, `period`, `revenue`, `net_income`, `total_assets`, `equity` |\n| **Foreign Ownership** | Daily foreign ownership tracking | `ticker`, `date`, `foreign_shares`, `foreign_pct`, `fol_limit`, `foreign_room` |\n| **Fund Holdings** | Semi-annual fund portfolio disclosures | `fund_name`, `report_date`, `ticker`, `shares_held`, `market_value` |\n\n: DataCore.vn Data Tables Used in This Chapter {#tbl-datacore-tables}\n\n::: {#datacore-reader .cell execution_count=2}\n``` {.python .cell-code code-summary=\"DataCore.vn Unified Data Reader\"}\nclass DataCoreReader:\n    \"\"\"\n    Unified data reader for DataCore.vn datasets.\n    \n    Assumes data has been downloaded from DataCore.vn and stored locally.\n    Supports both Parquet (recommended for performance) and CSV formats.\n    \n    Parameters\n    ----------\n    data_dir : str or Path\n        Root directory containing DataCore.vn data files\n    file_format : str\n        'parquet' or 'csv' (default: 'parquet')\n    \"\"\"\n    \n    # Expected file names in the data directory\n    FILE_MAP = {\n        'prices': 'stock_prices',\n        'ownership': 'ownership_structure',\n        'major_shareholders': 'major_shareholders',\n        'corporate_actions': 'corporate_actions',\n        'company_profile': 'company_profile',\n        'financials': 'financial_statements',\n        'foreign_ownership': 'foreign_ownership_daily',\n        'fund_holdings': 'fund_holdings',\n    }\n    \n    def __init__(self, data_dir: Union[str, Path], file_format: str = 'parquet'):\n        self.data_dir = Path(data_dir)\n        self.fmt = file_format\n        self._cache = {}\n        \n        # Verify data directory exists\n        if not self.data_dir.exists():\n            raise FileNotFoundError(\n                f\"Data directory not found: {self.data_dir}\\n\"\n                f\"Please download data from DataCore.vn and place it in this directory.\"\n            )\n        \n        print(f\"DataCore.vn reader initialized: {self.data_dir}\")\n        available = [f.stem for f in self.data_dir.glob(f'*.{self.fmt}')]\n        print(f\"Available datasets: {available}\")\n    \n    def _read(self, key: str) -> pd.DataFrame:\n        \"\"\"Read and cache a dataset.\"\"\"\n        if key in self._cache:\n            return self._cache[key]\n        \n        fname = self.FILE_MAP.get(key, key)\n        filepath = self.data_dir / f\"{fname}.{self.fmt}\"\n        \n        if not filepath.exists():\n            raise FileNotFoundError(\n                f\"Dataset not found: {filepath}\\n\"\n                f\"Expected file: {fname}.{self.fmt} in {self.data_dir}\"\n            )\n        \n        if self.fmt == 'parquet':\n            df = pd.read_parquet(filepath)\n        else:\n            df = pd.read_csv(filepath, parse_dates=True)\n        \n        # Auto-detect and parse date columns\n        for col in df.columns:\n            if 'date' in col.lower() or col.lower() in ['period', 'ex_date', 'record_date']:\n                try:\n                    df[col] = pd.to_datetime(df[col])\n                except (ValueError, TypeError):\n                    pass\n        \n        self._cache[key] = df\n        print(f\"Loaded {key}: {len(df):,} rows, {len(df.columns)} columns\")\n        return df\n    \n    @property\n    def prices(self) -> pd.DataFrame:\n        return self._read('prices')\n    \n    @property\n    def ownership(self) -> pd.DataFrame:\n        return self._read('ownership')\n    \n    @property\n    def major_shareholders(self) -> pd.DataFrame:\n        return self._read('major_shareholders')\n    \n    @property\n    def corporate_actions(self) -> pd.DataFrame:\n        return self._read('corporate_actions')\n    \n    @property\n    def company_profile(self) -> pd.DataFrame:\n        return self._read('company_profile')\n    \n    @property\n    def financials(self) -> pd.DataFrame:\n        return self._read('financials')\n    \n    @property\n    def foreign_ownership(self) -> pd.DataFrame:\n        return self._read('foreign_ownership')\n    \n    @property\n    def fund_holdings(self) -> pd.DataFrame:\n        return self._read('fund_holdings')\n    \n    def clear_cache(self):\n        \"\"\"Clear all cached datasets to free memory.\"\"\"\n        self._cache.clear()\n\n# Initialize reader — adjust path to your local DataCore.vn data\n# dc = DataCoreReader('/path/to/datacore_data', file_format='parquet')\n```\n:::\n\n\nThis chapter proceeds as follows. @sec-data-pipeline builds the complete data pipeline from raw DataCore.vn extracts to clean, analysis-ready datasets, with particular attention to corporate action adjustments. @sec-ownership-taxonomy defines Vietnam's unique ownership taxonomy. @sec-ownership-metrics computes institutional ownership ratios, concentration, and breadth for the Vietnamese market. @sec-foreign-ownership develops specialized foreign ownership analytics including FOL utilization and room premium. @sec-trades derives institutional trades from ownership disclosure snapshots. @sec-flows-turnover computes fund-level flows and turnover. @sec-state-ownership analyzes state ownership dynamics. @sec-modern-extensions introduces network analysis, ML classification, and event-study frameworks. @sec-empirical-applications presents complete empirical applications, and @sec-conclusion concludes.\n\n## Data Pipeline {#sec-data-pipeline}\n\n### Stock Price Data and Corporate Action Adjustments {#sec-price-pipeline}\n\nVietnam's equity market is notorious for frequent corporate actions, particularly stock dividends and bonus share issuances, that dramatically alter share counts. A company issuing a 30% stock dividend means every 100 shares become 130 shares, and the reference price adjusts downward proportionally. Failure to properly adjust historical shares and prices for these events is the single most common source of error in Vietnamese equity research.\n\n::: {#corporate-actions .cell execution_count=3}\n``` {.python .cell-code code-summary=\"Build Cumulative Adjustment Factors from Corporate Actions\"}\n# ============================================================================\n# Step 1: Corporate Action Adjustment Factors\n# ============================================================================\n\ndef build_adjustment_factors(corporate_actions: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Build cumulative adjustment factors from the corporate actions history.\n    \n    In Vietnam, the most common share-altering corporate actions are:\n    1. Stock dividends (cổ tức bằng cổ phiếu): e.g., 30% → ratio = 0.30\n       Effect: shares × (1 + 0.30), price × (1 / 1.30)\n    2. Bonus shares (thưởng cổ phiếu): mechanically identical to stock dividends\n    3. Stock splits (chia tách): e.g., 2:1 → ratio = 2.0\n       Effect: shares × 2, price × 0.5\n    4. Rights issues (phát hành thêm): dilutive, but not all shareholders exercise\n       We approximate with the subscription ratio\n    5. Reverse splits (gộp cổ phiếu): rare in Vietnam\n       Effect: shares ÷ ratio, price × ratio\n    \n    We construct a FORWARD-LOOKING cumulative adjustment factor such that:\n       adjusted_shares = raw_shares × cum_adj_factor(from_date, to_date)\n       adjusted_price = raw_price / cum_adj_factor(from_date, to_date)\n    \n    This is analogous to CRSP's cfacshr in the US context.\n    \n    Parameters\n    ----------\n    corporate_actions : pd.DataFrame\n        DataCore.vn corporate actions with columns:\n        ticker, ex_date, action_type, ratio\n        \n        action_type values:\n        - 'stock_dividend': ratio = dividend rate (e.g., 0.30 for 30%)\n        - 'bonus_shares': ratio = bonus rate (e.g., 0.20 for 20%)\n        - 'stock_split': ratio = split factor (e.g., 2.0 for 2:1)\n        - 'reverse_split': ratio = merge factor (e.g., 5.0 for 5:1 merge)\n        - 'rights_issue': ratio = subscription rate (e.g., 0.10 for 10:1)\n        - 'cash_dividend': ratio = VND per share (no share adjustment needed)\n    \n    Returns\n    -------\n    pd.DataFrame\n        Adjustment factors: ticker, ex_date, point_factor, cum_factor\n    \"\"\"\n    # Filter to share-altering events only\n    share_events = ['stock_dividend', 'bonus_shares', 'stock_split', \n                    'reverse_split', 'rights_issue']\n    ca = corporate_actions[\n        corporate_actions['action_type'].isin(share_events)\n    ].copy()\n    \n    if len(ca) == 0:\n        print(\"No share-altering corporate actions found.\")\n        return pd.DataFrame(columns=['ticker', 'ex_date', 'point_factor', 'cum_factor'])\n    \n    # Compute point adjustment factor for each event\n    def compute_point_factor(row):\n        atype = row['action_type']\n        ratio = row['ratio']\n        \n        if atype in ['stock_dividend', 'bonus_shares']:\n            # 30% stock dividend: 100 shares → 130 shares\n            return 1 + ratio\n        elif atype == 'stock_split':\n            # 2:1 split: 100 shares → 200 shares\n            return ratio\n        elif atype == 'reverse_split':\n            # 5:1 reverse: 500 shares → 100 shares\n            return 1.0 / ratio\n        elif atype == 'rights_issue':\n            # Approximate: assume all rights exercised\n            # In practice, this overestimates the adjustment\n            return 1 + ratio\n        else:\n            return 1.0\n    \n    ca['point_factor'] = ca.apply(compute_point_factor, axis=1)\n    \n    # Sort chronologically within each ticker\n    ca = ca.sort_values(['ticker', 'ex_date']).reset_index(drop=True)\n    \n    # Cumulative factor: product of all point factors from listing to date\n    # This gives us a running \"total adjustment\" for each ticker\n    ca['cum_factor'] = ca.groupby('ticker')['point_factor'].cumprod()\n    \n    # Summary statistics\n    n_tickers = ca['ticker'].nunique()\n    n_events = len(ca)\n    avg_events = n_events / n_tickers if n_tickers > 0 else 0\n    \n    print(f\"Corporate action adjustment factors built:\")\n    print(f\"  Tickers with adjustments: {n_tickers:,}\")\n    print(f\"  Total share-altering events: {n_events:,}\")\n    print(f\"  Average events per ticker: {avg_events:.1f}\")\n    print(f\"\\nEvent type distribution:\")\n    print(ca['action_type'].value_counts().to_string())\n    \n    return ca[['ticker', 'ex_date', 'action_type', 'ratio', \n               'point_factor', 'cum_factor']]\n\n\ndef adjust_shares(shares: float, ticker: str, from_date, to_date, \n                  adj_factors: pd.DataFrame) -> float:\n    \"\"\"\n    Adjust a share count from one date to another for corporate actions.\n    \n    Example: If a company had a 30% stock dividend with ex_date between\n    from_date and to_date, then 1000 shares at from_date = 1300 shares \n    at to_date.\n    \n    Parameters\n    ----------\n    shares : float\n        Number of shares at from_date\n    ticker : str\n        Stock ticker\n    from_date, to_date : pd.Timestamp\n        Period for adjustment\n    adj_factors : pd.DataFrame\n        Output of build_adjustment_factors()\n    \n    Returns\n    -------\n    float\n        Adjusted shares at to_date\n    \"\"\"\n    events = adj_factors[\n        (adj_factors['ticker'] == ticker) &\n        (adj_factors['ex_date'] > pd.Timestamp(from_date)) &\n        (adj_factors['ex_date'] <= pd.Timestamp(to_date))\n    ]\n    \n    if len(events) == 0:\n        return shares\n    \n    total_factor = events['point_factor'].prod()\n    return shares * total_factor\n\n\n# Example usage:\n# adj_factors = build_adjustment_factors(dc.corporate_actions)\n```\n:::\n\n\n::: {.callout-important title=\"The Stock Dividend Problem in Vietnam\"}\nVietnamese companies issue stock dividends with remarkable frequency, many growth companies do so 2-3 times per year. Consider **Vinhomes (VHM)** or **FPT Corporation**: their share counts may double or triple over a 5-year period purely from stock dividends. If you compare raw ownership shares from 2019 to 2024 without adjustment, you will obtain nonsensical ownership ratios. **Every time-series analysis of Vietnamese ownership data must use adjusted shares.** This is the Vietnamese equivalent of the CRSP cfacshr adjustment factor problem in US data, but more severe because the events are more frequent and larger in magnitude.\n:::\n\n::: {#price-processing .cell execution_count=4}\n``` {.python .cell-code code-summary=\"Process DataCore.vn Price Data with Adjustments\"}\n# ============================================================================\n# Step 2: Process Stock Price Data\n# ============================================================================\n\ndef process_price_data(prices: pd.DataFrame, \n                       adj_factors: pd.DataFrame,\n                       company_profile: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Process DataCore.vn stock price data:\n    1. Align dates to month-end and quarter-end\n    2. Merge company metadata (exchange, sector, FOL limit)\n    3. Compute adjusted prices and shares outstanding\n    4. Compute market capitalization\n    5. Create quarter-end snapshots\n    \n    Parameters\n    ----------\n    prices : pd.DataFrame\n        Daily/monthly price data from DataCore.vn\n    adj_factors : pd.DataFrame\n        Corporate action adjustment factors\n    company_profile : pd.DataFrame\n        Company metadata including exchange, sector, FOL\n    \n    Returns\n    -------\n    pd.DataFrame\n        Quarter-end processed stock data\n    \"\"\"\n    df = prices.copy()\n    \n    # Standardize date\n    df['date'] = pd.to_datetime(df['date'])\n    df['month_end'] = df['date'] + pd.offsets.MonthEnd(0)\n    df['quarter_end'] = df['date'] + pd.offsets.QuarterEnd(0)\n    \n    # Merge company profile\n    profile_cols = ['ticker', 'exchange', 'industry_code', 'fol_limit', \n                    'listing_date', 'company_name']\n    profile_cols = [c for c in profile_cols if c in company_profile.columns]\n    df = df.merge(company_profile[profile_cols], on='ticker', how='left')\n    \n    # Build cumulative adjustment factor for each ticker-date\n    # For each observation, compute the total adjustment from listing to that date\n    df = df.sort_values(['ticker', 'date'])\n    \n    # Merge adjustment events\n    # For each ticker-date, find the cumulative factor as of that date\n    def get_cum_factor_at_date(group):\n        ticker = group.name\n        ticker_adj = adj_factors[adj_factors['ticker'] == ticker].copy()\n        \n        if len(ticker_adj) == 0:\n            group['cum_adj_factor'] = 1.0\n            return group\n        \n        # For each date, find cumulative factor (product of all events up to that date)\n        group = group.sort_values('date')\n        group['cum_adj_factor'] = 1.0\n        \n        for _, event in ticker_adj.iterrows():\n            mask = group['date'] >= event['ex_date']\n            group.loc[mask, 'cum_adj_factor'] *= event['point_factor']\n        \n        return group\n    \n    df = df.groupby('ticker', group_keys=False).apply(get_cum_factor_at_date)\n    \n    # Adjusted price and shares\n    # adjusted_close should already be provided by DataCore.vn\n    # But we compute our own for consistency\n    if 'adjusted_close' not in df.columns:\n        df['adjusted_close'] = df['close'] / df['cum_adj_factor']\n    \n    # Adjusted shares outstanding\n    df['adjusted_shares'] = df['shares_outstanding'] * df['cum_adj_factor']\n    \n    # Market capitalization (in billion VND)\n    df['market_cap'] = df['close'] * df['shares_outstanding'] / 1e9\n    \n    # Monthly returns\n    df = df.sort_values(['ticker', 'date'])\n    df['ret'] = df.groupby('ticker')['adjusted_close'].pct_change()\n    \n    # Keep quarter-end observations\n    # For daily data: keep last trading day of each quarter\n    df_quarterly = (df.sort_values(['ticker', 'quarter_end', 'date'])\n                      .groupby(['ticker', 'quarter_end'])\n                      .last()\n                      .reset_index())\n    \n    print(f\"Processed price data:\")\n    print(f\"  Total records (daily): {len(df):,}\")\n    print(f\"  Quarter-end records: {len(df_quarterly):,}\")\n    print(f\"  Unique tickers: {df_quarterly['ticker'].nunique():,}\")\n    print(f\"  Date range: {df_quarterly['quarter_end'].min()} to \"\n          f\"{df_quarterly['quarter_end'].max()}\")\n    print(f\"\\nExchange distribution:\")\n    print(df_quarterly.groupby('exchange')['ticker'].nunique().to_string())\n    \n    return df_quarterly\n\n# prices_q = process_price_data(dc.prices, adj_factors, dc.company_profile)\n```\n:::\n\n\n### Ownership Structure Data {#sec-ownership-data}\n\nVietnamese ownership data from DataCore.vn captures the composition of shareholders as disclosed in annual reports, semi-annual reports, and event-driven disclosures. The key distinction from US 13F data is that Vietnamese disclosures provide a **complete ownership decomposition**, not just institutional long positions, but the full breakdown into state, institutional, foreign, and individual ownership.\n\n::: {#ownership-processing .cell execution_count=5}\n``` {.python .cell-code code-summary=\"Process and Standardize Ownership Structure Data\"}\n# ============================================================================\n# Step 3: Process Ownership Structure Data\n# ============================================================================\n\nclass OwnershipType:\n    \"\"\"\n    Vietnam's ownership taxonomy.\n    \n    Unlike the US where 13F captures only institutional long positions,\n    Vietnamese disclosure provides a complete ownership decomposition.\n    We classify shareholders into five mutually exclusive categories.\n    \"\"\"\n    STATE = 'state'                    # Nhà nước (government entities, SOE parents)\n    FOREIGN_INST = 'foreign_inst'      # Tổ chức nước ngoài\n    DOMESTIC_INST = 'domestic_inst'    # Tổ chức trong nước (non-state)\n    INDIVIDUAL = 'individual'          # Cá nhân\n    TREASURY = 'treasury'              # Cổ phiếu quỹ\n    \n    ALL_TYPES = [STATE, FOREIGN_INST, DOMESTIC_INST, INDIVIDUAL, TREASURY]\n    INSTITUTIONAL = [STATE, FOREIGN_INST, DOMESTIC_INST]\n    FOREIGN = [FOREIGN_INST]  # Can be expanded if foreign individuals are tracked\n\n\ndef classify_shareholders(ownership: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Classify shareholders into Vietnam's ownership taxonomy.\n    \n    DataCore.vn may provide a `shareholder_type` field, but naming \n    conventions vary. This function standardizes the classification \n    using a combination of provided flags and name-based heuristics.\n    \n    The classification challenge in Vietnam (noted by @huang2023factors):\n    DataCore.vn may not always cleanly separate institution types, so we \n    use a cascading approach:\n    1. Use explicit flags (is_state, is_foreign, is_institution) if available\n    2. Apply name-based heuristics for Vietnamese entity names\n    3. Default to 'individual' for unclassified shareholders\n    \n    Parameters\n    ----------\n    ownership : pd.DataFrame\n        Raw ownership data from DataCore.vn\n    \n    Returns\n    -------\n    pd.DataFrame\n        Ownership data with standardized `owner_type` column\n    \"\"\"\n    df = ownership.copy()\n    \n    # --- Method 1: Use explicit flags if available ---\n    if all(col in df.columns for col in ['is_state', 'is_foreign', 'is_institution']):\n        conditions = [\n            (df['is_state'] == True),\n            (df['is_foreign'] == True) & (df['is_institution'] == True),\n            (df['is_foreign'] == True) & (df['is_institution'] != True),\n            (df['is_institution'] == True) & (df['is_state'] != True) & \n                (df['is_foreign'] != True),\n        ]\n        choices = [\n            OwnershipType.STATE,\n            OwnershipType.FOREIGN_INST,\n            OwnershipType.FOREIGN_INST,  # Foreign individuals often grouped\n            OwnershipType.DOMESTIC_INST,\n        ]\n        df['owner_type'] = np.select(conditions, choices, \n                                      default=OwnershipType.INDIVIDUAL)\n    \n    # --- Method 2: Name-based heuristics ---\n    elif 'shareholder_name' in df.columns:\n        name = df['shareholder_name'].str.lower().fillna('')\n        \n        # State entities: government ministries, SCIC, state corporations\n        state_keywords = [\n            'bộ tài chính', 'tổng công ty đầu tư', 'scic', \n            'ủy ban nhân dân', 'nhà nước', 'state capital',\n            'tổng công ty', 'vốn nhà nước', 'bộ công thương',\n            'bộ quốc phòng', 'bộ giao thông', 'vinashin',\n        ]\n        is_state = name.apply(\n            lambda x: any(kw in x for kw in state_keywords)\n        )\n        \n        # Foreign entities: common fund names, foreign company patterns\n        foreign_keywords = [\n            'fund', 'investment', 'capital', 'limited', 'ltd', 'inc',\n            'corporation', 'holdings', 'asset management', 'pte',\n            'gmbh', 'management', 'partners', 'advisors',\n            'dragon capital', 'vinacapital', 'templeton', \n            'blackrock', 'jpmorgan', 'samsung', 'mirae',\n        ]\n        # Also check for non-Vietnamese characters as a heuristic\n        is_foreign_name = name.apply(\n            lambda x: any(kw in x for kw in foreign_keywords)\n        )\n        \n        # Domestic institutions: Vietnamese bank, securities, insurance names\n        domestic_inst_keywords = [\n            'ngân hàng', 'chứng khoán', 'bảo hiểm', 'quỹ đầu tư',\n            'công ty quản lý', 'bảo việt', 'techcombank', 'vietcombank',\n            'bidv', 'vietinbank', 'vpbank', 'mb bank', 'ssi', 'hsc',\n            'vcsc', 'vndirect', 'fpt capital', 'manulife',\n        ]\n        is_domestic_inst = name.apply(\n            lambda x: any(kw in x for kw in domestic_inst_keywords)\n        )\n        \n        # Treasury shares\n        is_treasury = name.str.contains('cổ phiếu quỹ|treasury', case=False)\n        \n        # Apply classification cascade\n        df['owner_type'] = OwnershipType.INDIVIDUAL  # Default\n        df.loc[is_domestic_inst, 'owner_type'] = OwnershipType.DOMESTIC_INST\n        df.loc[is_foreign_name, 'owner_type'] = OwnershipType.FOREIGN_INST\n        df.loc[is_state, 'owner_type'] = OwnershipType.STATE\n        df.loc[is_treasury, 'owner_type'] = OwnershipType.TREASURY\n    \n    # --- Method 3: Use shareholder_type directly ---\n    elif 'shareholder_type' in df.columns:\n        type_map = {\n            'state': OwnershipType.STATE,\n            'foreign_institution': OwnershipType.FOREIGN_INST,\n            'foreign_individual': OwnershipType.FOREIGN_INST,\n            'domestic_institution': OwnershipType.DOMESTIC_INST,\n            'individual': OwnershipType.INDIVIDUAL,\n            'treasury': OwnershipType.TREASURY,\n        }\n        df['owner_type'] = df['shareholder_type'].str.lower().map(type_map)\n        df['owner_type'] = df['owner_type'].fillna(OwnershipType.INDIVIDUAL)\n    \n    else:\n        raise ValueError(\n            \"Cannot classify shareholders. Expected one of:\\n\"\n            \"  1. Columns: is_state, is_foreign, is_institution\\n\"\n            \"  2. Column: shareholder_name (for heuristic classification)\\n\"\n            \"  3. Column: shareholder_type (pre-classified)\"\n        )\n    \n    # Summary\n    print(\"Ownership classification results:\")\n    print(df['owner_type'].value_counts().to_string())\n    \n    return df\n\n# ownership_classified = classify_shareholders(dc.ownership)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Vietnam's Ownership Taxonomy {#sec-ownership-taxonomy}\n\n### The Five Ownership Categories\n\nVietnam's ownership structure is decomposed into five mutually exclusive categories that together sum to 100% of shares outstanding:\n\n| Category | Vietnamese Term | Description | Typical Share (2020s) |\n|:-----------------|:-----------------|:-----------------|:------------------|\n| **State** | Sở hữu Nhà nước | Government entities, SCIC, SOE parent companies | \\~15-25% of market cap |\n| **Foreign Institutional** | Tổ chức nước ngoài | Foreign funds, banks, corporations | \\~15-20% |\n| **Domestic Institutional** | Tổ chức trong nước | Vietnamese funds, banks, insurance, securities firms | \\~5-10% |\n| **Individual** | Cá nhân | Retail investors (both Vietnamese and foreign individuals) | \\~55-65% |\n| **Treasury** | Cổ phiếu quỹ | Company's own repurchased shares | \\~0-2% |\n\n: Vietnam's Ownership Taxonomy {#tbl-ownership-taxonomy}\n\nThis taxonomy differs fundamentally from the US 13F framework in several ways:\n\n1.  **Completeness:** We observe 100% of ownership, not just institutional long positions above \\$100 million AUM.\n2.  **State as a category:** State ownership is a first-class analytical category, not subsumed under \"All Others\" as in the LSEG type code system.\n3.  **Individual visibility:** We observe aggregate individual ownership directly, whereas in the US, individual ownership is merely the residual (100% − institutional ownership).\n4.  **No short position ambiguity:** Vietnam's market has very limited short-selling infrastructure, so ownership data genuinely represents long positions.\n\n::: {#ownership-decomposition .cell execution_count=6}\n``` {.python .cell-code code-summary=\"Compute Full Ownership Decomposition for Each Stock-Period\"}\n# ============================================================================\n# Step 4: Compute Ownership Decomposition\n# ============================================================================\n\ndef compute_ownership_decomposition(ownership: pd.DataFrame,\n                                     prices_q: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Compute the full ownership decomposition for each stock at each \n    disclosure date.\n    \n    For each stock-date combination, aggregates shares held by each \n    ownership category and computes ownership ratios relative to \n    total shares outstanding.\n    \n    Parameters\n    ----------\n    ownership : pd.DataFrame\n        Classified ownership data (output of classify_shareholders)\n    prices_q : pd.DataFrame\n        Quarter-end price data with shares_outstanding\n    \n    Returns\n    -------\n    pd.DataFrame\n        Stock-period level ownership decomposition with columns for\n        each ownership type's share count and percentage\n    \"\"\"\n    # Aggregate shares by ticker, date, and owner type\n    agg = (ownership.groupby(['ticker', 'date', 'owner_type'])['shares_held']\n                    .sum()\n                    .reset_index())\n    \n    # Pivot to wide format: one column per ownership type\n    wide = agg.pivot_table(\n        index=['ticker', 'date'],\n        columns='owner_type',\n        values='shares_held',\n        fill_value=0\n    ).reset_index()\n    \n    # Rename columns\n    type_cols = [c for c in wide.columns if c in OwnershipType.ALL_TYPES]\n    rename_map = {t: f'shares_{t}' for t in type_cols}\n    wide = wide.rename(columns=rename_map)\n    \n    # Total institutional shares\n    inst_cols = [f'shares_{t}' for t in OwnershipType.INSTITUTIONAL \n                 if f'shares_{t}' in wide.columns]\n    wide['shares_institutional'] = wide[inst_cols].sum(axis=1)\n    \n    # Total foreign shares (for FOL tracking)\n    foreign_cols = [f'shares_{t}' for t in OwnershipType.FOREIGN \n                    if f'shares_{t}' in wide.columns]\n    wide['shares_foreign_total'] = wide[foreign_cols].sum(axis=1)\n    \n    # Align with quarter-end dates for merging with price data\n    wide['quarter_end'] = wide['date'] + pd.offsets.QuarterEnd(0)\n    \n    # Merge with price data to get shares outstanding\n    merged = wide.merge(\n        prices_q[['ticker', 'quarter_end', 'shares_outstanding', \n                  'adjusted_shares', 'market_cap', 'exchange', \n                  'industry_code', 'fol_limit', 'close']],\n        on=['ticker', 'quarter_end'],\n        how='left'\n    )\n    \n    # Compute ownership ratios\n    tso = merged['shares_outstanding']\n    for col in merged.columns:\n        if col.startswith('shares_') and col != 'shares_outstanding':\n            ratio_col = col.replace('shares_', 'pct_')\n            merged[ratio_col] = merged[col] / tso\n            merged.loc[tso <= 0, ratio_col] = np.nan\n    \n    # Derived measures\n    merged['pct_free_float'] = 1 - merged.get('pct_state', 0) - merged.get('pct_treasury', 0)\n    \n    # SOE flag: state ownership > 50%\n    merged['is_soe'] = (merged.get('pct_state', 0) > 0.50).astype(int)\n    \n    # FOL utilization\n    if 'fol_limit' in merged.columns and 'pct_foreign_total' in merged.columns:\n        merged['fol_utilization'] = merged['pct_foreign_total'] / merged['fol_limit']\n        merged['foreign_room'] = merged['fol_limit'] - merged['pct_foreign_total']\n        merged.loc[merged['fol_limit'] <= 0, ['fol_utilization', 'foreign_room']] = np.nan\n    \n    # Number of institutional owners (breadth)\n    n_owners = (ownership[ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL)]\n                .groupby(['ticker', 'date'])['shareholder_name']\n                .nunique()\n                .reset_index()\n                .rename(columns={'shareholder_name': 'n_inst_owners'}))\n    \n    n_foreign_owners = (ownership[ownership['owner_type'] == OwnershipType.FOREIGN_INST]\n                        .groupby(['ticker', 'date'])['shareholder_name']\n                        .nunique()\n                        .reset_index()\n                        .rename(columns={'shareholder_name': 'n_foreign_owners'}))\n    \n    merged = merged.merge(n_owners, on=['ticker', 'date'], how='left')\n    merged = merged.merge(n_foreign_owners, on=['ticker', 'date'], how='left')\n    merged[['n_inst_owners', 'n_foreign_owners']] = (\n        merged[['n_inst_owners', 'n_foreign_owners']].fillna(0)\n    )\n    \n    print(f\"Ownership decomposition computed:\")\n    print(f\"  Stock-period observations: {len(merged):,}\")\n    print(f\"  Unique tickers: {merged['ticker'].nunique():,}\")\n    print(f\"\\nMean ownership structure:\")\n    pct_cols = [c for c in merged.columns if c.startswith('pct_')]\n    print(merged[pct_cols].mean().round(4).to_string())\n    \n    return merged\n\n# ownership_decomp = compute_ownership_decomposition(\n#     ownership_classified, prices_q\n# )\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Institutional Ownership Measures {#sec-ownership-metrics}\n\n### Ownership Ratio {#sec-io-ratio}\n\nThe **Institutional Ownership Ratio (IOR)** for stock $i$ at time $t$ in Vietnam is:\n\n$$\nIOR_{i,t} = \\frac{S_{i,t}^{state} + S_{i,t}^{foreign\\_inst} + S_{i,t}^{domestic\\_inst}}{TSO_{i,t}}\n$$ {#eq-ior-vn}\n\nwhere $S_{i,t}^{type}$ denotes adjusted shares held by each ownership category and $TSO_{i,t}$ is total shares outstanding. Unlike the US where the IOR can exceed 100% due to long-only reporting and short selling, the Vietnamese IOR is bounded by construction in $[0, 1]$ because we observe the complete ownership decomposition.\n\nWe also compute category-specific ownership ratios:\n\n$$\nIOR_{i,t}^{foreign} = \\frac{S_{i,t}^{foreign\\_inst}}{TSO_{i,t}}, \\quad\nIOR_{i,t}^{state} = \\frac{S_{i,t}^{state}}{TSO_{i,t}}, \\quad\nIOR_{i,t}^{domestic} = \\frac{S_{i,t}^{domestic\\_inst}}{TSO_{i,t}}\n$$ {#eq-ior-components}\n\n### Concentration: Herfindahl-Hirschman Index {#sec-hhi}\n\nThe **Institutional Ownership Concentration** via the Herfindahl-Hirschman Index is:\n\n$$\nIOC_{i,t}^{HHI} = \\sum_{j=1}^{N_{i,t}} \\left(\\frac{S_{i,j,t}}{\\sum_{k=1}^{N_{i,t}} S_{i,k,t}}\\right)^2\n$$ {#eq-hhi-vn}\n\nIn Vietnam, the HHI is particularly informative because it captures the dominance of state shareholders. A company where the government holds 65% will have a mechanically high HHI even if the remaining 35% is diversely held.\n\nWe therefore compute **separate HHI measures** for different ownership categories:\n\n$$\nHHI_{i,t}^{total} = \\sum_{j} w_{i,j,t}^2, \\quad\nHHI_{i,t}^{non-state} = \\sum_{j \\notin state} \\left(\\frac{S_{i,j,t}}{\\sum_{k \\notin state} S_{i,k,t}}\\right)^2\n$$ {#eq-hhi-decomposed}\n\nThe non-state HHI is more comparable to the US institutional HHI, as it captures concentration among market-driven investors.\n\n### Breadth of Ownership {#sec-breadth}\n\nFollowing @chen2002breadth, **Institutional Breadth** ($N_{i,t}$) is the number of institutional investors holding stock $i$ in period $t$. The **Change in Breadth** is:\n\n$$\n\\Delta Breadth_{i,t} = \\frac{N_{i,t}^{cont} - N_{i,t-1}^{cont}}{TotalInstitutions_{t-1}}\n$$ {#eq-dbreadth-vn}\n\nwhere $N_{i,t}^{cont}$ counts only institutions that appear in the disclosure universe in both periods $t$ and $t-1$, following the @lehavy2008investor algorithm. This adjustment is particularly important in Vietnam where:\n\n-   New funds launch frequently (especially ETFs tracking VN30)\n-   Foreign funds enter and exit the market\n-   Domestic securities firms consolidate or spin off asset management divisions\n\n::: {#compute-all-metrics .cell execution_count=7}\n``` {.python .cell-code code-summary=\"Compute All Institutional Ownership Metrics for Vietnam\"}\n# ============================================================================\n# Step 5: Compute All IO Metrics\n# ============================================================================\n\ndef compute_io_metrics_vietnam(ownership: pd.DataFrame,\n                                ownership_decomp: pd.DataFrame,\n                                adj_factors: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Compute security-level institutional ownership metrics adapted for Vietnam.\n    \n    Computes:\n    1. Ownership ratios by category (state, foreign, domestic inst, individual)\n    2. HHI concentration (total, non-state, foreign-only)\n    3. Number of institutional owners (total, foreign, domestic)\n    4. Change in breadth (Lehavy-Sloan adjusted)\n    5. FOL-related metrics (utilization, room, near-cap indicator)\n    \n    Parameters\n    ----------\n    ownership : pd.DataFrame\n        Classified ownership data with individual shareholder records\n    ownership_decomp : pd.DataFrame\n        Aggregated ownership decomposition (output of compute_ownership_decomposition)\n    adj_factors : pd.DataFrame\n        Corporate action adjustment factors\n    \n    Returns\n    -------\n    pd.DataFrame\n        Stock-period level metrics\n    \"\"\"\n    # Start with the ownership decomposition\n    metrics = ownership_decomp.copy()\n    \n    # --- HHI Concentration ---\n    # Total HHI: across all institutional shareholders\n    inst_ownership = ownership[\n        ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL)\n    ].copy()\n    \n    def compute_hhi_group(group):\n        \"\"\"Compute HHI for a group of shareholders.\"\"\"\n        total = group['shares_held'].sum()\n        if total <= 0:\n            return np.nan\n        weights = group['shares_held'] / total\n        return (weights ** 2).sum()\n    \n    # Total institutional HHI\n    hhi_total = (inst_ownership.groupby(['ticker', 'date'])\n                               .apply(compute_hhi_group)\n                               .reset_index(name='hhi_institutional'))\n    metrics = metrics.merge(hhi_total, on=['ticker', 'date'], how='left')\n    \n    # Non-state HHI (exclude state shareholders)\n    non_state = ownership[\n        ownership['owner_type'].isin([OwnershipType.FOREIGN_INST, \n                                       OwnershipType.DOMESTIC_INST])\n    ]\n    hhi_nonstate = (non_state.groupby(['ticker', 'date'])\n                             .apply(compute_hhi_group)\n                             .reset_index(name='hhi_non_state'))\n    metrics = metrics.merge(hhi_nonstate, on=['ticker', 'date'], how='left')\n    \n    # Foreign-only HHI\n    foreign_only = ownership[ownership['owner_type'] == OwnershipType.FOREIGN_INST]\n    hhi_foreign = (foreign_only.groupby(['ticker', 'date'])\n                               .apply(compute_hhi_group)\n                               .reset_index(name='hhi_foreign'))\n    metrics = metrics.merge(hhi_foreign, on=['ticker', 'date'], how='left')\n    \n    # --- Change in Breadth (Lehavy-Sloan Algorithm) ---\n    metrics = metrics.sort_values(['ticker', 'date'])\n    \n    # Get list of all institutions filing in each period\n    inst_by_period = (inst_ownership.groupby('date')['shareholder_name']\n                                     .apply(set)\n                                     .to_dict())\n    \n    # For each stock-period: count continuing institutions\n    def compute_breadth_change(group):\n        group = group.sort_values('date').reset_index(drop=True)\n        group['dbreadth'] = np.nan\n        \n        for i in range(1, len(group)):\n            current_date = group.loc[i, 'date']\n            prev_date = group.loc[i-1, 'date']\n            \n            # Institutions in universe for both periods\n            current_universe = inst_by_period.get(current_date, set())\n            prev_universe = inst_by_period.get(prev_date, set())\n            continuing_universe = current_universe & prev_universe\n            \n            if len(prev_universe) == 0:\n                continue\n            \n            # Count continuing institutions holding this stock in each period\n            ticker = group.loc[i, 'ticker']\n            \n            current_holders = set(\n                inst_ownership[\n                    (inst_ownership['ticker'] == ticker) & \n                    (inst_ownership['date'] == current_date)\n                ]['shareholder_name']\n            )\n            prev_holders = set(\n                inst_ownership[\n                    (inst_ownership['ticker'] == ticker) & \n                    (inst_ownership['date'] == prev_date)\n                ]['shareholder_name']\n            )\n            \n            # Count only continuing institutions\n            n_current_cont = len(current_holders & continuing_universe)\n            n_prev_cont = len(prev_holders & continuing_universe)\n            \n            group.loc[i, 'dbreadth'] = (\n                (n_current_cont - n_prev_cont) / len(prev_universe)\n            )\n        \n        return group\n    \n    metrics = metrics.groupby('ticker', group_keys=False).apply(compute_breadth_change)\n    \n    # --- FOL Indicators ---\n    if 'fol_utilization' in metrics.columns:\n        metrics['near_fol_cap'] = (metrics['fol_utilization'] > 0.90).astype(int)\n        metrics['at_fol_cap'] = (metrics['fol_utilization'] > 0.98).astype(int)\n    \n    print(f\"IO metrics computed for Vietnam:\")\n    print(f\"  Observations: {len(metrics):,}\")\n    print(f\"\\nKey metric distributions:\")\n    summary_cols = ['pct_institutional', 'pct_state', 'pct_foreign_total',\n                    'hhi_institutional', 'n_inst_owners', 'dbreadth']\n    summary_cols = [c for c in summary_cols if c in metrics.columns]\n    print(metrics[summary_cols].describe().round(4).to_string())\n    \n    return metrics\n\n# io_metrics = compute_io_metrics_vietnam(\n#     ownership_classified, ownership_decomp, adj_factors\n# )\n```\n:::\n\n\n### Time Series Visualization\n\n::: {#fig-io-timeseries-vn .cell fig-height='12' execution_count=8}\n``` {.python .cell-code}\ndef plot_ownership_timeseries_vietnam(metrics: pd.DataFrame):\n    \"\"\"\n    Create publication-quality time series plots of Vietnamese \n    ownership structure evolution.\n    \"\"\"\n    fig, axes = plt.subplots(3, 1, figsize=(12, 14))\n    \n    # Aggregate across all stocks (market-cap weighted)\n    ts = metrics.groupby('quarter_end').apply(\n        lambda g: pd.Series({\n            'pct_state': np.average(g['pct_state'].fillna(0), \n                                     weights=g['market_cap'].fillna(1)),\n            'pct_foreign': np.average(g['pct_foreign_total'].fillna(0), \n                                       weights=g['market_cap'].fillna(1)),\n            'pct_domestic_inst': np.average(g['pct_domestic_inst'].fillna(0), \n                                             weights=g['market_cap'].fillna(1)),\n            'pct_individual': np.average(g['pct_individual'].fillna(0), \n                                          weights=g['market_cap'].fillna(1)),\n            'n_stocks': g['ticker'].nunique(),\n            'total_mktcap': g['market_cap'].sum(),\n            'median_n_inst': g['n_inst_owners'].median(),\n            'median_hhi': g['hhi_institutional'].median(),\n            'pct_soe': g['is_soe'].mean(),\n        })\n    ).reset_index()\n    \n    # ---- Panel A: Ownership Composition (Stacked Area) ----\n    ax = axes[0]\n    dates = ts['quarter_end']\n    ax.stackplot(dates,\n                 ts['pct_state'] * 100,\n                 ts['pct_foreign'] * 100,\n                 ts['pct_domestic_inst'] * 100,\n                 ts['pct_individual'] * 100,\n                 labels=['State', 'Foreign Institutional', \n                         'Domestic Institutional', 'Individual'],\n                 colors=[OWNER_COLORS['State'], OWNER_COLORS['Foreign Institutional'],\n                         OWNER_COLORS['Domestic Institutional'], OWNER_COLORS['Individual']],\n                 alpha=0.8)\n    ax.set_ylabel('Ownership Share (%)')\n    ax.set_title('Panel A: Ownership Composition of Vietnamese Listed Companies '\n                 '(Market-Cap Weighted)')\n    ax.legend(loc='upper right', frameon=True, framealpha=0.9)\n    ax.set_ylim(0, 100)\n    \n    # ---- Panel B: Institutional Ownership by Component ----\n    ax = axes[1]\n    ax.plot(dates, ts['pct_state'] * 100, label='State',\n            color=OWNER_COLORS['State'], linewidth=2)\n    ax.plot(dates, ts['pct_foreign'] * 100, label='Foreign Institutional',\n            color=OWNER_COLORS['Foreign Institutional'], linewidth=2)\n    ax.plot(dates, ts['pct_domestic_inst'] * 100, label='Domestic Institutional',\n            color=OWNER_COLORS['Domestic Institutional'], linewidth=2)\n    total_inst = (ts['pct_state'] + ts['pct_foreign'] + ts['pct_domestic_inst']) * 100\n    ax.plot(dates, total_inst, label='Total Institutional',\n            color=OWNER_COLORS['Total Institutional'], linewidth=2.5, linestyle='--')\n    ax.set_ylabel('Ownership Ratio (%)')\n    ax.set_title('Panel B: Institutional Ownership Components')\n    ax.legend(loc='upper left', frameon=True, framealpha=0.9)\n    \n    # ---- Panel C: Market Structure ----\n    ax = axes[2]\n    ax2 = ax.twinx()\n    ax.plot(dates, ts['n_stocks'], color='#1f77b4', linewidth=2, label='# Listed Stocks')\n    ax2.plot(dates, ts['total_mktcap'] / 1000, color='#d62728', linewidth=2, \n             label='Total Market Cap (Trillion VND)')\n    ax.set_ylabel('Number of Listed Stocks', color='#1f77b4')\n    ax2.set_ylabel('Market Cap (Trillion VND)', color='#d62728')\n    ax.set_title('Panel C: Vietnamese Stock Market Development')\n    \n    # Combine legends\n    lines1, labels1 = ax.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left', framealpha=0.9)\n    \n    plt.tight_layout()\n    plt.savefig('fig_ownership_timeseries_vn.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# plot_ownership_timeseries_vietnam(io_metrics)\n```\n:::\n\n\n::: {#fig-io-by-exchange .cell execution_count=9}\n``` {.python .cell-code}\ndef plot_io_by_exchange_size(metrics: pd.DataFrame):\n    \"\"\"Plot IO ratios by exchange and size quintile.\"\"\"\n    df = metrics[metrics['market_cap'].notna() & (metrics['market_cap'] > 0)].copy()\n    \n    # Size quintiles within each quarter\n    df['size_quintile'] = df.groupby('quarter_end')['market_cap'].transform(\n        lambda x: pd.qcut(x, 5, labels=['Q1\\n(Small)', 'Q2', 'Q3', 'Q4', 'Q5\\n(Large)'],\n                          duplicates='drop')\n    )\n    \n    fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n    \n    metrics_to_plot = [\n        ('pct_institutional', 'Total Institutional'),\n        ('pct_foreign_total', 'Foreign Institutional'),\n        ('pct_state', 'State'),\n    ]\n    \n    for ax, (col, title) in zip(axes, metrics_to_plot):\n        for exchange, color in EXCHANGE_COLORS.items():\n            data = df[df['exchange'] == exchange]\n            if len(data) == 0:\n                continue\n            means = data.groupby('size_quintile')[col].mean() * 100\n            ax.bar(np.arange(len(means)) + list(EXCHANGE_COLORS.keys()).index(exchange) * 0.25,\n                   means, width=0.25, label=exchange, color=color, alpha=0.8)\n        \n        ax.set_title(title)\n        ax.set_xlabel('Size Quintile')\n        if ax == axes[0]:\n            ax.set_ylabel('Mean Ownership (%)')\n        ax.legend()\n        ax.set_xticks(np.arange(5) + 0.25)\n        ax.set_xticklabels(['Q1\\n(Small)', 'Q2', 'Q3', 'Q4', 'Q5\\n(Large)'])\n    \n    plt.tight_layout()\n    plt.savefig('fig_io_by_exchange_size.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# plot_io_by_exchange_size(io_metrics)\n```\n:::\n\n\n::: {#tbl-io-summary .cell tbl-cap='Summary Statistics of Ownership Structure in Vietnam by Size Quintile and Exchange (Pooled 2010-2024)' execution_count=10}\n``` {.python .cell-code}\ndef tabulate_io_summary(metrics: pd.DataFrame, start_year: int = 2010) -> pd.DataFrame:\n    \"\"\"\n    Create publication-quality summary table of Vietnamese ownership\n    structure by firm size.\n    \"\"\"\n    df = metrics[\n        (metrics['quarter_end'].dt.year >= start_year) &\n        (metrics['market_cap'].notna()) & (metrics['market_cap'] > 0)\n    ].copy()\n    \n    df['size_quintile'] = df.groupby('quarter_end')['market_cap'].transform(\n        lambda x: pd.qcut(x, 5, labels=['Q1 (Small)', 'Q2', 'Q3', 'Q4', 'Q5 (Large)'],\n                          duplicates='drop')\n    )\n    \n    table = df.groupby('size_quintile').agg(\n        N=('ticker', 'count'),\n        Mean_MktCap=('market_cap', 'mean'),\n        Mean_IO_Total=('pct_institutional', 'mean'),\n        Mean_State=('pct_state', 'mean'),\n        Mean_Foreign=('pct_foreign_total', 'mean'),\n        Mean_Domestic_Inst=('pct_domestic_inst', 'mean'),\n        Mean_Individual=('pct_individual', 'mean'),\n        Median_N_Owners=('n_inst_owners', 'median'),\n        Median_HHI=('hhi_institutional', 'median'),\n        Pct_SOE=('is_soe', 'mean'),\n        Mean_FOL_Util=('fol_utilization', 'mean'),\n    ).round(4)\n    \n    # Format\n    table['N'] = table['N'].apply(lambda x: f\"{x:,.0f}\")\n    table['Mean_MktCap'] = table['Mean_MktCap'].apply(lambda x: f\"{x:,.0f}B VND\")\n    for col in ['Mean_IO_Total', 'Mean_State', 'Mean_Foreign', \n                'Mean_Domestic_Inst', 'Mean_Individual', 'Pct_SOE', 'Mean_FOL_Util']:\n        table[col] = table[col].apply(lambda x: f\"{x:.1%}\" if pd.notna(x) else \"—\")\n    table['Median_N_Owners'] = table['Median_N_Owners'].apply(lambda x: f\"{x:.0f}\")\n    table['Median_HHI'] = table['Median_HHI'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"—\")\n    \n    table.columns = ['N', 'Mean Mkt Cap', 'IO Total', 'State', 'Foreign', \n                      'Dom. Inst.', 'Individual', 'Med. # Owners', \n                      'Med. HHI', '% SOE', 'FOL Util.']\n    \n    return table\n\n# io_summary = tabulate_io_summary(io_metrics)\n# print(io_summary.to_string())\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Foreign Ownership Dynamics {#sec-foreign-ownership}\n\n### Foreign Ownership Limits and the FOL Premium {#sec-fol}\n\nVietnam's Foreign Ownership Limits create a unique market segmentation. When a stock reaches its FOL, the only way for a new foreign investor to buy is if an existing foreign holder sells. This creates a de facto \"foreign-only\" market for FOL-constrained stocks, with documented price premiums [@vo2015foreign].\n\nThe **FOL Utilization Ratio** for stock $i$ at time $t$ is:\n\n$$\nFOL\\_Util_{i,t} = \\frac{ForeignOwnership_{i,t}}{FOL\\_Limit_i}\n$$ {#eq-fol-util}\n\nStocks are classified by FOL proximity (@tbl-fol-zones).\n\n| FOL Zone   | Utilization Range | Market Implication                            |\n|:-----------------|:-----------------|:-----------------------------------|\n| **Green**  | \\< 50%            | Ample foreign room; normal trading            |\n| **Yellow** | 50-80%            | Moderate room; some foreign interest pressure |\n| **Orange** | 80-95%            | Limited room; foreign premium emerging        |\n| **Red**    | 95-100%           | Near cap; significant foreign premium         |\n| **Capped** | ≈ 100%            | At limit; foreign-only secondary market       |\n\n: FOL Proximity Zones {#tbl-fol-zones}\n\n::: {#fol-analysis .cell execution_count=11}\n``` {.python .cell-code code-summary=\"Comprehensive Foreign Ownership Limit Analysis\"}\n# ============================================================================\n# Step 6: Foreign Ownership Limit Analysis\n# ============================================================================\n\nclass FOLAnalyzer:\n    \"\"\"\n    Analyze Foreign Ownership Limit dynamics in the Vietnamese market.\n    \n    Key analyses:\n    1. FOL utilization tracking and classification\n    2. FOL premium estimation (price impact of being near cap)\n    3. Foreign room dynamics (opening/closing events)\n    4. Cross-sectional determinants of foreign ownership\n    \"\"\"\n    \n    FOL_ZONES = {\n        'Green': (0, 0.50),\n        'Yellow': (0.50, 0.80),\n        'Orange': (0.80, 0.95),\n        'Red': (0.95, 1.00),\n        'Capped': (1.00, 1.50),\n    }\n    \n    def __init__(self, io_metrics: pd.DataFrame,\n                 foreign_daily: Optional[pd.DataFrame] = None):\n        \"\"\"\n        Parameters\n        ----------\n        io_metrics : pd.DataFrame\n            Full ownership metrics from compute_io_metrics_vietnam()\n        foreign_daily : pd.DataFrame, optional\n            Daily foreign ownership tracking from DataCore.vn\n        \"\"\"\n        self.metrics = io_metrics.copy()\n        self.foreign_daily = foreign_daily\n    \n    def classify_fol_zones(self) -> pd.DataFrame:\n        \"\"\"Classify stocks into FOL proximity zones.\"\"\"\n        df = self.metrics.copy()\n        \n        if 'fol_utilization' not in df.columns:\n            print(\"FOL utilization not available in metrics.\")\n            return df\n        \n        conditions = []\n        choices = []\n        for zone, (lo, hi) in self.FOL_ZONES.items():\n            conditions.append(\n                (df['fol_utilization'] >= lo) & (df['fol_utilization'] < hi)\n            )\n            choices.append(zone)\n        \n        df['fol_zone'] = np.select(conditions, choices, default='Unknown')\n        \n        # Summary\n        zone_dist = df.groupby('fol_zone')['ticker'].nunique()\n        print(\"FOL Zone Distribution (unique stocks):\")\n        print(zone_dist.to_string())\n        \n        return df\n    \n    def estimate_fol_premium(self) -> pd.DataFrame:\n        \"\"\"\n        Estimate the FOL premium using a cross-sectional approach.\n        \n        For each period, regress stock valuations (P/B or P/E) on FOL \n        utilization, controlling for fundamentals. The coefficient on \n        FOL utilization captures the premium investors pay for stocks \n        near their foreign ownership cap.\n        \n        Alternative: Compare returns of stocks transitioning between \n        FOL zones as a natural experiment.\n        \"\"\"\n        df = self.metrics.copy()\n        df = df[df['fol_utilization'].notna() & df['market_cap'].notna()].copy()\n        \n        # FOL zone dummies\n        df['near_cap'] = (df['fol_utilization'] > 0.90).astype(int)\n        df['at_cap'] = (df['fol_utilization'] > 0.98).astype(int)\n        \n        # Price-to-book as valuation measure\n        # (Assumes 'equity' is available from financial data)\n        if 'equity' in df.columns:\n            df['pb_ratio'] = df['market_cap'] * 1e9 / df['equity']\n        else:\n            # Use market cap as proxy for cross-sectional analysis\n            df['log_mktcap'] = np.log(df['market_cap'])\n        \n        # Fama-MacBeth style: run cross-sectional regressions each period\n        results = []\n        for quarter, group in df.groupby('quarter_end'):\n            group = group.dropna(subset=['fol_utilization', 'log_mktcap'])\n            if len(group) < 50:\n                continue\n            \n            y = group['log_mktcap']\n            X = sm.add_constant(group[['fol_utilization', 'pct_state', \n                                        'n_inst_owners']])\n            try:\n                model = sm.OLS(y, X).fit()\n                results.append({\n                    'quarter': quarter,\n                    'beta_fol': model.params.get('fol_utilization', np.nan),\n                    'tstat_fol': model.tvalues.get('fol_utilization', np.nan),\n                    'r2': model.rsquared,\n                    'n': len(group),\n                })\n            except Exception:\n                continue\n        \n        if results:\n            results_df = pd.DataFrame(results)\n            print(\"FOL Premium (Fama-MacBeth Regression):\")\n            print(f\"  Mean β(FOL_util): {results_df['beta_fol'].mean():.4f}\")\n            print(f\"  t-statistic: {results_df['beta_fol'].mean() / \"\n                  f\"(results_df['beta_fol'].std() / np.sqrt(len(results_df))):.2f}\")\n            return results_df\n        \n        return pd.DataFrame()\n    \n    def analyze_foreign_room_events(self) -> pd.DataFrame:\n        \"\"\"\n        Analyze events where foreign room opens or closes.\n        \n        Room-opening events (FOL cap raised, foreign seller exits) can\n        trigger significant price movements as pent-up foreign demand \n        is released. Room-closing events (approaching cap) can create\n        selling pressure as foreign investors anticipate illiquidity.\n        \"\"\"\n        if self.foreign_daily is None:\n            print(\"Daily foreign ownership data required for event analysis.\")\n            return pd.DataFrame()\n        \n        df = self.foreign_daily.copy()\n        df = df.sort_values(['ticker', 'date'])\n        \n        # Compute daily change in foreign room\n        df['foreign_room_change'] = df.groupby('ticker')['foreign_room'].diff()\n        \n        # Identify room-opening events (room increases by > 1 percentage point)\n        df['room_open_event'] = (df['foreign_room_change'] > 0.01).astype(int)\n        \n        # Identify room-closing events (room decreases to < 2%)\n        df['room_close_event'] = (\n            (df['foreign_room'] < 0.02) & \n            (df.groupby('ticker')['foreign_room'].shift(1) >= 0.02)\n        ).astype(int)\n        \n        events = df[\n            (df['room_open_event'] == 1) | (df['room_close_event'] == 1)\n        ].copy()\n        \n        print(f\"Foreign room events identified:\")\n        print(f\"  Room-opening events: {df['room_open_event'].sum():,}\")\n        print(f\"  Room-closing events: {df['room_close_event'].sum():,}\")\n        \n        return events\n\n# fol_analyzer = FOLAnalyzer(io_metrics, dc.foreign_ownership)\n# fol_classified = fol_analyzer.classify_fol_zones()\n# fol_premium = fol_analyzer.estimate_fol_premium()\n```\n:::\n\n\n::: {#fig-fol-utilization .cell execution_count=12}\n``` {.python .cell-code}\ndef plot_fol_utilization(metrics: pd.DataFrame):\n    \"\"\"Plot FOL utilization distribution by sector.\"\"\"\n    df = metrics[metrics['fol_utilization'].notna()].copy()\n    \n    # Assign broad sectors\n    sector_map = {\n        'Banking': ['VCB', 'BID', 'CTG', 'TCB', 'VPB', 'MBB', 'ACB', 'HDB', 'STB', 'TPB'],\n        'Real Estate': ['VHM', 'VIC', 'NVL', 'KDH', 'DXG', 'HDG', 'VRE'],\n        'Technology': ['FPT', 'CMG', 'FOX'],\n        'Consumer': ['VNM', 'MSN', 'SAB', 'MWG', 'PNJ'],\n    }\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    for sector, tickers in sector_map.items():\n        data = df[df['ticker'].isin(tickers)]['fol_utilization']\n        if len(data) > 0:\n            ax.hist(data * 100, bins=30, alpha=0.4, label=sector, density=True)\n    \n    ax.axvline(x=30, color='red', linestyle='--', alpha=0.7, label='Banking FOL (30%)')\n    ax.axvline(x=49, color='blue', linestyle='--', alpha=0.7, label='Standard FOL (49%)')\n    ax.set_xlabel('FOL Utilization (%)')\n    ax.set_ylabel('Density')\n    ax.set_title('Foreign Ownership Limit Utilization Distribution')\n    ax.legend()\n    \n    plt.tight_layout()\n    plt.savefig('fig_fol_utilization.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# plot_fol_utilization(io_metrics)\n```\n:::\n\n\n## Institutional Trades {#sec-trades}\n\n### Trade Inference in Vietnam {#sec-trade-inference}\n\nIn the US, institutional trades are inferred from quarterly 13F holding snapshots. In Vietnam, the challenge is more acute because disclosure frequency varies:\n\n-   **Major shareholders (**$\\ge$ **5%)**: Must disclose within 7 business days of crossing ownership thresholds (5%, 10%, 15%, 20%, 25%, 50%, 65%, 75%)\n-   **Fund portfolio reports:** Semi-annual disclosure required; some funds report quarterly\n-   **Annual reports:** Provide complete shareholder register but only once per year\n-   **Daily foreign ownership:** HOSE/HNX publish aggregate daily foreign buy/sell data\n\nWe derive trades from the **change in ownership between consecutive disclosure dates**, applying the same logic as the US @bendavid2012hedge algorithm but adapted for Vietnam's irregular disclosure intervals.\n\n::: {#derive-trades-vn .cell execution_count=13}\n``` {.python .cell-code code-summary=\"Derive Institutional Trades from Vietnamese Ownership Disclosures\"}\n# ============================================================================\n# Step 7: Derive Institutional Trades\n# ============================================================================\n\ndef derive_trades_vietnam(ownership: pd.DataFrame,\n                           adj_factors: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Derive institutional trades from changes in ownership disclosures.\n    \n    Adapted from Ben-David, Franzoni, and Moussawi (2012) for \n    Vietnam's irregular disclosure frequency.\n    \n    Key differences from US approach:\n    1. Disclosure intervals are irregular (not always quarterly)\n    2. We observe ALL institutional types, not just 13F filers\n    3. No $100M AUM threshold (we see all institutional holders)\n    4. Must adjust for corporate actions between disclosure dates\n    \n    Trade types:\n    +1: Initiating Buy (new position)\n    +2: Incremental Buy (increased existing position)\n    -1: Terminating Sale (fully exited position)\n    -2: Incremental Sale (reduced existing position)\n    \n    Parameters\n    ----------\n    ownership : pd.DataFrame\n        Classified ownership with: ticker, date, shareholder_name, \n        shares_held, owner_type\n    adj_factors : pd.DataFrame\n        Corporate action adjustment factors\n    \n    Returns\n    -------\n    pd.DataFrame\n        Trade-level data: date, shareholder_name, ticker, trade, \n        buysale, owner_type\n    \"\"\"\n    # Focus on institutional shareholders only\n    inst = ownership[\n        ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL)\n    ].copy()\n    \n    inst = inst.sort_values(['shareholder_name', 'ticker', 'date']).reset_index(drop=True)\n    \n    trades_list = []\n    \n    for (shareholder, ticker), group in inst.groupby(['shareholder_name', 'ticker']):\n        group = group.reset_index(drop=True)\n        \n        for i in range(len(group)):\n            current = group.iloc[i]\n            current_date = current['date']\n            current_shares = current['shares_held']\n            owner_type = current['owner_type']\n            \n            if i == 0:\n                # First observation: if institution appears, it's an initiating buy\n                # (we don't know if they held before our data starts)\n                # Skip the very first observation to avoid false initiating buys\n                continue\n            \n            prev = group.iloc[i - 1]\n            prev_date = prev['date']\n            prev_shares = prev['shares_held']\n            \n            # Adjust previous shares for corporate actions between dates\n            prev_shares_adj = adjust_shares(\n                prev_shares, ticker, prev_date, current_date, adj_factors\n            )\n            \n            # Compute trade (in adjusted shares)\n            trade = current_shares - prev_shares_adj\n            \n            # Classify trade type\n            if abs(trade) < 1:  # De minimis threshold\n                continue\n            \n            if prev_shares_adj <= 0 and current_shares > 0:\n                buysale = 1  # Initiating buy\n            elif prev_shares_adj > 0 and current_shares <= 0:\n                buysale = -1  # Terminating sale\n            elif trade > 0:\n                buysale = 2  # Incremental buy\n            else:\n                buysale = -2  # Incremental sale\n            \n            trades_list.append({\n                'date': current_date,\n                'shareholder_name': shareholder,\n                'ticker': ticker,\n                'trade': trade,\n                'prev_shares_adj': prev_shares_adj,\n                'current_shares': current_shares,\n                'buysale': buysale,\n                'owner_type': owner_type,\n                'days_between': (current_date - prev_date).days,\n            })\n    \n    trades = pd.DataFrame(trades_list)\n    \n    if len(trades) > 0:\n        print(f\"Trades derived: {len(trades):,}\")\n        print(f\"\\nTrade type distribution:\")\n        labels = {1: 'Initiating Buy', 2: 'Incremental Buy',\n                  -1: 'Terminating Sale', -2: 'Incremental Sale'}\n        for bs, label in sorted(labels.items()):\n            n = (trades['buysale'] == bs).sum()\n            print(f\"  {label}: {n:,} ({n/len(trades):.1%})\")\n        \n        print(f\"\\nBy owner type:\")\n        print(trades.groupby('owner_type')['trade'].agg(['count', 'mean', 'median'])\n              .round(0).to_string())\n    \n    return trades\n\n# trades = derive_trades_vietnam(ownership_classified, adj_factors)\n```\n:::\n\n\n::: {.callout-warning title=\"Corporate Action Adjustment in Trade Derivation\"}\nWhen computing trades as $\\Delta Shares = Shares_t - Shares_{t-1}$, the previous period's shares **must** be adjusted for any corporate actions between $t-1$ and $t$. If VNM issued a 20% stock dividend between the two disclosure dates, then 1,000 shares at $t-1$ should be compared to 1,200 adjusted shares, not 1,000 raw shares. Failing to make this adjustment would create a phantom \"buy\" of 200 shares that never actually occurred.\n:::\n\n::: {#vectorized-trades-vn .cell execution_count=14}\n``` {.python .cell-code code-summary=\"Vectorized Trade Derivation for Large Datasets\"}\ndef derive_trades_vectorized_vietnam(ownership: pd.DataFrame,\n                                      adj_factors: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Vectorized version of Vietnamese trade derivation.\n    \n    Uses pandas groupby and vectorized operations instead of Python loops.\n    Approximately 20-50x faster for large datasets.\n    \n    Note: Corporate action adjustment is applied per-group, which still\n    requires some iteration but is much faster than row-by-row.\n    \"\"\"\n    inst = ownership[\n        ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL) &\n        (ownership['shares_held'] > 0)\n    ].copy()\n    \n    inst = inst.sort_values(['shareholder_name', 'ticker', 'date']).reset_index(drop=True)\n    \n    # Lagged values\n    inst['prev_date'] = inst.groupby(['shareholder_name', 'ticker'])['date'].shift(1)\n    inst['prev_shares'] = inst.groupby(['shareholder_name', 'ticker'])['shares_held'].shift(1)\n    inst['is_first'] = inst['prev_date'].isna()\n    \n    # Remove first observations (no prior to compare)\n    inst = inst[~inst['is_first']].copy()\n    \n    # Adjust previous shares for corporate actions\n    # Vectorized: for each row, apply adjustment between prev_date and date\n    def adjust_row(row):\n        return adjust_shares(\n            row['prev_shares'], row['ticker'], \n            row['prev_date'], row['date'], adj_factors\n        )\n    \n    inst['prev_shares_adj'] = inst.apply(adjust_row, axis=1)\n    \n    # Compute trade\n    inst['trade'] = inst['shares_held'] - inst['prev_shares_adj']\n    inst['days_between'] = (inst['date'] - inst['prev_date']).dt.days\n    \n    # Classify trade type\n    inst['buysale'] = np.select(\n        [\n            (inst['prev_shares_adj'] <= 0) & (inst['shares_held'] > 0),\n            (inst['prev_shares_adj'] > 0) & (inst['shares_held'] <= 0),\n            inst['trade'] > 0,\n            inst['trade'] < 0,\n        ],\n        [1, -1, 2, -2],\n        default=0\n    )\n    \n    # Remove zero trades\n    trades = inst[inst['buysale'] != 0].copy()\n    \n    trades = trades[['date', 'shareholder_name', 'ticker', 'trade', \n                     'buysale', 'owner_type', 'days_between',\n                     'prev_shares_adj', 'shares_held']].copy()\n    trades = trades.rename(columns={'shares_held': 'current_shares'})\n    \n    print(f\"Vectorized trades: {len(trades):,}\")\n    return trades\n\n# trades = derive_trades_vectorized_vietnam(ownership_classified, adj_factors)\n```\n:::\n\n\n## Fund-Level Flows and Turnover {#sec-flows-turnover}\n\n### Portfolio Assets and Returns from Fund Holdings\n\nUsing DataCore.vn's fund holdings data, we compute fund-level portfolio analytics analogous to the US 13F approach:\n\n$$\nAssets_{j,t} = \\sum_{i=1}^{N_{j,t}} S_{i,j,t} \\times P_{i,t}\n$$ {#eq-assets-vn}\n\n$$\nR_{j,t \\to t+1}^{holdings} = \\frac{\\sum_{i} S_{i,j,t} \\times P_{i,t} \\times R_{i,t \\to t+1}}{\\sum_{i} S_{i,j,t} \\times P_{i,t}}\n$$ {#eq-hret-vn}\n\n$$\nNetFlows_{j,t} = Assets_{j,t} - Assets_{j,t-1} \\times (1 + R_{j,t-1 \\to t}^{holdings})\n$$ {#eq-flows-vn}\n\n### Turnover Measures\n\nFollowing @carhart1997persistence, adapted for Vietnam's fund reporting:\n\n$$\nTurnover_{j,t}^{Carhart} = \\frac{\\min(TotalBuys_{j,t}, TotalSales_{j,t})}{\\overline{Assets}_{j,t}}\n$$ {#eq-turnover-vn}\n\n::: {#fund-analytics .cell execution_count=15}\n``` {.python .cell-code code-summary=\"Fund-Level Portfolio Analytics from DataCore.vn Fund Holdings\"}\n# ============================================================================\n# Step 8: Fund-Level Portfolio Analytics\n# ============================================================================\n\ndef compute_fund_analytics(fund_holdings: pd.DataFrame,\n                            prices_q: pd.DataFrame,\n                            adj_factors: pd.DataFrame) -> Dict:\n    \"\"\"\n    Compute fund-level portfolio analytics from DataCore.vn fund holdings.\n    \n    Vietnamese fund disclosure is typically semi-annual (some quarterly),\n    which limits the frequency of these analytics compared to the US\n    quarterly approach.\n    \n    Returns\n    -------\n    dict with keys:\n        'fund_assets': pd.DataFrame of fund-level assets and returns\n        'fund_trades': pd.DataFrame of fund-level derived trades\n        'fund_aggregates': pd.DataFrame of flows and turnover\n    \"\"\"\n    fh = fund_holdings.copy()\n    fh = fh[fh['shares_held'] > 0].copy()\n    \n    # Merge with prices\n    fh = fh.merge(\n        prices_q[['ticker', 'quarter_end', 'close', 'adjusted_close', 'ret']],\n        left_on=['ticker', 'report_date'],\n        right_on=['ticker', 'quarter_end'],\n        how='inner'\n    )\n    \n    # Portfolio value\n    fh['holding_value'] = fh['shares_held'] * fh['close']\n    \n    # --- Fund-Level Assets ---\n    fund_assets = fh.groupby(['fund_name', 'report_date']).agg(\n        total_assets=('holding_value', lambda x: x.sum() / 1e9),  # Billion VND\n        n_stocks=('ticker', 'nunique'),\n    ).reset_index()\n    \n    # Holdings return (value-weighted)\n    fh['weight'] = fh.groupby(['fund_name', 'report_date'])['holding_value'].transform(\n        lambda x: x / x.sum()\n    )\n    fund_hret = (fh.groupby(['fund_name', 'report_date'])\n                   .apply(lambda g: np.average(g['ret'].fillna(0), weights=g['weight']))\n                   .reset_index(name='holdings_return'))\n    \n    fund_assets = fund_assets.merge(fund_hret, on=['fund_name', 'report_date'])\n    \n    # --- Fund-Level Trades ---\n    # Derive trades from changes in holdings\n    fh_sorted = fh.sort_values(['fund_name', 'ticker', 'report_date'])\n    fh_sorted['prev_shares'] = fh_sorted.groupby(['fund_name', 'ticker'])['shares_held'].shift(1)\n    fh_sorted['prev_date'] = fh_sorted.groupby(['fund_name', 'ticker'])['report_date'].shift(1)\n    \n    # Adjust for corporate actions\n    fh_sorted['prev_shares_adj'] = fh_sorted.apply(\n        lambda r: adjust_shares(r['prev_shares'], r['ticker'], \n                                r['prev_date'], r['report_date'], adj_factors)\n        if pd.notna(r['prev_shares']) else np.nan,\n        axis=1\n    )\n    \n    fh_sorted['trade'] = fh_sorted['shares_held'] - fh_sorted['prev_shares_adj']\n    fh_sorted['trade_value'] = fh_sorted['trade'] * fh_sorted['close'] / 1e9  # Billion VND\n    \n    # Aggregate buys and sells per fund-period\n    fund_trades = fh_sorted[fh_sorted['trade'].notna()].copy()\n    fund_flows = fund_trades.groupby(['fund_name', 'report_date']).agg(\n        total_buys=('trade_value', lambda x: x[x > 0].sum()),\n        total_sales=('trade_value', lambda x: -x[x < 0].sum()),\n    ).reset_index()\n    \n    # --- Fund-Level Aggregates ---\n    fund_agg = fund_assets.merge(fund_flows, on=['fund_name', 'report_date'], how='left')\n    fund_agg[['total_buys', 'total_sales']] = fund_agg[['total_buys', 'total_sales']].fillna(0)\n    \n    fund_agg = fund_agg.sort_values(['fund_name', 'report_date'])\n    fund_agg['lag_assets'] = fund_agg.groupby('fund_name')['total_assets'].shift(1)\n    fund_agg['lag_hret'] = fund_agg.groupby('fund_name')['holdings_return'].shift(1)\n    \n    # Net flows\n    fund_agg['net_flows'] = (fund_agg['total_assets'] - \n                              fund_agg['lag_assets'] * (1 + fund_agg['holdings_return']))\n    \n    # Turnover (Carhart definition)\n    fund_agg['avg_assets'] = (fund_agg['total_assets'] + fund_agg['lag_assets']) / 2\n    fund_agg['turnover'] = (\n        fund_agg[['total_buys', 'total_sales']].min(axis=1) / fund_agg['avg_assets']\n    )\n    \n    # Annualize (approximate, since disclosure may be semi-annual)\n    fund_agg['periods_per_year'] = 365 / fund_agg.groupby('fund_name')['report_date'].diff().dt.days\n    fund_agg['turnover_annual'] = fund_agg['turnover'] * fund_agg['periods_per_year'].fillna(2)\n    \n    print(f\"Fund analytics computed:\")\n    print(f\"  Unique funds: {fund_agg['fund_name'].nunique():,}\")\n    print(f\"  Fund-period observations: {len(fund_agg):,}\")\n    print(f\"\\nTurnover statistics:\")\n    print(fund_agg[['turnover', 'turnover_annual']].describe().round(4))\n    \n    return {\n        'fund_assets': fund_assets,\n        'fund_trades': fund_trades,\n        'fund_aggregates': fund_agg,\n    }\n\n# fund_analytics = compute_fund_analytics(dc.fund_holdings, prices_q, adj_factors)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## State Ownership Analysis {#sec-state-ownership}\n\n### Equitization and the Decline of State Ownership\n\nVietnam's equitization (cổ phần hóa) program has been a defining feature of the market since the early 2000s. The program converts state-owned enterprises into joint-stock companies, typically with the state retaining a controlling or significant minority stake that is then gradually reduced through secondary offerings.\n\n::: {#state-ownership-analysis .cell execution_count=16}\n``` {.python .cell-code code-summary=\"Analyze State Ownership Dynamics and Equitization Trends\"}\n# ============================================================================\n# Step 9: State Ownership Analysis\n# ============================================================================\n\ndef analyze_state_ownership(metrics: pd.DataFrame) -> Dict:\n    \"\"\"\n    Comprehensive analysis of state ownership in Vietnam.\n    \n    Computes:\n    1. Aggregate state ownership trends\n    2. SOE population dynamics (entry/exit from SOE classification)\n    3. Equitization event detection (large drops in state ownership)\n    4. State ownership by sector and size\n    5. Governance implications (state as blockholder)\n    \"\"\"\n    df = metrics.copy()\n    \n    # --- 1. Aggregate Trends ---\n    ts = df.groupby('quarter_end').agg(\n        n_soe=('is_soe', 'sum'),\n        n_total=('ticker', 'nunique'),\n        pct_soe=('is_soe', 'mean'),\n        mean_state_pct=('pct_state', 'mean'),\n        median_state_pct=('pct_state', 'median'),\n        # Market cap share of SOEs\n        soe_mktcap=('market_cap', lambda x: x[df.loc[x.index, 'is_soe'] == 1].sum()),\n        total_mktcap=('market_cap', 'sum'),\n    ).reset_index()\n    ts['soe_mktcap_share'] = ts['soe_mktcap'] / ts['total_mktcap']\n    \n    # --- 2. Equitization Events ---\n    # Detect large drops in state ownership (>10 percentage points)\n    df_sorted = df.sort_values(['ticker', 'quarter_end'])\n    df_sorted['state_change'] = df_sorted.groupby('ticker')['pct_state'].diff()\n    \n    equitization_events = df_sorted[\n        df_sorted['state_change'] < -0.10  # > 10pp drop\n    ][['ticker', 'quarter_end', 'pct_state', 'state_change', 'market_cap']].copy()\n    \n    # --- 3. By Sector ---\n    if 'industry_code' in df.columns:\n        by_sector = df.groupby('industry_code').agg(\n            mean_state=('pct_state', 'mean'),\n            pct_soe=('is_soe', 'mean'),\n            n_firms=('ticker', 'nunique'),\n        ).sort_values('mean_state', ascending=False)\n    else:\n        by_sector = None\n    \n    print(f\"State Ownership Analysis:\")\n    print(f\"  Current SOE count: {ts.iloc[-1]['n_soe']:.0f} / {ts.iloc[-1]['n_total']:.0f}\")\n    print(f\"  SOE market cap share: {ts.iloc[-1]['soe_mktcap_share']:.1%}\")\n    print(f\"  Mean state ownership: {ts.iloc[-1]['mean_state_pct']:.1%}\")\n    print(f\"\\nEquitization events detected: {len(equitization_events):,}\")\n    \n    return {\n        'trends': ts,\n        'equitization_events': equitization_events,\n        'by_sector': by_sector,\n    }\n\n# state_analysis = analyze_state_ownership(io_metrics)\n```\n:::\n\n\n::: {#fig-state-ownership .cell fig-height='10' execution_count=17}\n``` {.python .cell-code}\ndef plot_state_ownership(state_analysis: Dict, metrics: pd.DataFrame):\n    \"\"\"Plot state ownership dynamics.\"\"\"\n    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n    ts = state_analysis['trends']\n    \n    # Panel A: SOE trends\n    ax = axes[0]\n    ax.plot(ts['quarter_end'], ts['pct_soe'] * 100, \n            label='% of Firms that are SOEs', linewidth=2, color='#d62728')\n    ax.plot(ts['quarter_end'], ts['soe_mktcap_share'] * 100,\n            label='SOE Market Cap Share (%)', linewidth=2, color='#1f77b4')\n    ax.plot(ts['quarter_end'], ts['mean_state_pct'] * 100,\n            label='Mean State Ownership (%)', linewidth=2, color='#2ca02c', linestyle='--')\n    ax.set_ylabel('Percentage')\n    ax.set_title('Panel A: State Ownership and SOE Prevalence Over Time')\n    ax.legend(frameon=True, framealpha=0.9)\n    \n    # Panel B: Distribution\n    ax = axes[1]\n    # Use most recent period\n    latest = metrics[metrics['quarter_end'] == metrics['quarter_end'].max()]\n    state_pct = latest['pct_state'].dropna() * 100\n    \n    ax.hist(state_pct, bins=50, color='#d62728', alpha=0.7, edgecolor='black')\n    ax.axvline(x=50, color='black', linestyle='--', alpha=0.7, label='50% (SOE threshold)')\n    ax.set_xlabel('State Ownership (%)')\n    ax.set_ylabel('Number of Companies')\n    ax.set_title('Panel B: Distribution of State Ownership (Most Recent Quarter)')\n    ax.legend()\n    \n    plt.tight_layout()\n    plt.savefig('fig_state_ownership.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n# plot_state_ownership(state_analysis, io_metrics)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Modern Extensions {#sec-modern-extensions}\n\n### Network Analysis of Co-Ownership {#sec-network}\n\nInstitutional co-ownership networks capture how stocks are connected through shared investors. In Vietnam, these networks reveal the influence structure of major domestic conglomerates (e.g., Vingroup, Masan, FPT) and the overlap between foreign fund portfolios.\n\n::: {#coownership-network .cell execution_count=18}\n``` {.python .cell-code code-summary=\"Construct Co-Ownership Network for Vietnamese Stocks\"}\ndef construct_stock_coownership_network(ownership: pd.DataFrame,\n                                         period: str,\n                                         min_overlap: int = 3) -> Dict:\n    \"\"\"\n    Construct a stock-level co-ownership network.\n    \n    Two stocks are connected if they share institutional investors.\n    Edge weight = number of shared institutional investors.\n    \n    This is particularly informative in Vietnam where:\n    - Foreign fund portfolios concentrate on the same blue-chips\n    - Conglomerate cross-holdings create explicit linkages\n    - State ownership creates implicit connections (SCIC holds multiple stocks)\n    \n    Parameters\n    ----------\n    ownership : pd.DataFrame\n        Classified ownership data\n    period : str\n        Analysis date\n    min_overlap : int\n        Minimum shared investors to create an edge\n    \n    Returns\n    -------\n    dict with network statistics and adjacency data\n    \"\"\"\n    import networkx as nx\n    \n    date = pd.Timestamp(period)\n    \n    # Get institutional holders for this period\n    inst = ownership[\n        (ownership['date'] == date) &\n        (ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL))\n    ][['ticker', 'shareholder_name', 'owner_type']].copy()\n    \n    # Create bipartite mapping: institution → set of stocks held\n    inst_to_stocks = inst.groupby('shareholder_name')['ticker'].apply(set).to_dict()\n    \n    # Stock → set of institutions\n    stock_to_inst = inst.groupby('ticker')['shareholder_name'].apply(set).to_dict()\n    \n    # Build stock-level network\n    stocks = list(stock_to_inst.keys())\n    G = nx.Graph()\n    \n    for i in range(len(stocks)):\n        for j in range(i + 1, len(stocks)):\n            shared = stock_to_inst[stocks[i]] & stock_to_inst[stocks[j]]\n            if len(shared) >= min_overlap:\n                G.add_edge(stocks[i], stocks[j], weight=len(shared),\n                           shared_investors=list(shared)[:5])  # Store sample\n    \n    # Add node attributes\n    for stock in stocks:\n        if stock in G.nodes:\n            G.nodes[stock]['n_inst_holders'] = len(stock_to_inst[stock])\n    \n    # Network statistics\n    stats = {\n        'n_nodes': G.number_of_nodes(),\n        'n_edges': G.number_of_edges(),\n        'density': nx.density(G) if G.number_of_nodes() > 1 else 0,\n        'avg_clustering': nx.average_clustering(G, weight='weight') if G.number_of_nodes() > 0 else 0,\n        'n_components': nx.number_connected_components(G),\n    }\n    \n    # Centrality measures\n    if G.number_of_nodes() > 0:\n        degree_cent = nx.degree_centrality(G)\n        stats['most_connected'] = sorted(degree_cent.items(), \n                                          key=lambda x: x[1], reverse=True)[:10]\n        \n        if G.number_of_nodes() > 2:\n            try:\n                eigen_cent = nx.eigenvector_centrality_numpy(G, weight='weight')\n                stats['most_central'] = sorted(eigen_cent.items(),\n                                                key=lambda x: x[1], reverse=True)[:10]\n            except Exception:\n                stats['most_central'] = []\n    \n    print(f\"Co-Ownership Network ({period}):\")\n    for k, v in stats.items():\n        if k not in ['most_connected', 'most_central']:\n            print(f\"  {k}: {v}\")\n    \n    if 'most_connected' in stats:\n        print(f\"\\nMost connected stocks:\")\n        for stock, cent in stats['most_connected'][:5]:\n            print(f\"  {stock}: {cent:.3f}\")\n    \n    return {'graph': G, 'stats': stats}\n\n# network = construct_stock_coownership_network(\n#     ownership_classified, '2024-06-30'\n# )\n```\n:::\n\n\n### ML-Enhanced Investor Classification {#sec-ml-classification}\n\nVietnam's investor classification challenge is distinct from the US. While the US has the Bushee typology based on portfolio turnover and concentration, Vietnam requires classification of both investor **type** (when not explicitly labeled) and investor **behavior** (active vs passive, short-term vs long-term).\n\n::: {#ml-classification-vn .cell execution_count=19}\n``` {.python .cell-code code-summary=\"Machine Learning Investor Classification for Vietnam\"}\ndef classify_investors_vietnam(ownership: pd.DataFrame,\n                                prices_q: pd.DataFrame,\n                                n_clusters: int = 4) -> pd.DataFrame:\n    \"\"\"\n    ML-based classification of Vietnamese institutional investors.\n    \n    Features adapted for Vietnam's market:\n    1. Portfolio concentration (HHI of holdings)\n    2. Holding duration (average time in positions)\n    3. Size preference (average market cap of holdings)\n    4. Sector concentration\n    5. Foreign/domestic indicator\n    6. Trading frequency (inverse of average days between disclosures)\n    \n    Expected clusters for Vietnam:\n    - Passive State Holders: SOE parents, SCIC - low turnover, concentrated\n    - Active Foreign Funds: Dragon Capital, VinaCapital - moderate turnover\n    - Domestic Securities Firms: SSI, VNDirect - high turnover, diversified\n    - Long-Term Foreign: Pension funds, sovereign wealth - low turnover\n    \"\"\"\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler\n    \n    inst = ownership[\n        ownership['owner_type'].isin(OwnershipType.INSTITUTIONAL)\n    ].copy()\n    \n    # Merge with price data\n    inst = inst.merge(\n        prices_q[['ticker', 'quarter_end', 'close', 'market_cap']],\n        left_on=['ticker', 'date'],\n        right_on=['ticker', 'quarter_end'],\n        how='left'\n    )\n    \n    inst['holding_value'] = inst['shares_held'] * inst['close'].fillna(0)\n    \n    # Compute features per investor-period\n    features = inst.groupby(['shareholder_name', 'date']).agg(\n        n_stocks=('ticker', 'nunique'),\n        total_value=('holding_value', 'sum'),\n        hhi_portfolio=('holding_value', \n                        lambda x: ((x/x.sum())**2).sum() if x.sum() > 0 else np.nan),\n        avg_mktcap=('market_cap', 'mean'),\n        is_foreign=('owner_type', \n                     lambda x: (x == OwnershipType.FOREIGN_INST).any().astype(int)),\n        is_state=('owner_type', \n                   lambda x: (x == OwnershipType.STATE).any().astype(int)),\n    ).reset_index()\n    \n    # Average across all periods per investor\n    investor_features = features.groupby('shareholder_name').agg(\n        avg_n_stocks=('n_stocks', 'mean'),\n        avg_hhi=('hhi_portfolio', 'mean'),\n        avg_mktcap=('avg_mktcap', 'mean'),\n        avg_total_value=('total_value', 'mean'),\n        is_foreign=('is_foreign', 'max'),\n        is_state=('is_state', 'max'),\n        n_periods=('date', 'nunique'),\n    ).dropna()\n    \n    # Feature matrix\n    feature_cols = ['avg_n_stocks', 'avg_hhi', 'avg_mktcap', 'avg_total_value']\n    X = investor_features[feature_cols].copy()\n    \n    # Log-transform\n    for col in feature_cols:\n        X[col] = np.log1p(X[col].clip(lower=0))\n    \n    # Add binary features\n    X['is_foreign'] = investor_features['is_foreign']\n    X['is_state'] = investor_features['is_state']\n    \n    # Standardize\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    # K-means\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n    investor_features['cluster'] = kmeans.fit_predict(X_scaled)\n    \n    # Label clusters\n    cluster_profiles = investor_features.groupby('cluster').agg({\n        'avg_n_stocks': 'mean',\n        'avg_hhi': 'mean',\n        'avg_total_value': 'mean',\n        'is_foreign': 'mean',\n        'is_state': 'mean',\n        'shareholder_name': 'count',\n    }).rename(columns={'shareholder_name': 'n_investors'})\n    \n    print(\"Investor Clusters:\")\n    print(cluster_profiles.round(3).to_string())\n    \n    return investor_features\n\n# investor_classes = classify_investors_vietnam(ownership_classified, prices_q)\n```\n:::\n\n\n### Event Study: Ownership Disclosure Shocks {#sec-event-study}\n\nVietnam's threshold-based major shareholder disclosure creates natural events for studying the price impact of ownership changes.\n\n::: {#event-study .cell execution_count=20}\n``` {.python .cell-code code-summary=\"Event Study Framework for Ownership Disclosure Events\"}\ndef ownership_event_study(major_shareholders: pd.DataFrame,\n                           prices: pd.DataFrame,\n                           event_window: Tuple[int, int] = (-5, 20),\n                           estimation_window: int = 120) -> pd.DataFrame:\n    \"\"\"\n    Event study of ownership disclosure announcements.\n    \n    Vietnam requires major shareholders (≥5%) to disclose within 7 \n    business days of crossing ownership thresholds. These disclosures \n    can be informationally significant, especially:\n    1. Foreign fund accumulation (signal of quality)\n    2. State divestiture (equitization signal)\n    3. Insider purchases (management confidence signal)\n    \n    Uses market model for expected returns:\n    E[R_i,t] = α_i + β_i × R_m,t\n    \n    Parameters\n    ----------\n    major_shareholders : pd.DataFrame\n        Disclosure events from DataCore.vn\n    prices : pd.DataFrame\n        Daily stock prices\n    event_window : tuple\n        (pre_event_days, post_event_days)\n    estimation_window : int\n        Days before event window for market model estimation\n    \"\"\"\n    events = major_shareholders.copy()\n    events = events.sort_values(['ticker', 'date'])\n    \n    # Identify significant ownership changes\n    events['ownership_change'] = events.groupby(\n        ['ticker', 'shareholder_name']\n    )['ownership_pct'].diff()\n    \n    significant_events = events[\n        events['ownership_change'].abs() > 0.01  # > 1 percentage point\n    ].copy()\n    \n    significant_events['event_type'] = np.where(\n        significant_events['ownership_change'] > 0, 'accumulation', 'divestiture'\n    )\n    \n    # Merge with daily prices\n    prices_daily = prices[['ticker', 'date', 'ret']].copy()\n    prices_daily = prices_daily.sort_values(['ticker', 'date'])\n    \n    # VN-Index as market return (ticker code depends on data provider)\n    if 'VNINDEX' in prices_daily['ticker'].values:\n        market_ret = prices_daily[prices_daily['ticker'] == 'VNINDEX'][['date', 'ret']].copy()\n        market_ret = market_ret.rename(columns={'ret': 'mkt_ret'})\n    else:\n        # Use equal-weighted market return as proxy\n        market_ret = (prices_daily.groupby('date')['ret']\n                                  .mean()\n                                  .reset_index()\n                                  .rename(columns={'ret': 'mkt_ret'}))\n    \n    # For each event, compute abnormal returns\n    results = []\n    pre, post = event_window\n    \n    for _, event in significant_events.iterrows():\n        ticker = event['ticker']\n        event_date = event['date']\n        \n        # Get stock returns around the event\n        stock_ret = prices_daily[prices_daily['ticker'] == ticker].copy()\n        stock_ret = stock_ret.merge(market_ret, on='date', how='left')\n        stock_ret = stock_ret.sort_values('date').reset_index(drop=True)\n        \n        # Find event date index\n        event_idx = stock_ret[stock_ret['date'] >= event_date].index\n        if len(event_idx) == 0:\n            continue\n        event_idx = event_idx[0]\n        \n        # Estimation window\n        est_start = max(0, event_idx - estimation_window + pre)\n        est_end = event_idx + pre\n        est_data = stock_ret.iloc[est_start:est_end].dropna(subset=['ret', 'mkt_ret'])\n        \n        if len(est_data) < 30:\n            continue\n        \n        # Market model\n        X = sm.add_constant(est_data['mkt_ret'])\n        y = est_data['ret']\n        try:\n            model = sm.OLS(y, X).fit()\n        except Exception:\n            continue\n        \n        # Event window abnormal returns\n        ew_start = event_idx + pre\n        ew_end = min(event_idx + post + 1, len(stock_ret))\n        event_data = stock_ret.iloc[ew_start:ew_end].copy()\n        \n        if len(event_data) == 0:\n            continue\n        \n        event_data['expected_ret'] = (model.params['const'] + \n                                       model.params['mkt_ret'] * event_data['mkt_ret'])\n        event_data['abnormal_ret'] = event_data['ret'] - event_data['expected_ret']\n        event_data['car'] = event_data['abnormal_ret'].cumsum()\n        event_data['event_day'] = range(pre, pre + len(event_data))\n        event_data['ticker'] = ticker\n        event_data['event_date'] = event_date\n        event_data['event_type'] = event['event_type']\n        event_data['ownership_change'] = event['ownership_change']\n        event_data['shareholder_name'] = event['shareholder_name']\n        \n        results.append(event_data)\n    \n    if results:\n        all_results = pd.concat(results, ignore_index=True)\n        \n        # Average CARs by event type\n        avg_car = (all_results.groupby(['event_type', 'event_day'])['car']\n                              .agg(['mean', 'std', 'count'])\n                              .reset_index())\n        avg_car['t_stat'] = avg_car['mean'] / (avg_car['std'] / np.sqrt(avg_car['count']))\n        \n        print(f\"Event Study Results:\")\n        print(f\"  Total events: {significant_events['event_type'].value_counts().to_string()}\")\n        \n        # CAR at event day 0, +5, +10, +20\n        for et in ['accumulation', 'divestiture']:\n            print(f\"\\n  {et.title()} Events:\")\n            subset = avg_car[avg_car['event_type'] == et]\n            for day in [0, 5, 10, 20]:\n                row = subset[subset['event_day'] == day]\n                if len(row) > 0:\n                    print(f\"    CAR({day:+d}): {row.iloc[0]['mean']:.4f} \"\n                          f\"(t={row.iloc[0]['t_stat']:.2f})\")\n        \n        return all_results\n    \n    return pd.DataFrame()\n\n# event_results = ownership_event_study(dc.major_shareholders, dc.prices)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Empirical Applications {#sec-empirical-applications}\n\n### Application 1: Foreign Ownership and Stock Returns in Vietnam\n\nDoes foreign institutional ownership predict returns in Vietnam? @huang2023factors find evidence consistent with the information advantage hypothesis.\n\n::: {#foreign-io-returns .cell execution_count=21}\n``` {.python .cell-code code-summary=\"Test Foreign Ownership-Return Predictability\"}\ndef test_foreign_io_returns(metrics: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Test whether changes in foreign institutional ownership predict \n    future stock returns in Vietnam.\n    \n    Methodology:\n    1. Sort stocks into quintiles by change in foreign IO\n    2. Compute equal-weighted and VN-Index-adjusted returns\n    3. Report portfolio returns and long-short spread\n    \n    This adapts the Chen, Hong, and Stein (2002) breadth test \n    specifically for Vietnam's foreign ownership component.\n    \"\"\"\n    df = metrics.copy()\n    df = df.sort_values(['ticker', 'quarter_end'])\n    \n    # Change in foreign IO\n    df['delta_foreign'] = df.groupby('ticker')['pct_foreign_total'].diff()\n    \n    # Forward quarterly return\n    df['fwd_ret'] = df.groupby('ticker')['ret'].shift(-1)\n    \n    # Drop missing\n    df = df.dropna(subset=['delta_foreign', 'fwd_ret'])\n    \n    # Quintile portfolios each quarter\n    df['foreign_quintile'] = df.groupby('quarter_end')['delta_foreign'].transform(\n        lambda x: pd.qcut(x, 5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n    )\n    \n    # Portfolio returns\n    port_ret = (df.groupby(['quarter_end', 'foreign_quintile'])['fwd_ret']\n                  .mean()\n                  .reset_index())\n    \n    port_wide = port_ret.pivot(index='quarter_end', columns='foreign_quintile', \n                                values='fwd_ret')\n    port_wide['LS'] = port_wide[5] - port_wide[1]\n    \n    # Test significance\n    results = {}\n    for q in [1, 2, 3, 4, 5, 'LS']:\n        data = port_wide[q].dropna()\n        mean_ret = data.mean()\n        t_stat = mean_ret / (data.std() / np.sqrt(len(data)))\n        results[q] = {\n            'Mean Return (%)': mean_ret * 100,\n            't-statistic': t_stat,\n            'N quarters': len(data),\n        }\n    \n    results_df = pd.DataFrame(results).T\n    results_df.index.name = 'ΔForeign IO Quintile'\n    \n    print(\"Foreign Ownership Change and Future Returns (Vietnam)\")\n    print(\"=\" * 60)\n    print(results_df.round(3).to_string())\n    \n    return results_df\n\n# foreign_return_results = test_foreign_io_returns(io_metrics)\n```\n:::\n\n\n### Application 2: State Divestiture and Value Creation\n\n::: {#equitization-value .cell execution_count=22}\n``` {.python .cell-code code-summary=\"Analyze Value Impact of State Ownership Reduction\"}\ndef analyze_equitization_value(metrics: pd.DataFrame, \n                                state_analysis: Dict) -> pd.DataFrame:\n    \"\"\"\n    Test whether reductions in state ownership are associated with \n    subsequent value creation (higher returns, improved governance).\n    \n    Hypothesis: State divestiture reduces agency costs, improves \n    operational efficiency, and attracts institutional investors,\n    leading to positive abnormal returns.\n    \n    Uses a difference-in-differences approach:\n    Treatment: Firms experiencing >10pp drop in state ownership\n    Control: Matched firms with stable state ownership\n    \"\"\"\n    df = metrics.copy()\n    events = state_analysis['equitization_events']\n    \n    if len(events) == 0:\n        print(\"No equitization events detected.\")\n        return pd.DataFrame()\n    \n    # Get treated firms and their event quarters\n    treated = events[['ticker', 'quarter_end']].drop_duplicates()\n    treated['treated'] = 1\n    \n    # Merge with metrics\n    df = df.merge(treated, on=['ticker', 'quarter_end'], how='left')\n    df['treated'] = df['treated'].fillna(0)\n    \n    # Pre/post comparison for treated firms\n    treated_tickers = treated['ticker'].unique()\n    \n    results = []\n    for ticker in treated_tickers:\n        firm = df[df['ticker'] == ticker].sort_values('quarter_end')\n        event_row = firm[firm['treated'] == 1]\n        if len(event_row) == 0:\n            continue\n        \n        event_q = event_row.iloc[0]['quarter_end']\n        \n        # Pre-event (4 quarters before)\n        pre = firm[firm['quarter_end'] < event_q].tail(4)\n        # Post-event (4 quarters after)\n        post = firm[firm['quarter_end'] > event_q].head(4)\n        \n        if len(pre) < 2 or len(post) < 2:\n            continue\n        \n        results.append({\n            'ticker': ticker,\n            'event_quarter': event_q,\n            'state_pct_pre': pre['pct_state'].mean(),\n            'state_pct_post': post['pct_state'].mean(),\n            'foreign_pct_pre': pre['pct_foreign_total'].mean(),\n            'foreign_pct_post': post['pct_foreign_total'].mean(),\n            'n_inst_pre': pre['n_inst_owners'].mean(),\n            'n_inst_post': post['n_inst_owners'].mean(),\n            'ret_pre': pre['ret'].mean(),\n            'ret_post': post['ret'].mean(),\n        })\n    \n    if results:\n        results_df = pd.DataFrame(results)\n        \n        # Paired t-tests\n        print(\"Equitization Value Analysis\")\n        print(\"=\" * 60)\n        for metric in ['state_pct', 'foreign_pct', 'n_inst', 'ret']:\n            pre_col = f'{metric}_pre'\n            post_col = f'{metric}_post'\n            diff = results_df[post_col] - results_df[pre_col]\n            t_stat, p_val = stats.ttest_1samp(diff.dropna(), 0)\n            print(f\"  Δ{metric}: {diff.mean():.4f} (t={t_stat:.2f}, p={p_val:.3f})\")\n        \n        return results_df\n    \n    return pd.DataFrame()\n\n# equitization_results = analyze_equitization_value(io_metrics, state_analysis)\n```\n:::\n\n\n### Application 3: Institutional Herding in Vietnam\n\n::: {#herding-vn .cell execution_count=23}\n``` {.python .cell-code code-summary=\"Compute LSV Herding Measure for Vietnamese Market\"}\ndef compute_herding_vietnam(trades: pd.DataFrame,\n                             owner_types: Optional[List[str]] = None) -> pd.DataFrame:\n    \"\"\"\n    Compute the Lakonishok, Shleifer, and Vishny (1992) herding measure\n    adapted for the Vietnamese market.\n    \n    Can be computed separately for:\n    - All institutional investors\n    - Foreign institutions only\n    - Domestic institutions only\n    \n    The herding measure captures whether institutions systematically\n    trade in the same direction beyond what chance would predict.\n    \"\"\"\n    from scipy.stats import binom\n    \n    t = trades.copy()\n    \n    if owner_types:\n        t = t[t['owner_type'].isin(owner_types)]\n    \n    t['is_buy'] = (t['trade'] > 0).astype(int)\n    \n    # For each stock-period\n    stock_trades = t.groupby(['ticker', 'date']).agg(\n        n_traders=('shareholder_name', 'nunique'),\n        n_buyers=('is_buy', 'sum'),\n    ).reset_index()\n    \n    # Minimum traders threshold\n    stock_trades = stock_trades[stock_trades['n_traders'] >= 3]\n    stock_trades['p_buy'] = stock_trades['n_buyers'] / stock_trades['n_traders']\n    \n    # Expected proportion per period\n    E_p = stock_trades.groupby('date').apply(\n        lambda g: g['n_buyers'].sum() / g['n_traders'].sum()\n    ).reset_index(name='E_p')\n    \n    stock_trades = stock_trades.merge(E_p, on='date')\n    \n    # Adjustment factor\n    def expected_abs_dev(n, p):\n        k = np.arange(0, n + 1)\n        probs = binom.pmf(k, n, p)\n        return np.sum(probs * np.abs(k / n - p))\n    \n    stock_trades['adj_factor'] = stock_trades.apply(\n        lambda r: expected_abs_dev(int(r['n_traders']), r['E_p']), axis=1\n    )\n    \n    stock_trades['hm'] = (np.abs(stock_trades['p_buy'] - stock_trades['E_p']) - \n                           stock_trades['adj_factor'])\n    \n    stock_trades['buy_herd'] = np.where(\n        stock_trades['p_buy'] > stock_trades['E_p'], stock_trades['hm'], np.nan\n    )\n    stock_trades['sell_herd'] = np.where(\n        stock_trades['p_buy'] < stock_trades['E_p'], stock_trades['hm'], np.nan\n    )\n    \n    # Time series of herding\n    ts_herding = stock_trades.groupby('date').agg(\n        mean_hm=('hm', 'mean'),\n        mean_buy_herd=('buy_herd', 'mean'),\n        mean_sell_herd=('sell_herd', 'mean'),\n        pct_herding=('hm', lambda x: (x > 0).mean()),\n        n_stocks=('ticker', 'nunique'),\n    ).reset_index()\n    \n    print(f\"Herding Analysis ({owner_types or 'All Institutions'}):\")\n    print(f\"  Mean HM: {stock_trades['hm'].mean():.4f}\")\n    print(f\"  Mean Buy Herding: {stock_trades['buy_herd'].mean():.4f}\")\n    print(f\"  Mean Sell Herding: {stock_trades['sell_herd'].mean():.4f}\")\n    print(f\"  % stocks with herding: {(stock_trades['hm'] > 0).mean():.1%}\")\n    \n    return stock_trades, ts_herding\n\n# herding_all, herding_ts = compute_herding_vietnam(trades)\n# herding_foreign, _ = compute_herding_vietnam(\n#     trades, owner_types=[OwnershipType.FOREIGN_INST]\n# )\n```\n:::\n\n\n## Conclusion and Practical Recommendations {#sec-conclusion}\n\n### Summary of Measures\n\n@tbl-summary-all summarizes all institutional ownership measures developed in this chapter for the Vietnamese market.\n\n| Measure | Definition | Key Adaptation for Vietnam | Python Function |\n|:-----------------|:-----------------|:-------------------|:-----------------|\n| IO Ratio | Inst. shares / TSO | Decomposed into state, foreign, domestic | `compute_ownership_decomposition()` |\n| HHI Concentration | $\\sum w_j^2$ | Separate HHI for total, non-state, foreign | `compute_io_metrics_vietnam()` |\n| ΔBreadth | Lehavy-Sloan adjusted | Applied to irregular disclosure intervals | `compute_io_metrics_vietnam()` |\n| FOL Utilization | Foreign % / FOL limit | Vietnam-specific; no US equivalent | `FOLAnalyzer` |\n| FOL Premium | Price impact of FOL proximity | Cross-sectional regression approach | `FOLAnalyzer.estimate_fol_premium()` |\n| Trades | ΔShares (corp-action adjusted) | Critical: adjust for stock dividends | `derive_trades_vectorized_vietnam()` |\n| Fund Turnover | min(B,S)/avg(A) | Semi-annual frequency; annualized | `compute_fund_analytics()` |\n| SOE Status | State ownership \\> 50% | Tracks equitization program | `analyze_state_ownership()` |\n| LSV Herding | $|p - E[p]| - E[|p - E[p]|]$ | Separate foreign vs domestic herding | `compute_herding_vietnam()` |\n| Co-Ownership Network | Shared institutional holders | Reveals conglomerate linkages | `construct_stock_coownership_network()` |\n\n: Summary of All Ownership Measures for Vietnam {#tbl-summary-all}\n\n### Data Quality Checklist for Vietnam\n\n::: {.callout-tip title=\"Vietnam Data Quality Checklist\"}\n1.  [ ] **Corporate actions:** Have you built and applied adjustment factors for ALL stock dividends, bonus shares, splits, and rights issues?\n2.  [ ] **Shareholder classification:** Have you verified the owner type classification (state vs foreign vs domestic institutional vs individual)?\n3.  [ ] **FOL limits:** Are sector-specific FOL limits correctly assigned (30% for banks, 49% standard, unlimited for some sectors)?\n4.  [ ] **Disclosure dates:** Are you using the actual disclosure date (not the record date or ex-date) for ownership snapshots?\n5.  [ ] **Treasury shares:** Are treasury shares excluded from ownership ratio denominators?\n6.  [ ] **UPCOM coverage:** Does your sample include or exclude UPCOM stocks (which have weaker disclosure requirements)?\n7.  [ ] **Cross-listings:** Are you handling NVDR (Non-Voting Depository Receipts) if applicable after market reforms?\n8.  [ ] **Name consistency:** Are shareholder names standardized across disclosure periods (Vietnamese names can have multiple romanization forms)?\n9.  [ ] **Trade adjustment:** When deriving trades between periods, have you adjusted previous shares for ALL intervening corporate actions?\n10. [ ] **Fund mandate changes:** For fund analytics, have you accounted for fund mergers, closures, and mandate changes that affect time-series continuity?\n:::\n\n### Comparison with US Framework\n\n| Dimension | US (WRDS/13F) | Vietnam (DataCore.vn) |\n|:------------------|:--------------------|:-------------------------------|\n| **Disclosure** | Quarterly 13F (mandatory) | Annual reports + event-driven |\n| **Coverage** | Institutions \\> \\$100M AUM | All shareholders in annual reports |\n| **Ownership observed** | Long positions only | Complete decomposition |\n| **IO can exceed 100%** | Yes (short selling) | No (by construction) |\n| **Permanent ID** | CRSP PERMNO | Ticker (with manual tracking of changes) |\n| **Adjustment factors** | CRSP cfacshr | Must build from corporate actions |\n| **Investor classification** | LSEG typecode / Bushee | State/Foreign/Domestic/Individual |\n| **Short selling** | Not in 13F; exists in market | Very limited; not a concern |\n| **Unique features** | — | FOL, SOE ownership, stock dividend frequency |\n\n: US vs Vietnam Institutional Ownership Framework Comparison {#tbl-us-vn-comparison}\n\n",
    "supporting": [
      "16_institutional_ownership_files/figure-pdf"
    ],
    "filters": []
  }
}