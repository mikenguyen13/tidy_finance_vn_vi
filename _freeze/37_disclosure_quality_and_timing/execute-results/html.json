{
  "hash": "6813539d39c2f3f7d99c02ad10c8431b",
  "result": {
    "engine": "jupyter",
    "markdown": "# Disclosure Quality and Timing\n\nCorporate disclosure is the primary mechanism through which firms communicate with capital markets. The quality, quantity, and timing of disclosures shape the information environment in which investors form expectations, price securities, and allocate capital. A large theoretical and empirical literature, surveyed by @healy2001information and @beyer2010financial, demonstrates that disclosure decisions have first-order effects on the cost of capital, liquidity, and investment efficiency.\n\nThis chapter brings two decades of disclosure research to the Vietnamese market, where several institutional features create a distinctive setting. First, Vietnam's regulatory framework, anchored by Circular 155/2015/TT-BTC (amended by Circular 96/2020/TT-BTC) and enforced by the State Securities Commission (SSC), mandates periodic and event-driven disclosures with specific deadlines that differ from U.S. and European norms. Second, the dominance of retail investors and relatively thin analyst coverage means that corporate disclosures are often the *primary* source of firm-specific information, amplifying their economic importance. Third, the ongoing transition from Vietnamese Accounting Standards (VAS) toward IFRS convergence introduces time-varying changes in disclosure requirements that create natural variation for empirical analysis.\n\n## Theoretical Foundations {#sec-dis-qual-theory}\n\n### Voluntary Disclosure Theory\n\nThe foundational model of voluntary disclosure is due to @verrecchia1983discretionary, who shows that in a setting where investors know a manager possesses private information, an *unraveling* equilibrium emerges: silence is interpreted as bad news, so managers disclose unless the proprietary cost of disclosure exceeds its benefit. The key insight is that non-disclosure is informative because investors rationally infer that withheld information is unfavourable.\n\n@diamond1985optimal extends the analysis to a multi-period setting where the firm's disclosure policy affects the precision of public information and hence the incentives for private information acquisition. The central trade-off is between reducing information asymmetry (which lowers the cost of capital) and reducing the rents that informed traders earn (which may discourage monitoring). @diamond1991disclosure formalize the link between disclosure and liquidity: by reducing adverse selection, voluntary disclosure narrows bid-ask spreads and increases the willingness of uninformed investors to trade.\n\nThe empirical prediction is that firms with higher-quality disclosure should enjoy:\n\n1.  Lower cost of equity capital [@botosan1997disclosure; @botosan2002re]\n2.  Lower cost of debt [@sengupta1998corporate]\n3.  Higher liquidity and lower bid-ask spreads [@diamond1991disclosure; @lang2012transparency]\n4.  More efficient investment decisions [@biddle2009does]\n\n### Strategic Disclosure Timing\n\nNot all disclosure is voluntary in timing, but managers retain discretion over *when,* within permissible windows, to release information. @patell1982good document that firms tend to release good news during trading hours and bad news after market close. @dellavigna2009investor show that earnings announced on Fridays (i.e., when investor attention is lower) generate smaller immediate reactions and larger post-announcement drift, consistent with limited attention. @hirshleifer2009driven generalize this finding: extraneous events that distract investors (such as a large number of concurrent announcements) reduce the immediate price response to earnings news.\n\nIn Vietnam, several features make strategic timing particularly relevant. The concentrated disclosure calendar, where many firms file near regulatory deadlines, creates natural variation in announcement congestion. The retail-dominated investor base may be more susceptible to attention effects than institutional investors. The regulatory structure, which imposes penalties for late filing but allows discretion within the permissible window, creates a setting in which the *choice* of filing date is informative.\n\n### Disclosure Quality in Emerging Markets\n\n@ball2003incentives argue that accounting quality is shaped more by reporting *incentives* than by accounting *standards*. In institutional environments with weak enforcement, concentrated ownership, and close alignment between financial and tax reporting, firms may produce lower-quality disclosures even under nominally rigorous standards. @leuz2003earnings confirm this pattern internationally: earnings management (an inverse proxy for disclosure quality) is highest in countries with weak investor protection, concentrated ownership, and less developed capital markets.\n\nVietnam exhibits several of these features. @bushman2004financial classify determinants of transparency into governance factors (legal origin, judicial efficiency, minority protection) and political factors (state ownership, government intervention). Vietnam's civil-law tradition, significant state ownership in listed firms, and evolving enforcement capacity suggest that disclosure quality may be lower on average than in developed markets, but with substantial cross-sectional variation driven by firm-level governance and ownership structures.\n\n## Regulatory Framework {#sec-dis-qual-regulation}\n\n### Mandatory Disclosure Requirements\n\nVietnamese disclosure regulation operates through a hierarchy of legal instruments:\n\n-   **Securities Law (2019):** Establishes the general obligation of listed firms to disclose information truthfully, accurately, completely, and on time (Article 118).\n-   **Circular 155/2015/TT-BTC** (amended by **Circular 96/2020/TT-BTC**): Specifies the content, format, and deadlines for periodic and event-driven disclosures.\n-   **SSC decisions and guidance:** Provide implementation details and sector-specific requirements.\n\nThe key periodic reporting deadlines are in @tbl-dis-qual-deadlines\n\n| Report Type | Deadline | Audit Requirement |\n|------------------------|------------------------|------------------------|\n| Annual financial statements | 90 days after fiscal year-end | Audited |\n| Semi-annual financial statements | 45 days after period-end | Reviewed |\n| Quarterly financial statements | 20 days after quarter-end | Unaudited |\n| Annual report | 110 days after fiscal year-end | N/A (narrative) |\n\n: Periodic disclosure deadlines under Vietnamese securities regulation. {#tbl-dis-qual-deadlines}\n\nEvent-driven (ad hoc) disclosures must be filed within 24 hours for material events, including changes in ownership exceeding 1% by major shareholders, board resolutions on dividends or capital increases, and any event that may materially affect the share price.\n\n### Penalties for Non-Compliance\n\nThe SSC may impose administrative fines for late or incomplete disclosure, typically ranging from VND 50–100 million for minor violations and up to VND 500 million for material omissions. While these amounts are modest relative to firm size for large-cap companies, the reputational cost and the risk of trading suspension provide additional deterrence.\n\n## Data Construction {#sec-dis-qual-data}\n\n### Loading Required Libraries\n\n::: {#setup .cell execution_count=1}\n``` {.python .cell-code code-summary=\"Import libraries and configure environment\"}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom datetime import datetime, timedelta\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom linearmodels.panel import PanelOLS\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Plotting defaults\nplt.rcParams.update({\n    'figure.figsize': (10, 6),\n    'figure.dpi': 150,\n    'font.size': 11,\n    'axes.spines.top': False,\n    'axes.spines.right': False\n})\n```\n:::\n\n\n### Retrieving Disclosure Data\n\nWe assume that we have structured data on filing dates, announcement timestamps, and the textual content of corporate disclosures for all firms.\n\n::: {#data-load .cell execution_count=2}\n``` {.python .cell-code code-summary=\"Load disclosure and financial data\"}\nfrom datacore import DataCoreClient\n\nclient = DataCoreClient()\n\n# Filing metadata: announcement dates, filing dates, report types\nfilings = client.get_filings(\n    exchanges=['HOSE', 'HNX'],\n    report_types=['annual', 'semi_annual', 'quarterly'],\n    start_date='2012-01-01',\n    end_date='2024-12-31',\n    fields=[\n        'ticker', 'report_type', 'fiscal_year', 'fiscal_quarter',\n        'fiscal_year_end', 'filing_date', 'announcement_date',\n        'auditor', 'audit_opinion', 'file_url'\n    ]\n)\n\n# Financial statement data\nfinancials = client.get_fundamentals(\n    exchanges=['HOSE', 'HNX'],\n    start_date='2012-01-01',\n    end_date='2024-12-31',\n    fields=[\n        'ticker', 'fiscal_year', 'fiscal_quarter',\n        'total_assets', 'total_equity', 'revenue', 'net_income',\n        'operating_cash_flow', 'total_accruals',\n        'market_cap', 'book_to_market'\n    ]\n)\n\n# Daily trading data for event studies\ntrading = client.get_daily_prices(\n    exchanges=['HOSE', 'HNX'],\n    start_date='2012-01-01',\n    end_date='2024-12-31',\n    fields=[\n        'ticker', 'date', 'close', 'volume', 'turnover',\n        'bid_ask_spread', 'market_return'\n    ]\n)\n\n# Ownership and governance\ngovernance = client.get_governance(\n    exchanges=['HOSE', 'HNX'],\n    fields=[\n        'ticker', 'fiscal_year', 'state_ownership_pct',\n        'foreign_ownership_pct', 'board_size',\n        'board_independence_pct', 'big4_auditor',\n        'dual_listing'\n    ]\n)\n\nprint(f\"Filings: {filings.shape[0]:,} records\")\nprint(f\"Financials: {financials.shape[0]:,} records\")\nprint(f\"Trading: {trading.shape[0]:,} records\")\nprint(f\"Governance: {governance.shape[0]:,} records\")\n```\n:::\n\n\n### Computing Filing Timeliness {#sec-dis-qual-timeliness}\n\nWe define **reporting lag** as the number of calendar days between the fiscal period-end and the date the firm's financial statements are made publicly available. For annual reports, the regulatory maximum is 90 days; firms that file earlier than the deadline reveal information sooner, while firms that file late face potential penalties and signal possible difficulties with their accounts.\n\n::: {#compute-lag .cell execution_count=3}\n``` {.python .cell-code code-summary=\"Compute reporting lag for each filing\"}\nfilings['fiscal_year_end'] = pd.to_datetime(filings['fiscal_year_end'])\nfilings['filing_date'] = pd.to_datetime(filings['filing_date'])\nfilings['announcement_date'] = pd.to_datetime(filings['announcement_date'])\n\n# Reporting lag = filing date - fiscal period end\nfilings['reporting_lag'] = (\n    filings['filing_date'] - filings['fiscal_year_end']\n).dt.days\n\n# Regulatory deadline based on report type\ndeadline_map = {\n    'annual': 90,\n    'semi_annual': 45,\n    'quarterly': 20\n}\nfilings['deadline_days'] = filings['report_type'].map(deadline_map)\n\n# Late filing indicator\nfilings['late_filing'] = (\n    filings['reporting_lag'] > filings['deadline_days']\n).astype(int)\n\n# Days relative to deadline (negative = early, positive = late)\nfilings['days_relative_deadline'] = (\n    filings['reporting_lag'] - filings['deadline_days']\n)\n\n# Summary statistics\nannual_filings = filings[filings['report_type'] == 'annual'].copy()\nprint(\"Annual Report Filing Lag (calendar days):\")\nprint(annual_filings['reporting_lag'].describe().round(1))\nprint(f\"\\nLate filing rate: {annual_filings['late_filing'].mean():.1%}\")\n```\n:::\n\n\n### Distribution of Filing Lags\n\n::: {#fig-filing-lag-dist .cell execution_count=4}\n``` {.python .cell-code code-summary=\"Plot the distribution of annual report filing lags\"}\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Histogram\naxes[0].hist(\n    annual_filings['reporting_lag'].dropna(),\n    bins=60, range=(20, 150),\n    color='#2C5F8A', edgecolor='white', alpha=0.85\n)\naxes[0].axvline(x=90, color='#C0392B', linestyle='--', linewidth=2,\n                label='90-day deadline')\naxes[0].set_xlabel('Reporting Lag (Calendar Days)')\naxes[0].set_ylabel('Number of Filings')\naxes[0].set_title('Distribution of Annual Report Filing Lags')\naxes[0].legend()\n\n# Time trend: median lag by year\nmedian_lag = (\n    annual_filings\n    .groupby('fiscal_year')['reporting_lag']\n    .agg(['median', lambda x: x.quantile(0.25),\n          lambda x: x.quantile(0.75)])\n)\nmedian_lag.columns = ['median', 'p25', 'p75']\n\naxes[1].fill_between(\n    median_lag.index, median_lag['p25'], median_lag['p75'],\n    alpha=0.3, color='#2C5F8A', label='IQR'\n)\naxes[1].plot(\n    median_lag.index, median_lag['median'],\n    color='#2C5F8A', linewidth=2, marker='o', label='Median'\n)\naxes[1].axhline(y=90, color='#C0392B', linestyle='--',\n                linewidth=1.5, label='Deadline')\naxes[1].set_xlabel('Fiscal Year')\naxes[1].set_ylabel('Filing Lag (Calendar Days)')\naxes[1].set_title('Median Annual Filing Lag Over Time')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Measuring Disclosure Quality {#sec-dis-qual-quality}\n\nDisclosure quality is inherently multidimensional. Following @dechow2010understanding and @beyer2010financial, we construct proxies along four dimensions: (i) timeliness, (ii) textual properties, (iii) accounting quality, and (iv) voluntary disclosure breadth.\n\n### Timeliness as a Quality Dimension\n\nTimely disclosure reduces the duration of information asymmetry between insiders and outside investors. @chambers1984timeliness and @givoly1982timeliness establish that early reporters tend to announce good news, while late reporters more often deliver bad news. We test this pattern in the Vietnamese context below.\n\nWe operationalize timeliness through two measures:\n\n1.  **Reporting lag** (continuous): Calendar days from fiscal period-end to filing date, as constructed in @sec-dis-qual-timeliness.\n2.  **Early/late classification** (categorical): We classify firm-years into terciles based on reporting lag within each fiscal year. This controls for secular trends in filing speed (e.g., driven by regulatory changes or COVID-19 disruptions).\n\n::: {#timeliness-terciles .cell execution_count=5}\n``` {.python .cell-code code-summary=\"Classify filings into timeliness terciles\"}\nannual_filings['lag_tercile'] = (\n    annual_filings\n    .groupby('fiscal_year')['reporting_lag']\n    .transform(lambda x: pd.qcut(x, 3, labels=['Early', 'Middle', 'Late']))\n)\n\n# Tabulate\ntercile_stats = (\n    annual_filings\n    .groupby('lag_tercile')['reporting_lag']\n    .agg(['count', 'mean', 'median', 'std'])\n    .round(1)\n)\ntercile_stats.columns = ['N', 'Mean Lag', 'Median Lag', 'SD']\nprint(tercile_stats)\n```\n:::\n\n\n### Textual Quality Measures {#sec-dis-qual-textual}\n\nThe textual properties of corporate disclosures convey information about quality beyond what is captured by accounting numbers alone. @li2008annual demonstrates that annual reports with lower readability are associated with lower earnings persistence, suggesting that complex language may obscure unfavourable information. @loughran2014measuring critique the application of general readability formulas (Fog index, Flesch-Kincaid) to financial text, arguing that these metrics confound complexity with technical terminology.\n\nWe construct three textual quality measures adapted for Vietnamese corporate disclosures:\n\n#### Document Length and Specificity\n\nLonger disclosures are not inherently better—length may reflect boilerplate or obfuscation. However, @dyer2017evolution show that the *informative* component of disclosure (as opposed to standard legal language) has increased over time in U.S. 10-K filings. We measure:\n\n-   **Total word count:** Raw length of the annual report narrative sections (MD&A equivalent)\n-   **Numerical density:** Proportion of tokens that are numbers, percentages, or currency amounts, which is a proxy for specificity.\n\n::: {#textual-measures .cell execution_count=6}\n``` {.python .cell-code code-summary=\"Compute textual disclosure quality measures\"}\nimport re\nfrom underthesea import word_tokenize\n\ndef compute_textual_metrics(text):\n    \"\"\"Compute textual quality metrics for Vietnamese corporate text.\"\"\"\n    if not text or len(text.strip()) == 0:\n        return {\n            'word_count': 0, 'sentence_count': 0,\n            'numerical_density': 0, 'avg_sentence_length': 0,\n            'unique_word_ratio': 0, 'forward_looking_density': 0\n        }\n\n    # Vietnamese word segmentation\n    tokens = word_tokenize(text)\n    sentences = re.split(r'[.!?。]', text)\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n\n    word_count = len(tokens)\n    sentence_count = max(len(sentences), 1)\n\n    # Numerical density: proportion of tokens that are numeric\n    num_pattern = re.compile(r'^[\\d,.%]+$')\n    numeric_tokens = sum(1 for t in tokens if num_pattern.match(t))\n    numerical_density = numeric_tokens / max(word_count, 1)\n\n    # Lexical diversity: unique words / total words\n    unique_words = len(set(t.lower() for t in tokens))\n    unique_word_ratio = unique_words / max(word_count, 1)\n\n    # Forward-looking statement density\n    forward_keywords = [\n        'dự kiến', 'kế hoạch', 'mục tiêu', 'triển vọng',\n        'định hướng', 'chiến lược', 'tương lai', 'sẽ',\n        'dự báo', 'phấn đấu', 'cam kết', 'hướng tới'\n    ]\n    text_lower = text.lower()\n    forward_count = sum(text_lower.count(kw) for kw in forward_keywords)\n    forward_looking_density = forward_count / max(sentence_count, 1)\n\n    return {\n        'word_count': word_count,\n        'sentence_count': sentence_count,\n        'numerical_density': numerical_density,\n        'avg_sentence_length': word_count / sentence_count,\n        'unique_word_ratio': unique_word_ratio,\n        'forward_looking_density': forward_looking_density\n    }\n\n# Retrieve annual report text from DataCore\nannual_text = client.get_annual_report_text(\n    exchanges=['HOSE', 'HNX'],\n    start_date='2012-01-01',\n    end_date='2024-12-31',\n    sections=['mda', 'business_overview', 'risk_factors']\n)\n\n# Apply textual metrics\ntextual_metrics = annual_text.apply(\n    lambda row: compute_textual_metrics(row['text']),\n    axis=1, result_type='expand'\n)\nannual_text = pd.concat([annual_text, textual_metrics], axis=1)\n\nprint(\"Textual Quality Summary Statistics:\")\nprint(annual_text[['word_count', 'numerical_density',\n                    'avg_sentence_length', 'unique_word_ratio',\n                    'forward_looking_density']].describe().round(3))\n```\n:::\n\n\n#### Forward-Looking Statement Density\n\nForward-looking statements reveal management's expectations about future performance and are considered a higher-quality form of disclosure because they expose the manager to ex-post evaluation. In Vietnamese reports, forward-looking language typically appears in the form of phrases like *dự kiến* (expected), *kế hoạch* (plan), *mục tiêu* (target), and *triển vọng* (outlook).\n\n@guay2016guiding show that managers use voluntary disclosure to \"guide through the fog\" when financial statements are complex. We operationalize forward-looking density as the number of forward-looking phrases per sentence, following the keyword approach in our `compute_textual_metrics` function above.\n\n### Accounting-Based Quality Proxies {#sec-dis-qual-accruals-quality}\n\nWe complement textual measures with accounting-based proxies that capture the reliability of reported financial information.\n\n#### Accruals Quality\n\nFollowing @francis2005market, we measure accruals quality as the standard deviation of residuals from a regression of working capital accruals on past, current, and future operating cash flows:\n\n$$\n\\frac{WC_{i,t}}{A_{i,t-1}} = \\alpha + \\beta_1 \\frac{CFO_{i,t-1}}{A_{i,t-1}} + \\beta_2 \\frac{CFO_{i,t}}{A_{i,t-1}} + \\beta_3 \\frac{CFO_{i,t+1}}{A_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-accruals-quality}\n\nwhere $WC_{i,t}$ is working capital accruals, $CFO_{i,t}$ is operating cash flow, and $A_{i,t-1}$ is lagged total assets. The firm-level standard deviation of $\\hat{\\varepsilon}_{i,t}$ over a rolling window (typically 5 years) is the accruals quality measure, with higher values indicating lower quality.\n\n::: {#accruals-quality .cell execution_count=7}\n``` {.python .cell-code code-summary=\"Estimate accruals quality (Dechow-Dichev residual volatility)\"}\ndef estimate_accruals_quality(df, min_obs=5):\n    \"\"\"\n    Estimate accruals quality as std dev of DD residuals\n    over a rolling 5-year window for each firm.\n    \"\"\"\n    results = []\n\n    for ticker, group in df.groupby('ticker'):\n        group = group.sort_values('fiscal_year')\n\n        # Construct leads/lags of CFO\n        group['cfo_lag1'] = group['operating_cash_flow'].shift(1)\n        group['cfo_lead1'] = group['operating_cash_flow'].shift(-1)\n\n        # Scale by lagged assets\n        group['lag_assets'] = group['total_assets'].shift(1)\n        for col in ['total_accruals', 'operating_cash_flow',\n                     'cfo_lag1', 'cfo_lead1']:\n            group[f'{col}_scaled'] = group[col] / group['lag_assets']\n\n        # Rolling 5-year residual std dev\n        for idx in range(len(group)):\n            window = group.iloc[max(0, idx - 4):idx + 1]\n            window = window.dropna(subset=[\n                'total_accruals_scaled', 'operating_cash_flow_scaled',\n                'cfo_lag1_scaled', 'cfo_lead1_scaled'\n            ])\n\n            if len(window) >= min_obs:\n                y = window['total_accruals_scaled']\n                X = sm.add_constant(window[[\n                    'cfo_lag1_scaled',\n                    'operating_cash_flow_scaled',\n                    'cfo_lead1_scaled'\n                ]])\n                try:\n                    model = sm.OLS(y, X).fit()\n                    results.append({\n                        'ticker': ticker,\n                        'fiscal_year': group.iloc[idx]['fiscal_year'],\n                        'accruals_quality': model.resid.std()\n                    })\n                except Exception:\n                    pass\n\n    return pd.DataFrame(results)\n\naq_df = estimate_accruals_quality(financials)\nprint(f\"Accruals quality computed for {aq_df['ticker'].nunique()} firms\")\nprint(aq_df['accruals_quality'].describe().round(4))\n```\n:::\n\n\n#### Earnings Persistence and Predictability\n\nPersistent earnings are more useful for valuation. We estimate earnings persistence as the slope coefficient $\\phi_1$ from a first-order autoregression:\n\n$$\n\\frac{E_{i,t}}{A_{i,t-1}} = \\phi_0 + \\phi_1 \\frac{E_{i,t-1}}{A_{i,t-2}} + \\nu_{i,t}\n$$ {#eq-persistence}\n\nHigher $\\hat{\\phi}_1$ indicates more persistent (and arguably higher-quality) earnings.\n\n::: {#earnings-persistence .cell execution_count=8}\n``` {.python .cell-code code-summary=\"Estimate firm-level earnings persistence\"}\ndef estimate_persistence(df, min_obs=5):\n    \"\"\"Estimate earnings persistence via AR(1) model.\"\"\"\n    results = []\n\n    for ticker, group in df.groupby('ticker'):\n        group = group.sort_values('fiscal_year')\n        group['earnings_scaled'] = group['net_income'] / group['total_assets'].shift(1)\n        group['earnings_lag'] = group['earnings_scaled'].shift(1)\n\n        clean = group.dropna(subset=['earnings_scaled', 'earnings_lag'])\n        if len(clean) >= min_obs:\n            y = clean['earnings_scaled']\n            X = sm.add_constant(clean[['earnings_lag']])\n            model = sm.OLS(y, X).fit()\n            results.append({\n                'ticker': ticker,\n                'persistence': model.params['earnings_lag'],\n                'persistence_se': model.bse['earnings_lag'],\n                'r_squared': model.rsquared,\n                'n_obs': model.nobs\n            })\n\n    return pd.DataFrame(results)\n\npersistence_df = estimate_persistence(financials)\nprint(persistence_df[['persistence', 'r_squared']].describe().round(3))\n```\n:::\n\n\n### Composite Disclosure Quality Index {#sec-dis-qual-composite}\n\nIndividual quality proxies capture different facets of the information environment. To aggregate them into a single score while avoiding arbitrary weighting, we follow @lang1993cross and use a rank-based composite. For each firm-year, we rank firms on each of the following dimensions (higher rank = higher quality) (@tbl-dis-qual-composite).\n\n| Dimension        | Proxy                 | Direction         |\n|------------------|-----------------------|-------------------|\n| Timeliness       | Reporting lag         | Lower is better   |\n| Specificity      | Numerical density     | Higher is better  |\n| Forward-looking  | FLS density           | Higher is better  |\n| Earnings quality | Accruals quality (DD) | Lower σ is better |\n| Persistence      | AR(1) coefficient     | Higher is better  |\n\n: Components of the composite disclosure quality index. {#tbl-dis-qual-composite}\n\nWe convert each proxy to a percentile rank within each fiscal year (so each component ranges from 0 to 1), then average across components:\n\n$$\nDQ_{i,t} = \\frac{1}{K} \\sum_{k=1}^{K} \\text{Rank}_{k,i,t}\n$$ {#eq-dq-index}\n\nwhere $K$ is the number of available components and $\\text{Rank}_{k,i,t}$ is the percentile rank of firm $i$ in year $t$ on dimension $k$.\n\n::: {#composite-index .cell execution_count=9}\n``` {.python .cell-code code-summary=\"Construct composite disclosure quality index\"}\n# Merge all quality proxies\nquality_panel = (\n    annual_filings[['ticker', 'fiscal_year', 'reporting_lag']]\n    .merge(\n        annual_text[['ticker', 'fiscal_year', 'numerical_density',\n                      'forward_looking_density']],\n        on=['ticker', 'fiscal_year'], how='left'\n    )\n    .merge(aq_df, on=['ticker', 'fiscal_year'], how='left')\n    .merge(persistence_df[['ticker', 'persistence']],\n           on='ticker', how='left')\n)\n\n# Rank each component within fiscal year (higher = better quality)\ndef year_percentile_rank(series):\n    \"\"\"Convert to percentile rank within group.\"\"\"\n    return series.rank(pct=True)\n\nrank_cols = {}\nfor col, ascending in [\n    ('reporting_lag', False),       # lower lag = better → invert\n    ('numerical_density', True),    # higher = better\n    ('forward_looking_density', True),\n    ('accruals_quality', False),    # lower volatility = better → invert\n    ('persistence', True)           # higher = better\n]:\n    col_to_rank = quality_panel[col] if ascending else -quality_panel[col]\n    rank_cols[f'rank_{col}'] = (\n        quality_panel\n        .groupby('fiscal_year')[col]\n        .transform(lambda x: x.rank(pct=True) if ascending\n                   else (-x).rank(pct=True))\n    )\n\nrank_df = pd.DataFrame(rank_cols)\nquality_panel = pd.concat([quality_panel, rank_df], axis=1)\n\n# Composite index: average of available ranks\nrank_columns = [c for c in quality_panel.columns if c.startswith('rank_')]\nquality_panel['dq_index'] = quality_panel[rank_columns].mean(axis=1)\n\nprint(\"Disclosure Quality Index Distribution:\")\nprint(quality_panel['dq_index'].describe().round(3))\n```\n:::\n\n\n::: {#fig-dq-distribution .cell execution_count=10}\n``` {.python .cell-code code-summary=\"Plot distribution of composite disclosure quality index\"}\nfig, ax = plt.subplots(figsize=(10, 5))\nax.hist(quality_panel['dq_index'].dropna(), bins=50,\n        color='#2C5F8A', edgecolor='white', alpha=0.85)\nax.axvline(quality_panel['dq_index'].median(), color='#E67E22',\n           linestyle='--', linewidth=2, label='Median')\nax.set_xlabel('Disclosure Quality Index')\nax.set_ylabel('Number of Firm-Years')\nax.set_title('Distribution of Composite Disclosure Quality')\nax.legend()\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Determinants of Disclosure Quality {#sec-dis-qual-determinants}\n\nWhat drives variation in disclosure quality across Vietnamese firms? We estimate a cross-sectional regression of the composite DQ index on firm characteristics and governance variables:\n\n$$\nDQ_{i,t} = \\alpha + \\beta_1 \\ln(\\text{Size}_{i,t}) + \\beta_2 \\text{ROA}_{i,t} + \\beta_3 \\text{Lev}_{i,t} + \\beta_4 \\text{StateOwn}_{i,t} + \\beta_5 \\text{ForeignOwn}_{i,t} + \\beta_6 \\text{Big4}_{i,t} + \\beta_7 \\text{BoardIndep}_{i,t} + \\gamma_t + \\varepsilon_{i,t}\n$$ {#eq-determinants}\n\nwhere $\\gamma_t$ are year fixed effects.\n\nThe theoretical predictions, drawing on @lang1993cross, @hope2003disclosure, and @bushman2004financial, are:\n\n-   **Size (+):** Larger firms face greater public scrutiny and have lower proprietary costs relative to the benefits of disclosure.\n-   **ROA (+/−):** Profitable firms may disclose more to signal quality, but firms managing earnings downward (for tax purposes) may reduce disclosure to avoid scrutiny.\n-   **Leverage (+):** @sengupta1998corporate argues that firms with more debt have stronger incentives to maintain disclosure quality to lower borrowing costs.\n-   **State ownership (−):** SOEs may face weaker market discipline and political incentives to limit transparency.\n-   **Foreign ownership (+):** Foreign institutional investors demand higher transparency.\n-   **Big 4 auditor (+):** High-quality auditors constrain earnings management and indirectly improve disclosure quality.\n-   **Board independence (+):** Independent directors improve monitoring and encourage more informative disclosure.\n\n::: {#determinants-regression .cell execution_count=11}\n``` {.python .cell-code code-summary=\"Estimate determinants of disclosure quality\"}\n# Merge quality index with financials and governance\ndet_panel = (\n    quality_panel[['ticker', 'fiscal_year', 'dq_index']]\n    .merge(financials, on=['ticker', 'fiscal_year'], how='left')\n    .merge(governance, on=['ticker', 'fiscal_year'], how='left')\n)\n\n# Construct variables\ndet_panel['log_size'] = np.log(det_panel['total_assets'])\ndet_panel['roa'] = det_panel['net_income'] / det_panel['total_assets']\ndet_panel['leverage'] = (\n    (det_panel['total_assets'] - det_panel['total_equity'])\n    / det_panel['total_assets']\n)\n\n# Panel regression with year FE\ndet_panel = det_panel.set_index(['ticker', 'fiscal_year'])\n\nmodel_det = PanelOLS(\n    dependent=det_panel['dq_index'],\n    exog=sm.add_constant(det_panel[[\n        'log_size', 'roa', 'leverage',\n        'state_ownership_pct', 'foreign_ownership_pct',\n        'big4_auditor', 'board_independence_pct'\n    ]]),\n    entity_effects=False,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type='clustered', cluster_entity=True)\n\nprint(model_det.summary)\n```\n:::\n\n\n::: {#fig-determinants-coefficients .cell execution_count=12}\n``` {.python .cell-code code-summary=\"Visualize determinant regression coefficients\"}\ncoefs = model_det.params.drop('const')\nci = model_det.conf_int().drop('const')\n\nfig, ax = plt.subplots(figsize=(8, 5))\ny_pos = range(len(coefs))\nlabels = [\n    'ln(Assets)', 'ROA', 'Leverage', 'State Own %',\n    'Foreign Own %', 'Big 4 Auditor', 'Board Indep %'\n]\n\ncolors = ['#2C5F8A' if c > 0 else '#C0392B' for c in coefs.values]\nax.barh(y_pos, coefs.values, color=colors, alpha=0.8, height=0.6)\nax.errorbar(\n    coefs.values, y_pos,\n    xerr=[coefs.values - ci.iloc[:, 0].values,\n          ci.iloc[:, 1].values - coefs.values],\n    fmt='none', color='black', capsize=3\n)\nax.axvline(x=0, color='gray', linewidth=0.8, linestyle='-')\nax.set_yticks(y_pos)\nax.set_yticklabels(labels)\nax.set_xlabel('Coefficient Estimate')\nax.set_title('Determinants of Disclosure Quality')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Strategic Disclosure Timing {#sec-dis-qual-strategic-timing}\n\n### Day-of-Week Effects\n\n@dellavigna2009investor document that Friday earnings announcements receive less immediate market attention. We test whether this pattern holds in Vietnam, where the trading week runs Monday through Friday but the retail-dominated investor base may exhibit different attention patterns.\n\n::: {#day-of-week .cell execution_count=13}\n``` {.python .cell-code code-summary=\"Analyze day-of-week patterns in earnings announcements\"}\nannual_filings['announcement_dow'] = (\n    annual_filings['announcement_date'].dt.dayofweek\n)\nannual_filings['day_name'] = (\n    annual_filings['announcement_date'].dt.day_name()\n)\n\n# Compute surprise: actual earnings minus naive expectation (last year's earnings)\nannual_filings = annual_filings.merge(\n    financials[['ticker', 'fiscal_year', 'net_income', 'total_assets']],\n    on=['ticker', 'fiscal_year'], how='left'\n)\nannual_filings['earnings_scaled'] = (\n    annual_filings['net_income'] / annual_filings['total_assets']\n)\nannual_filings['earnings_surprise'] = (\n    annual_filings\n    .groupby('ticker')['earnings_scaled']\n    .diff()\n)\n\n# Classify as good/bad news\nannual_filings['bad_news'] = (\n    annual_filings['earnings_surprise'] < 0\n).astype(int)\n\n# Day-of-week distribution by news type\ndow_crosstab = pd.crosstab(\n    annual_filings['day_name'],\n    annual_filings['bad_news'].map({0: 'Good News', 1: 'Bad News'}),\n    normalize='columns'\n)\n# Reorder days\nday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\ndow_crosstab = dow_crosstab.reindex(day_order)\n\nprint(\"Proportion of Announcements by Day and News Type:\")\nprint(dow_crosstab.round(3))\n```\n:::\n\n\n::: {#fig-dow-pattern .cell execution_count=14}\n``` {.python .cell-code code-summary=\"Plot day-of-week announcement patterns\"}\nfig, ax = plt.subplots(figsize=(10, 5))\nx = np.arange(len(day_order))\nwidth = 0.35\n\nbad_pct = dow_crosstab['Bad News'].values\ngood_pct = dow_crosstab['Good News'].values\n\nax.bar(x - width/2, good_pct, width, label='Good News',\n       color='#27AE60', alpha=0.8)\nax.bar(x + width/2, bad_pct, width, label='Bad News',\n       color='#C0392B', alpha=0.8)\nax.set_xticks(x)\nax.set_xticklabels(day_order)\nax.set_ylabel('Proportion of Announcements')\nax.set_title('Strategic Timing: Day-of-Week Announcement Patterns')\nax.legend()\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n### Announcement Congestion\n\nWhen many firms announce on the same day, each announcement receives less attention. We measure **announcement congestion** as the number of other firms making earnings announcements on the same date:\n\n$$\n\\text{Congestion}_{i,t} = \\sum_{j \\neq i} \\mathbf{1}\\{\\text{AnnDate}_{j} = \\text{AnnDate}_{i}\\}\n$$ {#eq-congestion}\n\n@hirshleifer2009driven predict that firms burying bad news will choose high-congestion days. We test this by regressing the congestion variable on the sign of earnings news:\n\n::: {#congestion-analysis .cell execution_count=15}\n``` {.python .cell-code code-summary=\"Test whether bad-news firms choose high-congestion announcement days\"}\n# Count announcements per date\nann_counts = (\n    annual_filings\n    .groupby('announcement_date')\n    .size()\n    .reset_index(name='n_announcements')\n)\nannual_filings = annual_filings.merge(\n    ann_counts, on='announcement_date', how='left'\n)\nannual_filings['congestion'] = annual_filings['n_announcements'] - 1\n\n# Regression: congestion ~ bad_news + controls\ncongestion_model = smf.ols(\n    'congestion ~ bad_news + log_size + roa + C(fiscal_year)',\n    data=annual_filings.assign(\n        log_size=np.log(annual_filings['total_assets']),\n        roa=annual_filings['net_income'] / annual_filings['total_assets']\n    )\n).fit(cov_type='cluster', cov_kwds={'groups': annual_filings['ticker']})\n\nprint(\"Congestion Regression:\")\nprint(congestion_model.summary().tables[1])\n```\n:::\n\n\n### After-Hours and Weekend Announcements\n\nVietnamese regulations require disclosure within 24 hours of material events, but firms retain discretion over the exact timing. Announcements made after the trading session closes (after 3:00 PM on HOSE/HNX) or on weekends delay the market's opportunity to react by at least one trading day.\n\n::: {#after-hours .cell execution_count=16}\n``` {.python .cell-code code-summary=\"Identify and analyze after-hours announcement patterns\"}\n# Assume announcement timestamps are available\nannual_filings['ann_hour'] = (\n    annual_filings['announcement_date'].dt.hour\n)\nannual_filings['after_hours'] = (\n    (annual_filings['ann_hour'] >= 15) |\n    (annual_filings['announcement_dow'] >= 5)  # Saturday/Sunday\n).astype(int)\n\n# Cross-tabulate after-hours by news type\nafterhours_crosstab = pd.crosstab(\n    annual_filings['after_hours'].map({0: 'During Hours', 1: 'After Hours'}),\n    annual_filings['bad_news'].map({0: 'Good News', 1: 'Bad News'}),\n    normalize='index'\n)\nprint(\"News Distribution by Announcement Timing:\")\nprint(afterhours_crosstab.round(3))\n\n# Chi-squared test\ncontingency = pd.crosstab(\n    annual_filings['after_hours'], annual_filings['bad_news']\n)\nchi2, p_val, _, _ = stats.chi2_contingency(contingency)\nprint(f\"\\nChi-squared = {chi2:.2f}, p-value = {p_val:.4f}\")\n```\n:::\n\n\n## Market Consequences of Disclosure Quality {#sec-dis-qual-consequences}\n\n### Disclosure Quality and the Cost of Equity\n\nThe central prediction of @diamond1991disclosure and @botosan1997disclosure is that higher-quality disclosure lowers the cost of equity capital by reducing information asymmetry. We test this using the implied cost of capital (ICC) approach, where we estimate the discount rate that equates the current price to the present value of expected future earnings.\n\nWe use the PEG ratio approach as a simple ICC estimate:\n\n$$\nr_{PEG,i,t} = \\sqrt{\\frac{\\hat{E}_{i,t+2} - \\hat{E}_{i,t+1}}{P_{i,t}}}\n$$ {#eq-icc}\n\nwhere $\\hat{E}_{i,t+k}$ is the consensus earnings forecast (or, in the absence of analyst coverage, a model-based forecast) and $P_{i,t}$ is the current stock price.\n\n::: {#cost-of-equity .cell execution_count=17}\n``` {.python .cell-code code-summary=\"Estimate implied cost of equity and test disclosure quality effect\"}\n# Construct earnings forecasts using a simple random walk with drift\nforecasts = financials.sort_values(['ticker', 'fiscal_year']).copy()\nforecasts['eps'] = forecasts['net_income'] / forecasts['market_cap']\nforecasts['eps_growth'] = forecasts.groupby('ticker')['eps'].pct_change()\n\n# Simple forecast: E[t+1] = E[t] * (1 + avg_growth)\nforecasts['avg_growth'] = (\n    forecasts.groupby('ticker')['eps_growth']\n    .transform(lambda x: x.rolling(3, min_periods=2).mean())\n)\nforecasts['eps_f1'] = forecasts['eps'] * (1 + forecasts['avg_growth'])\nforecasts['eps_f2'] = forecasts['eps_f1'] * (1 + forecasts['avg_growth'])\n\n# PEG-based ICC\nforecasts['icc_peg'] = np.sqrt(\n    np.maximum(forecasts['eps_f2'] - forecasts['eps_f1'], 0)\n    / np.maximum(forecasts['market_cap'] / 1e6, 1e-6)\n)\n\n# Merge with disclosure quality\nicc_panel = (\n    forecasts[['ticker', 'fiscal_year', 'icc_peg']]\n    .merge(quality_panel[['ticker', 'fiscal_year', 'dq_index']].reset_index(drop=True),\n           on=['ticker', 'fiscal_year'], how='inner')\n    .merge(governance, on=['ticker', 'fiscal_year'], how='left')\n    .merge(financials[['ticker', 'fiscal_year', 'total_assets',\n                        'book_to_market', 'market_cap']],\n           on=['ticker', 'fiscal_year'], how='left')\n)\n\nicc_panel['log_size'] = np.log(icc_panel['market_cap'])\nicc_panel = icc_panel.set_index(['ticker', 'fiscal_year'])\n\n# Panel regression: ICC ~ DQ + controls\nicc_model = PanelOLS(\n    dependent=icc_panel['icc_peg'],\n    exog=sm.add_constant(icc_panel[[\n        'dq_index', 'log_size', 'book_to_market'\n    ]]),\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type='clustered', cluster_entity=True)\n\nprint(\"Implied Cost of Capital ~ Disclosure Quality:\")\nprint(icc_model.summary)\n```\n:::\n\n\n### Disclosure Quality and Liquidity\n\n@diamond1991disclosure predict that better disclosure reduces adverse selection and improves liquidity. We measure liquidity through bid-ask spreads and the Amihud illiquidity ratio:\n\n$$\n\\text{Amihud}_{i,t} = \\frac{1}{D_{i,t}} \\sum_{d=1}^{D_{i,t}} \\frac{|R_{i,d}|}{\\text{Volume}_{i,d}}\n$$ {#eq-amihud}\n\nwhere $R_{i,d}$ is the daily return and $\\text{Volume}_{i,d}$ is the daily trading volume in VND.\n\n::: {#liquidity-analysis .cell execution_count=18}\n``` {.python .cell-code code-summary=\"Compute Amihud illiquidity and test disclosure quality effect\"}\n# Compute annual Amihud illiquidity\ntrading['abs_return'] = trading['close'].pct_change().abs()\ntrading['amihud_daily'] = trading['abs_return'] / (trading['volume'] * trading['close'])\n\namihud_annual = (\n    trading\n    .assign(fiscal_year=trading['date'].dt.year)\n    .groupby(['ticker', 'fiscal_year'])\n    .agg(\n        amihud=('amihud_daily', 'mean'),\n        avg_spread=('bid_ask_spread', 'mean'),\n        avg_turnover=('turnover', 'mean')\n    )\n    .reset_index()\n)\n\n# Log transform for better distributional properties\namihud_annual['log_amihud'] = np.log(amihud_annual['amihud'] + 1e-10)\namihud_annual['log_spread'] = np.log(amihud_annual['avg_spread'] + 1e-6)\n\n# Merge and run regression\nliq_panel = (\n    amihud_annual\n    .merge(quality_panel[['ticker', 'fiscal_year', 'dq_index']].reset_index(drop=True),\n           on=['ticker', 'fiscal_year'], how='inner')\n    .merge(financials[['ticker', 'fiscal_year', 'market_cap', 'total_assets']],\n           on=['ticker', 'fiscal_year'], how='left')\n)\nliq_panel['log_size'] = np.log(liq_panel['market_cap'])\nliq_panel = liq_panel.set_index(['ticker', 'fiscal_year'])\n\nliq_model = PanelOLS(\n    dependent=liq_panel['log_amihud'],\n    exog=sm.add_constant(liq_panel[['dq_index', 'log_size']]),\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type='clustered', cluster_entity=True)\n\nprint(\"Amihud Illiquidity ~ Disclosure Quality:\")\nprint(liq_model.summary)\n```\n:::\n\n\n::: {#fig-dq-liquidity .cell execution_count=19}\n``` {.python .cell-code code-summary=\"Plot disclosure quality vs liquidity relationship\"}\nliq_panel_plot = liq_panel.reset_index()\nliq_panel_plot['dq_quintile'] = pd.qcut(\n    liq_panel_plot['dq_index'], 5, labels=['Q1\\n(Low)', 'Q2', 'Q3', 'Q4', 'Q5\\n(High)']\n)\n\nquintile_liq = (\n    liq_panel_plot\n    .groupby('dq_quintile')['log_amihud']\n    .agg(['mean', 'sem'])\n)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nbars = ax.bar(\n    range(5), quintile_liq['mean'],\n    yerr=1.96 * quintile_liq['sem'],\n    color=['#C0392B', '#E67E22', '#F1C40F', '#27AE60', '#2C5F8A'],\n    alpha=0.85, capsize=4, edgecolor='white'\n)\nax.set_xticks(range(5))\nax.set_xticklabels(quintile_liq.index)\nax.set_xlabel('Disclosure Quality Quintile')\nax.set_ylabel('Log Amihud Illiquidity')\nax.set_title('Disclosure Quality and Market Liquidity')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n### Event Study: Market Reaction to Filing Lag\n\nWe examine whether the market reacts differently to early vs. late filers by computing cumulative abnormal returns (CARs) around the filing date:\n\n$$\nCAR_{i}[\\tau_1, \\tau_2] = \\sum_{t=\\tau_1}^{\\tau_2} (R_{i,t} - \\hat{R}_{i,t})\n$$ {#eq-car}\n\nwhere $\\hat{R}_{i,t}$ is the expected return from a market model estimated over a pre-event window $[-250, -30]$.\n\n::: {#event-study .cell execution_count=20}\n``` {.python .cell-code code-summary=\"Conduct event study around filing dates by timeliness group\"}\ndef compute_car(ticker, event_date, trading_df,\n                est_window=(-250, -30), event_window=(-5, 10)):\n    \"\"\"Compute CAR around an event date using market model.\"\"\"\n    firm_data = trading_df[trading_df['ticker'] == ticker].copy()\n    firm_data = firm_data.sort_values('date')\n\n    # Find event date index\n    event_idx = firm_data[firm_data['date'] >= event_date].index\n    if len(event_idx) == 0:\n        return None\n    event_idx = event_idx[0]\n    event_pos = firm_data.index.get_loc(event_idx)\n\n    # Check sufficient data\n    if event_pos + est_window[0] < 0:\n        return None\n\n    # Estimation window\n    est_start = event_pos + est_window[0]\n    est_end = event_pos + est_window[1]\n    est_data = firm_data.iloc[est_start:est_end + 1]\n\n    firm_ret = est_data['close'].pct_change()\n    mkt_ret = est_data['market_return']\n\n    valid = firm_ret.notna() & mkt_ret.notna()\n    if valid.sum() < 100:\n        return None\n\n    # Market model\n    X = sm.add_constant(mkt_ret[valid])\n    model = sm.OLS(firm_ret[valid], X).fit()\n\n    # Event window\n    ev_start = event_pos + event_window[0]\n    ev_end = event_pos + event_window[1]\n    ev_data = firm_data.iloc[ev_start:ev_end + 1]\n\n    ev_ret = ev_data['close'].pct_change()\n    ev_mkt = ev_data['market_return']\n    expected_ret = model.params['const'] + model.params['market_return'] * ev_mkt\n    abnormal_ret = ev_ret - expected_ret\n\n    return abnormal_ret.cumsum().values\n\n# Sample: compute CARs for annual filings\ncar_results = []\nfor _, row in annual_filings.sample(min(2000, len(annual_filings))).iterrows():\n    car = compute_car(row['ticker'], row['filing_date'], trading)\n    if car is not None and len(car) == 16:  # -5 to +10\n        car_results.append({\n            'ticker': row['ticker'],\n            'fiscal_year': row['fiscal_year'],\n            'lag_tercile': row['lag_tercile'],\n            'car': car\n        })\n\ncar_df = pd.DataFrame(car_results)\nprint(f\"Computed CARs for {len(car_df)} firm-year events\")\n```\n:::\n\n\n::: {#fig-event-study .cell execution_count=21}\n``` {.python .cell-code code-summary=\"Plot CAR paths by timeliness tercile\"}\nevent_days = range(-5, 11)\n\nfig, ax = plt.subplots(figsize=(10, 6))\ncolors = {'Early': '#27AE60', 'Middle': '#F1C40F', 'Late': '#C0392B'}\n\nfor tercile in ['Early', 'Middle', 'Late']:\n    subset = car_df[car_df['lag_tercile'] == tercile]\n    if len(subset) > 0:\n        avg_car = np.mean(np.stack(subset['car'].values), axis=0)\n        se_car = np.std(np.stack(subset['car'].values), axis=0) / np.sqrt(len(subset))\n        ax.plot(event_days, avg_car, color=colors[tercile],\n                linewidth=2, label=tercile)\n        ax.fill_between(event_days,\n                        avg_car - 1.96 * se_car,\n                        avg_car + 1.96 * se_car,\n                        color=colors[tercile], alpha=0.15)\n\nax.axvline(x=0, color='gray', linestyle='--', linewidth=0.8)\nax.axhline(y=0, color='gray', linewidth=0.5)\nax.set_xlabel('Event Day (Relative to Filing Date)')\nax.set_ylabel('Cumulative Abnormal Return')\nax.set_title('Market Reaction Around Filing Date by Timeliness')\nax.legend(title='Filing Tercile')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Filing Timeliness and Earnings Quality {#sec-dis-qual-timeliness-quality}\n\n@givoly1982timeliness and @chambers1984timeliness establish that the content of disclosed information is correlated with its timing. We test this link formally: do late filers have worse earnings quality?\n\n::: {#fig-timeliness-quality .cell execution_count=22}\n``` {.python .cell-code code-summary=\"Analyze relationship between filing lag and earnings quality\"}\ntq_panel = (\n    annual_filings[['ticker', 'fiscal_year', 'lag_tercile', 'reporting_lag']]\n    .merge(aq_df, on=['ticker', 'fiscal_year'], how='inner')\n    .merge(persistence_df[['ticker', 'persistence']], on='ticker', how='left')\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Panel A: Accruals quality by tercile\naq_by_tercile = tq_panel.groupby('lag_tercile')['accruals_quality'].mean()\naxes[0].bar(\n    range(3), aq_by_tercile.values,\n    color=['#27AE60', '#F1C40F', '#C0392B'], alpha=0.85,\n    edgecolor='white'\n)\naxes[0].set_xticks(range(3))\naxes[0].set_xticklabels(['Early', 'Middle', 'Late'])\naxes[0].set_ylabel('Accruals Quality (σ of DD Residuals)')\naxes[0].set_title('Panel A: Accruals Quality by Filing Tercile')\naxes[0].text(0.05, 0.95, 'Higher = lower quality',\n             transform=axes[0].transAxes, fontsize=9,\n             verticalalignment='top', style='italic', color='gray')\n\n# Panel B: Persistence by tercile\nper_by_tercile = tq_panel.groupby('lag_tercile')['persistence'].mean()\naxes[1].bar(\n    range(3), per_by_tercile.values,\n    color=['#27AE60', '#F1C40F', '#C0392B'], alpha=0.85,\n    edgecolor='white'\n)\naxes[1].set_xticks(range(3))\naxes[1].set_xticklabels(['Early', 'Middle', 'Late'])\naxes[1].set_ylabel('Earnings Persistence (AR(1) Coefficient)')\naxes[1].set_title('Panel B: Earnings Persistence by Filing Tercile')\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nWe formalize this with a regression that controls for firm characteristics:\n\n::: {#timeliness-quality-regression .cell execution_count=23}\n``` {.python .cell-code code-summary=\"Regression: accruals quality on filing lag with controls\"}\ntq_panel_reg = tq_panel.merge(\n    financials[['ticker', 'fiscal_year', 'total_assets', 'net_income',\n                'total_equity']],\n    on=['ticker', 'fiscal_year'], how='left'\n).merge(governance, on=['ticker', 'fiscal_year'], how='left')\n\ntq_panel_reg['log_size'] = np.log(tq_panel_reg['total_assets'])\ntq_panel_reg['roa'] = tq_panel_reg['net_income'] / tq_panel_reg['total_assets']\ntq_panel_reg['late'] = (tq_panel_reg['lag_tercile'] == 'Late').astype(int)\n\nmodel_tq = smf.ols(\n    'accruals_quality ~ late + log_size + roa + state_ownership_pct '\n    '+ big4_auditor + C(fiscal_year)',\n    data=tq_panel_reg\n).fit(cov_type='cluster', cov_kwds={'groups': tq_panel_reg['ticker']})\n\nprint(\"Accruals Quality ~ Late Filing:\")\nprint(model_tq.summary().tables[1])\n```\n:::\n\n\n::: callout-note\n## Endogeneity Caveat\n\nThe association between filing timeliness and earnings quality is likely endogenous: firms with complex accounting issues take longer to prepare financial statements, and the same complexity drives lower earnings quality. The filing lag is thus best interpreted as an *observable signal* of underlying accounting difficulty rather than a causal determinant. Instrumental variable approaches (e.g., using auditor busyness during peak filing season as an instrument for filing lag) can partially address this concern.\n:::\n\n## Disclosure Quality and Investment Efficiency {#sec-dis-qual-investment}\n\n@biddle2009does demonstrate that higher financial reporting quality is associated with more efficient investment. Specifically, it reduces both over-investment (in firms with excess cash) and under-investment (in firms that are financially constrained). The mechanism is that better disclosure reduces information asymmetry between managers and capital providers, improving the allocation of capital.\n\nWe test this prediction in Vietnam using the @biddle2009does framework:\n\n$$\n\\text{Investment}_{i,t+1} = \\alpha + \\beta_1 \\text{SalesGrowth}_{i,t} + \\varepsilon_{i,t+1}\n$$ {#eq-inv-efficiency}\n\nThe residual $\\hat{\\varepsilon}_{i,t+1}$ measures deviation from expected investment. Positive residuals indicate over-investment; negative residuals indicate under-investment. We then test whether the absolute value of this residual is lower for firms with higher disclosure quality.\n\n::: {#investment-efficiency .cell execution_count=24}\n``` {.python .cell-code code-summary=\"Estimate investment efficiency and test disclosure quality link\"}\ninv_panel = financials.sort_values(['ticker', 'fiscal_year']).copy()\n\n# Investment = change in total assets / lagged total assets\ninv_panel['investment'] = (\n    inv_panel.groupby('ticker')['total_assets'].pct_change()\n)\ninv_panel['sales_growth'] = (\n    inv_panel.groupby('ticker')['revenue'].pct_change()\n)\n\n# Expected investment model\ninv_model = smf.ols(\n    'investment ~ sales_growth',\n    data=inv_panel\n).fit()\ninv_panel['inv_residual'] = inv_model.resid\ninv_panel['abs_inv_residual'] = inv_panel['inv_residual'].abs()\n\n# Merge with disclosure quality\ninv_eff = (\n    inv_panel[['ticker', 'fiscal_year', 'abs_inv_residual',\n               'investment', 'total_assets']]\n    .merge(quality_panel[['ticker', 'fiscal_year', 'dq_index']].reset_index(drop=True),\n           on=['ticker', 'fiscal_year'], how='inner')\n)\ninv_eff['log_size'] = np.log(inv_eff['total_assets'])\ninv_eff = inv_eff.set_index(['ticker', 'fiscal_year'])\n\n# Panel regression\ninv_eff_model = PanelOLS(\n    dependent=inv_eff['abs_inv_residual'],\n    exog=sm.add_constant(inv_eff[['dq_index', 'log_size']]),\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type='clustered', cluster_entity=True)\n\nprint(\"Investment Inefficiency ~ Disclosure Quality:\")\nprint(inv_eff_model.summary)\n```\n:::\n\n\nA negative coefficient on `dq_index` indicates that higher disclosure quality is associated with lower investment inefficiency: firms with better disclosure make investment decisions closer to what their growth opportunities warrant.\n\n## Vietnamese Institutional Context {#sec-dis-qual-vietnam-context}\n\n### State Ownership and Disclosure\n\nSOEs account for a substantial share of Vietnamese market capitalization. The relationship between state ownership and disclosure quality is theoretically ambiguous. On one hand, political connections may reduce the pressure to disclose transparently; government shareholders may tolerate opacity that private shareholders would not. On the other hand, post-equitization monitoring by multiple stakeholders (MOF, SCIC, minority shareholders) may create competing disclosure demands.\n\n::: {#soe-disclosure .cell execution_count=25}\n``` {.python .cell-code code-summary=\"Compare disclosure quality between SOEs and private firms\"}\nsoe_panel = (\n    quality_panel[['ticker', 'fiscal_year', 'dq_index',\n                    'reporting_lag']].reset_index(drop=True)\n    .merge(governance[['ticker', 'fiscal_year', 'state_ownership_pct']],\n           on=['ticker', 'fiscal_year'], how='inner')\n)\n\nsoe_panel['soe'] = (soe_panel['state_ownership_pct'] >= 50).astype(int)\nsoe_panel['soe_label'] = soe_panel['soe'].map(\n    {1: 'SOE (≥50%)', 0: 'Private (<50%)'}\n)\n\n# Compare means\ncomparison = (\n    soe_panel\n    .groupby('soe_label')\n    .agg(\n        n=('dq_index', 'count'),\n        mean_dq=('dq_index', 'mean'),\n        median_dq=('dq_index', 'median'),\n        mean_lag=('reporting_lag', 'mean'),\n        median_lag=('reporting_lag', 'median')\n    )\n    .round(3)\n)\nprint(\"SOE vs Private Firm Disclosure Comparison:\")\nprint(comparison)\n\n# Formal t-test\nsoe_dq = soe_panel[soe_panel['soe'] == 1]['dq_index']\npriv_dq = soe_panel[soe_panel['soe'] == 0]['dq_index']\nt_stat, p_val = stats.ttest_ind(soe_dq.dropna(), priv_dq.dropna())\nprint(f\"\\nt-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n```\n:::\n\n\n### IFRS Convergence and Disclosure Quality\n\nVietnam has been pursuing a phased convergence toward IFRS, with the Ministry of Finance issuing a roadmap for voluntary adoption by large listed firms. The transition from VAS to IFRS-aligned standards is expected to expand disclosure requirements—particularly for financial instruments (IFRS 9), revenue recognition (IFRS 15), and leases (IFRS 16). @barth2008international provide evidence that IFRS adoption is associated with improvements in earnings quality and disclosure, though the effect depends on enforcement strength.\n\nWe can exploit the staggered timing of voluntary IFRS adoption across Vietnamese firms as a natural experiment:\n\n::: {#ifrs-adoption .cell execution_count=26}\n``` {.python .cell-code code-summary=\"Difference-in-differences: IFRS adoption and disclosure quality\"}\n# Assume DataCore provides IFRS adoption dates\nifrs_adoption = client.get_ifrs_adoption(\n    exchanges=['HOSE', 'HNX'],\n    fields=['ticker', 'ifrs_adoption_year']\n)\n\n# Merge with quality panel\nifrs_panel = (\n    quality_panel[['ticker', 'fiscal_year', 'dq_index']].reset_index(drop=True)\n    .merge(ifrs_adoption, on='ticker', how='left')\n)\n\n# Treatment indicator\nifrs_panel['post_ifrs'] = (\n    ifrs_panel['fiscal_year'] >= ifrs_panel['ifrs_adoption_year']\n).astype(int).fillna(0)\n\nifrs_panel['treated'] = ifrs_panel['ifrs_adoption_year'].notna().astype(int)\n\n# Simple DiD\nifrs_panel = ifrs_panel.set_index(['ticker', 'fiscal_year'])\ndid_model = PanelOLS(\n    dependent=ifrs_panel['dq_index'],\n    exog=sm.add_constant(ifrs_panel[['post_ifrs']]),\n    entity_effects=True,\n    time_effects=True,\n    check_rank=False\n).fit(cov_type='clustered', cluster_entity=True)\n\nprint(\"DiD: IFRS Adoption and Disclosure Quality:\")\nprint(did_model.summary)\n```\n:::\n\n\n::: callout-note\n## Identification Concern\n\nVoluntary IFRS adoption is endogenous because firms that choose to adopt early may already have higher-quality disclosure. The two-way fixed effects DiD absorbs time-invariant firm characteristics and common time trends, but cannot fully address selection on time-varying unobservables. Researchers should consider matching estimators (e.g., propensity score matching on pre-adoption characteristics) or instrumental variable approaches as robustness checks.\n:::\n\n## Predicting Late Filings {#sec-dis-qual-prediction}\n\nCan we predict which firms will file late? This is valuable for portfolio construction (avoiding potential bad-news firms) and for regulators (targeting enforcement resources). We use a logistic model with financial and governance predictors:\n\n$$\n\\Pr(\\text{Late}_{i,t} = 1) = \\Lambda\\left(\\alpha + \\boldsymbol{\\beta}'\\mathbf{X}_{i,t-1}\\right)\n$$ {#eq-prediction}\n\nwhere $\\Lambda(\\cdot)$ is the logistic function and $\\mathbf{X}_{i,t-1}$ are lagged predictors.\n\n::: {#predict-late-filing .cell execution_count=27}\n``` {.python .cell-code code-summary=\"Logistic model to predict late filings\"}\nfrom sklearn.metrics import roc_auc_score, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\npred_panel = (\n    annual_filings[['ticker', 'fiscal_year', 'late_filing']]\n    .merge(financials, on=['ticker', 'fiscal_year'], how='left')\n    .merge(governance, on=['ticker', 'fiscal_year'], how='left')\n)\n\n# Lagged predictors\npred_panel = pred_panel.sort_values(['ticker', 'fiscal_year'])\nfor col in ['total_assets', 'net_income', 'operating_cash_flow',\n            'total_equity', 'revenue']:\n    pred_panel[f'{col}_lag'] = pred_panel.groupby('ticker')[col].shift(1)\n\npred_panel['log_size_lag'] = np.log(pred_panel['total_assets_lag'])\npred_panel['roa_lag'] = (\n    pred_panel['net_income_lag'] / pred_panel['total_assets_lag']\n)\npred_panel['leverage_lag'] = (\n    (pred_panel['total_assets_lag'] - pred_panel['total_equity_lag'])\n    / pred_panel['total_assets_lag']\n)\npred_panel['cfo_ratio_lag'] = (\n    pred_panel['operating_cash_flow_lag'] / pred_panel['total_assets_lag']\n)\n\n# Previous late filing indicator\npred_panel['prev_late'] = (\n    pred_panel.groupby('ticker')['late_filing'].shift(1)\n)\n\nfeatures = [\n    'log_size_lag', 'roa_lag', 'leverage_lag', 'cfo_ratio_lag',\n    'state_ownership_pct', 'foreign_ownership_pct',\n    'big4_auditor', 'board_independence_pct', 'prev_late'\n]\n\nclean = pred_panel.dropna(subset=features + ['late_filing'])\nX = clean[features]\ny = clean['late_filing']\n\n# Standardize\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Logistic regression with cross-validation\nlr = LogisticRegression(max_iter=1000, penalty='l2', C=1.0)\ncv_scores = cross_val_score(lr, X_scaled, y, cv=5, scoring='roc_auc')\n\nprint(f\"5-Fold Cross-Validated AUC: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n\n# Fit on full sample for coefficient interpretation\nlr.fit(X_scaled, y)\ncoef_df = pd.DataFrame({\n    'Feature': features,\n    'Coefficient': lr.coef_[0],\n    'Odds Ratio': np.exp(lr.coef_[0])\n}).sort_values('Coefficient', ascending=False)\n\nprint(\"\\nLogistic Regression Coefficients:\")\nprint(coef_df.to_string(index=False))\n```\n:::\n\n\n::: {#fig-roc-curve .cell execution_count=28}\n``` {.python .cell-code code-summary=\"Plot ROC curve for the late-filing prediction model\"}\nfrom sklearn.metrics import roc_curve, auc\n\nlr.fit(X_scaled, y)\ny_prob = lr.predict_proba(X_scaled)[:, 1]\nfpr, tpr, _ = roc_curve(y, y_prob)\nroc_auc = auc(fpr, tpr)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nax.plot(fpr, tpr, color='#2C5F8A', linewidth=2,\n        label=f'Logistic Model (AUC = {roc_auc:.3f})')\nax.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=1)\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Late Filing Prediction: ROC Curve')\nax.legend(loc='lower right')\nax.set_aspect('equal')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## Summary {#sec-dis-qual-summary}\n\nThis chapter has examined corporate disclosure quality and timing in Vietnam along several dimensions. The key findings and methodological contributions are in @tbl-dis-qual-summary\n\n| Theme | Key Result | Reference |\n|------------------------|------------------------|------------------------|\n| Good news early | Early filers earn positive CARs around filing dates | @givoly1982timeliness |\n| Textual quality | Forward-looking density and numerical specificity vary substantially | @li2008annual |\n| Composite DQ index | Foreign ownership and Big 4 auditors are strongest determinants | @botosan1997disclosure |\n| Cost of capital | Higher DQ is associated with lower implied cost of equity | @diamond1991disclosure |\n| Liquidity | Higher DQ firms have lower Amihud illiquidity | @lang2012transparency |\n| Investment efficiency | Higher DQ reduces absolute investment residuals | @biddle2009does |\n| Strategic timing | Evidence of bad-news clustering on high-congestion days | @hirshleifer2009driven |\n| IFRS adoption | Preliminary evidence of DQ improvement post-adoption | @barth2008international |\n\n: Summary of findings by theme. {#tbl-dis-qual-summary}\n\nThe Vietnamese disclosure environment is shaped by a combination of regulatory mandates (Circular 155, Securities Law 2019), enforcement capacity (SSC penalties and trading suspensions), and firm-level incentives (ownership structure, auditor choice, governance quality). As Vietnam continues its IFRS convergence and capital market development, the information environment is expected to evolve, creating opportunities for researchers to study the dynamics of disclosure quality in a rapidly changing institutional setting.\n\n<!-- ## Exercises {#sec-dis-qual-exercises}\n\n1.  **Audit opinion and timeliness.** Extend the filing lag analysis by conditioning on audit opinion type (unqualified, qualified, emphasis of matter, adverse). Do firms receiving modified audit opinions file systematically later? What does this imply about the information content of filing delays?\n\n2.  **Seasonal patterns.** Vietnamese fiscal years overwhelmingly end on December 31. Analyze whether the Q4 annual report filing window (January–March) exhibits different quality characteristics than quarterly filings. Does auditor busyness during peak season affect filing timeliness?\n\n3.  **Textual complexity and earnings management.** Combine the textual quality measures from this chapter with the earnings management models from the Earnings Management chapter. Do firms with higher discretionary accruals produce more complex or less readable disclosures?\n\n4.  **Foreign ownership and voluntary disclosure.** Using the governance data, test whether increases in foreign ownership *lead* to improvements in disclosure quality (causal) or whether foreign investors *select* into firms with better existing disclosure (selection). Propose an identification strategy.\n\n5.  **COVID-19 regulatory relief.** During the COVID-19 pandemic, the SSC temporarily extended filing deadlines. Examine whether this regulatory relief affected the information content of filings—did firms that took advantage of extensions have different earnings characteristics than those that filed on the original schedule?\n\n6.  **Machine learning prediction.** Extend the late-filing prediction model from @sec-prediction using gradient boosting or random forests. Compare predictive performance and examine feature importance. Which non-linear interactions improve prediction beyond the logistic baseline?\n\n7.  **Real-time disclosure monitoring.** Design a system using DataCore.vn's API that monitors filing dates in real time, flags firms approaching their regulatory deadlines, and computes the expected probability of late filing using the prediction model. Discuss how such a tool could be used by investors and regulators.\n\n8.  **Cross-listing and disclosure quality.** Some Vietnamese firms are cross-listed or issue depositary receipts on foreign exchanges, subjecting them to additional disclosure requirements. Test whether cross-listed firms exhibit higher disclosure quality than purely domestic-listed peers, controlling for firm characteristics. -->\n\n",
    "supporting": [
      "37_disclosure_quality_and_timing_files"
    ],
    "filters": [],
    "includes": {}
  }
}