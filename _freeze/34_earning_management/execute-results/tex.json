{
  "hash": "67c2954212228610936f167a7a7229d4",
  "result": {
    "engine": "jupyter",
    "markdown": "# Earnings Management: Detection and Measurement\n\n::: {#setup .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\nfrom typing import Optional\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.rcParams.update({\n    \"figure.dpi\": 150,\n    \"axes.spines.top\": False,\n    \"axes.spines.right\": False,\n    \"font.size\": 11,\n})\n```\n:::\n\n\nEarnings management refers to the purposeful intervention by managers in the financial reporting process to achieve outcomes that serve private objectives, whether to meet analyst forecasts, trigger bonus thresholds, avoid covenant violations, or influence equity valuations. While the concept is intuitive, its rigorous detection poses one of the most enduring methodological challenges in empirical accounting research.\n\nThe difficulty is fundamental: researchers observe *total* accruals, which combine a legitimate component (reflecting genuine economic activity) with a discretionary component (reflecting managerial intervention). Separating these two components requires a model of what accruals *should* be absent manipulation, what the literature calls **non-discretionary accruals (NDA)**. Any residual, the gap between observed accruals and the model's prediction, is then attributed to managerial discretion. The quality of the detection method therefore hinges entirely on the quality of this model.\n\nThis chapter examines three foundational approaches to measuring earnings management (i.e., the @healy1985effect model, the @jones1991earnings model, and the modified Jones model of @dechow1995detecting) and evaluates their statistical properties using simulation. We then adapt the analysis to the institutional setting of Vietnam, where distinct governance structures, accounting standards, and enforcement regimes create both unique incentives for earnings management and unique challenges for its detection.\n\n### Defining Earnings Management\n\nA useful taxonomy distinguishes three forms:\n\n1.  **Accrual-based earnings management (AEM).** Managers exploit discretion within accounting standards to shift the timing of revenue or expense recognition. Examples include aggressive revenue recognition, delays in write-downs, or manipulation of allowance estimates. This form does not alter the firm's underlying cash flows.\n\n2.  **Real earnings management (REM).** Managers take genuine economic actions (e.g., overproduction to reduce unit costs, cutting R&D or advertising expenditure, offering price discounts to accelerate sales) that have real cash flow consequences [@roychowdhury2006earnings]. These actions may improve current-period earnings at the expense of future value.\n\n3.  **Classification shifting.** Managers reclassify core expenses as non-recurring items to inflate core earnings without changing bottom-line net income. This form leaves both total accruals and cash flows unchanged.\n\n### Why Vietnam?\n\nVietnam's institutional environment amplifies several channels relevant to earnings management research:\n\n-   **State-owned enterprise (SOE) incentives.** Partially privatized SOEs face dual pressures: political targets from state shareholders and market expectations from minority investors.\n\n-   **Regulatory enforcement.** Vietnam's State Securities Commission (SSC) has limited resources and a short institutional history relative to bodies like the U.S. SEC. Weaker enforcement reduces the expected cost of manipulation, potentially increasing its prevalence [@leuz2003earnings].\n\n-   **Accounting standards.** VAS (Vietnamese Accounting Standards) are based on older IAS versions and have not fully converged with IFRS. Certain VAS provisions, such as rules-based revenue recognition criteria and prescribed depreciation methods, constrain some forms of discretion while creating predictable opportunities for others.\n\n-   **Benchmark-beating behavior.** @burgstahler1997earnings documented discontinuities around zero earnings and zero earnings changes in U.S. data. The Vietnamese market, with its high retail participation and emphasis on headline profitability, may exhibit similar or even more pronounced patterns.\n\n## Models of Non-Discretionary Accruals {#sec-models}\n\n### Notation and Setup\n\nLet $i$ index firms and $t$ index fiscal years. Define:\n\n| Symbol | Definition |\n|-------------------------------|-----------------------------------------|\n| $TA_{i,t}$ | Total accruals (scaled by lagged assets) |\n| $NDA_{i,t}$ | Non-discretionary accruals (model prediction) |\n| $DA_{i,t}$ | Discretionary accruals: $DA_{i,t} = TA_{i,t} - NDA_{i,t}$ |\n| $A_{i,t}$ | Total assets |\n| $\\Delta Rev_{i,t}$ | Change in revenues, scaled by $A_{i,t-1}$ |\n| $\\Delta Rec_{i,t}$ | Change in net receivables, scaled by $A_{i,t-1}$ |\n| $PPE_{i,t}$ | Gross property, plant, and equipment, scaled by $A_{i,t-1}$ |\n| $PART_{i,t}$ | Indicator equal to 1 for the test (event) year |\n\n: Notation for earnings management models {#tbl-em-notation}\n\nTotal accruals are computed using the balance sheet approach:\n\n$$\nTA_{i,t} = \\frac{(\\Delta CA_{i,t} - \\Delta Cash_{i,t}) - (\\Delta CL_{i,t} - \\Delta STD_{i,t}) - Dep_{i,t}}{A_{i,t-1}}\n$$ {#eq-total-accruals}\n\nwhere $\\Delta CA$ is the change in current assets, $\\Delta Cash$ is the change in cash, $\\Delta CL$ is the change in current liabilities, $\\Delta STD$ is the change in short-term debt, and $Dep$ is depreciation expense.\n\n### Five Models\n\nWe implement five models, each estimating $NDA$ during a firm-specific estimation window and computing $DA$ for the test year as the residual.\n\n**Model 1: @healy1985effect.** Non-discretionary accruals equal the mean of total accruals during the estimation period:\n\n$$\nNDA^{Healy}_{i,t} = \\frac{1}{T} \\sum_{s \\in \\text{est}} TA_{i,s}\n$$ {#eq-healy}\n\nThis is the simplest possible benchmark. Its limitation is obvious: it treats *all* time-variation in accruals as discretionary, even variation driven by changes in the firm's economic environment.\n\n\\*\\*Model 2: @*\\*deangelo1986accounting. Non-discretionary accruals equal last period's total accruals:\n\n$$\nNDA^{DeAngelo}_{i,t} = TA_{i,t-1}\n$$ {#eq-deangelo}\n\nThis is equivalent to assuming that the change in total accruals is entirely discretionary. It performs well when accruals follow a random walk, but poorly when they exhibit mean-reversion or trend.\n\n**Model 3: @jones1991earnings**. This model controls for changes in a firm's economic environment by regressing accruals on revenue changes and the level of fixed assets:\n\n$$\nTA_{i,t} = \\alpha_1 \\frac{1}{A_{i,t-1}} + \\alpha_2 \\Delta Rev_{i,t} + \\alpha_3 PPE_{i,t} + \\varepsilon_{i,t}\n$$ {#eq-jones}\n\nThe parameters $\\hat{\\alpha}_1, \\hat{\\alpha}_2, \\hat{\\alpha}_3$ are estimated on the estimation-period data. Non-discretionary accruals for the test year are the fitted values from this regression applied to test-year covariates.\n\nThe economic logic is that revenue growth generates legitimate working capital accruals (higher receivables and inventory), while fixed assets proxy for non-discretionary depreciation charges. The intercept is scaled by lagged assets rather than included as a conventional constant, following @jones1991earnings.\n\n**Model 4: Modified Jones [@dechow1995detecting].** The modification adjusts revenue changes for changes in receivables during the test year, on the premise that credit revenue growth is more susceptible to manipulation than cash revenue growth:\n\n$$\nNDA^{ModJones}_{i,t} = \\hat{\\alpha}_1 \\frac{1}{A_{i,t-1}} + \\hat{\\alpha}_2 (\\Delta Rev_{i,t} - \\Delta Rec_{i,t}) + \\hat{\\alpha}_3 PPE_{i,t}\n$$ {#eq-mod-jones}\n\nThe coefficients are still estimated from the *unadjusted* Jones model (@eq-jones) on estimation-period data, but receivables are subtracted from revenues only when computing fitted values for the test year.\n\n**Model 5: Industry Model.** This model assumes that the common component of accruals within an industry captures non-discretionary variation:\n\n$$\nTA_{i,t} = \\phi_0 + \\phi_1 \\cdot \\widetilde{TA}_{j,t} + \\eta_{i,t}\n$$ {#eq-industry}\n\nwhere $\\widetilde{TA}_{j,t}$ is the median total accrual across all firms in industry $j$ (excluding firm $i$), estimated during the estimation period.\n\n### Implementation\n\n::: {#calc-accruals-fn .cell execution_count=2}\n``` {.python .cell-code code-summary=\"Function to compute total accruals from balance sheet data\"}\ndef calc_accruals(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Compute total accruals using the balance sheet approach.\n    \n    Expected columns: gvkey/ticker, year/fyear, at, act, che, lct, dlc,\n                      dp, sale, rect, ppegt\n    \"\"\"\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    year_col = \"year\" if \"year\" in df.columns else \"fyear\"\n    \n    df = df.sort_values([firm_col, year_col]).copy()\n    \n    # Lagged values and changes\n    g = df.groupby(firm_col)\n    df[\"lag_at\"] = g[\"at\"].shift(1)\n    df[\"d_ca\"] = g[\"act\"].diff()\n    df[\"d_cash\"] = g[\"che\"].diff()\n    df[\"d_cl\"] = g[\"lct\"].diff()\n    df[\"d_std\"] = g[\"dlc\"].diff()\n    df[\"d_rev\"] = g[\"sale\"].diff()\n    df[\"d_rec\"] = g[\"rect\"].diff()\n    \n    # Total accruals (raw)\n    df[\"acc_raw\"] = (df[\"d_ca\"] - df[\"d_cash\"] - df[\"d_cl\"] + df[\"d_std\"]) - df[\"dp\"]\n    \n    return df\n```\n:::\n\n\n::: {#nda-models .cell execution_count=3}\n``` {.python .cell-code code-summary=\"Implementations of five non-discretionary accrual models\"}\ndef fit_healy(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Healy (1985): NDA = mean accruals in estimation period.\"\"\"\n    est_mean = df.loc[~df[\"part\"], \"acc_at\"].mean()\n    df = df.copy()\n    df[\"nda_healy\"] = est_mean\n    df[\"da_healy\"] = df[\"acc_at\"] - df[\"nda_healy\"]\n    return df\n\n\ndef fit_deangelo(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"DeAngelo (1986): NDA = prior-period total accruals.\"\"\"\n    df = df.copy()\n    df[\"nda_deangelo\"] = df[\"acc_at\"].shift(1)\n    df[\"da_deangelo\"] = df[\"acc_at\"] - df[\"nda_deangelo\"]\n    return df\n\n\ndef fit_jones(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Jones (1991): Regression-based NDA controlling for revenue and PPE.\"\"\"\n    df = df.copy()\n    est = df[~df[\"part\"]].dropna(subset=[\"acc_at\", \"one_at\", \"d_rev_at\", \"ppe_at\"])\n    \n    if len(est) < 5:\n        df[\"nda_jones\"] = np.nan\n        df[\"da_jones\"] = np.nan\n        return df\n    \n    y = est[\"acc_at\"]\n    X = est[[\"one_at\", \"d_rev_at\", \"ppe_at\"]]\n    model = sm.OLS(y, X).fit()\n    \n    pred_X = df[[\"one_at\", \"d_rev_at\", \"ppe_at\"]].copy()\n    df[\"nda_jones\"] = model.predict(pred_X)\n    df[\"da_jones\"] = df[\"acc_at\"] - df[\"nda_jones\"]\n    return df\n\n\ndef fit_mod_jones(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Modified Jones (Dechow et al., 1995): Adjust revenues for receivables.\"\"\"\n    df = df.copy()\n    est = df[~df[\"part\"]].dropna(subset=[\"acc_at\", \"one_at\", \"d_rev_at\", \"ppe_at\"])\n    \n    if len(est) < 5:\n        df[\"nda_mod_jones\"] = np.nan\n        df[\"da_mod_jones\"] = np.nan\n        return df\n    \n    # Estimate on unadjusted Jones model\n    y = est[\"acc_at\"]\n    X = est[[\"one_at\", \"d_rev_at\", \"ppe_at\"]]\n    model = sm.OLS(y, X).fit()\n    \n    # Predict using adjusted revenue (subtract receivable changes)\n    pred_X = df[[\"one_at\", \"d_rev_alt_at\", \"ppe_at\"]].copy()\n    pred_X.columns = [\"one_at\", \"d_rev_at\", \"ppe_at\"]\n    df[\"nda_mod_jones\"] = model.predict(pred_X)\n    df[\"da_mod_jones\"] = df[\"acc_at\"] - df[\"nda_mod_jones\"]\n    return df\n\n\ndef fit_industry(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Industry model: NDA = f(industry median accruals).\"\"\"\n    df = df.copy()\n    est = df[~df[\"part\"]].dropna(subset=[\"acc_at\", \"acc_ind\"])\n    \n    if len(est) < 5:\n        df[\"nda_industry\"] = np.nan\n        df[\"da_industry\"] = np.nan\n        return df\n    \n    y = est[\"acc_at\"]\n    X = sm.add_constant(est[\"acc_ind\"])\n    model = sm.OLS(y, X).fit()\n    \n    pred_X = sm.add_constant(df[\"acc_ind\"])\n    df[\"nda_industry\"] = model.predict(pred_X)\n    df[\"da_industry\"] = df[\"acc_at\"] - df[\"nda_industry\"]\n    return df\n```\n:::\n\n\n::: {#get-nda-all .cell execution_count=4}\n``` {.python .cell-code code-summary=\"Master function to apply all five models to a panel\"}\ndef prepare_model_vars(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Add scaled variables needed by the five NDA models.\"\"\"\n    df = calc_accruals(df)\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    \n    df[\"sic2\"] = df[\"sic\"].astype(str).str[:2]\n    df[\"acc_at\"] = df[\"acc_raw\"] / df[\"lag_at\"]\n    df[\"one_at\"] = 1.0 / df[\"lag_at\"]\n    df[\"d_rev_at\"] = df[\"d_rev\"] / df[\"lag_at\"]\n    df[\"d_rev_alt_at\"] = (df[\"d_rev\"] - df[\"d_rec\"]) / df[\"lag_at\"]\n    df[\"ppe_at\"] = df[\"ppegt\"] / df[\"lag_at\"]\n    \n    # Industry median accruals (estimation period only)\n    # est_acc = df.loc[~df[\"part\"], [\"sic2\", \"acc_at\"]].copy()\n    est_acc = df.loc[df[\"part\"] == False, [\"sic2\", \"acc_at\"]].copy()\n    ind_median = est_acc.groupby(\"sic2\")[\"acc_at\"].median().rename(\"acc_ind\")\n    df = df.merge(ind_median, on=\"sic2\", how=\"left\")\n    \n    return df\n\n\ndef get_all_nda(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Apply all five NDA models on a firm-by-firm basis.\n    Returns a DataFrame with DA columns for each model.\n    \"\"\"\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    year_col = \"year\" if \"year\" in df.columns else \"fyear\"\n    \n    df_mod = prepare_model_vars(df)\n    df_mod[\"part\"] = df_mod[\"part\"].astype(bool)\n    \n    results = []\n    for firm, group in df_mod.groupby(firm_col):\n        g = group.sort_values(year_col).copy()\n        g = fit_healy(g)\n        g = fit_deangelo(g)\n        g = fit_jones(g)\n        g = fit_mod_jones(g)\n        g = fit_industry(g)\n        results.append(g)\n    \n    return pd.concat(results, ignore_index=True)\n```\n:::\n\n\n### The Salkever (1976) Correction\n\nAn important but underappreciated methodological issue arises when computing standard errors for discretionary accruals under the Jones-type models. In the standard two-stage procedure, the researcher first estimates the Jones model on the estimation period, then computes discretionary accruals for the test year as a *prediction error*. But the standard error of a prediction error is larger than the standard error of a fitted residual, because it incorporates parameter uncertainty from the first-stage estimation. Ignoring this distinction leads to understated standard errors and inflated rejection rates,exactly the problem documented in @dechow1995detecting.\n\n@salkever1976use provides an elegant solution: run a single regression on the *combined* estimation and test periods, including a dummy variable $PART$ for the test year. The coefficient on $PART$ equals the prediction error (discretionary accruals), and its standard error correctly accounts for first-stage estimation uncertainty.\n\nFor the Jones model, the Salkever single-stage regression is:\n\n$$\nTA_{i,t} = \\alpha_1 \\frac{1}{A_{i,t-1}} + \\alpha_2 \\Delta Rev_{i,t} + \\alpha_3 PPE_{i,t} + \\delta \\cdot PART_{i,t} + u_{i,t}\n$$ {#eq-salkever}\n\nThe coefficient $\\hat{\\delta}$ is numerically identical to the two-stage $DA$ estimate, but its standard error $\\text{se}(\\hat{\\delta})$ is the correct prediction error standard error.\n\n::: {#salkever-demo .cell execution_count=5}\n``` {.python .cell-code code-summary=\"Demonstration of the Salkever (1976) equivalence\"}\ndef demonstrate_salkever(df_firm: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    For a single firm, show that the two-stage Jones DA equals\n    the Salkever one-stage coefficient on PART.\n    \"\"\"\n    df = prepare_model_vars(df_firm)\n    needed = [\"acc_at\", \"one_at\", \"d_rev_at\", \"ppe_at\", \"part\"]\n    df = df.dropna(subset=needed).copy()\n    \n    # ── Two-stage approach ──\n    est = df[~df[\"part\"]]\n    y_est = est[\"acc_at\"]\n    X_est = est[[\"one_at\", \"d_rev_at\", \"ppe_at\"]]\n    fm_stage1 = sm.OLS(y_est, X_est).fit()\n    \n    df[\"nda_two_stage\"] = fm_stage1.predict(df[[\"one_at\", \"d_rev_at\", \"ppe_at\"]])\n    df[\"da_two_stage\"] = df[\"acc_at\"] - df[\"nda_two_stage\"]\n    \n    # Test-year DA from two-stage\n    da_two_stage = df.loc[df[\"part\"], \"da_two_stage\"].values\n    \n    # ── Salkever one-stage ──\n    df[\"part_float\"] = df[\"part\"].astype(float)\n    y_full = df[\"acc_at\"]\n    X_full = df[[\"one_at\", \"d_rev_at\", \"ppe_at\", \"part_float\"]]\n    fm_salkever = sm.OLS(y_full, X_full).fit()\n    \n    da_salkever = fm_salkever.params[\"part_float\"]\n    se_two_stage_wrong = np.nan  # two-stage doesn't give correct SE\n    se_salkever = fm_salkever.bse[\"part_float\"]\n    \n    return pd.DataFrame({\n        \"Method\": [\"Two-stage Jones\", \"Salkever one-stage\"],\n        \"DA estimate\": [da_two_stage[0] if len(da_two_stage) else np.nan,\n                        da_salkever],\n        \"Correct SE\": [\"Not available\", f\"{se_salkever:.6f}\"],\n        \"t-statistic\": [\"Biased\", f\"{fm_salkever.tvalues['part_float']:.4f}\"],\n    })\n```\n:::\n\n\n## Type I Error Under the Null Hypothesis {#sec-type1}\n\n### Experimental Design\n\nTo evaluate whether the five models produce well-calibrated test statistics, we conduct a simulation experiment parallel to Table 2 of @dechow1995detecting. The procedure is:\n\n1.  Generate a panel of $N$ firms, each with $T$ years of financial statement data.\n2.  For each firm, randomly designate one year as the test year ($PART = 1$). By construction, *no earnings management occurs* in this year.\n3.  Estimate discretionary accruals using each of the five models.\n4.  Regress $DA$ on $PART$ for each firm and record whether the null $H_0:\n    \\delta = 0$ is rejected at the 5% and 1% significance levels.\n5.  Compute the rejection rate across all $N$ firms.\n\nIf the model is well-specified, rejection rates should equal the nominal test size (5% or 1%). Systematic over-rejection indicates that the model produces biased test statistics, a critical flaw for research that relies on these measures to draw causal inferences.\n\n### Data Generation\n\nWe generate synthetic panel data that preserves the key cross-sectional and time-series properties of Vietnamese listed firms while allowing us to know with certainty that no manipulation exists.\n\n::: {#gen-panel .cell execution_count=6}\n``` {.python .cell-code code-summary=\"Generate synthetic Vietnamese panel data for Type I error analysis\"}\ndef generate_em_panel(\n    n_firms: int = 500,\n    n_years: int = 15,\n    seed: int = 2024,\n) -> pd.DataFrame:\n    \"\"\"\n    Generate a synthetic panel of Vietnamese-style financial data.\n    No earnings management is present by construction.\n    \n    The data generation process captures:\n    - AR(1) revenue process\n    - Accruals driven by revenue growth and PPE levels\n    - Industry-level common shocks\n    - SOE/non-SOE heterogeneity\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    industries = [10, 20, 25, 41, 46, 47, 52, 62, 64, 68]\n    \n    records = []\n    for i in range(n_firms):\n        # Firm characteristics\n        sic = rng.choice(industries)\n        is_soe = int(rng.random() < 0.30)\n        base_assets = rng.lognormal(mean=12, sigma=1.5)  # VND billions\n        growth_rate = rng.normal(0.08, 0.04)\n        \n        # Jones model parameters (firm-specific true DGP)\n        true_alpha1 = rng.normal(0, 0.02)\n        true_alpha2 = rng.normal(0.06, 0.03)   # revenue-accrual sensitivity\n        true_alpha3 = rng.normal(-0.04, 0.02)  # depreciation effect\n        \n        at_prev = base_assets\n        sale_prev = base_assets * rng.uniform(0.5, 1.5)\n        rect_prev = sale_prev * rng.uniform(0.05, 0.25)\n        \n        for t in range(n_years):\n            year = 2009 + t\n            \n            # Evolve fundamentals\n            at = at_prev * (1 + growth_rate + rng.normal(0, 0.05))\n            sale = sale_prev * (1 + rng.normal(0.06, 0.08))\n            rect = sale * rng.uniform(0.05, 0.25)\n            ppegt = at * rng.uniform(0.3, 0.7)\n            \n            # Generate accruals from true Jones DGP + noise\n            d_rev = sale - sale_prev\n            one_at = 1.0 / at_prev\n            d_rev_at = d_rev / at_prev\n            ppe_at = ppegt / at_prev\n            \n            acc_at = (true_alpha1 * one_at \n                      + true_alpha2 * d_rev_at \n                      + true_alpha3 * ppe_at\n                      + rng.normal(0, 0.03))\n            \n            acc_raw = acc_at * at_prev\n            \n            # Reverse-engineer balance sheet items consistent with accruals\n            dp = ppegt * rng.uniform(0.05, 0.12)\n            d_cl = rng.normal(0, at * 0.02)\n            d_std = rng.normal(0, at * 0.01)\n            d_cash = rng.normal(0, at * 0.02)\n            d_ca = acc_raw + dp + d_cl - d_std + d_cash\n            \n            act = at * rng.uniform(0.3, 0.6)\n            che = act * rng.uniform(0.05, 0.2)\n            lct = at * rng.uniform(0.15, 0.35)\n            dlc = lct * rng.uniform(0.1, 0.4)\n            ni = sale * rng.uniform(0.03, 0.12)\n            ib = ni\n            \n            records.append({\n                \"ticker\": f\"VN{i:04d}\",\n                \"fyear\": year,\n                \"at\": at,\n                \"act\": act,\n                \"che\": che,\n                \"lct\": lct,\n                \"dlc\": dlc,\n                \"dp\": dp,\n                \"sale\": sale,\n                \"rect\": rect,\n                \"ppegt\": ppegt,\n                \"ni\": ni,\n                \"ib\": ib,\n                \"sic\": sic,\n                \"is_soe\": is_soe,\n            })\n            \n            at_prev = at\n            sale_prev = sale\n            rect_prev = rect\n    \n    df = pd.DataFrame(records)\n    return df\n\npanel_raw = generate_em_panel(n_firms=500, n_years=15, seed=2024)\nprint(f\"Panel: {panel_raw.shape[0]:,} firm-years, \"\n      f\"{panel_raw['ticker'].nunique()} firms\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPanel: 7,500 firm-years, 500 firms\n```\n:::\n:::\n\n\n### Sample Construction\n\nWe construct a sample of 500 firms, each with a randomly designated test year, mirroring the design of @dechow1995detecting.\n\n::: {#sample-construction .cell execution_count=7}\n``` {.python .cell-code code-summary=\"Construct analysis sample with random test-year assignment\"}\ndef construct_sample(\n    df: pd.DataFrame,\n    n_sample: int = 500,\n    min_est_years: int = 10,\n    seed: int = 42,\n    selection_filter: Optional[callable] = None,\n) -> pd.DataFrame:\n    \"\"\"\n    For each firm, randomly assign one year as the test year (part=True).\n    Require at least min_est_years of estimation data.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    firm_col = \"ticker\"\n    year_col = \"fyear\"\n    \n    # Compute accruals and filter for data availability\n    df = calc_accruals(df)\n    required = [\"acc_raw\", \"lag_at\", \"d_rev\", \"d_rec\", \"ppegt\"]\n    df = df.dropna(subset=required)\n    df = df[df[\"lag_at\"] > 0]\n    \n    # Require minimum years\n    firm_counts = df.groupby(firm_col)[year_col].count()\n    eligible = firm_counts[firm_counts >= (min_est_years + 1)].index\n    df = df[df[firm_col].isin(eligible)]\n    \n    if selection_filter is not None:\n        df = selection_filter(df)\n    \n    # Sample n_sample firms\n    firms = df[firm_col].unique()\n    if len(firms) > n_sample:\n        firms = rng.choice(firms, n_sample, replace=False)\n    df = df[df[firm_col].isin(firms)].copy()\n    \n    # For each firm, randomly pick one test year (not the first year)\n    parts = []\n    for firm, group in df.groupby(firm_col):\n        years = group[year_col].sort_values().values\n        if len(years) < 2:\n            continue\n        test_year = rng.choice(years[1:])\n        parts.append({firm_col: firm, year_col: test_year, \"part\": True})\n    \n    part_df = pd.DataFrame(parts)\n    df = df.merge(part_df, on=[firm_col, year_col], how=\"left\")\n    df[\"part\"] = df[\"part\"].fillna(False)\n    df[\"part\"] = df[\"part\"].astype(bool)\n\n    return df\n\nsample_1 = construct_sample(panel_raw, n_sample=500, seed=2024)\nprint(f\"Sample 1: {sample_1.shape[0]:,} firm-years, \"\n      f\"{sample_1['ticker'].nunique()} firms, \"\n      f\"{sample_1['part'].sum()} test years\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSample 1: 7,000 firm-years, 500 firms, 500 test years\n```\n:::\n:::\n\n\n### Estimating Discretionary Accruals\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-summary=\"Apply all five models to Sample 1\"}\nda_results = get_all_nda(sample_1)\n\n# Verify: peek at test-year DA across models\nda_cols = [\"da_healy\", \"da_deangelo\", \"da_jones\", \"da_mod_jones\", \"da_industry\"]\ntest_da = da_results[da_results[\"part\"]][da_cols]\nprint(\"Test-year discretionary accruals (first 5 firms):\")\ntest_da.head().round(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest-year discretionary accruals (first 5 firms):\n```\n:::\n\n::: {#estimate-da .cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>da_healy</th>\n      <th>da_deangelo</th>\n      <th>da_jones</th>\n      <th>da_mod_jones</th>\n      <th>da_industry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>-0.0791</td>\n      <td>-0.1320</td>\n      <td>-0.1252</td>\n      <td>-0.1511</td>\n      <td>-0.0791</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>-0.0792</td>\n      <td>0.0813</td>\n      <td>-0.1799</td>\n      <td>-0.1426</td>\n      <td>-0.0792</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.0618</td>\n      <td>0.1403</td>\n      <td>0.1458</td>\n      <td>0.1308</td>\n      <td>0.0618</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.2106</td>\n      <td>0.2069</td>\n      <td>0.0578</td>\n      <td>0.5023</td>\n      <td>0.2106</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>-0.1326</td>\n      <td>0.0865</td>\n      <td>-0.1425</td>\n      <td>-0.1193</td>\n      <td>-0.1326</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Firm-Level Regressions and Rejection Rates\n\nFor each firm and each model, we regress $DA$ on $PART$ and record whether the null hypothesis of zero discretionary accruals in the test year is rejected.\n\n::: {#type1-regressions .cell execution_count=9}\n``` {.python .cell-code code-summary=\"Compute firm-specific t-statistics and rejection rates\"}\ndef firm_regressions(df: pd.DataFrame, models: list[str]) -> pd.DataFrame:\n    \"\"\"\n    For each firm and model, regress DA on PART.\n    Return coefficients, std errors, t-stats, and rejection indicators.\n    \"\"\"\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    records = []\n    \n    for firm, group in df.groupby(firm_col):\n        for model in models:\n            da_col = f\"da_{model}\"\n            g = group.dropna(subset=[da_col]).copy()\n            g[\"part_float\"] = g[\"part\"].astype(float)\n            \n            if len(g) < 5 or g[\"part\"].sum() == 0:\n                continue\n            \n            try:\n                fm = sm.OLS(\n                    g[da_col], sm.add_constant(g[\"part_float\"])\n                ).fit()\n                \n                coef = fm.params[\"part_float\"]\n                se = fm.bse[\"part_float\"]\n                t_stat = fm.tvalues[\"part_float\"]\n                df_resid = fm.df_resid\n                \n                # One-sided p-values\n                p_neg = stats.t.cdf(t_stat, df_resid)\n                p_pos = 1 - p_neg\n                \n                records.append({\n                    firm_col: firm,\n                    \"model\": model,\n                    \"coef\": coef,\n                    \"se\": se,\n                    \"t_stat\": t_stat,\n                    \"neg_p01\": p_neg < 0.01,\n                    \"neg_p05\": p_neg < 0.05,\n                    \"pos_p01\": p_pos < 0.01,\n                    \"pos_p05\": p_pos < 0.05,\n                })\n            except Exception:\n                continue\n    \n    return pd.DataFrame(records)\n\nmodels = [\"healy\", \"deangelo\", \"jones\", \"mod_jones\", \"industry\"]\nreg_results = firm_regressions(da_results, models)\n```\n:::\n\n\n### Results\n\n@tbl-type1-coefs reports the distribution of estimated coefficients on $PART$ across firms. Under the null of no manipulation, we expect the mean coefficient to be approximately zero.\n\n::: {#tbl-type1-coefs .cell tbl-cap='Distribution of firm-level discretionary accrual estimates (coefficient on PART) under the null hypothesis of no earnings management. All five models produce mean estimates near zero, as expected.' execution_count=10}\n``` {.python .cell-code}\ncoef_stats = (\n    reg_results\n    .groupby(\"model\")[\"coef\"]\n    .agg([\"mean\", \"std\", lambda x: x.quantile(0.25),\n          \"median\", lambda x: x.quantile(0.75)])\n)\ncoef_stats.columns = [\"Mean\", \"Std Dev\", \"Q1\", \"Median\", \"Q3\"]\ncoef_stats.index.name = \"Model\"\ncoef_stats.round(4)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Std Dev</th>\n      <th>Q1</th>\n      <th>Median</th>\n      <th>Q3</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>deangelo</th>\n      <td>0.0110</td>\n      <td>0.2584</td>\n      <td>-0.1604</td>\n      <td>0.0140</td>\n      <td>0.1839</td>\n    </tr>\n    <tr>\n      <th>healy</th>\n      <td>0.0047</td>\n      <td>0.1506</td>\n      <td>-0.0993</td>\n      <td>0.0050</td>\n      <td>0.1066</td>\n    </tr>\n    <tr>\n      <th>industry</th>\n      <td>0.0047</td>\n      <td>0.1506</td>\n      <td>-0.0993</td>\n      <td>0.0050</td>\n      <td>0.1066</td>\n    </tr>\n    <tr>\n      <th>jones</th>\n      <td>0.0035</td>\n      <td>0.1739</td>\n      <td>-0.1134</td>\n      <td>0.0069</td>\n      <td>0.1125</td>\n    </tr>\n    <tr>\n      <th>mod_jones</th>\n      <td>0.0068</td>\n      <td>0.1807</td>\n      <td>-0.1127</td>\n      <td>0.0108</td>\n      <td>0.1177</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n@tbl-type1-rejection reports rejection rates. The critical comparison is whether these rates approximate the nominal test size.\n\n::: {#tbl-type1-rejection .cell tbl-cap='Type I error rates for one-sided tests of earnings management under the null hypothesis. Rates exceeding the nominal size (5% or 1%) indicate that the model over-rejects—a significant concern for the Jones and Modified Jones models.' execution_count=11}\n``` {.python .cell-code}\nrejection_rates = (\n    reg_results\n    .groupby(\"model\")[[\"neg_p01\", \"neg_p05\", \"pos_p01\", \"pos_p05\"]]\n    .mean()\n    .round(4)\n)\nrejection_rates.columns = [\n    \"Neg (1%)\", \"Neg (5%)\", \"Pos (1%)\", \"Pos (5%)\"\n]\nrejection_rates.index.name = \"Model\"\nrejection_rates\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neg (1%)</th>\n      <th>Neg (5%)</th>\n      <th>Pos (1%)</th>\n      <th>Pos (5%)</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>deangelo</th>\n      <td>0.0109</td>\n      <td>0.0457</td>\n      <td>0.0043</td>\n      <td>0.0478</td>\n    </tr>\n    <tr>\n      <th>healy</th>\n      <td>0.0100</td>\n      <td>0.0380</td>\n      <td>0.0080</td>\n      <td>0.0500</td>\n    </tr>\n    <tr>\n      <th>industry</th>\n      <td>0.0100</td>\n      <td>0.0380</td>\n      <td>0.0080</td>\n      <td>0.0500</td>\n    </tr>\n    <tr>\n      <th>jones</th>\n      <td>0.0280</td>\n      <td>0.0800</td>\n      <td>0.0380</td>\n      <td>0.1000</td>\n    </tr>\n    <tr>\n      <th>mod_jones</th>\n      <td>0.0320</td>\n      <td>0.0740</td>\n      <td>0.0300</td>\n      <td>0.0900</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Binomial Test for Size Distortion\n\nWe formally test whether observed rejection rates differ from nominal sizes using a two-sided binomial test. Small $p$-values indicate significant mis-calibration of the test statistic.\n\n::: {#tbl-binom-test .cell tbl-cap='Binomial test p-values for whether rejection rates equal nominal test sizes. Small values (e.g., < 0.05) indicate statistically significant size distortion.' execution_count=12}\n``` {.python .cell-code}\ndef binom_test_rate(series: pd.Series, nominal: float) -> float:\n    \"\"\"Two-sided binomial test for rejection rate = nominal.\"\"\"\n    x = series.dropna()\n    k = int(x.sum())\n    n = len(x)\n    if n == 0:\n        return np.nan\n    return stats.binomtest(k, n, nominal, alternative=\"two-sided\").pvalue\n\nbinom_results = {}\nfor model, group in reg_results.groupby(\"model\"):\n    binom_results[model] = {\n        \"Neg (1%)\": binom_test_rate(group[\"neg_p01\"], 0.01),\n        \"Neg (5%)\": binom_test_rate(group[\"neg_p05\"], 0.05),\n        \"Pos (1%)\": binom_test_rate(group[\"pos_p01\"], 0.01),\n        \"Pos (5%)\": binom_test_rate(group[\"pos_p05\"], 0.05),\n    }\n\nbinom_df = pd.DataFrame(binom_results).T.round(4)\nbinom_df.index.name = \"Model\"\nbinom_df\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neg (1%)</th>\n      <th>Neg (5%)</th>\n      <th>Pos (1%)</th>\n      <th>Pos (5%)</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>deangelo</th>\n      <td>0.8117</td>\n      <td>0.7486</td>\n      <td>0.3423</td>\n      <td>0.9150</td>\n    </tr>\n    <tr>\n      <th>healy</th>\n      <td>1.0000</td>\n      <td>0.2581</td>\n      <td>0.8236</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>industry</th>\n      <td>1.0000</td>\n      <td>0.2581</td>\n      <td>0.8236</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>jones</th>\n      <td>0.0006</td>\n      <td>0.0038</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>mod_jones</th>\n      <td>0.0001</td>\n      <td>0.0179</td>\n      <td>0.0002</td>\n      <td>0.0002</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: callout-warning\n## Interpreting Over-Rejection\n\nIf the Jones and Modified Jones models show rejection rates significantly above 5%, this signals that the standard two-stage procedure produces anti-conservative test statistics. The @salkever1976use correction addresses this by computing standard errors that reflect first-stage estimation uncertainty. In practical research on Vietnamese firms, where sample sizes per firm are often short (10–15 years of listed history), this correction is especially important because prediction error variance is a larger fraction of residual variance with fewer estimation-period observations.\n:::\n\n## Extreme Performance Firms {#sec-extreme}\n\nA well-known weakness of accrual-based models is their poor performance when test firms experience extreme economic performance. @dechow1995detecting documented that all five models over-reject the null hypothesis when test firm-years are drawn from the tails of the earnings or cash flow distribution. @kothari2005performance subsequently proposed \"performance matching\" as a partial remedy.\n\nThe intuition for the problem is straightforward: the Jones model assumes a linear, symmetric relationship between revenue changes and accruals. But firms experiencing extreme growth or contraction generate accruals that deviate nonlinearly from the model's predictions, even absent any manipulation. This nonlinearity is misattributed to discretionary accruals.\n\n### Constructing Extreme-Performance Samples\n\n::: {#extreme-sample .cell execution_count=13}\n``` {.python .cell-code code-summary=\"Construct samples from top and bottom earnings deciles\"}\ndef add_earnings_deciles(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Compute firm-year earnings (scaled) and assign to deciles.\"\"\"\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    df = df.copy()\n    g = df.groupby(firm_col)\n    df[\"lag_at_earn\"] = g[\"at\"].shift(1)\n    df[\"earn\"] = df[\"ib\"] / df[\"lag_at_earn\"]\n    df[\"earn_decile\"] = pd.qcut(\n        df[\"earn\"], 10, labels=False, duplicates=\"drop\"\n    ) + 1\n    return df\n\npanel_with_earn = add_earnings_deciles(panel_raw)\n\n# High-earners sample (top decile)\ndef filter_high_earn(df):\n    df = add_earnings_deciles(df)\n    return df[df[\"earn_decile\"] == 10]\n\n# Low-earners sample (bottom decile)\ndef filter_low_earn(df):\n    df = add_earnings_deciles(df)\n    return df[df[\"earn_decile\"] == 1]\n\nsample_high = construct_sample(\n    panel_raw, n_sample=300, seed=100,\n    selection_filter=filter_high_earn\n)\nsample_low = construct_sample(\n    panel_raw, n_sample=300, seed=200,\n    selection_filter=filter_low_earn\n)\n\nprint(f\"High-earnings sample: {sample_high['ticker'].nunique()} firms\")\nprint(f\"Low-earnings sample: {sample_low['ticker'].nunique()} firms\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHigh-earnings sample: 164 firms\nLow-earnings sample: 203 firms\n```\n:::\n:::\n\n\n::: {#tbl-extreme-rejection .cell tbl-cap='Type I error rates (5% one-sided) when test firm-years are drawn from extreme earnings deciles. Over-rejection is expected because accrual models misattribute performance-driven accrual variation to managerial discretion.' execution_count=14}\n``` {.python .cell-code}\nextreme_results = {}\nfor label, sample_df in [(\"High earners\", sample_high), (\"Low earners\", sample_low)]:\n    da = get_all_nda(sample_df)\n    regs = firm_regressions(da, models)\n    rates = regs.groupby(\"model\")[[\"neg_p05\", \"pos_p05\"]].mean().round(4)\n    rates.columns = [f\"{label} Neg(5%)\", f\"{label} Pos(5%)\"]\n    extreme_results[label] = rates\n\nif extreme_results:\n    extreme_df = pd.concat(extreme_results.values(), axis=1)\n    extreme_df.index.name = \"Model\"\n    extreme_df\n```\n:::\n\n\n### Performance Matching\n\n@kothari2005performance propose adjusting discretionary accruals by subtracting the DA of a performance-matched firm (one in the same industry with similar ROA). This removes the systematic component of accruals correlated with performance. The matched discretionary accrual is:\n\n$$\nDA^{PM}_{i,t} = DA_{i,t} - DA_{i^*,t}\n$$ {#eq-performance-match}\n\nwhere $i^*$ is the matched control firm. This approach is particularly relevant in Vietnam, where the cross-section of listed firms includes many high-growth firms alongside stagnant SOEs, which is performance heterogeneity that standard models may mischaracterize.\n\n## Power Analysis {#sec-power}\n\n### Artificially Introducing Earnings Management\n\nA model that never rejects is useless even if its Type I error rate is perfect. We need to evaluate **power**: the probability of detecting manipulation when it truly exists. Following @dechow1995detecting, we introduce known artificial manipulation into test-year financial statements and measure detection rates.\n\nWe consider three forms of manipulation at varying magnitudes:\n\n1.  **Expense manipulation.** Decrease current liabilities by the manipulation amount (e.g., delaying recognition of accrued expenses): $$LCT'_{i,t} = LCT_{i,t} - \\lambda \\cdot A_{i,t-1}$$\n\n2.  **Revenue manipulation.** Increase sales and receivables by the manipulation amount (e.g., premature revenue recognition or channel stuffing): $$Sale'_{i,t} = Sale_{i,t} + \\lambda \\cdot A_{i,t-1}, \\quad Rect'_{i,t} = Rect_{i,t} + \\lambda \\cdot A_{i,t-1}$$\n\n3.  **Margin manipulation.** Increase sales by the gross amount needed to inflate net income by $\\lambda \\cdot A_{i,t-1}$, increasing both receivables and current liabilities proportionally.\n\nThe parameter $\\lambda$ represents manipulation as a fraction of lagged total assets, ranging from 0% to 50%.\n\n::: {#manipulate-fn .cell execution_count=15}\n``` {.python .cell-code code-summary=\"Function to introduce artificial manipulation\"}\ndef manipulate(\n    df: pd.DataFrame,\n    level: float = 0.0,\n    manip_type: str = \"expense\",\n) -> pd.DataFrame:\n    \"\"\"\n    Introduce artificial earnings management of a given type and level\n    into test-year (part=True) observations.\n    \n    Parameters\n    ----------\n    df : DataFrame with 'part' indicator and required financial variables.\n    level : Manipulation as fraction of lagged total assets.\n    manip_type : One of 'expense', 'revenue', 'margin'.\n    \"\"\"\n    firm_col = \"ticker\" if \"ticker\" in df.columns else \"gvkey\"\n    year_col = \"fyear\" if \"fyear\" in df.columns else \"year\"\n    \n    df = df.sort_values([firm_col, year_col]).copy()\n    g = df.groupby(firm_col)\n    lag_at = g[\"at\"].shift(1)\n    manip_amt = lag_at * level\n    \n    if manip_type == \"expense\":\n        # Decrease current liabilities in test year\n        df.loc[df[\"part\"], \"lct\"] -= manip_amt[df[\"part\"]]\n        \n    elif manip_type == \"revenue\":\n        # Increase sales and receivables in test year\n        df.loc[df[\"part\"], \"sale\"] += manip_amt[df[\"part\"]]\n        df.loc[df[\"part\"], \"rect\"] += manip_amt[df[\"part\"]]\n        df.loc[df[\"part\"], \"act\"] += manip_amt[df[\"part\"]]\n        # Reverse in following year\n        next_part = g[\"part\"].shift(1).fillna(False)\n        df.loc[next_part, \"sale\"] -= manip_amt[next_part]\n        \n    elif manip_type == \"margin\":\n        # Compute net income ratio for scaling\n        est_mask = ~df[\"part\"]\n        ni_ratio = g.apply(\n            lambda x: (x.loc[~x[\"part\"], \"ni\"] / x.loc[~x[\"part\"], \"sale\"]).median()\n        )\n        df[\"_ni_ratio\"] = df[firm_col].map(ni_ratio)\n        gross_amt = np.where(\n            df[\"_ni_ratio\"] > 0, manip_amt / df[\"_ni_ratio\"], 0\n        )\n        df.loc[df[\"part\"], \"sale\"] += gross_amt[df[\"part\"]]\n        df.loc[df[\"part\"], \"rect\"] += gross_amt[df[\"part\"]]\n        df.loc[df[\"part\"], \"act\"] += gross_amt[df[\"part\"]]\n        net_effect = gross_amt - manip_amt\n        df.loc[df[\"part\"], \"lct\"] += net_effect[df[\"part\"]]\n        df.drop(columns=[\"_ni_ratio\"], inplace=True)\n    \n    return df\n```\n:::\n\n\n::: {#power-analysis .cell execution_count=16}\n``` {.python .cell-code code-summary=\"Power analysis across manipulation levels and types\"}\nlevels = [0.0, 0.05, 0.10, 0.20, 0.30, 0.50]\nmanip_types = [\"expense\", \"revenue\", \"margin\"]\n\npower_records = []\n\nfor level in levels:\n    for mtype in manip_types:\n        # Copy base sample and introduce manipulation\n        manip_sample = sample_1.copy()\n        if level > 0:\n            manip_sample = manipulate(manip_sample, level=level, manip_type=mtype)\n        \n        # Estimate DA and run tests\n        da = get_all_nda(manip_sample)\n        regs = firm_regressions(da, models)\n        \n        # Power = positive one-sided rejection rate at 5%\n        power = regs.groupby(\"model\")[\"pos_p05\"].mean()\n        for model_name, pwr in power.items():\n            power_records.append({\n                \"level\": level,\n                \"type\": mtype,\n                \"model\": model_name,\n                \"power\": pwr,\n            })\n\npower_df = pd.DataFrame(power_records)\n```\n:::\n\n\n::: {#power-analysis-parallel .cell execution_count=17}\n``` {.python .cell-code code-summary=\"Power analysis across manipulation levels and types\"}\nlevels = [0.0, 0.05, 0.10, 0.20, 0.30, 0.50]\nmanip_types = [\"expense\", \"revenue\", \"margin\"]\n\nfrom joblib import Parallel, delayed\nfrom itertools import product\n\ndef _run_one(level, mtype, base_sample, models):\n    manip_sample = base_sample.copy()\n    if level > 0:\n        manip_sample = manipulate(manip_sample, level=level, manip_type=mtype)\n    da = get_all_nda(manip_sample)\n    regs = firm_regressions(da, models)\n    power = regs.groupby(\"model\")[\"pos_p05\"].mean()\n    return [\n        {\"level\": level, \"type\": mtype, \"model\": m, \"power\": p}\n        for m, p in power.items()\n    ]\n\n# Skip redundant level=0 runs (all manip_types identical when level=0)\ncombos = [(0.0, \"expense\")] + [\n    (l, m) for l in levels if l > 0 for m in manip_types\n]\n\nresults = Parallel(n_jobs=-1, verbose=1)(\n    delayed(_run_one)(lvl, mt, sample_1, models)\n    for lvl, mt in combos\n)\n\n# Expand level=0 result across all manip_types\nflat = []\nfor (lvl, mt), batch in zip(combos, results):\n    if lvl == 0:\n        for mtype in manip_types:\n            flat.extend([{**r, \"type\": mtype} for r in batch])\n    else:\n        flat.extend(batch)\n\npower_df = pd.DataFrame(flat)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  2.1min finished\n```\n:::\n:::\n\n\n### Power Functions\n\n@fig-power plots the estimated power functions. The key questions are: (i) which model has the highest power for a given manipulation level and type, and (ii) at what magnitudes does manipulation become reliably detectable?\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 3, figsize=(14, 5), sharey=True)\n\nmodel_colors = {\n    \"healy\": \"#2196F3\",\n    \"deangelo\": \"#FF9800\",\n    \"jones\": \"#4CAF50\",\n    \"mod_jones\": \"#E91E63\",\n    \"industry\": \"#9C27B0\",\n}\n\nfor idx, mtype in enumerate(manip_types):\n    ax = axes[idx]\n    subset = power_df[power_df[\"type\"] == mtype]\n    for model_name in models:\n        m_data = subset[subset[\"model\"] == model_name].sort_values(\"level\")\n        ax.plot(\n            m_data[\"level\"] * 100, m_data[\"power\"],\n            marker=\"o\", markersize=4,\n            label=model_name.replace(\"_\", \" \").title(),\n            color=model_colors[model_name],\n            linewidth=1.5,\n        )\n    ax.set_title(mtype.title(), fontweight=\"bold\")\n    ax.set_xlabel(\"Manipulation (% of assets)\")\n    ax.set_ylim(-0.02, 1.02)\n    ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n    ax.axhline(0.05, color=\"grey\", linestyle=\"--\", linewidth=0.7, label=\"5% size\")\n\naxes[0].set_ylabel(\"Rejection Rate (Power)\")\naxes[2].legend(fontsize=8, loc=\"center left\", bbox_to_anchor=(1.02, 0.5))\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Power functions for the five earnings management detection models across three manipulation types. Power increases with manipulation magnitude but remains low for economically plausible levels (< 10% of assets), highlighting the fundamental difficulty of detecting earnings management.](34_earning_management_files/figure-pdf/fig-power-output-1.pdf){#fig-power fig-pos='H'}\n:::\n:::\n\n\n### Summary Statistics\n\n@tbl-power-summary reports power at selected manipulation levels for the Jones and Modified Jones models, which are most commonly used in applied research.\n\n::: {#tbl-power-summary .cell tbl-cap='Power of the Jones and Modified Jones models at selected manipulation levels. Even at 10% of assets—a large amount of manipulation—detection rates remain well below 50% for most manipulation types, underscoring the low statistical power of standard tests.' execution_count=19}\n``` {.python .cell-code}\npower_summary = (\n    power_df[power_df[\"model\"].isin([\"jones\", \"mod_jones\"])]\n    .pivot_table(index=[\"model\", \"level\"], columns=\"type\", values=\"power\")\n    .round(3)\n)\npower_summary.index.names = [\"Model\", \"Level (% assets)\"]\npower_summary\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>expense</th>\n      <th>margin</th>\n      <th>revenue</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th>Level (% assets)</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">jones</th>\n      <th>0.00</th>\n      <td>0.100</td>\n      <td>0.100</td>\n      <td>0.100</td>\n    </tr>\n    <tr>\n      <th>0.05</th>\n      <td>0.154</td>\n      <td>0.132</td>\n      <td>0.142</td>\n    </tr>\n    <tr>\n      <th>0.10</th>\n      <td>0.218</td>\n      <td>0.126</td>\n      <td>0.178</td>\n    </tr>\n    <tr>\n      <th>0.20</th>\n      <td>0.432</td>\n      <td>0.122</td>\n      <td>0.300</td>\n    </tr>\n    <tr>\n      <th>0.30</th>\n      <td>0.660</td>\n      <td>0.122</td>\n      <td>0.436</td>\n    </tr>\n    <tr>\n      <th>0.50</th>\n      <td>0.912</td>\n      <td>0.122</td>\n      <td>0.710</td>\n    </tr>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">mod_jones</th>\n      <th>0.00</th>\n      <td>0.090</td>\n      <td>0.090</td>\n      <td>0.090</td>\n    </tr>\n    <tr>\n      <th>0.05</th>\n      <td>0.130</td>\n      <td>0.106</td>\n      <td>0.128</td>\n    </tr>\n    <tr>\n      <th>0.10</th>\n      <td>0.198</td>\n      <td>0.174</td>\n      <td>0.190</td>\n    </tr>\n    <tr>\n      <th>0.20</th>\n      <td>0.404</td>\n      <td>0.368</td>\n      <td>0.422</td>\n    </tr>\n    <tr>\n      <th>0.30</th>\n      <td>0.636</td>\n      <td>0.598</td>\n      <td>0.652</td>\n    </tr>\n    <tr>\n      <th>0.50</th>\n      <td>0.884</td>\n      <td>0.878</td>\n      <td>0.922</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: callout-important\n## Implications for Vietnamese Research\n\nThe power analysis has stark implications for earnings management research in Vietnam. The typical Vietnamese listed firm has been listed for 10–15 years, providing far fewer estimation-period observations than in the U.S. context where @dechow1995detecting had decades of Compustat data. Shorter estimation windows increase parameter uncertainty in the Jones model, further reducing power. Combined with the noisier financial data common in emerging markets, researchers should interpret non-rejection of the null as uninformative rather than as evidence of clean financial reporting.\n:::\n\n## Vietnamese Institutional Context {#sec-vietnam}\n\n### Channels of Earnings Management\n\nSeveral features of the Vietnamese institutional environment create distinctive earnings management incentives and opportunities:\n\n**Tax-driven manipulation.** Vietnamese corporate income tax (CIT) rates have declined from 28% (pre-2009) to 20% (2016 onwards), with preferential rates for firms in Special Economic Zones and high-tech sectors. The close alignment between VAS accounting and tax accounting creates incentives to manage earnings downward to reduce tax obligations—a pattern documented in developing economies with code-law accounting traditions [@ball2003incentives].\n\n**IPO and seasoned equity offering (SEO) incentives.** Vietnam has experienced several waves of SOE equitization (partial privatization). Managers have incentives to inflate earnings before share offerings to maximize proceeds. The SSC requires minimum profitability thresholds for listing eligibility, creating sharp incentives around these regulatory cutoffs, which is a natural setting for the discontinuity analysis of @burgstahler1997earnings.\n\n**Real earnings management in manufacturing.** @roychowdhury2006earnings identifies overproduction, discretionary expenditure cuts, and sales manipulation as the three main channels of real earnings management. Vietnam's large manufacturing sector (textiles, electronics assembly, food processing) provides ample scope for overproduction-based REM, where unit costs are reduced by spreading fixed overhead across larger production runs.\n\n**Related-party transactions.** Transactions with affiliated entities are a well-documented channel for earnings manipulation in Asian markets. Vietnamese conglomerates (*tập đoàn*) often feature complex cross-ownership structures where transfer pricing between subsidiaries can shift profits across reporting entities.\n\n### The Earnings Distribution Test\n\n@burgstahler1997earnings observed a striking discontinuity in the distribution of reported earnings around zero: far more firms report small positive earnings than small losses, relative to what a smooth distribution would predict. This pattern is interpreted as evidence that firms manage earnings to avoid reporting losses.\n\nWe apply this test to Vietnamese-style data to illustrate the methodology.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# Generate earnings for a larger sample with benchmark-beating behavior\nrng_dist = np.random.default_rng(2024)\nn_firms_dist = 2000\nn_years_dist = 10\n\nearnings = []\nfor i in range(n_firms_dist):\n    base_earn = rng_dist.normal(0.06, 0.08)\n    for t in range(n_years_dist):\n        e = base_earn + rng_dist.normal(0, 0.04)\n        # Simulate benchmark-beating: firms near zero bump earnings up\n        if -0.01 < e < 0.005:\n            e += rng_dist.uniform(0.005, 0.015) * (rng_dist.random() < 0.6)\n        earnings.append(e)\n\nearn_array = np.array(earnings)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nbins = np.arange(-0.30, 0.35, 0.01)\nax.hist(earn_array, bins=bins, color=\"steelblue\", edgecolor=\"white\",\n        alpha=0.85, density=True)\nax.axvline(0, color=\"firebrick\", linestyle=\"--\", linewidth=1.5, label=\"Zero threshold\")\nax.set_xlabel(\"Earnings / Total Assets\")\nax.set_ylabel(\"Density\")\nax.set_title(\"Earnings Distribution Around Zero\")\nax.legend()\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Distribution of scaled earnings around zero. A discontinuity—excess density just above zero and a deficit just below—would suggest benchmark-beating behavior. The red dashed line marks the zero threshold.](34_earning_management_files/figure-pdf/fig-earnings-distribution-output-1.pdf){#fig-earnings-distribution fig-pos='H'}\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# Year-over-year changes\nearn_changes = np.diff(earn_array.reshape(n_firms_dist, n_years_dist), axis=1).flatten()\n\nfig, ax = plt.subplots(figsize=(8, 5))\nbins_chg = np.arange(-0.15, 0.15, 0.005)\nax.hist(earn_changes, bins=bins_chg, color=\"darkorange\", edgecolor=\"white\",\n        alpha=0.85, density=True)\nax.axvline(0, color=\"firebrick\", linestyle=\"--\", linewidth=1.5, label=\"Zero change\")\nax.set_xlabel(\"Change in Earnings / Total Assets\")\nax.set_ylabel(\"Density\")\nax.set_title(\"Earnings Change Distribution Around Zero\")\nax.legend()\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Distribution of year-over-year earnings changes around zero. A discontinuity here suggests that firms manage earnings to avoid reporting declines, even when small.](34_earning_management_files/figure-pdf/fig-earnings-change-dist-output-1.pdf){#fig-earnings-change-dist fig-pos='H'}\n:::\n:::\n\n\n### Accrual-Based vs. Real Earnings Management\n\n@cohen2008real document a shift from AEM to REM following the passage of the Sarbanes-Oxley Act (SOX) in 2002, suggesting that tighter regulatory scrutiny redirects manipulation toward less detectable channels. @zang2012evidence provides further evidence that firms trade off between AEM and REM based on their relative costs.\n\nIn Vietnam, where regulatory enforcement of accounting standards is weaker than in post-SOX America, we might expect AEM to remain the dominant channel. However, as Vietnam moves toward IFRS adoption and strengthens SSC oversight, the AEM-to-REM substitution hypothesis becomes testable.\n\nWe can measure REM using the @roychowdhury2006earnings approach. Three proxies capture different manipulation channels:\n\n**Abnormal cash flow from operations.** Estimate normal CFO as a function of sales and sales changes:\n\n$$\n\\frac{CFO_{i,t}}{A_{i,t-1}} = \\beta_0 + \\beta_1 \\frac{1}{A_{i,t-1}} + \\beta_2 \\frac{S_{i,t}}{A_{i,t-1}} + \\beta_3 \\frac{\\Delta S_{i,t}}{A_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-abnormal-cfo}\n\n**Abnormal production costs.** Production costs = COGS + change in inventory. Normal levels are modeled as:\n\n$$\n\\frac{PROD_{i,t}}{A_{i,t-1}} = \\beta_0 + \\beta_1 \\frac{1}{A_{i,t-1}} + \\beta_2 \\frac{S_{i,t}}{A_{i,t-1}} + \\beta_3 \\frac{\\Delta S_{i,t}}{A_{i,t-1}} + \\beta_4 \\frac{\\Delta S_{i,t-1}}{A_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-abnormal-prod}\n\n**Abnormal discretionary expenditures.** R&D + advertising + SGA, modeled as:\n\n$$\n\\frac{DISC_{i,t}}{A_{i,t-1}} = \\beta_0 + \\beta_1 \\frac{1}{A_{i,t-1}} + \\beta_2 \\frac{S_{i,t-1}}{A_{i,t-1}} + \\varepsilon_{i,t}\n$$ {#eq-abnormal-disc}\n\nResiduals from these regressions serve as proxies for real manipulation. A firm that overproduces will show abnormally *high* production costs and abnormally *low* CFO (cash tied up in inventory).\n\n## Summary\n\nThis chapter examined the measurement and detection of earnings management, with a focus on methodological rigor and adaptation to Vietnam's institutional environment. The key takeaways are:\n\n-   Detecting earnings management requires separating discretionary from non-discretionary accruals, which depends critically on the quality of the non-discretionary accrual model. All five canonical models have known weaknesses.\n\n-   Under the null hypothesis of no manipulation, the Jones and Modified Jones models over-reject when standard two-stage standard errors are used. The @salkever1976use correction provides properly calibrated inference.\n\n-   When test firms experience extreme financial performance, all models exhibit severe size distortion, misattributing performance-driven accrual variation to managerial discretion. Performance matching [@kothari2005performance] partially addresses this.\n\n-   Power analysis reveals that economically plausible levels of manipulation (below 10% of assets) are detected with very low probability. This casts doubt on studies that report null results as evidence of no manipulation.\n\n-   Vietnam's institutional features, such aSOE governance, VAS accounting rules, weak enforcement, and thin audit coverage—create a rich setting for earnings management research, but the methodological challenges are amplified by shorter time series and noisier data.\n\nResearchers working with Vietnamese data should: (i) use the Salkever correction for proper inference, (ii) implement performance matching, (iii) consider multiple models and triangulate results, and (iv) supplement accrual-based approaches with real earnings management and distributional tests.\n\n<!-- ## Exercises\n\n1.  **Salkever equivalence.** Using the `demonstrate_salkever()` function, verify numerically that the two-stage Jones $DA$ estimate equals the Salkever coefficient on $PART$ for a randomly selected firm. Report both estimates to six decimal places.\n\n2.  **Modified Jones with Salkever.** Extend the Salkever approach to the Modified Jones model. In the one-stage regression, how should $\\Delta Rev$ be specified—adjusted or unadjusted? Justify your choice.\n\n3.  **Performance matching.** Implement the @kothari2005performance performance-matching procedure: for each test firm-year, find a control firm in the same 2-digit industry with the closest ROA, and subtract its $DA$. Re-run the Type I error analysis with performance-matched $DA$. Does performance matching reduce over-rejection for extreme-performance samples?\n\n4.  **SOE vs. non-SOE detection.** Split the sample by SOE status and estimate discretionary accruals separately for each subsample. Are there systematic differences in estimated $DA$ that might reflect genuine differences in accrual quality, or could they be artifacts of the model specification?\n\n5.  **Earnings discontinuity test.** Using the synthetic earnings data (or actual Vietnamese data if available), formally test for a discontinuity at zero using the approach of @burgstahler1997earnings. Compute the standardized difference between the bin just above and just below zero: $$\n    z = \\frac{n_{+} - n_{-}}{\\sqrt{N \\cdot p \\cdot (1-p)}}\n    $$ where $n_{+}$ and $n_{-}$ are the counts in the two adjacent bins and $p$ is the expected proportion under smoothness.\n\n6.  **Real earnings management.** Implement the @roychowdhury2006earnings model for abnormal production costs (@eq-abnormal-prod) using the synthetic panel. Estimate the model cross-sectionally by year and 2-digit industry. What fraction of the cross-sectional variation in production costs is explained by the model?\n\n7.  **Power under Vietnamese conditions.** Re-run the power analysis with a shortened estimation window (7 years instead of 10) to simulate the typical data availability for Vietnamese firms listed after 2007. How does the reduction in estimation data affect detection power? What is the minimum manipulation level that can be detected with 50% power?\n\n8.  **Stub-period revenue manipulation.** @stubben2010discretionary proposes a revenue-based measure of earnings management that regresses changes in receivables on changes in revenue, arguing that revenue manipulation is easier to detect through its receivable footprint than through the broad accrual models. Implement this approach and compare its Type I error and power properties to the Jones model on Vietnamese data. -->\n\n",
    "supporting": [
      "34_earning_management_files/figure-pdf"
    ],
    "filters": []
  }
}